(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([[6],{"0087":function(n,r,e){"use strict";e.r(r),r["default"]='这篇文章主要是对 Redis 官方网站刊登的 [Distributed locks with Redis](https://redis.io/topics/distlock) 部分内容的总结和翻译。\n\n## 什么是 RedLock\n\nRedis 官方站这篇文章提出了一种权威的基于 Redis 实现分布式锁的方式名叫 *Redlock*，此种方式比原先的单节点的方法更安全。它可以保证以下特性：\n\n1. 安全特性：互斥访问，即永远只有一个 client 能拿到锁\n2. 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区\n3. 容错性：只要大部分 Redis 节点存活就可以正常提供服务\n\n## 怎么在单节点上实现分布式锁\n\n> SET resource_name my_random_value NX PX 30000\n\n主要依靠上述命令，该命令仅当 Key 不存在时（NX保证）set 值，并且设置过期时间 3000ms （PX保证），值 my_random_value 必须是所有 client 和所有锁请求发生期间唯一的，释放锁的逻辑是：\n\n```lua\nif redis.call("get",KEYS[1]) == ARGV[1] then\n    return redis.call("del",KEYS[1])\nelse\n    return 0\nend\n```\n\n上述实现可以避免释放另一个client创建的锁，如果只有 del 命令的话，那么如果 client1 拿到 lock1 之后因为某些操作阻塞了很长时间，此时 Redis 端 lock1 已经过期了并且已经被重新分配给了 client2，那么 client1 此时再去释放这把锁就会造成 client2 原本获取到的锁被 client1 无故释放了，但现在为每个 client 分配一个 unique 的 string 值可以避免这个问题。至于如何去生成这个 unique string，方法很多随意选择一种就行了。\n\n## Redlock 算法\n\n算法很易懂，起 5 个 master 节点，分布在不同的机房尽量保证可用性。为了获得锁，client 会进行如下操作：\n\n1. 得到当前的时间，微秒单位\n2. 尝试顺序地在 5 个实例上申请锁，当然需要使用相同的 key 和 random value，这里一个 client 需要合理设置与 master 节点沟通的 timeout 大小，避免长时间和一个 fail 了的节点浪费时间\n3. 当 client 在大于等于 3 个 master 上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。\n4. 如果锁申请到了，那么锁真正的 lock validity time 应该是 origin（lock validity time） - 申请锁期间流逝的时间\n5. 如果 client 申请锁失败了，那么它就会在少部分申请成功锁的 master 节点上执行释放锁的操作，重置状态\n\n## 失败重试\n\n如果一个 client 申请锁失败了，那么它需要稍等一会在重试避免多个 client 同时申请锁的情况，最好的情况是一个 client 需要几乎同时向 5 个 master 发起锁申请。另外就是如果 client 申请锁失败了它需要尽快在它曾经申请到锁的 master 上执行 unlock 操作，便于其他 client 获得这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得 client 无法联系上这些 master，那么这种浪费就是不得不付出的代价了。\n\n## 放锁\n\n放锁操作很简单，就是依次释放所有节点上的锁就行了\n\n## 性能、崩溃恢复和 fsync\n\n如果我们的节点没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这是注意 **整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！** 违反了互斥性。如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，我们规定在 max TTL 期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。\n'},"093b":function(n,r,e){"use strict";e.r(r),r["default"]="## 何为索引？有什么作用？\n\n**索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash。**\n\n索引的作用就相当于目录的作用。打个比方: 我们在查字典的时候，如果没有目录，那我们就只能一页一页的去找我们需要查的那个字，速度很慢。如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了。\n\n## 索引的优缺点\n\n**优点** ：\n\n- 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。\n- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。\n\n**缺点** ：\n\n- 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。\n- 索引需要使用物理文件存储，也会耗费一定空间。\n\n但是，**使用索引一定能提高查询性能吗?**\n\n大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。\n\n## 索引的底层数据结构\n\n### Hash表 & B+树\n\n哈希表是键值对的集合，通过键(key)即可快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O（1））。\n\n**为何能够通过 key 快速取出 value呢？** 原因在于 **哈希算法**（也叫散列算法）。通过哈希算法，我们可以快速找到 value 对应的 index，找到了 index 也就找到了对应的 value。\n\n```java\nhash = hashfunc(key)\nindex = hash % array_size\n```\n\n\n\n![](MySQL数据库索引.assets/20210513092328171.png)\n\n但是！哈希算法有个 **Hash 冲突** 问题，也就是说多个不同的  key 最后得到的 index 相同。通常情况下，我们常用的解决办法是 **链地址法**。链地址法就是将哈希冲突数据存放在链表中。就比如 JDK1.8 之前 `HashMap` 就是通过链地址法来解决哈希冲突的。不过，JDK1.8 以后`HashMap`为了减少链表过长的时候搜索时间过长引入了红黑树。\n\n![](MySQL数据库索引.assets/20210513092224836.png)\n\n为了减少 Hash 冲突的发生，一个好的哈希函数应该“均匀地”将数据分布在整个可能的哈希值集合中。\n\n既然哈希表这么快，**为什么MySQL 没有使用其作为索引的数据结构呢？**\n\n**1.Hash 冲突问题** ：我们上面也提到过Hash 冲突了，不过对于数据库来说这还不算最大的缺点。\n\n**2.Hash 索引不支持顺序和范围查询(Hash 索引不支持顺序和范围查询是它最大的缺点：** 假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引可就不行了。\n\n试想一种情况:\n\n```java\nSELECT * FROM tb1 WHERE id < 500;Copy to clipboardErrorCopied\n```\n\n在这种范围查询中，优势非常大，直接遍历比 500 小的叶子节点就够了。而 Hash 索引是根据 hash 算法来定位的，难不成还要把 1 - 499 的数据，每个都进行一次 hash 计算来定位吗?这就是 Hash 最大的缺点了。\n\n### B 树& B+树\n\nB 树也称 B-树,全称为 **多路平衡查找树** ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 `Balanced` （平衡）的意思。\n\n目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。\n\n**B 树& B+树两者有何异同呢？**\n\n- B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。\n- B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。\n- B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。\n\n![](MySQL数据库索引.assets/20210420165409106.png)\n\n在 MySQL 中，MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是，两者的实现方式不太一样。（下面的内容整理自《Java 工程师修炼之道》）\n\nMyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。\n\nInnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。\n\n## 索引类型\n\n### 主键索引(Primary Key)\n\n数据表的主键列使用的就是主键索引。\n\n一张数据表有只能有一个主键，并且主键不能为 null，不能重复。\n\n在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。\n\n### 二级索引(辅助索引)\n\n**二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。**\n\n唯一索引，普通索引，前缀索引等索引属于二级索引。\n\n**PS:不懂的同学可以暂存疑，慢慢往下看，后面会有答案的，也可以自行搜索。**\n\n1. **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。\n2. **普通索引(Index)** ：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**\n3. **前缀索引(Prefix)** ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小，\n   因为只取前几个字符。\n4. **全文索引(Full Text)** ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。\n\n二级索引:\n![](MySQL数据库索引.assets/20210420165254215.png)\n\n## 聚集索引与非聚集索引\n\n### 聚集索引\n\n**聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。**\n\n在 Mysql 中，InnoDB 引擎的表的 `.ibd`文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。\n\n#### 聚集索引的优点\n\n聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。\n\n#### 聚集索引的缺点\n\n1. **依赖于有序的数据** ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。\n2. **更新代价大** ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，\n   而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，\n   所以对于主键索引来说，主键一般都是不可被修改的。\n\n### 非聚集索引\n\n**非聚集索引即索引结构和数据分开存放的索引。**\n\n**二级索引属于非聚集索引。**\n\n> MYISAM 引擎的表的.MYI 文件包含了表的索引，\n> 该表的索引(B+树)的每个叶子非叶子节点存储索引，\n> 叶子节点存储索引和索引对应数据的指针，指向.MYD 文件的数据。\n>\n> **非聚集索引的叶子节点并不一定存放数据的指针，\n> 因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。**\n\n#### 非聚集索引的优点\n\n**更新代价比聚集索引要小** 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的\n\n#### 非聚集索引的缺点\n\n1. 跟聚集索引一样，非聚集索引也依赖于有序的数据\n2. **可能会二次查询(回表)** :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。\n\n这是 MySQL 的表的文件截图:\n\n![](MySQL数据库索引.assets/20210420165311654.png)\n\n聚集索引和非聚集索引:\n\n![](MySQL数据库索引.assets/20210420165326946.png)\n\n### 非聚集索引一定回表查询吗(覆盖索引)?\n\n**非聚集索引不一定回表查询。**\n\n> 试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。\n\n```text\n SELECT name FROM table WHERE name='guang19';\n```\n\n> 那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。\n\n**即使是 MYISAM 也是这样，虽然 MYISAM 的主键索引确实需要回表，\n因为它的主键索引的叶子节点存放的是指针。但是如果 SQL 查的就是主键呢?**\n\n```text\nSELECT id FROM table WHERE id=1;\n```\n\n主键索引本身的 key 就是主键，查到返回就行了。这种情况就称之为覆盖索引了。\n\n## 覆盖索引\n\n如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！\n\n**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，\n而无需回表查询。**\n\n> 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。\n>\n> 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引，\n> 那么直接根据这个索引就可以查到数据，也无需回表。\n\n覆盖索引:\n![](MySQL数据库索引.assets/20210420165341868.png)\n\n## 创建索引的注意事项\n\n**1.选择合适的字段创建索引：**\n\n- **不为 NULL 的字段** ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。\n- **被频繁查询的字段** ：我们创建索引的字段应该是查询操作非常频繁的字段。\n- **被作为条件查询的字段** ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。\n- **频繁需要排序的字段** ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。\n- **被经常频繁用于连接的字段** ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。\n\n**2.被频繁更新的字段应该慎重建立索引。**\n\n虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。\n如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。\n\n**3.尽可能的考虑建立联合索引而不是单列索引。**\n\n因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。\n\n**4.注意避免冗余索引** 。\n\n冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。\n\n**5.考虑在字符串类型的字段上使用前缀索引代替普通索引。**\n\n前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引。\n\n## 使用索引的一些建议\n\n- 对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引\n- 避免 where 子句中对字段施加函数，这会造成无法命中索引。\n- 在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。\n- 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 schema_unused_indexes 视图来查询哪些索引从未被使用\n- 在使用 limit offset 查询缓慢时，可以借助索引来提高性能\n\n## MySQL 如何为表字段添加索引？\n\n1.添加 PRIMARY KEY（主键索引）\n\n```sql\nALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )\n```\n\n2.添加 UNIQUE(唯一索引)\n\n```sqlite\nALTER TABLE `table_name` ADD UNIQUE ( `column` )\n```\n\n3.添加 INDEX(普通索引)\n\n```sql\nALTER TABLE `table_name` ADD INDEX index_name ( `column` )\n```\n\n4.添加 FULLTEXT(全文索引)\n\n```sql\nALTER TABLE `table_name` ADD FULLTEXT ( `column`)\n```\n\n5.添加多列索引\n\n```sql\nALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )\n```\n\n\n\n# MySQL常见问题（索引相关）\n\n**1. 什么是索引?**\n\n索引是一种数据结构,可以帮助我们快速的进行数据的查找.\n\n**2. 索引是个什么样的数据结构呢?**\n\n索引的数据结构和具体存储引擎的实现有关, 在MySQL中使用较多的索引有Hash索引,B+树索引等,而我们经常使用的InnoDB存储引擎的默认索引实现为:B+树索引.\n\n**3. Hash索引和B+树所有有什么区别或者说优劣呢?**\n\n首先要知道Hash索引和B+树索引的底层实现原理:\n\nhash索引底层就是hash表,进行查找时,调用一次hash函数就可以获取到相应的键值,之后进行回表查询获得实际数据.B+树底层实现是多路平衡查找树.对于每一次的查询都是从根节点出发,查找到叶子节点方可以获得所查键值,然后根据查询判断是否需要回表查询数据.\n\n那么可以看出他们有以下的不同:\n\n- hash索引进行等值查询更快(一般情况下),但是却无法进行范围查询.\n\n因为在hash索引中经过hash函数建立索引之后,索引的顺序与原顺序无法保持一致,不能支持范围查询.而B+树的的所有节点皆遵循(左节点小于父节点,右节点大于父节点,多叉树也类似),天然支持范围.\n\n- hash索引不支持使用索引进行排序,原理同上.\n- hash索引不支持模糊查询以及多列索引的最左前缀匹配.原理也是因为hash函数的不可预测.**AAAA**和**AAAAB**的索引没有相关性.\n- hash索引任何时候都避免不了回表查询数据,而B+树在符合某些条件(聚簇索引,覆盖索引等)的时候可以只通过索引完成查询.\n- hash索引虽然在等值查询上较快,但是不稳定.性能不可预测,当某个键值存在大量重复的时候,发生hash碰撞,此时效率可能极差.而B+树的查询效率比较稳定,对于所有的查询都是从根节点到叶子节点,且树的高度较低.\n\n因此,在大多数情况下,直接选择B+树索引可以获得稳定且较好的查询速度.而不需要使用hash索引.\n\n**4. 上面提到了B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据,什么是聚簇索引?**\n\n在B+树的索引中,叶子节点可能存储了当前的key值,也可能存储了当前的key值以及整行的数据,这就是聚簇索引和非聚簇索引. 在InnoDB中,只有主键索引是聚簇索引,如果没有主键,则挑选一个唯一键建立聚簇索引.如果没有唯一键,则隐式的生成一个键来建立聚簇索引.\n\n当查询使用聚簇索引时,在对应的叶子节点,可以获取到整行数据,因此不用再次进行回表查询.\n\n**5. 非聚簇索引一定会回表查询吗?**\n\n不一定,这涉及到查询语句所要求的字段是否全部命中了索引,如果全部命中了索引,那么就不必再进行回表查询.\n\n举个简单的例子,假设我们在员工表的年龄上建立了索引,那么当进行`select age from employee where age < 20`的查询时,在索引的叶子节点上,已经包含了age信息,不会再次进行回表查询.\n\n**6. 在建立索引的时候,都有哪些需要考虑的因素呢?**\n\n建立索引的时候一般要考虑到字段的使用频率,经常作为条件进行查询的字段比较适合.如果需要建立联合索引的话,还需要考虑联合索引中的顺序.此外也要考虑其他方面,比如防止过多的所有对表造成太大的压力.这些都和实际的表结构以及查询方式有关.\n\n**7. 联合索引是什么?为什么需要注意联合索引中的顺序?**\n\nMySQL可以使用多个字段同时建立一个索引,叫做联合索引.在联合索引中,如果想要命中索引,需要按照建立索引时的字段顺序挨个使用,否则无法命中索引.\n\n具体原因为:\n\nMySQL使用索引时需要索引有序,假设现在建立了\"name,age,school\"的联合索引,那么索引的排序为: 先按照name排序,如果name相同,则按照age排序,如果age的值也相等,则按照school进行排序.\n\n当进行查询时,此时索引仅仅按照name严格有序,因此必须首先使用name字段进行等值查询,之后对于匹配到的列而言,其按照age字段严格有序,此时可以使用age字段用做索引查找,,,以此类推.因此在建立联合索引的时候应该注意索引列的顺序,一般情况下,将查询需求频繁或者字段选择性高的列放在前面.此外可以根据特例的查询或者表结构进行单独的调整.\n\n**8. 创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因?**\n\nMySQL提供了explain命令来查看语句的执行计划,MySQL在执行某个语句之前,会将该语句过一遍查询优化器,之后会拿到对语句的分析,也就是执行计划,其中包含了许多信息.\n可以通过其中和索引有关的信息来分析是否命中了索引,例如possilbe_key,key,key_len等字段,分别说明了此语句可能会使用的索引,实际使用的索引以及使用的索引长度.\n\n**9. 那么在哪些情况下会发生针对该列创建了索引但是在查询的时候并没有使用呢?**\n\n- 使用不等于查询,\n- 列参与了数学运算或者函数\n- 在字符串like时左边是通配符.类似于'%aaa'.\n- 当mysql分析全表扫描比使用索引快的时候不使用索引.\n- 当使用联合索引,前面一个条件为范围查询,后面的即使符合最左前缀原则,也无法使用索引.\n- \n\n\n\n# MySQL索引设计规范\n\n### 1. 限制每张表上的索引数量,建议单张表索引不超过 5 个\n\n索引并不是越多越好！索引可以提高效率同样可以降低效率。\n\n索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。\n\n因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。\n\n### 2. 禁止给表中的每一列都建立单独的索引\n\n5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。\n\n### 3. 每个 Innodb 表必须有个主键\n\nInnodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。\n\nInnodb 是按照主键索引的顺序来组织表的\n\n•不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）•不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）•主键建议使用自增 ID 值\n\n------\n\n### 4. 常见索引列建议\n\n•出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列•包含在 ORDER BY、GROUP BY、DISTINCT 中的字段•并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好•多表 join 的关联列\n\n------\n\n### 5.如何选择索引列的顺序\n\n建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。\n\n•区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）•尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）•使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）\n\n------\n\n### 6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）\n\n•重复索引示例：primary key(id)、index(id)、unique index(id)•冗余索引示例：index(a,b,c)、index(a,b)、index(a)\n\n------\n\n### 7. 对于频繁的查询优先考虑使用覆盖索引\n\n> 覆盖索引：就是包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引\n\n**覆盖索引的好处：**\n\n•**避免 Innodb 表进行索引的二次查询:** Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。•**可以把随机 IO 变成顺序 IO 加快查询效率:** 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。\n\n------\n\n### 8.索引 SET 规范\n\n**尽量避免使用外键约束**\n\n•不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引•外键可用于保证数据的参照完整性，但建议在业务端实现•外键会影响父表和子表的写操作从而降低性能\n\n\n\n# 小心陷入MySQL索引的坑\n\n索引可以说是数据库中的一个大心脏了，如果说一个数据库少了索引，那么数据库本身存在的意义就不大了，和普通的文件没什么两样。所以说一个好的索引对数据库系统尤其重要，今天来说说MySQL索引，从细节和实际业务的角度看看在MySQL中B+树索引好处，以及我们在使用索引时需要注意的知识点。\n\n## ***\\*合理利用索引\\****\n\n在工作中，我们可能判断数据表中的一个字段是不是需要加索引的最直接办法就是：这个字段会不会经常出现在我们的where条件中。从宏观的角度来说，这样思考没有问题，但是从长远的角度来看，有时可能需要更细致的思考，比如我们是不是不仅仅需要在这个字段上建立一个索引？多个字段的联合索引是不是更好？以一张用户表为例，用户表中的字段可能会有***\\*用户的姓名\\****、***\\*用户的身份证号\\****、***\\*用户的家庭地址\\****等等。\n\n![img](MySQL数据库索引.assets/wps1FAA.tmp.png) \n\n### ***\\*「1.普通索引的弊端」\\****\n\n现在有个需求需要根据用户的身份证号找到用户的姓名，这时候很显然想到的第一个办法就是在id_card上建立一个索引，严格来说是唯一索引，因为身份证号肯定是唯一的，那么当我们执行以下查询的时候：\n\n***\\*SELECT\\**** ***\\*name\\**** ***\\*FROM\\**** ***\\*user\\**** ***\\*WHERE\\**** id_card=xxx\n\n它的流程应该是这样的：\n\n\\1. 先在id_card索引树上搜索，找到id_card对应的主键id\n\n\\2. 通过id去主键索引上搜索，找到对应的name\n\n从效果上来看，结果是没问题的，但是从效率上来看，似乎这个查询有点昂贵，因为它检索了两颗B+树，假设一颗树的高度是3，那么两颗树的高度就是6，因为根节点在内存里（此处两个根节点），所以最终要在磁盘上进行IO的次数是4次，以一次磁盘随机IO的时间平均耗时是10ms来说，那么最终就需要40ms。这个数字一般，不算快。![img](MySQL数据库索引.assets/wps1FAB.tmp.png)\n\n### ***\\*「2.主键索引的陷阱」\\****\n\n既然问题是回表，造成了在两颗树都检索了，那么核心问题就是看看能不能只在一颗树上检索。这里从业务的角度你可能发现了一个切入点，***\\*身份证号是唯一的\\****，那么我们的主键是不是可以不用默认的自增id了，我们把主键设置成我们的身份证号，这样整个表的只需要一个索引，并且通过身份证号可以查到所有需要的数据包括我们的姓名，简单一想似乎有道理，只要每次插入数据的时候，指定id是身份证号就行了，但是仔细一想似乎有问题。\n\n这里要从B+树的特点来说，B+树的数据都存在叶子节点上，并数据是页式管理的，一页是16K，这是什么意思呢？哪怕我们现在是一行数据，它也要占用16K的数据页，只有当我们的数据页写满了之后才会写到一个新的数据页上，新的数据页和老的数据页在物理上***\\*不一定是连续的\\****，而且有一点很关键，虽然数据页物理上是不连续的，但是数据在***\\*逻辑上是连续的\\****。\n\n![img](MySQL数据库索引.assets/wps1FBC.tmp.png)也许你会好奇，这和我们说的身份证号当主键ID有什么关系？这时你应该关注**「连续」**这个关键字，身份证号不是连续的，这意味着什么？当我们插入一条不连续的数据的时候，为了保持连续，需要移动数据，比如原来在一页上的数据有1->5，这时候插入了一条3，那么就需要把5移到3后面，也许你会说这也没多少开销，但是如果当新的数据3造成这个页A满了，那么就要看它后面的页B是否有空间，如果有空间，这时候页B的开始数据应该是这个从页A溢出来的那条，对应的也要移动数据。如果此时页B也没有足够的空间，那么就要申请新的页C，然后移一部分数据到这个新页C上，并且会切断页A与页B之间的关系，在两者之间插入一个页C，从代码的层面来说，就是切换链表的指针。\n\n![img](MySQL数据库索引.assets/wps1FBD.tmp.png) \n\n***\\*总结来说，不连续的身份证号当主键可能会造成页数据的移动、随机IO、频繁申请新页相关的开销\\****。如果我们用的是自增的主键，那么对于id来说一定是顺序的，不会因为随机IO造成数据移动的问题，在插入方面开销一定是相对较小的。\n\n其实不推荐用身份证号当主键的还有另外一个原因：身份证号作为数字来说太大了，得用bigint来存，正常来说一个学校的学生用int已经足够了，我们知道一页可以存放16K，当一个索引本身占用的空间越大时，会导致一页能存放的数据越少，所以在一定数据量的情况下，使用bigint要比int需要更多的页也就是更多的存储空间。\n\n### ***\\*「3.联合索引的矛与盾」\\****\n\n由上面两条结论可以得出：\n\n**1.** ***\\*尽量不要去回表\\****\n\n**2.** ***\\*身份证号不适合当主键索引\\****\n\n所以自然而然地想到了联合索引，创建一个【身份证号+姓名】的联合索引，注意联合索引的顺序，要符合最左原则。这样当我们同样执行以下sql时：\n\nselect name from user where id_card=xxx\n\n不需要回表就可以得到我们需要的name字段，然而还是没有解决身份证号本身占用空间过大的问题，这是业务数据本身的问题，如果你要解决它的话，我们可以通过一些转换算法将原本大的数据转换成小的数据，比如crc32：\n\ncrc32.ChecksumIEEE([]byte(\"341124199408203232\"))\n\n可以将原本需要8个字节存储空间的身份证号用4个字节的crc码替代，因此我们的数据库需要再加个字段crc_id_card，联合索引也从【身份证号+姓名】变成了【crc32(身份证号)+姓名】，联合索引占的空间变小了。但是这种转换也是有代价的：\n\n\\1. 每次额外的crc，导致需要更多cpu资源\n\n\\2. 额外的字段，虽然让索引的空间变小了，但是本身也要占用空间\n\n\\3. crc会存在冲突的概率，这需要我们查询出来数据后，再根据id_card过滤一下，过滤的成本根据重复数据的数量而定，重复越多，过滤越慢。\n\n关于联合索引存储优化，这里有个小细节，假设现在有两个字段A和B，分别占用8个字节和20个字节，我们在联合索引已经是[A,B]的情况下，还要支持B的单独查询，因此自然而然我们在B上也建立个索引，那么两个索引占用的空间为 ***\\*8+20+20=48\\****，现在无论我们通过A还是通过B查询都可以用到索引，如果在业务允许的条件下，我们是否可以建立[B,A]和A索引，这样的话，不仅满足单独通过A或者B查询数据用到索引，还可以占用更小的空间：***\\*20+8+8=36\\****。\n\n### ***\\*「4.前缀索引的短小精悍」\\****\n\n有时候我们需要索引的字段是字符串类型的，并且这个字符串很长，我们希望这个字段加上索引，但是我们又不希望这个索引占用太多的空间，这时可以考虑建立个前缀索引，以这个字段的前一部分字符建立个索引，这样既可以享受索引，又可以节省空间，这里需要注意的是在前缀重复度较高的情况下，前缀索引和普通索引的速度应该是有差距的。\n\nalter table xx add index(name(7));#name前7个字符建立索引\nselect xx from xx where name=\"JamesBond\"\n\n### ***\\*「5.唯一索引的快与慢」\\****\n\n在说唯一索引之前，我们先了解下普通索引的特点，我们知道对于B+树而言，叶子节点的数据是有序的。\n\n![img](MySQL数据库索引.assets/wps1FBE.tmp.png) \n\n假设现在我们要查询***\\*2\\****这条数据，那么在通过索引树找到2的时候，存储引擎并没有停止搜索，因为可能存在多个2，这表现为存储引擎会在叶子节点上接着向后查找，在找到第二个2之后，就停止了吗？答案是否，因为存储引擎并不知道后面还有没有更多的2，所以得接着向后查找，直至找到第一个不是2的数据，也就是3，找到3之后，停止检索，这就是普通索引的检索过程。\n\n唯一索引就不一样了，因为唯一性，不可能存在重复的数据，所以在检索到我们的目标数据之后直接返回，不会像普通索引那样还要向后多***\\*查找一次\\****，从这个角度来看，唯一索引是要比普通索引快的，但是当普通索引的数据都在一个页内的话，其实也并不会快多少。在数据的插入方面，唯一索引可能就稍逊色，因为唯一性，每次插入的时候，都需要将判断要插入的数据是否已经存在，而普通索引不需要这个逻辑，并且很重要的一点是唯一索引会用不到change buffer（见下文）。\n\n### ***\\*「6.不要盲目加索引」\\****\n\n在工作中，你可能会遇到这样的情况：这个字段我需不需要加索引？。对于这个问题，我们常用的判断手段就是：查询会不会用到这个字段，如果这个字段经常在查询的条件中，我们可能会考虑加个索引。但是如果只根据这个条件判断，你可能会加了一个错误的索引。我们来看个例子：假设有张用户表，大概有100w的数据，用户表中有个性别字段表示男女，男女差不多各占一半，现在我们要统计所有男生的信息，然后我们给性别字段加了索引，并且我们这样写下了sql：\n\nselect * from user where sex=\"男\"\n\n如果不出意外的话，InnoDB是不会选择性别这个索引的。如果走性别索引，那么一定是需要回表的，在数据量很大的情况下，回表会造成什么样的后果？我贴一张和上面一样的图想必大家都知道了：\n\n![img](MySQL数据库索引.assets/wps1FBF.tmp.png)主要就是大量的IO，一条数据需要4次，那么50w的数据呢？结果可想而知。因此针对这种情况，MySQL的优化器大概率走全表扫描，直接扫描主键索引，因为这样性能可能会更高。\n\n### ***\\*「7.索引失效那些事」\\****\n\n某些情况下，因为我们自己使用的不当，导致mysql用不到索引，这一般很容易发生在类型转换方面，也许你会说，mysql不是已经支持隐式转换了吗？比如现在有个整型的user_id索引字段，我们因为查询的时候没注意，写成了：\n\nselect xx from user where user_id=\"1234\"\n\n注意这里是字符的1234，当发生这种情况下，MySQL确实足够聪明，会把字符的1234转成数字的1234，然后愉快的使用了user_id索引。但是如果我们有个字符型的user_id索引字段，还是因为我们查询的时候没注意，写成了：\n\nselect xx from user where user_id=1234\n\n这时候就有问题了，会用不到索引，也许你会问，这时MySQL为什么不会转换了，把数字的1234转成字符型的1234不就行了？这里需要解释下转换的规则了，当出现字符串和数字比较的时候，要记住：MySQL会把字符串转换成数字。也许你又会问：为什么把字符型user_id字段转换成数字就用不到索引了? 这又要说到B+树索引的结构了，我们知道B+树的索引是按照索引的值来分叉和排序的，当我们把索引字段发生类型转换时会发生值的变化，比如原来是A值，如果执行整型转换可能会对应一个B值（int(A)=B）,这时这颗索引树就不能用了，因为索引树是按照A来构造的，不是B，所以会用不到索引。\n\n## ***\\*索引优化\\****\n\n### ***\\*「1.change buffer」\\****\n\n我们知道在更新一条数据的时候，要先判断这条数据的页是否在内存里，如果在的话，直接更新对应的内存页，如果不在的话，只能去磁盘把对应的数据页读到内存中来，然后再更新，这会有什么问题呢？\n\n\\1. 去磁盘的读这个动作稍显的有点慢\n\n\\2. 如果同时更新很多数据，那么即有可能发生很多离散的IO\n\n为了解决这种情况下的速度问题，***\\*change buffer\\****出现了，首先不要被buffer这个单词误导，change buffer除了会在公共的buffer pool里之外，也是会持久化到磁盘的。当有了change buffer之后，我们更新的过程中，如果发现对应的数据页不在内存里的话，也不去磁盘读取相应的数据页了，而是把要更新的数据放入到change buffer中，那change buffer的数据何时被同步到磁盘上去？如果此时发生读动作怎么办？首先后台有个线程会定期把change buffer的数据同步到磁盘上去的，如果线程还没来得及同步，但是又发生了读操作，那么也会触发把change buffer的数据merge到磁盘的事件。\n\n![img](MySQL数据库索引.assets/wps1FC0.tmp.png) \n\n需要注意的是并不是所有的索引都能用到changer buffer，像主键索引和唯一索引就用不到，因为唯一性，所以它们在更新的时候要判断数据存不存在，如果数据页不在内存中，就必须去磁盘上把对应的数据页读到内存里，而普通索引就没关系了，不需要校验唯一性。change buffer越大，理论收益就越大，这是因为首先离散的读IO变少了，其次当一个数据页上发生多次变更，只需merge一次到磁盘上。当然并不是所有的场景都适合change buffer，如果你的业务是更新之后，需要立马去读，change buffer会适得其反，因为需要不停地触发merge动作，导致随机IO的次数不会变少，反而增加了维护change buffer的开销。\n\n### ***\\*「2.索引下推」\\****\n\n前面我们说了联合索引，联合索引要满足最左原则，即在联合索引是[A,B]的情况下，我们可以通过以下的sql用到索引：\n\nselect * from table where A=\"xx\"\nselect * from table where A=\"xx\" AND B=\"xx\"\n\n其实联合索引也可以使用最左前缀的原则，即：\n\nselect * from table where A like \"赵%\" AND B=\"上海市\"\n\n但是这里需要注意的是，因为使用了A的一部分，在MySQL5.6之前，上面的sql在检索出所有A是“赵”开头的数据之后，就立马回表（使用的select *），然后再对比B是不是“上海市”这个判断，这里是不是有点懵？为什么B这个判断不直接在联合索引上判断，这样的话回表的次数不就少了吗？造成这个问题的原因还是因为使用了最左前缀的问题，导致索引虽然能使用部分A，但是完全用不到B，看起来是有点“傻”，于是在MySQL5.6之后，就出现了索引下推这个优化（Index Condition Pushdown）,有了这个功能以后，虽然使用的是最左前缀，但是也可以在联合索引上搜索出符合A%的同时也过滤非B的数据，大大减少了回表的次数。\n\n![img](MySQL数据库索引.assets/wps1FC1.tmp.png) \n\n### ***\\*「3.刷新邻接页」\\****\n\n在说刷新邻接页之前，我们先说下脏页，我们知道在更新一条数据的时候，得先判断这条数据所在的页是否在内存中，如果不在的话，需要把这个数据页先读到内存中，然后再更新内存中的数据，这时会发现内存中的页有最新的数据，但是磁盘上的页却依然是老数据，那么此时这条数据所在的内存中的页就是脏页，需要刷到磁盘上来保持一致。所以问题来了，何时刷？每次刷多少脏页才合适？如果每次变更就刷，那么性能会很差，如果很久才刷，脏页就会堆积很多，造成内存池中可用的页变少，进而影响正常的功能。所以刷的速度不能太快但要及时，MySQL有个***\\*清理线程\\****会定期执行，保证了不会太快，当***\\*脏页太多\\****或者***\\*redo log已经快满\\****了，也会立刻触发刷盘，保证了及时。\n\n![img](MySQL数据库索引.assets/wps1FC2.tmp.png) \n\n在脏页刷盘的过程中，InnoDB这里有个优化：如果要刷的脏页的邻居页也脏了，那么就顺带一起刷，这样的好处就是可以减少随机IO，在机械磁盘的情况下，优化应该挺大，但是这里可能会有坑，如果当前脏页的邻居脏页在被一起刷入后，邻居页立马因为数据的变更又变脏了，那此时是不是有种多此一举的感觉，并且反而浪费了时间和开销。更糟糕的是如果邻居页的邻居也是脏页...，那么这个连锁反应可能会出现短暂的性能问题。\n\n### ***\\*「4.MRR」\\****\n\n在实际业务中，我们可能会被告知尽量使用覆盖索引，不要回表，因为回表需要更多IO，耗时更长，但是有时候我们又不得不回表，回表不仅仅会造成过多的IO，更严重的是过多的离散IO。\n\nselect * from user where grade between 60 and 70\n\n现在要查询成绩在60-70之间的用户信息，于是我们的sql写成上面的那样，当然我们的grade字段是有索引的，按照常理来说，会先在grade索引上找到grade=60这条数据，然后再根据grade=60这条数据对应的id去主键索引上找，最后再次回到grade索引上，不停的重复同样的动作...， 假设现在grade=60对应的id=1，数据是在page_no_1上，grade=61对应的id=10，数据是在page_no_2上，grade=62对应的id=2，数据是在page_no_1上，所以真实的情况就是先在page_no_1上找数据，然后切到page_no_2，最后又切回page_no_1上，但其实id=1和id=2完全可以合并，读一次page_no_1即可，不仅节省了IO，同时避免了随机IO，这就是MRR。当使用MRR之后，辅助索引不会立即去回表，而是将得到的主键id，放在一个buffer中，然后再对其排序，排序后再去顺序读主键索引，大大减少了离散的IO。\n\n![img](MySQL数据库索引.assets/wps1FD2.tmp.png) \n\n \n\n# MySQL的order by\n\n排序这个词，我的第一感觉是几乎所有App都有排序的地方，淘宝商品有按照购买时间的排序、B站的评论有按照热度排序的...，当然我们今天说的并不是大数据下该如何优雅的排序，如何提升排序性能的问题，我们说一说MySQL中的排序。\n\n对于MySQL，一说到排序，你第一时间想到的是什么？关键字order by？order by的字段最好有索引？叶子结点已经是顺序的？还是说尽量不要在MySQL内部排序？\n\n## ***\\*事情的起因\\****\n\n现在假设有一张用户的朋友表：\n\n***\\*CREATE\\**** ***\\*TABLE\\**** `user` (\n `id` int(10) AUTO_INCREMENT,\n `user_id` int(10),\n `friend_addr` varchar(1000),\n `friend_name` varchar(100), \n PRIMARY ***\\*KEY\\**** (`id`),\n ***\\*KEY\\**** `user_id` (`user_id`)\n) ***\\*ENGINE\\****=***\\*InnoDB\\****;\n\n表中目前有两个点需要关注下：\n\n\\1. 用户的 ***\\*user_id\\**** ，朋友的姓名 ***\\*friend_name\\****、朋友的地址 ***\\*friend_addr\\****\n\n\\2. user_id 是有***\\*索引\\****的\n\n有一天，有个初级开发工程师小猿，收到了来自初级产品经理小汪的需求：\n***\\*小汪\\****：小猿同志，现在需要在后台加个功能，这个功能要支持根据用户 id 能查到他所有的朋友姓名和地址，并且要求朋友的姓名是按照字典排序的。\n***\\*小猿\\****：好的，这个功能简单，我马上就上线。\n\n于是小猿书写了这样的sql：\n\n***\\*select\\**** friend_name，friend_addr ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** user_id=? ***\\*order\\**** ***\\*by\\**** ***\\*name\\****\n\n在电光石火的瞬间，小猿趾高气昂的上线了，这一切都很顺利，直到有一天有个运营同学导致了这样的查询：\n\n***\\*select\\**** friend_name，friend_addr ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** user_id=10086 ***\\*order\\**** ***\\*by\\**** ***\\*name\\****\n\n然而，这个查询竟然比平时慢很多，数据库报了慢查询，小猿此时慌的一b：这是怎么回事？user_id 明明有索引啊，而且机智地我还只用了 select friend_name,friend_addr，并没有用 select *呀。小猿此时不停地安慰自己，要淡定要淡定，然后突然想到有个explain命令，用explain来查看下那条sql的执行计划吧，当小猿用了explain之后，发现extra字段里面有个看起来很危险的字眼：***\\*using filesort\\****。\n\n“这个查询竟然用到了传说中的文件排序，但是如果一个人朋友不是很多，就算了用了文件排序，应该也很快吧”，除非这个user_id=10086的朋友很多，后来小猿去查了下，这个用户的朋友竟然有10w多个～。\n\n陷入了沉思的小猿心想：这个锅看来是背定了，10w数据是有点大了，还有这个 using filesort 到底是怎么个排序原理？\n\n## ***\\*解剖文件排序\\****\n\n有人可能说上面的问题是10w数据太大了，就算不排序也慢，这个其实是有道理的，10w数据一次性查出来，无论是MySQL内存缓冲区的占用，还是网络带宽的消耗都是非常大的，那如果我加了limit 1000呢？网络带宽的问题肯定是解决了，因为数据包整体变小了，但是 ***\\*using filesort\\**** 的问题其实还是没有解决，看到这里你可能会有疑问，using filesort 难道是在文件中排序的？在文件中到底是怎么排序的？或者我这样问：如果给你来设计排序你会怎么处理？带着这些疑问和思考我们来看看 using filesort 会涉及到哪些技术难点以及是如何解决的？\n\n\\1. 首先我们的 user_id 是有索引的，所以会先在 user_id 索引树上检索我们的目标数据，即 user_id=10086 的数据，但是我们要查询的是 friend_name 和 friend_addr 字段，很不幸，光靠 user_id 索引是找不到这两个字段值的\n\n\\2. 于是需要回表，通过 user_id 对应的主键去主键索引树上去查找，ok，我们找到了第一条 user_id=10086 的 friend_name 和 friend_addr 字段\n\n\\3. 这时该怎么办？直接返回回去肯定不对，因为我需要对 friend_name 排序，如何排？数据都还没找全，那么就得把查到的数据先放在一个地方，这个地方就是 ***\\*sort_buffer\\****，看到名字我想你应该猜出来，没错，sort_buffer 就是用于这种情况下排序用的缓冲区，这里需要注意的是每个线程都会有一个单独的 sort_buffer，这么做的目的主要是为了避免多个线程对同一块内存进行操作带来锁竞争的问题。\n\n\\4. 当第一条数据的 friend_name 和 friend_addr 已经放入 sort_buffer 中，这当然没完，会一直重复同步的步骤，直至把所有 user_id=10086 的 friend_name 和 friend_addr 都放入到 sort_buffer 中才结束\n\n\\5. sort_buffer 中的数据已经放入完毕，接下来就该排序了，这里 MySQL 会对 friend_name 进行快排，通过快排后，sort_buffer 中 friend_name 就是有序的了\n\n\\6. 最后返回 sort_buffer 中的前1000条，结束。\n\n![img](MySQL数据库索引.assets/wps146F.tmp.png) \n\n一切看起来很丝滑，但是 sort_buffer 占用的是内存空间，这就尴尬了，内存本身就不是无限大的，它肯定是有上限的，当然 sort_buffer 也不能太小，太小的话，意义不大。在 InnoDB 存储引擎中，这个值是默认是256K。\n\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'sort_buffer_size';\n+------------------+--------+\n| Variable_name  | Value |\n+------------------+--------+\n| sort_buffer_size | 262144 |\n+------------------+--------+\n\n也就是说，如果要放进 sort_buffer 中的数据是大于256K的话，那么采用在 sort_buffer 中快排的方式肯定是行不通的，这时候，你可能会问：MySQL难道不能根据数据大小自动扩充吗？额，MySQL是多线程模型，如果每个线程都扩充，那么分给其他功能buffer就小了（比如change buffer等），就会影响其他功能的质量。\n\n这时就得换种方式来排序了，没错，此时就是真正的文件排序了，也就是磁盘的临时文件，MySQL会采用归并排序的思想，把要排序的数据分成若干份，每一份数据在内存中排序后会放入临时文件中，最终对这些已经排序好的临时文件的数据再做一次合并排序就ok了，典型的分而治之原理，它的具体步骤如下：\n\n\\1. 先将要排序的数据分割，分割成每块数据都可以放到 sort_buffer 中\n\n\\2. 对每块数据在 sort_buffer 中进行排序，排序好后，写入某个临时文件中\n\n\\3. 当所有的数据都写入临时文件后，这时对于每个临时文件而言，内部都是有序的，但是它们并不是一个整体，整体还不是有序的，所以接下来就得合并数据了\n\n\\4. 假设现在存在 tmpX 和 tmpY 两个临时文件，这时会从 tmpX 读取一部分数据进入内存，然后从 tmpY 中读取一部分数据进入内存，这里你可能会好奇为什么是一部分而不是整个或者单个？因为首先磁盘是缓慢的，所以尽量每次多读点数据进入内存，但是不能读太多，因为还有 buffer 空间的限制。\n\n\\5. 对于 tmpX 假设读进来了的是 tmpX[0-5] ,对于 tmpY 假设读进来了的是 tmpY[0-5]，于是只需要这样比较：如果 tmpX[0] < tmpY[0]，那么 tmpX[0] 肯定是最小的，然后 tmpX[1] 和 tmpY[0] 比较，如果 tmpX[1] > tmpY[0]，那么 tmpY[0] 肯定是第二小的...，就这样两两比较最终就可以把 tmpX 和 tmpY 合并成一个有序的文件tmpZ，多个这样的tmpZ再次合并...，最终就可以把所有的数据合并成一个有序的大文件。\n\n![img](MySQL数据库索引.assets/wps1470.tmp.png) \n\n## ***\\*文件排序很慢，还有其他办法吗\\****\n\n通过上面的排序流程我们知道，如果要排序的数据很大，超过 sort_buffer 的大小，那么就需要文件排序，文件排序涉及到分批排序与合并，很耗时，造成这个问题的根本原因是 ***\\*sort_buffer 不够用\\****，不知道你发现没有我们的 friend_name 需要排序，但是却把 friend_addr 也塞进了 sort_buffer 中，这样***\\*单行数据的大小就等于 friend_name 的长度 + friend_addr 的长度\\****，能否让 sort_buffer 中只存 friend_name 字段，这样的话，整体的利用空间就大了，不一定用得到到临时文件。没错，这就是接下来要说的另一种排序优化***\\*rowid排序\\****。\n\nrowid 排序的思想就是把不需要的数据不要放到 sort_buffer 中，让 sort_buffer 中只保留必要的数据，那么你认为什么是必要的数据呢？只放 friend_name？这肯定不行，排序完了之后，friend_addr 怎么办？因此还要把主键id放进去，这样排完之后，通过 id 再回次表，拿到 friend_addr 即可，因此它的大致流程如下：\n\n\\1. 根据 user_id 索引，查到目标数据，然后回表，只把 id 和 friend_name 放进 sort_buffer 中\n\n\\2. 重复1步骤，直至全部的目标数据都在 sort_buffer 中\n\n\\3. 对 sort_buffer 中的数据按照 friend_name 字段进行排序\n\n\\4. 排序后根据 id 再次回表查到 friend_addr 返回，直至返回1000条数据，结束。\n\n![img](MySQL数据库索引.assets/wps1471.tmp.png) \n\n这里面其实有几点需要注意的：\n\n\\1. 这种方式需要两次回表的\n\n\\2. sort_buffer 虽然小了，但是如果数据量本身还是很大，应该还是要临时文件排序的\n\n那么问题来了，两种方式，MySQL 该如何选择？得根据某个条件来判断走哪种方式吧，这个条件就是进 sort_buffer 单行的长度，如果长度太大（friend_name + friend_addr的长度），就会采用 rowid 这种方式，否则第一种，长度的标准是根据 ***\\*max_length_for_sort_data\\**** 来的，这个值默认是1024字节：\n\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'max_length_for_sort_data';\n+--------------------------+-------+\n| Variable_name     | Value |\n+--------------------------+-------+\n| max_length_for_sort_data | 1024 |\n+--------------------------+-------+\n\n## ***\\*不想回表，不想再次排序\\****\n\n其实不管是上面哪种方法，他们都需要***\\*回表\\****+***\\*排序\\****，回表是因为二级索引上没有目标字段，排序是因为数据不是有序的，那如果二级索引上有目标字段并且已经是排序好的了，那不就两全其美了嘛。\n\n没错，就是联合索引，我们只需要建立一个 （user_id，friend_name，friend_addr）的联合索引即可，这样我就可以通过这个索引拿到目标数据，并且friend_name已经是排序好的，同时还有friend_addr字段，一招搞定，不需要回表，不需要再次排序。因此对于上述的sql，它的大致流程如下：\n\n\\1. 通过联合索引找到user_id=10086的数据，然后读取对应的 friend_name 和 friend_addr 字段直接返回，因为 friend_name 已经是排序好的了，不需要额外处理\n\n\\2. 重复第一步骤，顺着叶子节点接着向后找，直至找到第一个不是10086的数据，结束。\n\n![img](MySQL数据库索引.assets/wps1472.tmp.png) \n\n联合索引虽然可以解决这种问题，但是在实际应用中切不可盲目建立，要根据实际的业务逻辑来判断是否需要建立，如果不是经常有类似的查询，可以不用建立，因为联合索引会占用更多的存储空间和维护开销。\n\n## ***\\*总结\\****\n\n\\1. 对于 order by 没有用到索引的时候，这时 explain 中 Extra 字段大概是会出现 using filesort 字眼\n\n\\2. 出现 using filesort 的时候也不用太慌张，如果本身数据量不大，比如也就几十条数据，那么在 sort buffer 中使用快排也是很快的\n\n\\3. 如果数据量很大，超过了 sort buffer 的大小，那么是要进行临时文件排序的，也就是归并排序，这部分是由 MySQL 优化器决定的\n\n\\4. 如果查询的字段很多，想要尽量避免使用临时文件排序，可以尝试设置下 max_length_for_sort_data 字段的大小，让其小于所有查询字段长度的总和，这样放入或许可以避免，但是会多一次回表操作\n\n\\5. 实际业务中，我们也可以给经常要查询的字段组合建立个联合索引，这样既不用回表也不需要单独排序，但是联合索引会占用更多的存储和开销\n\n\\6. 大量数据查询的时候，尽量分批次，提前 explain 来观察 sql 的执行计划是个不错的选择。\n\n \n\n# mysql索引\n\nmysql索引真的是一个让人不得不说的话题，这个东西你在面试中会用到，在实际的工作中也会用到，这更是一个专业的DBA所必须掌握的内容，它的重要性体你在大厂的面试题汇总也可以看到，属于必问的一个内容。\n这篇文章的内容可能有点多，也有点晦涩难懂，没有基础的小伙伴需要多读几遍才能读懂，但是希望你能沉下心来读完这篇文章，你会得到更多：\n\n**什么是索引？****\n****常见的索引模型有哪些？什么是回表？什么是覆盖索引？什么是最左前缀原则？什么是索引下推？****\n****..............****\n****\n**\n\n**正文**\n\n![img](MySQL数据库索引.assets/wps1168.tmp.png)**什么是索引？****\n**相信大家小时候学习汉字的时候都会查字典，想想你查字典的步骤，我们是通过汉字的首字母a～z一个一个在字典目录中查找，最终找到该字的页数。想想，如果没有目录会怎么样，最差的结果是你有可能翻到字典的最后一页才找到你想要找的字。\n索引就相当于我们字典中的目录，可以极大的提高我们在数据库的查询效率。\n\n**常见的索引模型有哪些？**\n**①有序数组**\n  如图：![img](MySQL数据库索引.assets/wps1169.tmp.png)\n我们按照IDCard从小到大排列：\n在我们想要根据IDCard查找某一条数据时，就可以通过二分法查找。\n\n在我们想要根据IDCard查找IDCard在 10 到 1000 内的的数据时，就可以先通过二分法先查找10，然后向递增的方向遍历，找到IDCard为1000，再继续遍历，直到找到的IDCard大于1000时就完成了整个范围查询。\n我们仅仅从查询的角度来看有序数组已经很优秀了，但是我们都知道，有序数组在插入一条数据时是非常麻烦的，你需要将你插入位置后面的数据整体向后移一位，这是非常消耗性能的。\n\n**优点**：查询效率很高，也很适合范围查询。**缺点**：当新数据插入时会影响效率。\n\n\n**②哈希表****\n**如图![img](MySQL数据库索引.assets/wps116A.tmp.png)学过hashmap 的朋友应该都比较了解了，它的原理其实就是将IDCard通过哈希算法计算出一个特定的值，然后存储地址，这样在你找数据的时候直接可以通过IDCard去找了，当然也会有种情况，就是两个元素选中了相同的空间，我们通常会引出一个链表去存储。\n我们可以看到hash表在等值查询的效率是很高的，但是由于hash表是无序的，所以在范围查询的时候只能遍历所有了，效率会很低。\n感兴趣的朋友可以去看看lru，是如何解决范围查询的问题的，后续我也会和大家讲讲。\n**优点**：等值查询效率高，插入效率高**缺点**：不适合范围查询\n\n**③二叉树**\n如图：![img](MySQL数据库索引.assets/wps116B.tmp.png)\n二叉树是比较经典的数据结构了，它的特点是每个节点的左儿子小于父节点，父节点又小于右儿子。\n二叉树是有序的，查找的时间复杂度为O(logn)\n\n二叉树可以说在插入查询方面都是比较优秀的，但是在数据的索引选择方面我们并不会选择二叉树，我们按照上图来讲：\n假如我要访问IDCard5，那么我要先访问IDCard1，然后访问IDCard3，最后才能访问到IDCard5，我们总会访问了3个数据块，每一次访问都是一次磁盘寻址的过程，假设树高30，那么我们最差的情况下寻找一个数据要访问30次磁盘，这在效率上是不能忍受的。\n**④B+树****\n**如图**\n**![img](MySQL数据库索引.assets/wps117B.tmp.png)\n我们数据库innodb默认的索引引擎就是B+树。\nB+树其实是就是一个N叉树，只在子节点上存储数据，并且子节点用链表维护，而且是有序的，在范围查询（链表更高效），等值查询，插入新数据上来说都是很高效的。并且作为N叉树，在树的每一层都可以存储很多数据，这样在数据库查询数据的时候最差也只需要几次磁盘寻址就可以了。\n\n在mysql中有主键索引和非主键索引之分，主键索引上存储的是数据行信息，非主键索引上存储的是主键信息。\n如下\n\n· \n\n· \n\n· \n\n· \n\n· \n\n· \n\n· \n\nCREATE TABLE `user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键',  `application` varchar(64) NOT NULL DEFAULT '' COMMENT '所属应用名称', `owner` varchar(32) NOT NULL DEFAULT '' COMMENT '负责人',  PRIMARY KEY (`id`),  UNIQUE KEY `idx_application_id` (`application`) USING BTREE)ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8mb4 COMMENT='用户表';\n\n\n主键为id，那么id这棵B+树上就会存储该行所有的信息字段，包括application，owner。\n对于没有主键的表，innodb会给默认创建一个Rowid做主键。\n唯一索引是application，那么在application这颗索引树上存储的信息就是id。\n\n**优点**：\n\n♦第一层只放索引信息，存放的索引信息更多。\n\n♦树高更低，故磁盘寻址带来的损耗更小。♦链表维护，范围查询效率更高。\n**⑤B-树**\n如图![img](MySQL数据库索引.assets/wps117C.tmp.png)B-树和B+树的区别是每一个节点都会存储数据，叶子节点之间不用链表链接。\n\n相比B+树来说做范围查询的效率会低一点，如果空间大小固定的话，第一层存放的索引信息更少（想想目录，我们都希望第一层是只用来存储目录信息的）。\n\n**什么是回表？**\n\n还按这个表举例：\n\n· \n\nCREATE TABLE `user` (  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键',  `application` varchar(64) NOT NULL DEFAULT '' COMMENT '所属应用名称', `owner` varchar(32) NOT NULL DEFAULT '' COMMENT '负责人',  PRIMARY KEY (`id`),  UNIQUE KEY `idx_application_id` (`application`) USING BTREE)ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8mb4 COMMENT='用户表';\n\n\n来一条查询语句\n\n· \n\nselect * from user where application = 'wechat';\n\n\n我们来看看，针对这张user表，上述的查询语句要经过哪些步骤：\n\n①由于application是索引，所以先搜索application这颗索引树，找到application='wechat'这条数据，取得主键id②通过取得的主键id，去主键id这颗B+树找到该条数据③找到该条数据后，取得该数据行的值，并且返回④结束\n刚刚的第一步到第二步，其实就是一个回表操作，我们定义一下回表:\n回表就是在普通索引树上取得主键信息，再返回到主键索引树去搜索数据信息，这就是回表操作。\n\n# **覆盖索引**\n\n\nmoon这里再举个例子你就能明白覆盖索引的含义了，还是刚刚的表\n\n· \n\nselect id from user where application = 'wechat';\n\n\n这条语句就可以用到覆盖索引这个特性了，我们再来看下步骤：\n\n①由于application是索引，所以先搜索application这颗索引树，找到application='wechat'这条数据，取得主键id②mysql发现id 就是select要查询的数据，并且application是唯一索引，于是直接返回\n这就是覆盖索引的效果，可以减少我们的回表次数，甚至可以不用回表。\n当然，在实际开发场景中也不要轻易只是为了能用到覆盖索引就建立冗余字段索引，还是要根据实际开发场景来的。\n\n# **最左前缀原则**\n\n**\n**还是之前的表，索引变成了（application，owner）的联合索引，我们再来写个sql：\n\n· \n\nselect owner from user where application like \"w%\";\n\n\n当你的查询条件是application以w开头的数据时，就可以用到最左前缀原则了。\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左N个字符。\n聪明的朋友已经发现了，最左前缀还有一层优化，比如（application，owner）这个联合索引中，我们用到了最左前缀，可以少维护一个application的单独索引，因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n\n# ***\\*索引下推\\****\n\n \n\n联合索引（application，owner）\n\n· \n\nselect * from user where application like \"w%\" and owner = \"老王\";\n\n \n\n这个语句在搜索索引树的时候，只能用 “w”，找到第一个满足条件的记录，然后判断其他条件是否满足。\n在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。\n而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n也就是owner在联合索引中，‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍判断owner是否等于'老王'，会直接过滤掉不等于'老王'的数据。\n\n "},"0f6a":function(n,r,e){"use strict";e.r(r),r["default"]="本文是对 [Martin Kleppmann](https://martin.kleppmann.com/) 的文章 [How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html) 部分内容的翻译和总结，上次写 Redlock 的原因就是看到了 Martin 的这篇文章，写得很好，特此翻译和总结。感兴趣的同学可以翻看原文，相信会收获良多。\n\n开篇作者认为现在 Redis 逐渐被使用到数据管理领域，这个领域需要更强的数据一致性和耐久性，这使得他感到担心，因为这不是 Redis 最初设计的初衷（事实上这也是很多业界程序员的误区，越来越把 Redis 当成数据库在使用），其中基于 Redis 的分布式锁就是令人担心的其一。\n\nMartin 指出首先你要明确你为什么使用分布式锁，为了性能还是正确性？为了帮你区分这二者，在这把锁 fail 了的时候你可以询问自己以下问题： \n1. **要性能的：** 拥有这把锁使得你不会重复劳动（例如一个 job 做了两次），如果这把锁 fail 了，两个节点同时做了这个 Job，那么这个 Job 增加了你的成本。\n2. **要正确性的：** 拥有锁可以防止并发操作污染你的系统或者数据，如果这把锁 fail 了两个节点同时操作了一份数据，结果可能是数据不一致、数据丢失、file 冲突等，会导致严重的后果。\n\n上述二者都是需求锁的正确场景，但是你必须清楚自己是因为什么原因需要分布式锁。\n\n如果你只是为了性能，那没必要用 Redlock，它成本高且复杂，你只用一个 Redis 实例也够了，最多加个从防止主挂了。当然，你使用单节点的 Redis 那么断电或者一些情况下，你会丢失锁，但是你的目的只是加速性能且断电这种事情不会经常发生，这并不是什么大问题。并且如果你使用了单节点 Redis，那么很显然你这个应用需要的锁粒度是很模糊粗糙的，也不会是什么重要的服务。\n\n那么是否 Redlock 对于要求正确性的场景就合适呢？Martin 列举了若干场景证明 Redlock 这种算法是不可靠的。\n\n## 用锁保护资源\n这节里 Martin 先将 Redlock 放在了一边而是仅讨论总体上一个分布式锁是怎么工作的。在分布式环境下，锁比 mutex 这类复杂，因为涉及到不同节点、网络通信并且他们随时可能无征兆的 fail 。\nMartin 假设了一个场景，一个 client 要修改一个文件，它先申请得到锁，然后修改文件写回，放锁。另一个 client 再申请锁 ... 代码流程如下：\n\n```java\n// THIS CODE IS BROKEN\nfunction writeData(filename, data) {\n    var lock = lockService.acquireLock(filename);\n    if (!lock) {\n        throw 'Failed to acquire lock';\n    }\n\n    try {\n        var file = storage.readFile(filename);\n        var updated = updateContents(file, data);\n        storage.writeFile(filename, updated);\n    } finally {\n        lock.release();\n    }\n}\n```\n\n可惜即使你的锁服务非常完美，上述代码还是可能跪，下面的流程图会告诉你为什么：\n\n![](如何做可靠的分布式锁，Redlock真的可行么.assets/unsafe-lock.png)\n\n上述图中，得到锁的 client1 在持有锁的期间 pause 了一段时间，例如 GC 停顿。锁有过期时间（一般叫租约，为了防止某个 client 崩溃之后一直占有锁），但是如果 GC 停顿太长超过了锁租约时间，此时锁已经被另一个 client2 所得到，原先的 client1 还没有感知到锁过期，那么奇怪的结果就会发生，曾经 HBase 就发生过这种 Bug。即使你在 client1 写回之前检查一下锁是否过期也无助于解决这个问题，因为 GC 可能在任何时候发生，即使是你非常不便的时候（在最后的检查与写操作期间）。\n如果你认为自己的程序不会有长时间的 GC 停顿，还有其他原因会导致你的进程 pause。例如进程可能读取尚未进入内存的数据，所以它得到一个 page fault 并且等待 page 被加载进缓存；还有可能你依赖于网络服务；或者其他进程占用 CPU；或者其他人意外发生 SIGSTOP 等。\n\n... .... 这里 Martin 又增加了一节列举各种进程 pause 的例子，为了证明上面的代码是不安全的，无论你的锁服务多完美。\n\n## 使用 Fencing （栅栏）使得锁变安全\n修复问题的方法也很简单：你需要在每次写操作时加入一个 fencing token。这个场景下，fencing token 可以是一个递增的数字（lock service 可以做到），每次有 client 申请锁就递增一次：\n\n![](如何做可靠的分布式锁，Redlock真的可行么.assets/fencing-tokens.png)\n\nclient1 申请锁同时拿到 token33，然后它进入长时间的停顿锁也过期了。client2 得到锁和 token34 写入数据，紧接着 client1 活过来之后尝试写入数据，自身 token33 比 34 小因此写入操作被拒绝。注意这需要存储层来检查 token，但这并不难实现。如果你使用 Zookeeper 作为 lock service 的话那么你可以使用 zxid 作为递增数字。\n但是对于 Redlock 你要知道，没什么生成 fencing token 的方式，并且怎么修改 Redlock 算法使其能产生 fencing token 呢？好像并不那么显而易见。因为产生 token 需要单调递增，除非在单节点 Redis 上完成但是这又没有高可靠性，你好像需要引进一致性协议来让 Redlock 产生可靠的 fencing token。\n\n## 使用时间来解决一致性\nRedlock 无法产生 fencing token 早该成为在需求正确性的场景下弃用它的理由，但还有一些值得讨论的地方。\n\n学术界有个说法，算法对时间不做假设：因为进程可能pause一段时间、数据包可能因为网络延迟延后到达、时钟可能根本就是错的。而可靠的算法依旧要在上述假设下做正确的事情。\n\n对于 failure detector 来说，timeout 只能作为猜测某个节点 fail 的依据，因为网络延迟、本地时钟不正确等其他原因的限制。考虑到 Redis 使用 gettimeofday，而不是单调的时钟，会受到系统时间的影响，可能会突然前进或者后退一段时间，这会导致一个 key 更快或更慢地过期。\n\n可见，Redlock 依赖于许多时间假设，它假设所有 Redis 节点都能对同一个 Key 在其过期前持有差不多的时间、跟过期时间相比网络延迟很小、跟过期时间相比进程 pause 很短。\n\n## 用不可靠的时间打破 Redlock \n这节 Martin 举了个因为时间问题，Redlock 不可靠的例子。\n\n1. client1 从 ABC 三个节点处申请到锁，DE由于网络原因请求没有到达\n2. C节点的时钟往前推了，导致 lock 过期\n3. client2 在CDE处获得了锁，AB由于网络原因请求未到达\n4. 此时 client1 和 client2 都获得了锁\n\n**在 Redlock 官方文档中也提到了这个情况，不过是C崩溃的时候，Redlock 官方本身也是知道 Redlock 算法不是完全可靠的，官方为了解决这种问题建议使用延时启动，相关内容可以看之前的[这篇文章](https://zhuanlan.zhihu.com/p/40915772)。但是 Martin 这里分析得更加全面，指出延时启动不也是依赖于时钟的正确性的么？**\n\n接下来 Martin 又列举了进程 Pause 时而不是时钟不可靠时会发生的问题：\n\n1. client1 从 ABCDE 处获得了锁\n2. 当获得锁的 response 还没到达 client1 时 client1 进入 GC 停顿\n3. 停顿期间锁已经过期了\n4. client2 在 ABCDE 处获得了锁\n5. client1 GC 完成收到了获得锁的 response，此时两个 client 又拿到了同一把锁\n\n**同时长时间的网络延迟也有可能导致同样的问题。**\n\n## Redlock 的同步性假设\n这些例子说明了，仅有在你假设了一个同步性系统模型的基础上，Redlock 才能正常工作，也就是系统能满足以下属性：\n\n1. 网络延时边界，即假设数据包一定能在某个最大延时之内到达\n2. 进程停顿边界，即进程停顿一定在某个最大时间之内\n3. 时钟错误边界，即不会从一个坏的 NTP 服务器处取得时间\n\n## 结论\nMartin 认为 Redlock 实在不是一个好的选择，对于需求性能的分布式锁应用它太重了且成本高；对于需求正确性的应用来说它不够安全。因为它对高危的时钟或者说其他上述列举的情况进行了不可靠的假设，如果你的应用只需要高性能的分布式锁不要求多高的正确性，那么单节点 Redis 够了；如果你的应用想要保住正确性，那么不建议 Redlock，建议使用一个合适的一致性协调系统，例如 Zookeeper，且保证存在 fencing token。\n"},1377:function(n,r,e){"use strict";e.r(r),r["default"]='- \n\n  # 第一章 Redis基础\n\n  **课程计划**\n\n  | 1. Redis 入 门         | **（了解）** | **（操作）** |              |\n  | ---------------------- | ------------ | ------------ | ------------ |\n  | 2. 数据类型            | **（重点）** | **（操作）** | **（理解）** |\n  | 3. 常用指令            |              | **（操作）** |              |\n  | 4. Jedis               | **（重点）** | **（操作）** |              |\n  | 5. 持 久 化            | **（重点）** |              | **（理解）** |\n  | 6. 数据删除与淘汰策略  |              |              | **（理解）** |\n  | 7. 主从复制            | **（重点）** | **（操作）** | **（理解）** |\n  | 8. 哨 兵               | **（重点）** | **（操作）** | **（理解）** |\n  | 9. Cluster集群方案     | **（重点）** | **（操作）** | **（理解）** |\n  | 10. 企业级缓存解决方案 | **（重点）** |              | **（理解）** |\n  | 11. 性能指标监控       | **（了解）** |              |              |\n\n  ## 学习目标：\n\n  目标1：能够说出NoSQL的概念，redis的应用场景，能够完成redis的下载安装与启动以及一些常用的配置\n\n  目标2：能够说出redis常用的5种数据类型，对应这些数据类型的基本操作，应用场景及对应的解决方案\n\n  目标3：能够说出redis中常用的一些基本指令\n\n  目标4：能够使用jedis完成客户端应用程序的开发\n\n  目标5：能够说出redis数据持久化的两种方式，各自相关的操作配置及指令，以及两种方式的优缺点比较\n\n  ## 1. Redis 简介\n\n  在这个部分，我们将学习以下3个部分的内容，分别是：\n\n  ◆ Redis 简介（NoSQL概念、Redis概念）\n\n  ◆ Redis 的下载与安装\n\n  ◆ Redis 的基本操作\n\n  ### 1.1 NoSQL概念\n\n  #### 1.1.1 问题现象\n\n  在讲解NoSQL的概念之前呢，我们先来看一个现象：\n\n  （1）问题现象\n\n  每年到了过年期间，大家都会自觉自发的组织一场活动，叫做春运！以前我们买票都是到火车站排队，后来呢有了12306，有了他以后就更方便了，我们可以在网上买票，但是带来的问题，大家也很清楚，春节期间买票进不去，进去了刷不着票。什么原因呢，人太多了！\n\n  ![](Redis基础.assets/12306-淘宝.png)\n\n  除了这种做铁路的，它系统做的不专业以外，还有马爸爸做的淘宝，它面临一样的问题。淘宝也崩，也是用户量太大！作为我们整个电商界的东哥来说，他第一次做图书促销的时候，也遇到了服务器崩掉的这样一个现象，原因同样是因为用户量太大！![](Redis基础.assets/京东翻车案.png)\n\n  （2）现象特征\n\n  再来看这几个现象，有两个非常相似的特征：\n\n  第一，用户比较多，海量用户\n\n  第二，高并发\n\n  这两个现象出现以后，对应的就会造成我们的服务器瘫痪。核心本质是什么呢？其实并不是我们的应用服务器，而是我们的关系型数据库。关系型数据库才是最终的罪魁祸首！\n\n  （3）造成原因\n\n  什么样的原因导致的整个系统崩掉的呢：\n\n  1.性能瓶颈：磁盘IO性能低下\n\n  关系型数据库菜存取数据的时候和读取数据的时候他要走磁盘IO。磁盘这个性能本身是比较低的。\n\n  2.扩展瓶颈：数据关系复杂，扩展性差，不便于大规模集群\n\n  我们说关系型数据库，它里面表与表之间的关系非常复杂，不知道大家能不能想象一点，就是一张表，通过它的外键关联了七八张表，这七八张表又通过她的外件，每张又关联了四五张表。你想想，查询一下，你要想拿到数据，你就要从A到B、B到C、C到D的一直这么关联下去，最终非常影响查询的效率。同时，你想扩展下，也很难!\n\n  （4）解决思路\n\n  面对这样的现象，我们要想解决怎么版呢。两方面：\n\n  一，降低磁盘IO次数，越低越好。\n\n  二，去除数据间关系，越简单越好。\n\n  降低磁盘IO次数，越低越好，怎么搞？我不用你磁盘不就行了吗？于是，内存存储的思想就提出来了，我数据不放到你磁盘里边，放内存里，这样是不是效率就高了。\n\n  第二，你的数据关系很复杂，那怎么办呢？干脆简单点，我断开你的关系，我不存关系了，我只存数据，这样不就没这事了吗？\n\n  把这两个特征一合并一起，就出来了一个新的概念：NoSQL\n\n  #### 1.1.2 NoSQL的概念\n\n  （1）概念\n\n  NoSQL：即 Not-Only SQL（ 泛指非关系型的数据库），作为关系型数据库的补充。 作用：应对基于海量用户和海量数据前提下的数据处理问题。\n\n  他说这句话说的非常客气，什么意思呢？就是我们数据存储要用SQL，但是呢可以不仅仅用SQL，还可以用别的东西，那别的东西叫什么呢？于是他定义了一句话叫做NoSQL。这个意思就是说我们存储数据，可以不光使用SQL，我们还可以使用非SQL的这种存储方案，这就是所谓的NoSQL。\n\n  （2）特征\n\n  可扩容，可伸缩。SQL数据关系过于复杂，你扩容一下难度很高，那我们Nosql 这种的，不存关系，所以它的扩容就简单一些。\n\n  大数据量下高性能。包数据非常多的时候，它的性能高，因为你不走磁盘IO，你走的是内存，性能肯定要比磁盘IO的性能快一些。\n\n  灵活的数据模型、高可用。他设计了自己的一些数据存储格式，这样能保证效率上来说是比较高的，最后一个高可用，我们等到集群内部分再去它！\n\n  （3）常见 Nosql 数据库\n\n  目前市面上常见的Nosql产品：Redis、memcache、HBase、MongoDB\n\n  （4）应用场景-电商为例\n\n  我们以电商为例，来看一看他在这里边起到的作用。\n\n  第一类，在电商中我们的基础数据一定要存储起来，比如说商品名称，价格，生产厂商，这些都属于基础数据，这些数据放在MySQL数据库。\n\n  第二类，我们商品的附加信息，比如说，你买了一个商品评价了一下，这个评价它不属于商品本身。就像你买一个苹果，“这个苹果很好吃”就是评论，但是你能说很好吃是这个商品的属性嘛？不能这么说，那只是一个人对他的评论而已。这一类数据呢，我们放在另外一个地方，我们放到MongoDB。它也可以用来加快我们的访问，他属于NoSQL的一种。\n\n  第三，图片内的信息。注意这种信息相对来说比较固定，他有专用的存储区，我们一般用文件系统来存储。至于是不是分布式，要看你的系统的一个整个   瓶颈   了？如果说你发现你需要做分布式，那就做，不需要的话，一台主机就搞定了。\n\n  第四，搜索关键字。为了加快搜索，我们会用到一些技术，有些人可能了解过，像分ES、Lucene、solr都属于搜索技术。那说的这么热闹，我们的电商解决方案中还没出现我们的redis啊！注意第五类信息。\n\n  第五，热点信息。访问频度比较高的信息，这种东西的第二特征就是它具有波段性。换句话说他不是稳定的，它具有一个时效性的。那么这类信息放哪儿了，放到我们的redis这个解决方案中来进行存储。\n\n  具体的我们从我们的整个数据存储结构的设计上来看一下。\n\n  ![](Redis基础.assets/电商场景解决方案.png)\n\n  我们的基础数据都存MySQL,在它的基础之上，我们把它连在一块儿，同时对外提供服务。向上走，有一些信息加载完以后,要放到我们的MongoDB中。还有一类信息，我们放到我们专用的文件系统中（比如图片），就放到我们的这个搜索专用的，如Lucene、solr及集群里边，或者用ES的这种技术里边。那么剩下来的热点信息，放到我们的redis里面。\n\n  ### 1.2 Redis概念\n\n  #### 1.2.1 redis概念\n\n  概念：Redis (REmote DIctionary Server) 是用 C 语言开发的一个开源的高性能键值对（key-value）数据库。\n\n  特征：\n\n  （1）数据间没有必然的关联关系；\n\n  （2）内部采用单线程机制进行工作；\n\n  （3）高性能。官方提供测试数据，50个并发执行100000 个请求,读的速度是110000 次/s,写的速度是81000次/s。\n\n  （4）多数据类型支持\n\n  字符串类型，string  list\n\n  列表类型，hash  set\n\n  散列类型，zset/sorted_set\n\n  集合类型\n\n  有序集合类型\n\n  （5）支持持久化，可以进行数据灾难恢复\n\n  #### 1.2.2 redis的应用场景\n\n  （1）为热点数据加速查询（主要场景）。如热点商品、热点新闻、热点资讯、推广类等高访问量信息等。\n\n  （2）即时信息查询。如各位排行榜、各类网站访问统计、公交到站信息、在线人数信息（聊天室、网站）、设备信号等。\n\n  （3）时效性信息控制。如验证码控制、投票控制等。\n\n  （4）分布式数据共享。如分布式集群架构中的 session 分离\n  消息队列.\n\n  ### 1.3 Redis 的下载与安装\n\n  后期所有资料分4中不同色块显示，详情如下：\n\n  ![](Redis基础.assets/约定格式.png)\n\n  #### 1.3.1 Redis 的下载与安装\n\n  本课程所示，均基于Center OS7安装Redis。\n\n  （1)下载Redis\n\n  下载安装包：\n\n  ```bash\n  wget http://download.redis.io/releases/redis-5.0.0.tar.gz\n  ```\n\n  解压安装包：\n\n  ```bash\n  tar –xvf redis-5.0.0.tar.gz\n  ```\n\n  编译（在解压的目录中执行）：\n\n  ```bash\n  make\n  ```\n\n  安装（在解压的目录中执行）：\n\n  ```bash\n  make install\n  ```\n\n  （2）安装 Redis\n\n  redis-server，服务器启动命令 客户端启动命令\n\n  redis-cli，redis核心配置文件\n\n  redis.conf，RDB文件检查工具（快照持久化文件）\n\n  redis-check-dump，AOF文件修复工具\n\n  redis-check-aof\n\n  ### 1.4 Redis服务器启动\n\n  #### 1.4.1 Redis服务器启动\n\n  启动服务器——参数启动\n\n  ```bash\n  redis-server [--port port]\n  ```\n\n  范例\n\n  ```bash\n  redis-server --port 6379\n  ```\n\n  启动服务器——配置文件启动\n\n  ```bash\n  redis-server config_file_name\n  ```\n\n  范例\n\n  ```bash\n  redis-server redis.conf\n  ```\n\n  #### 1.4.2 Redis客户端启动\n\n  启动客户端\n\n  ```bash\n  redis-cli [-h host] [-p port]\n  ```\n\n  范 例\n\n  ```bash\n  redis-cli –h 61.129.65.248 –p 6384\n  ```\n\n  注意：服务器启动指定端口使用的是--port，客户端启动指定端口使用的是-p。-的数量不同。\n\n  #### 1.4.3 Redis基础环境设置约定\n\n  创建配置文件存储目录\n\n  ```bash\n  mkdir conf\n  ```\n\n  创建服务器文件存储目录（包含日志、数据、临时配置文件等）\n\n  ```bash\n  mkdir data\n  ```\n\n  创建快速访问链接\n\n  ```bash\n  ln -s redis-5.0.0 redis\n  ```\n\n  ### 1.5 配置文件启动与常用配置\n\n  #### 1.5.1 服务器端设定\n\n  设置服务器以守护进程的方式运行，开启后服务器控制台中将打印服务器运行信息（同日志内容相同）\n\n  ```bash\n  daemonize yes|no\n  ```\n\n  绑定主机地址\n\n  ```bash\n  bind ip\n  ```\n\n  设置服务器端口\n\n  ```bash\n  port port\n  ```\n\n  设置服务器文件保存地址\n\n  ```bash\n  dir path\n  ```\n\n  #### 1.5.2  客户端配置\n\n   服务器允许客户端连接最大数量，默认0，表示无限制。当客户端连接到达上限后，Redis会拒绝新的连接\n\n  ```bash\n  maxclients count\n  ```\n\n  客户端闲置等待最大时长，达到最大值后关闭对应连接。如需关闭该功能，设置为 0\n\n  ```bash\n  timeout seconds\n  ```\n\n  #### 1.5.3  日志配置\n\n  设置服务器以指定日志记录级别\n\n  ```bash\n  loglevel debug|verbose|notice|warning\n  ```\n\n  日志记录文件名\n\n  ```bash\n  logfile filename\n  ```\n\n  注意：日志级别开发期设置为verbose即可，生产环境中配置为notice，简化日志输出量，降低写日志IO的频度。\n\n  ### 1.6 Redis基本操作\n\n  #### 1.6.1  命令行模式工具使用思考\n\n  功能性命令\n\n  帮助信息查阅\n\n  退出指令\n\n  清除屏幕信息\n\n  #### 1.6.2  信息读写\n\n  设置 key，value 数据\n\n  ```bash\n  set key value\n  ```\n\n  范例\n\n  ```bash\n  set name itheima\n  ```\n\n  根据 key 查询对应的 value，如果不存在，返回空（nil）\n\n  ```bash\n  get key\n  ```\n\n  范例\n\n  ```bash\n  get name\n  ```\n\n  #### 1.6.3  帮助信息\n\n  获取命令帮助文档\n\n  ```bash\n  help [command]\n  ```\n\n  范例\n\n  ```bash\n  help set\n  ```\n\n  获取组中所有命令信息名称\n\n  ```bash\n  help [@group-name]\n  ```\n\n  范例\n\n  ```bash\n  help @string\n  ```\n\n  1.6.4  退出命令行客户端模式\n\n  退出客户端\n\n  ````bash\n  quitexit\n  ````\n\n  快捷键\n\n  ```bash\n  Ctrl+C\n  ```\n\n  #### 1.6.4  redis入门总结\n\n  到这里，Redis 入门的相关知识，我们就全部学习完了，再来回顾一下，这个部分我们主要讲解了哪些内容呢？\n\n  首先，我们对Redis进行了一个简单介绍，包括NoSQL的概念、Redis的概念等。\n\n  然后，我们介绍了Redis 的下载与安装。包括下载与安装、服务器与客户端启动、以及相关配置文件（3类）。\n\n  最后，我们介绍了Redis 的基本操作。包括数据读写、退出与帮助信息获取。\n\n  ## 2. 数据类型\n\n  在这个部分，我们将学习一共要学习三大块内容，首先需要了解一下数据类型，接下来将针对着我们要学习的数据类型进行逐一的讲解，如string、hash、list、set等，最后我们通过一个案例来总结前面的数据类型的使用场景。\n\n  ### 2.1  数据存储类型介绍\n\n  #### 2.1.1  业务数据的特殊性\n\n  在讲解数据类型之前，我们得先思考一个问题，数据类型既然是用来描述数据的存储格式的，如果你不知道哪些数据未来会进入到我们来的redis中，那么对应的数据类型的选择，你就会出现问题，我们一块来看一下：\n\n  （1）原始业务功能设计\n\n  秒杀。他这个里边数据变化速度特别的快，访问量也特别的高，用户大量涌入以后都会针对着一部分数据进行操作，这一类要记住。\n\n  618活动。对于我们京东的618活动、以及天猫的双11活动，相信大家不用说都知道这些数据一定要进去，因为他们的访问频度实在太高了。\n\n  排队购票。我们12306的票务信息。这些信息在原始设计的时候，他们就注定了要进redis。\n\n  （2）运营平台监控到的突发高频访问数据\n\n  此类平台临时监控到的这些数据，比如说现在出来的一个八卦的信息，这个新闻一旦出现以后呢，顺速的被围观了，那么这个时候，这个数据就会变得访量特别高，那么这类信息也要进入进去。\n\n  （3）高频、复杂的统计数据\n\n  在线人数。比如说直播现在很火，直播里边有很多数据，例如在线人数。进一个人出一个人，这个数据就要跳动，那么这个访问速度非常的快，而且访量很高，并且它里边有一个复杂的数据统计，在这里这种信息也要进入到我们的redis中。\n\n  投票排行榜。投票投票类的信息他的变化速度也比较快，为了追求一个更快的一个即时投票的名次变化，这种数据最好也放到redis中。\n\n  #### 2.1.2  Redis 数据类型(5种常用)\n\n  基于以上数据特征我们进行分析，最终得出来我们的Redis中要设计5种 数据类型：\n\n  string、hash、list、set、sorted_set/zset（应用性较低）\n\n  ### 2.2  string数据类型\n\n  在学习第一个数据类型之前，先给大家介绍一下，在随后这部分内容的学习过程中，我们每一种数据类型都分成三块来讲：首先是讲下它的基本操作，接下来讲一些它的扩展操作，最后我们会去做一个小的案例分析。\n\n  #### 2.2.1Redis 数据存储格式\n\n  在学习string这个数据形式之前，我们先要明白string到底是修饰什么的。我们知道redis 自身是一个 Map，其中所有的数据都是采用 key : value 的形式存储。\n\n  对于这种结构来说，我们用来存储数据一定是一个值前面对应一个名称。我们通过名称来访问后面的值。按照这种形势，我们可以对出来我们的存储格式。前面这一部分我们称为key。后面的一部分称为value，而我们的数据类型，他一定是修饰value的。\n\n  ![](Redis基础.assets/redis存储空间.png)\n\n  数据类型指的是存储的数据的类型，也就是 value 部分的类型，key 部分永远都是字符串。\n\n  #### 2.2.2  string 类型\n\n  （1）存储的数据：单个数据，最简单的数据存储类型，也是最常用的数据存储类型。\n\n  string，他就是存一个字符串儿，注意是value那一部分是一个字符串，它是redis中最基本、最简单的存储数据的格式。\n\n  （2）存储数据的格式：一个存储空间保存一个数据\n\n  每一个空间中只能保存一个字符串信息，这个信息里边如果是存的纯数字，他也能当数字使用，我们来看一下，这是我们的数据的存储空间。\n\n  （3）存储内容：通常使用字符串，如果字符串以整数的形式展示，可以作为数字操作使用.\n\n  ![](Redis基础.assets/redis存储空间2.png)\n\n  一个key对一个value，而这个itheima就是我们所说的string类型，当然它也可以是一个纯数字的格式。\n\n  #### 2.2.3  string 类型数据的基本操作\n\n  （1）基础指令\n\n  添加/修改数据添加/修改数据\n\n  ```\n  set key value\n  ```\n\n  获取数据\n\n  ```\n  get key\n  ```\n\n  删除数据\n\n  ```\n  del key\n  ```\n\n  判定性添加数据\n\n  ```\n  setnx key value\n  ```\n\n  添加/修改多个数据\n\n  ```\n  mset key1 value1 key2 value2 …\n  ```\n\n  获取多个数据\n\n  ```\n  mget key1 key2 …\n  ```\n\n  获取数据字符个数（字符串长度）\n\n  ```\n  strlen key\n  ```\n\n  追加信息到原始信息后部（如果原始信息存在就追加，否则新建）\n\n  ```\n  append key value\n  ```\n\n  （2）单数据操作与多数据操作的选择之惑\n\n  即set 与mset的关系。这对于这两个操作来说，没有什么你应该选哪个，而是他们自己的特征是什么，你要根据这个特征去比对你的业务，看看究竟适用于哪个。\n\n  ![](Redis基础.assets/set.png)\n\n  假如说这是我们现在的服务器，他要向redis要数据的话，它会发出一条指令。那么当这条指令发过来的时候，比如说是这个set指令过来，那么它会把这个结果返回给你，这个时候我们要思考这里边一共经过了多长时间。\n\n  首先，发送set指令要时间，这是网络的一个时间，接下来redis要去运行这个指令要消耗时间，最终把这个结果返回给你又有一个时间，这个时间又是一个网络的时间，那我们可以理解为：一个指令发送的过程中需要消耗这样的时间.\n\n  但是如果说现在不是一条指令了，你要发3个set的话，还要多长时间呢？对应的发送时间要乘3了，因为这是三个单条指令,而运行的操作时间呢，它也要乘3了，但最终返回的也要发3次，所以这边也要乘3。\n\n  于是我们可以得到一个结论：单指令发3条它需要的时间，假定他们两个一样，是6个网络时间加3个处理时间，如果我们把它合成一个mset呢，我们想一想。\n\n  假如说用多指令发3个指令的话，其实只需要发一次就行了。这样我们可以得到一个结论，多指令发3个指令的话，其实它是两个网络时间加上3个redis的操作时间，为什么这写一个小加号呢，就是因为毕竟发的信息量变大了，所以网络时间有可能会变长。\n\n  那么通过这张图，你就可以得到一个结论，我们单指令和多指令他们的差别就在于你发送的次数是多还是少。当你影响的数据比较少的时候，你可以用单指令，也可以用多指令。但是一旦这个量大了，你就要选择多指令了，他的效率会高一些。\n\n  ### 2.3  string 类型数据的扩展操作\n\n  #### 2.3.1  string 类型数据的扩展操作\n\n  下面我们来看一string的扩展操作，分成两大块：一块是对数字进行操作的，第二块是对我们的key的时间进行操作的。\n\n  设置数值数据增加指定范围的值\n\n  ```bash\n  incr keyincrby key incrementincrbyfloat key increment\n  ```\n\n  设置数值数据减少指定范围的值\n\n  ```bash\n  decr keydecrby key increment\n  ```\n\n  设置数据具有指定的生命周期\n\n  ```bash\n  setex key seconds valuepsetex key milliseconds value\n  ```\n\n  #### 2.3.2  string 类型数据操作的注意事项\n\n  (1)数据操作不成功的反馈与数据正常操作之间的差异\n\n  表示运行结果是否成功\n\n  (integer) 0  → false                 失败\n\n  (integer) 1  → true                  成功\n\n  表示运行结果值\n\n  (integer) 3  → 3                        3个\n\n  (integer) 1  → 1                         1个\n\n  (2)数据未获取到时，对应的数据为（nil），等同于null\n\n  (3)数据最大存储量：512MB\n\n  (4)string在redis内部存储默认就是一个字符串，当遇到增减类操作incr，decr时会转成数值型进行计算\n\n  (5)按数值进行操作的数据，如果原始数据不能转成数值，或超越了redis 数值上限范围，将报错\n  9223372036854775807（java中Long型数据最大值，Long.MAX_VALUE）\n\n  (6)redis所有的操作都是原子性的，采用单线程处理所有业务，命令是一个一个执行的，因此无需考虑并发带来的数据影响.\n\n  ### 2.4string应用场景与key命名约定\n\n  #### 2.4.1  应用场景\n\n  它的应用场景在于：主页高频访问信息显示控制，例如新浪微博大V主页显示粉丝数与微博数量。\n\n  ![](Redis基础.assets/string应用场景.png)\n\n  我们来思考一下：这些信息是不是你进入大V的页面儿以后就要读取这写信息的啊，那这种信息一定要存储到我们的redis中，因为他的访问量太高了！那这种数据应该怎么存呢？我们来一块儿看一下方案！\n\n  #### 2.4.2  解决方案\n\n  （1）在redis中为大V用户设定用户信息，以用户主键和属性值作为key，后台设定定时刷新策略即可。\n\n  ```markdown\n  eg:\tuser:id:3506728370:fans\t\t→\t12210947eg:\tuser:id:3506728370:blogs\t→\t6164eg:\tuser:id:3506728370:focuses\t→\t83\n  ```\n\n  （2）也可以使用json格式保存数据\n\n  ```markdown\n  eg:\tuser:id:3506728370    →\t{“fans”：12210947，“blogs”：6164，“ focuses ”：83 }\n  ```\n\n  （3） key 的设置约定\n\n  数据库中的热点数据key命名惯例\n\n  |       | **表名** | **主键名** | 主键值    | **字段名** |\n  | ----- | -------- | ---------- | --------- | ---------- |\n  | eg1： | order    | id         | 29437595  | name       |\n  | eg2： | equip    | id         | 390472345 | type       |\n  | eg3： | news     | id         | 202004150 | title      |\n\n  ### 2.5  hash的基本操作\n\n  下面我们来学习第二个数据类型hash。\n\n  #### 2.5.1  数据存储的困惑\n\n  对象类数据的存储如果具有较频繁的更新需求操作会显得笨重！\n\n  在正式学习之前，我们先来看一个关于数据存储的困惑：\n\n  ![](Redis基础.assets/hash存储.png)\n\n  比如说前面我们用以上形式存了数据，如果我们用单条去存的话，它存的条数会很多。但如果我们用json格式，它存一条数据就够了。问题来了，假如说现在粉丝数量发生变化了，你要把整个值都改了。但是用单条存的话就不存在这个问题，你只需要改其中一个就行了。这个时候我们就想，有没有一种新的存储结构，能帮我们解决这个问题呢。\n\n  我们一块儿来分析一下：\n\n  ![](Redis基础.assets/数据.png)\n\n  如上图所示：单条的话是对应的数据在后面放着。仔细观察：我们看左边是不是长得都一模一样啊，都是对应的表名、ID等的一系列的东西。我们可以将右边红框中的这个区域给他封起来。\n\n  那如果要是这样的形式的话，如下图，我们把它一合并，并把右边的东西给他变成这个格式，这不就行了吗？\n\n  ![](Redis基础.assets/hash数据.png)\n\n  这个图其实大家并不陌生，第一，你前面学过一个东西叫hashmap不就这格式吗？第二，redis自身不也是这格式吗？那是什么意思呢？注意，这就是我们要讲的第二种格式，hash。\n\n  ![](Redis基础.assets/hash结构.png)\n\n  在右边对应的值，我们就存具体的值，那左边儿这就是我们的key。问题来了，那中间的这一块叫什么呢？这个东西我们给他起个名儿，叫做field字段。那么右边儿整体这块儿空间我们就称为hash，也就是说hash是存了一个key value的存储空间。\n\n  #### 2.5.2  hash 类型\n\n  新的存储需求：对一系列存储的数据进行编组，方便管理，典型应用存储对象信息\n\n  需要的存储结构：一个存储空间保存多个键值对数据\n\n  hash类型：底层使用哈希表结构实现数据存储\n\n  ![](Redis基础.assets/hash结构图.png)\n\n  如上图所示，这种结构叫做hash，左边一个key，对右边一个存储空间。这里要明确一点，右边这块儿存储空间叫hash，也就是说hash是指的一个数据类型，他指的不是一个数据，是这里边的一堆数据，那么它底层呢，是用hash表的结构来实现的。\n\n  值得注意的是：\n\n  如果field数量较少，存储结构优化为类数组结构\n\n  如果field数量较多，存储结构使用HashMap结构\n\n  #### 2.5.3  hash 类型数据的基本操作\n\n  添加/修改数据\n\n  ```bash\n  hset key field value\n  ```\n\n  获取数据\n\n  ```bash\n  hget key fieldhgetall key\n  ```\n\n  删除数据\n\n  ```bash\n  hdel key field1 [field2]\n  ```\n\n  设置field的值，如果该field存在则不做任何操作\n\n  ```bash\n  hsetnx key field value\n  ```\n\n  添加/修改多个数据\n\n  ```bash\n  hmset key field1 value1 field2 value2 …\n  ```\n\n  获取多个数据\n\n  ```bash\n  hmget key field1 field2 …\n  ```\n\n  获取哈希表中字段的数量\n\n  ```bash\n  hlen key\n  ```\n\n  获取哈希表中是否存在指定的字段\n\n  ```bash\n  hexists key field\n  ```\n\n  ### 2.6  hash的拓展操作\n\n  在看完hash的基本操作后，我们再来看他的拓展操作，他的拓展操作相对比较简单：\n\n  #### 2.6.1  hash 类型数据扩展操作\n\n  获取哈希表中所有的字段名或字段值\n\n  ```\n  hkeys keyhvals key\n  ```\n\n  设置指定字段的数值数据增加指定范围的值\n\n  ```\n  hincrby key field incrementhincrbyfloat key field increment\n  ```\n\n  #### 2.6.2  hash类型数据操作的注意事项\n\n  (1)hash类型中value只能存储字符串，不允许存储其他数据类型，不存在嵌套现象。如果数据未获取到，对应的值为（nil）。\n\n  (2）每个 hash 可以存储 232 - 1 个键值对\n  hash类型十分贴近对象的数据存储形式，并且可以灵活添加删除对象属性。但hash设计初衷不是为了存储大量对象而设计 的，切记不可滥用，更不可以将hash作为对象列表使用。\n\n  (3)hgetall 操作可以获取全部属性，如果内部field过多，遍历整体数据效率就很会低，有可能成为数据访问瓶颈。\n\n  ### 2.7  hash应用场景\n\n  #### 2.7.1  应用场景\n\n  双11活动日，销售手机充值卡的商家对移动、联通、电信的30元、50元、100元商品推出抢购活动，每种商品抢购上限1000  张。\n\n  ![](Redis基础.assets/hash应用.png)\n\n  也就是商家有了，商品有了，数量有了。最终我们的用户买东西就是在改变这个数量。那你说这个结构应该怎么存呢？对应的商家的ID作为key，然后这些充值卡的ID作为field，最后这些数量作为value。而我们所谓的操作是其实就是increa这个操作，只不过你传负值就行了。看一看对应的解决方案：\n\n  #### 2.7.2  解决方案\n\n  以商家id作为key\n\n  将参与抢购的商品id作为field\n\n  将参与抢购的商品数量作为对应的value\n\n  抢购时使用降值的方式控制产品数量\n\n  注意：实际业务中还有超卖等实际问题，这里不做讨论\n\n  ### 2.8  list基本操作\n\n  前面我们存数据的时候呢，单个数据也能存，多个数据也能存，但是这里面有一个问题，我们存多个数据用hash的时候它是没有顺序的。我们平时操作，实际上数据很多情况下都是有顺序的，那有没有一种能够用来存储带有顺序的这种数据模型呢，list就专门来干这事儿。\n\n  #### 2.8.1  list 类型\n\n  数据存储需求：存储多个数据，并对数据进入存储空间的顺序进行区分\n\n  需要的存储结构：一个存储空间保存多个数据，且通过数据可以体现进入顺序\n\n  list类型：保存多个数据，底层使用双向链表存储结构实现\n\n  先来通过一张图，回忆一下顺序表、链表、双向链表。\n\n  ![](Redis基础.assets/list1.png)\n\n  list对应的存储结构是什么呢？里边存的这个东西是个列表，他有一个对应的名称。就是key存一个list的这样结构。对应的基本操作，你其实是可以想到的。\n\n  ![](Redis基础.assets/list2.png)\n\n  来看一下，因为它是双向的，所以他左边右边都能操作，它对应的操作结构两边都能进数据。这就是链表的一个存储结构。往外拿数据的时候怎么拿呢？通常是从一端拿，当然另一端也能拿。如果两端都能拿的话，这就是个双端队列，两边儿都能操作。如果只能从一端进一端出，这个模型咱们前面了解过，叫做栈。\n\n  #### 2.8.2 list 类型数据基本操作\n\n  最后看一下他的基本操作\n\n  添加/修改数据\n\n  ```bash\n  lpush key value1 [value2] ……rpush key value1 [value2] ……\n  ```\n\n  获取数据\n\n  ```bash\n  lrange key start stoplindex key indexllen key\n  ```\n\n  获取并移除数据\n\n  ```bash\n  lpop keyrpop key\n  ```\n\n  ### 2.9  list扩展操作\n\n  #### 2.9.1  list 类型数据扩展操作\n\n  移除指定数据\n\n  ```\n  lrem key count value\n  ```\n\n  规定时间内获取并移除数据\n\n  ```\n  blpop key1 [key2] timeoutbrpop key1 [key2] timeoutbrpoplpush source destination timeout\n  ```\n\n  #### 2.9.2  list 类型数据操作注意事项\n\n  （1）list中保存的数据都是string类型的，数据总容量是有限的，最多232 - 1 个元素(4294967295)。\n\n  （2）list具有索引的概念，但是操作数据时通常以队列的形式进行入队出队操作，或以栈的形式进行入栈出栈操作\n\n  （3）获取全部数据操作结束索引设置为-1\n\n  （4）list可以对数据进行分页操作，通常第一页的信息来自于list，第2页及更多的信息通过数据库的形式加载\n\n  \n\n  ### 2.10 list 应用场景\n\n  #### 2.10.1  应用场景\n\n  企业运营过程中，系统将产生出大量的运营数据，如何保障多台服务器操作日志的统一顺序输出？\n\n  ![](Redis基础.assets/list应用.png)\n\n  假如现在你有多台服务器，每一台服务器都会产生它的日志，假设你是一个运维人员，你想看它的操作日志，你怎么看呢？打开A机器的日志看一看，打开B机器的日志再看一看吗？这样的话你会可能会疯掉的！因为左边看的有可能它的时间是11:01，右边11:02，然后再看左边11:03，它们本身是连续的，但是你在看的时候就分成四个文件了，这个时候你看起来就会很麻烦。能不能把他们合并呢？答案是可以的！怎么做呢？建立起redis服务器。当他们需要记日志的时候，记在哪儿,全部发给redis。等到你想看的时候，通过服务器访问redis获取日志。然后得到以后，就会得到一个完整的日志信息。那么这里面就可以获取到完整的日志了，依靠什么来实现呢？就依靠我们的list的模型的顺序来实现。进来一组数据就往里加，谁先进来谁先加进去，它是有一定的顺序的。\n\n  #### 2.10.2  解决方案\n\n  依赖list的数据具有顺序的特征对信息进行管理\n\n  使用队列模型解决多路信息汇总合并的问题\n\n  使用栈模型解决最新消息的问题\n\n  ### 2.11  set 基本操作\n\n  #### 2.11.1 set类型\n\n  新的存储需求：存储大量的数据，在查询方面提供更高的效率\n\n  需要的存储结构：能够保存大量的数据，高效的内部存储机制，便于查询\n\n  set类型：与hash存储结构完全相同，仅存储键，不存储值（nil），并且值是不允许重复的\n\n  ![](Redis基础.assets/set模型.png)\n\n  通过这个名称，大家也基本上能够认识到和我们Java中的set完全一样。我们现在要存储大量的数据，并且要求提高它的查询效率。用list这种链表形式，它的查询效率是不高的，那怎么办呢？这时候我们就想，有没有高效的存储机制。其实前面咱讲Java的时候说过hash表的结构就非常的好，但是这里边我们已经有hash了，他做了这么一个设定，干嘛呢，他把hash的存储空间给改一下，右边你原来存数据改掉,全部存空，那你说数据放哪儿了？放到原来的filed的位置，也就在这里边存真正的值，那么这个模型就是我们的set 模型。\n\n  set类型：与hash存储结构完全相同，仅存储键，不存储值（nil），并且值是不允许重复的。\n\n  看一下它的整个结构：\n\n  ![](Redis基础.assets/set4.png)\n\n  #### 2.11.2 set类型数据的基本操作\n\n  添加数据\n\n  ```bash\n  sadd key member1 [member2]\n  ```\n\n  获取全部数据\n\n  ```bash\n  smembers key\n  ```\n\n  删除数据\n\n  ```bash\n  srem key member1 [member2]\n  ```\n\n  获取集合数据总量\n\n  ```bash\n  scard key\n  ```\n\n  判断集合中是否包含指定数据\n\n  ```bash\n  sismember key member\n  ```\n\n  随机获取集合中指定数量的数据\n\n  ```bash\n  srandmember key [count]\n  ```\n\n  随机获取集中的某个数据并将该数据移除集合\n\n  ```bash\n  spop key [count]\n  ```\n\n  ### 2.12  set 类型数据的扩展操作\n\n  #### 2.12.1  set 类型数据的扩展操作\n\n  求两个集合的交、并、差集\n\n  ```\n  sinter key1 [key2 …]  sunion key1 [key2 …]  sdiff key1 [key2 …]\n  ```\n\n  求两个集合的交、并、差集并存储到指定集合中\n\n  ```\n  sinterstore destination key1 [key2 …]  sunionstore destination key1 [key2 …]  sdiffstore destination key1 [key2 …]\n  ```\n\n  将指定数据从原始集合中移动到目标集合中\n\n  ```\n  smove source destination member\n  ```\n\n  通过下面一张图回忆一下交、并、差\n\n  ![](Redis基础.assets/交并差.png)\n\n  #### 2.12.2  set 类型数据操作的注意事项\n\n  set 类型不允许数据重复，如果添加的数据在 set 中已经存在，将只保留一份。\n\n  set 虽然与hash的存储结构相同，但是无法启用hash中存储值的空间。\n\n  ### 2.13  set应用场景\n\n  #### 2.13.1  set应用场景\n\n  （1）黑名单\n\n  资讯类信息类网站追求高访问量，但是由于其信息的价值，往往容易被不法分子利用，通过爬虫技术，  快速获取信息，个别特种行业网站信息通过爬虫获取分析后，可以转换成商业机密进行出售。例如第三方火 车票、机票、酒店刷票代购软件，电商刷评论、刷好评。\n\n  同时爬虫带来的伪流量也会给经营者带来错觉，产生错误的决策，有效避免网站被爬虫反复爬取成为每个网站都要考虑的基本问题。在基于技术层面区分出爬虫用户后，需要将此类用户进行有效的屏蔽，这就是黑名单的典型应用。\n\n  ps:不是说爬虫一定做摧毁性的工作，有些小型网站需要爬虫为其带来一些流量。\n\n  （2）白名单\n\n  对于安全性更高的应用访问，仅仅靠黑名单是不能解决安全问题的，此时需要设定可访问的用户群体， 依赖白名单做更为苛刻的访问验证。\n\n  #### 2.13.2  解决方案\n\n  基于经营战略设定问题用户发现、鉴别规则\n\n  周期性更新满足规则的用户黑名单，加入set集合\n\n  用户行为信息达到后与黑名单进行比对，确认行为去向\n\n  黑名单过滤IP地址：应用于开放游客访问权限的信息源\n\n  黑名单过滤设备信息：应用于限定访问设备的信息源\n\n  黑名单过滤用户：应用于基于访问权限的信息源\n\n  ### 2.14  实践案例\n\n  #### 2.14.1业务场景\n\n  使用微信的过程中，当微信接收消息后，会默认将最近接收的消息置顶，当多个好友及关注的订阅号同时发 送消息时，该排序会不停的进行交替。同时还可以将重要的会话设置为置顶。一旦用户离线后，再次打开微信时，消息该按照什么样的顺序显示。\n\n  我们分析一下：\n\n  ![](Redis基础.assets/set案例.png)\n\n  100这台手机代表你。而200、300、400这三台代表你好友的手机。在这里有一些东西需要交代一下，因为我们每个人的都会对自己的微信中的一些比较重要的人设置会话置顶，将他的那条对话放在最上面。我们假定这个人有两个会话置顶的好友，分别是400和500，而这里边就包含400.\n\n  下面呢，我们就来发这个消息，第一个发消息的是300，他发了个消息给100。发完以后，这个东西应该怎么存储呢？在这里面一定要分开，记录置顶的这些人的会话，对应的会话显示顺序和非置顶的一定要分两。\n\n  这里面我们创建两个模型，一个是普通的，一个是置顶的，而上面的这个置顶的用户呢，我们用set来存储，因为不重复。而下面这些因为有顺序，很容易想到用list去存储,不然你怎么表达顺序呢？\n\n  ![](Redis基础.assets/300.png)\n\n  那当300发给消息给100以后，这个时候我们先判定你在置顶人群中吗？不在,那好，300的消息对应的顺序就应该放在普通的列表里边。而在这里边，我们把300加进去。第一个数据也就是现在300。\n\n  ![](Redis基础.assets/400.png)\n\n  接下来400，发了个消息。判断一下，他是需要置顶的，所以400将进入list的置顶里边放着。当前还没有特殊的地方。\n\n  ![](Redis基础.assets/200.png)\n\n  再来200发消息了，和刚才的判定方法一样，先看在不在置顶里，不在的话进普通，然后在普通里边把200加入就行了，OK，到这里目前还没有顺序变化。\n\n  接下来200又发消息过来，同一个人给你连发了两条，那这个时候200的消息到达以后，先判断是否在置顶范围，不在，接下来他要放在list普通中，这里你要注意一点，因为这里边已经有200，所以进来以后先干一件事儿，把200杀掉，没有200，然后再把200加进来，那你想一下，现在这个位置顺序是什么呢？就是新的都在右边，对不对？\n\n  还记得我们说list模型，如果是一个双端队列，它是可以两头进两头出。当然我们双端从一头进一头出，这就是栈模型，现在咱们运用的就是list模型中的栈模型。\n\n  ![](Redis基础.assets/3002.png)\n\n  现在300发消息，先判定他在不在，不在，用普通的队列，接下来按照刚才的操作，不管你里边原来有没有300，我先把300杀掉，没了，200自然就填到300的位置了，他现在是list里面唯一一个，然后让300进来，注意是从右侧进来的，那么现在300就是最新的。\n\n  ![](Redis基础.assets/分析.png)\n\n  那么到这里呢，我们让100来读取消息。你觉得这个消息顺序应该是什么样的？首先置顶的400有一个，他跑在最上面，然后list普通如果出来的话，300是最新的消息，而200在他后面的。用这种形式，我们就可以做出来他的消息顺序来。\n\n  #### 2.14.2  解决方案\n\n  看一下最终的解决方案：\n\n  依赖list的数据具有顺序的特征对消息进行管理，将list结构作为栈使用\n\n  置顶与普通会话分别创建独立的list分别管理\n\n  当某个list中接收到用户消息后，将消息发送方的id从list的一侧加入list（此处设定左侧）\n\n  多个相同id发出的消息反复入栈会出现问题，在入栈之前无论是否具有当前id对应的消息，先删除对应id\n\n  推送消息时先推送置顶会话list，再推送普通会话list，推送完成的list清除所有数据\n  消息的数量，也就是微信用户对话数量采用计数器的思想另行记录，伴随list操作同步更新\n\n  #### 2.14.3  数据类型总结\n\n  总结一下，在整个数据类型的部分，我们主要介绍了哪些内容：\n\n  首先我们了解了一下数据类型，接下来针对着我们要学习的数据类型，进行逐一讲解了string、hash、list、set等，最后通过一个案例总结了一下前面的数据类型的使用场景。\n\n  ## 3. 常用指令\n\n  在这部分中呢，我们家学习两个知识，第一个是key的常用指令，第二个是数据库的常用指令。和前面我们学数据类型做一下区分，前面你学的那些指令呢，都是针对某一个数据类型操作的，现在学的都是对所有的操作的，来看一下，我们在学习Key的操作的时候，我们先想一下的操作我们应该学哪些东西:\n\n  ### 3.1  key 操作分析\n\n  #### 3.1.1  key应该设计哪些操作？\n\n  key是一个字符串，通过key获取redis中保存的数据\n\n  对于key自身状态的相关操作，例如：删除，判定存在，获取类型等\n\n  对于key有效性控制相关操作，例如：有效期设定，判定是否有效，有效状态的切换等\n\n  对于key快速查询操作，例如：按指定策略查询key\n\n  #### 3.1.2  key 基本操作\n\n  删除指定key\n\n  ```bash\n  del key\n  ```\n\n  获取key是否存在\n\n  ```bash\n  exists key\n  ```\n\n  获取key的类型\n\n  ```bash\n  type key\n  ```\n\n  3.1.3  拓展操作\n\n  排序\n\n  ```bash\n  sort\n  ```\n\n  改名\n\n  ```bash\n  rename key newkeyrenamenx key newkey\n  ```\n\n  #### 3.1.3  key 扩展操作（时效性控制）\n\n  为指定key设置有效期\n\n  ```bash\n  expire key secondspexpire key millisecondsexpireat key timestamppexpireat key milliseconds-timestamp\n  ```\n\n  获取key的有效时间\n\n  ```bash\n  ttl keypttl key\n  ```\n\n  切换key从时效性转换为永久性\n\n  ```bash\n  persist key\n  ```\n\n  #### 3.1.4  key 扩展操作（查询模式）\n\n  查询key\n\n  ```bash\n  keys pattern\n  ```\n\n  查询模式规则\n\n  *匹配任意数量的任意符号      ?\t配合一个任意符号\t[]\t匹配一个指定符号\n\n  ```bash\n  keys *  keys    查询所有it*  keys       查询所有以it开头*heima          查询所有以heima结尾keys ??heima    查询所有前面两个字符任意，后面以heima结尾 查询所有以keys user:?     user:开头，最后一个字符任意keys u[st]er:1  查询所有以u开头，以er:1结尾，中间包含一个字母，s或t\n  ```\n\n  ### 3.2  数据库指令\n\n  #### 3.2.1  key 的重复问题\n\n  在这个地方我们来讲一下数据库的常用指令，在讲这个东西之前，我们先思考一个问题：\n\n  假如说你们十个人同时操作redis，会不会出现key名字命名冲突的问题。\n\n  一定会，为什么?因为你的key是由程序而定义的。你想写什么写什么，那在使用的过程中大家都在不停的加，早晚有一天他会冲突的。\n\n  redis在使用过程中，伴随着操作数据量的增加，会出现大量的数据以及对应的key。\n\n  那这个问题我们要不要解决？要！怎么解决呢？我们最好把数据进行一个分类，除了命名规范我们做统一以外，如果还能把它分开，这样是不是冲突的机率就会小一些了，这就是咱们下面要说的解决方案！\n\n  #### 3.2.2  解决方案\n\n  redis为每个服务提供有16个数据库，编号从0到15\n\n  每个数据库之间的数据相互独立\n\n  ![](Redis基础.assets/数据库.png)\n\n  在对应的数据库中划出一块区域，说他就是几，你就用几那块，同时，其他的这些都可以进行定义，一共是16个，这里边需要注意一点，他们这16个共用redis的内存。没有说谁大谁小，也就是说数字只是代表了一块儿区域，区域具体多大未知。这是数据库的一个分区的一个策略！\n\n  #### 3.2.3   数据库的基本操作\n\n  切换数据库\n\n  ```\n  select index\n  ```\n\n  其他操作\n\n  ```\n  ping\n  ```\n\n  #### 3.2.4  数据库扩展操作\n\n  数据移动\n\n  ```\n  move key db\n  ```\n\n  数据总量\n\n  ```\n  dbsize\n  ```\n\n  数据清除\n\n  ```\n  flushdb  flushall\n  ```\n\n  ## 4. Jedis\n\n  在学习完redis后，我们现在就要用Java来连接redis了，也就是我们的这一章要学的Jedis了。在这个部分，我们主要讲解以下3个内容：\n\n  HelloWorld（Jedis版）\n\n  Jedis简易工具类开发\n\n  可视化客户端\n\n  ### 4.1  Jedis简介\n\n  #### 4.1.1  编程语言与redis\n\n  ![](Redis基础.assets/jedis1.png)\n\n  对于我们现在的数据来说，它是在我们的redis中，而最终我们是要做程序。那么程序就要和我们的redis进行连接。干什么事情呢？两件事：程序中有数据的时候，我们要把这些数据全部交给redis管理。同时，redis中的数据还能取出来，回到我们的应用程序中。那在这个过程中，在Java与redis之间打交道的这个东西就叫做Jedis.简单说，Jedis就是提供了Java与redis的连接服务的，里边有各种各样的API接口，你可以去调用它。\n\n  除了Jedis外，还有没有其他的这种连接服务呢？其实还有很多，了解一下：\n\n  Java语言连接redis服务 Jedis（SpringData、Redis 、 Lettuce）\n\n  其它语言：C 、C++ 、C# 、Erlang、Lua 、Objective-C 、Perl 、PHP 、Python 、Ruby 、Scala\n\n  #### 4.1.2  准备工作\n\n  (1)jar包导入\n\n  下载地址：https://mvnrepository.com/artifact/redis.clients/jedis\n\n  基于maven\n\n  ```xml\n  <dependency><groupId>redis.clients</groupId><artifactId>jedis</artifactId><version>2.9.0</version></dependency>\n  ```\n\n  (2)客户端连接redis\n\n  连接redis\n\n  ```\n  Jedis jedis = new Jedis("localhost", 6379);\n  ```\n\n  操作redis\n\n  ```\n  jedis.set("name", "itheima");  jedis.get("name");\n  ```\n\n  关闭redis连接\n\n  ```\n  jedis.close();\n  ```\n\n  API文档\n\n  http://xetorthio.github.io/jedis/\n\n  #### 4.1.3 代码实现\n\n  创建：com.itheima.JedisTest\n\n  ```java\n  public class JedisTest {    public static void main(String[] args) {        //1.获取连接对象        Jedis jedis = new Jedis("192.168.40.130",6379);        //2.执行操作        jedis.set("age","39");        String hello = jedis.get("hello");        System.out.println(hello);        jedis.lpush("list1","a","b","c","d");        List<String> list1 = jedis.lrange("list1", 0, -1);        for (String s:list1 ) {            System.out.println(s);        }        jedis.sadd("set1","abc","abc","def","poi","cba");        Long len = jedis.scard("set1");        System.out.println(len);        //3.关闭连接        jedis.close();    }}\n  ```\n\n  \n\n  ### 4.2  Jedis简易工具类开发\n\n  前面我们做的程序还是有点儿小问题，就是我们的Jedis对象的管理是我们自己创建的，真实企业开发中是不可能让你去new一个的，那接下来咱们就要做一个工具类，简单来说，就是做一个创建Jedis的这样的一个工具。\n\n  #### 4.2.1  基于连接池获取连接\n\n  JedisPool：Jedis提供的连接池技术 \n\n  poolConfig:连接池配置对象 \n\n  host:redis服务地址\n\n  port:redis服务端口号\n\n  \n\n  JedisPool的构造器如下：\n\n  ```java\n  public JedisPool(GenericObjectPoolConfig poolConfig, String host, int port) {this(poolConfig, host, port, 2000, (String)null, 0, (String)null);}\n  ```\n\n  #### 4.2.2  封装连接参数\n\n  创建jedis的配置文件：jedis.properties\n\n  ```properties\n  jedis.host=192.168.40.130  jedis.port=6379  jedis.maxTotal=50  jedis.maxIdle=10\n  ```\n\n  #### 4.2.3  加载配置信息\n\n   创建JedisUtils：com.itheima.util.JedisUtils，使用静态代码块初始化资源\n\n  ```java\n  public class JedisUtils {    private static int maxTotal;    private static int maxIdel;    private static String host;    private static int port;    private static JedisPoolConfig jpc;    private static JedisPool jp;    static {        ResourceBundle bundle = ResourceBundle.getBundle("redis");        maxTotal = Integer.parseInt(bundle.getString("redis.maxTotal"));        maxIdel = Integer.parseInt(bundle.getString("redis.maxIdel"));        host = bundle.getString("redis.host");        port = Integer.parseInt(bundle.getString("redis.port"));        //Jedis连接池配置        jpc = new JedisPoolConfig();        jpc.setMaxTotal(maxTotal);        jpc.setMaxIdle(maxIdel);        jp = new JedisPool(jpc,host,port);    }}\n  ```\n\n  #### 4.2.4  获取连接\n\n   对外访问接口，提供jedis连接对象，连接从连接池获取，在JedisUtils中添加一个获取jedis的方法：getJedis\n\n  ```java\n  public static Jedis getJedis(){\tJedis jedis = jedisPool.getResource();\treturn jedis;}\n  ```\n\n  \n\n  ### 4.3  可视化客户端\n\n  4.3.1  Redis Desktop Manager\n\n  ![](Redis基础.assets/可视化.png)\n\n  ## 5. 持久化\n\n  下面呢，进入到持久化的学习.这部分内容理解的东西多，操作的东西少。在这个部分，我们将讲解四个东西：\n\n  持久化简介\n\n  RDB\n\n  AOF\n\n  RDB与AOF区别\n\n  ### 5.1  持久化简介\n\n  #### 5.1.1  场景-意外断电\n\n  不知道大家有没有遇见过，就是正工作的时候停电了，如果你用的是笔记本电脑还好，你有电池，但如果你用的是台式机呢，那恐怕就比较灾难了，假如你现在正在写一个比较重要的文档，如果你要使用的是word，这种办公自动化软件的话，他一旦遇到停电，其实你不用担心，因为它会给你生成一些其他的文件。\n\n  ![](Redis基础.assets/持久化案例1.png)\n\n  其实他们都在做一件事儿，帮你自动恢复，有了这个文件，你前面的东西就不再丢了。那什么是自动恢复呢？你要先了解他的整个过程。\n\n  我们说自动恢复，其实基于的一个前提就是他提前把你的数据给存起来了。你平常操作的所有信息都是在内存中的，而我们真正的信息是保存在硬盘中的，内存中的信息断电以后就消失了，硬盘中的信息断电以后还可以保留下来！\n\n  ![](Redis基础.assets/备份.png)\n\n  我们将文件由内存中保存到硬盘中的这个过程，我们叫做数据保存，也就叫做持久化。但是把它保存下来不是你的目的，最终你还要把它再读取出来，它加载到内存中这个过程，我们叫做数据恢复，这就是我们所说的word为什么断电以后还能够给你保留文件，因为它执行了一个自动备份的过程，也就是通过自动的形式，把你的数据存储起来，那么有了这种形式以后，我们的数据就可以由内存到硬盘上实现保存。\n\n  #### 5.1.2  什么是持久化\n\n  (1)什么是持久化\n\n  利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化 。\n\n  持久化用于防止数据的意外丢失，确保数据安全性。\n\n  (2)持久化过程保存什么？\n\n  我们知道一点，计算机中的数据全部都是二进制，如果现在我要你给我保存一组数据的话，你有什么样的方式呢，其实最简单的就是现在长什么样，我就记下来就行了，那么这种是记录纯粹的数据，也叫做快照存储，也就是它保存的是某一时刻的数据状态。\n\n  还有一种形式，它不记录你的数据，它记录你所有的操作过程，比如说大家用idea的时候，有没有遇到过写错了ctrl+z撤销，然后ctrl+y还能恢复，这个地方它也是在记录，但是记录的是你所有的操作过程，那我想问一下，操作过程，我都给你留下来了，你说数据还会丢吗？肯定不会丢，因为你所有的操作过程我都保存了。这种保存操作过程的存储，用专业术语来说可以说是日志，这是两种不同的保存数据的形式啊。\n\n  ![](Redis基础.assets/持久化2.png)\n\n  \n\n  总结一下：\n\n  第一种：将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据。\n\n  第二种：将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程。\n\n  ### 5.2  RDB\n\n  #### 5.2.1  save指令\n\n  手动执行一次保存操作\n\n  ```\n  save\n  ```\n\n  **save指令相关配置**\n\n  设置本地数据库文件名，默认值为 dump.rdb，通常设置为dump-端口号.rdb\n\n  ```\n  dbfilename filename\n  ```\n\n  设置存储.rdb文件的路径，通常设置成存储空间较大的目录中，目录名称data\n\n  ```\n  dir path\n  ```\n\n  设置存储至本地数据库时是否压缩数据，默认yes，设置为no，节省 CPU 运行时间，但存储文件变大\n\n  ```\n  rdbcompression yes|no\n  ```\n\n  设置读写文件过程是否进行RDB格式校验，默认yes，设置为no，节约读写10%时间消耗，单存在数据损坏的风险\n\n  ```\n  rdbchecksum yes|no\n  ```\n\n  **save指令工作原理**\n\n  ![](Redis基础.assets/rdb启动方式.png)\n\n  ![](Redis基础.assets/启动方式2.png)\n\n  需要注意一个问题，来看一下，现在有四个客户端各自要执行一个指令，把这些指令发送到redis服务器后，他们执行有一个先后顺序问题，假定就是按照1234的顺序放过去的话，那会是什么样的？\n\n  记得redis是个单线程的工作模式，它会创建一个任务队列，所有的命令都会进到这个队列里边，在这儿排队执行，执行完一个消失一个，当所有的命令都执行完了，OK，结果达到了。\n\n  但是如果现在我们执行的时候save指令保存的数据量很大会是什么现象呢？\n\n  他会非常耗时，以至于影响到它在执行的时候，后面的指令都要等，所以说这种模式是不友好的，这是save指令对应的一个问题，当cpu执行的时候会阻塞redis服务器，直到他执行完毕，所以说我们不建议大家在线上环境用save指令。\n\n  #### 5.2.2  bgsave指令\n\n  之前我们讲到了当save指令的数据量过大时，单线程执行方式造成效率过低，那应该如何处理？\n\n  此时我们可以使用：**bgsave**指令，bg其实是background的意思，后台执行的意思\n\n  手动启动后台保存操作，但不是立即执行\n\n  ```properties\n  bgsave\n  ```\n\n  **bgsave指令相关配置**\n\n  后台存储过程中如果出现错误现象，是否停止保存操作，默认yes\n\n  ```properties\n  stop-writes-on-bgsave-error yes|no\n  ```\n\n  其 他\n\n  ```properties\n  dbfilename filename  dir path  rdbcompression yes|no  rdbchecksum yes|no\n  ```\n\n  **bgsave指令工作原理**\n\n  ![](Redis基础.assets/rdb启动方式3.png)\n\n  当执行bgsave的时候，客户端发出bgsave指令给到redis服务器。注意，这个时候服务器马上回一个结果告诉客户端后台已经开始了，与此同时它会创建一个子进程，使用Linux的fork函数创建一个子进程，让这个子进程去执行save相关的操作，此时我们可以想一下，我们主进程一直在处理指令，而子进程在执行后台的保存，它会不会干扰到主进程的执行吗？\n\n  答案是不会，所以说他才是主流方案。子进程开始执行之后，它就会创建啊RDB文件把它存起来，操作完以后他会把这个结果返回，也就是说bgsave的过程分成两个过程，第一个是服务端拿到指令直接告诉客户端开始执行了；另外一个过程是一个子进程在完成后台的保存操作，操作完以后回一个消息。\n\n  #### 5.2.3 save配置自动执行\n\n  设置自动持久化的条件，满足限定时间范围内key的变化数量达到指定数量即进行持久化\n\n  ```properties\n  save second changes\n  ```\n\n  参数\n\n  second：监控时间范围\n\n  changes：监控key的变化量\n\n  范例：\n\n  ```markdown\n  save 900 1save 300 10save 60 10000\n  ```\n\n  其他相关配置：\n\n  ```markdown\n  dbfilename filenamedir pathrdbcompression yes|nordbchecksum yes|nostop-writes-on-bgsave-error yes|no\n  ```\n\n  **save配置工作原理**\n\n  ![](Redis基础.assets/启动方式4.png)\n\n  #### 5.2.4 RDB三种启动方式对比\n\n  | 方式           | save指令 | bgsave指令 |\n  | -------------- | -------- | ---------- |\n  | 读写           | 同步     | 异步       |\n  | 阻塞客户端指令 | 是       | 否         |\n  | 额外内存消耗   | 否       | 是         |\n  | 启动新进程     | 否       | 是         |\n\n  **RDB特殊启动形式**\n\n  服务器运行过程中重启\n\n  ```bash\n  debug reload\n  ```\n\n  关闭服务器时指定保存数据\n\n  ```bash\n  shutdown save\n  ```\n\n  全量复制（在主从复制中详细讲解）\n\n  \n\n  **RDB优点：**\n\n  - RDB是一个紧凑压缩的二进制文件，存储效率较高\n  - RDB内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景\n  - RDB恢复数据的速度要比AOF快很多\n  - 应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于灾难恢复。\n\n  **RDB缺点**\n\n  - RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性丢失数据\n  - bgsave指令每次运行要执行fork操作创建子进程，要牺牲掉一些性能\n  - Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现各版本服务之间数据格式无法兼容现象\n\n  \n\n  ### 5.3  AOF\n\n  为什么要有AOF,这得从RDB的存储的弊端说起：\n\n  - 存储数据量较大，效率较低，基于快照思想，每次读写都是全部数据，当数据量巨大时，效率非常低\n  - 大数据量下的IO性能较低\n  - 基于fork创建子进程，内存产生额外消耗\n  - 宕机带来的数据丢失风险\n\n  \n\n  那解决的思路是什么呢？\n\n  - 不写全数据，仅记录部分数据\n  - 降低区分数据是否改变的难度，改记录数据为记录操作过程\n  - 对所有操作均进行记录，排除丢失数据的风险\n\n  #### 5.3.1 AOF概念\n\n  **AOF**(append only file)持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令 达到恢复数据的目的。**与RDB相比可以简单理解为由记录数据改为记录数据产生的变化**\n\n  AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式\n\n  **AOF写数据过程**\n\n  ![](Redis基础.assets/1.png)\n\n  **启动AOF相关配置**\n\n  开启AOF持久化功能，默认no，即不开启状态\n\n  ```properties\n  appendonly yes|no\n  ```\n\n  AOF持久化文件名，默认文件名为appendonly.aof，建议配置为appendonly-端口号.aof\n\n  ```properties\n  appendfilename filename\n  ```\n\n  AOF持久化文件保存路径，与RDB持久化文件保持一致即可\n\n  ```properties\n  dir\n  ```\n\n  AOF写数据策略，默认为everysec\n\n  ```properties\n  appendfsync always|everysec|no\n  ```\n\n  \n\n  #### 5.3.2 AOF执行策略\n\n  AOF写数据三种策略(appendfsync)\n\n  - **always**(每次）：每次写入操作均同步到AOF文件中数据零误差，性能较低，不建议使用。\n\n\n  - **everysec**（每秒）：每秒将缓冲区中的指令同步到AOF文件中，在系统突然宕机的情况下丢失1秒内的数据 数据准确性较高，性能较高，建议使用，也是默认配置\n\n\n  - **no**（系统控制）：由操作系统控制每次同步到AOF文件的周期，整体过程不可控\n\n  #### 5.3.3 AOF重写\n\n  场景：AOF写数据遇到的问题，如果连续执行如下指令该如何处理\n\n  ![](Redis基础.assets/2.png)\n\n  **什么叫AOF重写？**\n\n  随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积。AOF文件重 写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。简单说就是将对同一个数据的若干个条命令执行结 果转化成最终结果数据对应的指令进行记录。\n\n  **AOF重写作用**\n\n  - 降低磁盘占用量，提高磁盘利用率\n  - 提高持久化效率，降低持久化写时间，提高IO性能\n  - 降低数据恢复用时，提高数据恢复效率\n\n  **AOF重写规则**\n\n  - 进程内具有时效性的数据，并且数据已超时将不再写入文件\n\n\n  - 非写入类的无效指令将被忽略，只保留最终数据的写入命令\n\n    如del key1、 hdel key2、srem key3、set key4 111、set key4 222等\n\n    如select指令虽然不更改数据，但是更改了数据的存储位置，此类命令同样需要记录\n\n  - 对同一数据的多条写命令合并为一条命令\n\n  如lpushlist1 a、lpush list1 b、lpush list1 c可以转化为：lpush list1 a b c。\n\n  为防止数据量过大造成客户端缓冲区溢出，对list、set、hash、zset等类型，每条指令最多写入64个元素\n\n  \n\n  **AOF重写方式**\n\n  - 手动重写\n\n  ```properties\n  bgrewriteaof\n  ```\n\n  **手动重写原理分析：**\n\n  ![](Redis基础.assets/3.png)\n\n  \n\n  - 自动重写\n\n  ```properties\n  auto-aof-rewrite-min-size sizeauto-aof-rewrite-percentage percentage\n  ```\n\n  自动重写触发条件设置\n\n  ```properties\n  auto-aof-rewrite-min-size sizeauto-aof-rewrite-percentage percent\n  ```\n\n  自动重写触发比对参数（ 运行指令info Persistence获取具体信息 ）\n\n  ```properties\n  aof_current_size  aof_base_size\n  ```\n\n   自动重写触发条件公式：\n\n  ![](Redis基础.assets/4.png)\n\n  \n\n  \n\n  #### 5.3.4 AOF工作流程及重写流程\n\n  ![](Redis基础.assets/AOF 工作流程.png)\n\n  \n\n  ![](Redis基础.assets/AOF流程2.png)\n\n  \n\n  ![](Redis基础.assets/AOF3.png)\n\n  \n\n  \n\n  ### 5.4  RDB与AOF区别\n\n  #### 5.4.1 RDB与AOF对比（优缺点）\n\n  | 持久化方式   | RDB                | AOF                |\n  | ------------ | ------------------ | ------------------ |\n  | 占用存储空间 | 小（数据级：压缩） | 大（指令级：重写） |\n  | 存储速度     | 慢                 | 快                 |\n  | 恢复速度     | 快                 | 慢                 |\n  | 数据安全性   | 会丢失数据         | 依据策略决定       |\n  | 资源消耗     | 高/重量级          | 低/轻量级          |\n  | 启动优先级   | 低                 | 高                 |\n\n  #### 5.4.2 RDB与AOF应用场景\n\n  RDB与AOF的选择之惑\n\n  - 对数据非常敏感，建议使用默认的AOF持久化方案\n\n  AOF持久化策略使用everysecond，每秒钟fsync一次。该策略redis仍可以保持很好的处理性能，当出 现问题时，最多丢失0-1秒内的数据。\n\n  注意：由于AOF文件存储体积较大，且恢复速度较慢\n\n  - 数据呈现阶段有效性，建议使用RDB持久化方案\n\n  数据可以良好的做到阶段内无丢失（该阶段是开发者或运维人员手工维护的），且恢复速度较快，阶段 点数据恢复通常采用RDB方案\n\n  注意：利用RDB实现紧凑的数据持久化会使Redis降的很低，慎重总结：\n\n  \n\n  **综合比对**\n\n  - RDB与AOF的选择实际上是在做一种权衡，每种都有利有弊\n  - 如不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用AOF\n  - 如能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用RDB\n  - 灾难恢复选用RDB\n  - 双保险策略，同时开启 RDB和 AOF，重启后，Redis优先使用 AOF 来恢复数据，降低丢失数据的量'},1451:function(n,r,e){"use strict";e.r(r),r["default"]="> 本文由 [SnailClimb](https://github.com/Snailclimb) 和 [guang19](https://github.com/guang19) 共同完成。\n\x3c!-- TOC --\x3e\n\n- [事务隔离级别(图文详解)](#事务隔离级别图文详解)\n    - [什么是事务?](#什么是事务)\n    - [事务的特性(ACID)](#事务的特性acid)\n    - [并发事务带来的问题](#并发事务带来的问题)\n    - [事务隔离级别](#事务隔离级别)\n    - [实际情况演示](#实际情况演示)\n        - [脏读(读未提交)](#脏读读未提交)\n        - [避免脏读(读已提交)](#避免脏读读已提交)\n        - [不可重复读](#不可重复读)\n        - [可重复读](#可重复读)\n        - [防止幻读(可重复读)](#防止幻读可重复读)\n    - [参考](#参考)\n\n\x3c!-- /TOC --\x3e\n\n## 事务隔离级别(图文详解)\n\n### 什么是事务?\n\n事务是逻辑上的一组操作，要么都执行，要么都不执行。\n\n事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。\n\n### 事务的特性(ACID)\n\n![事务的特性](事务隔离级别(图文详解).assets/事务特性.png)\n\n\n1.  **原子性：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；\n2.  **一致性：** 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；\n3.  **隔离性：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；\n4.  **持久性：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。\n\n### 并发事务带来的问题\n\n在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对统一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。\n\n- **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。\n- **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。\t例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。\n- **不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。\n- **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。\n\n**不可重复度和幻读区别：**\n\n不可重复读的重点是修改，幻读的重点在于新增或者删除。\n\n例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为     1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导        致A再读自己的工资时工资变为  2000；这就是不可重复读。\n\n 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。\n\n### 事务隔离级别\n\n**SQL 标准定义了四个隔离级别：**\n\n- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。\n- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。\n- **REPEATABLE-READ(可重复读)：**  对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。\n- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。\n\n----\n\n| 隔离级别 | 脏读 | 不可重复读 | 幻影读 |\n| :---: | :---: | :---:| :---: |\n| READ-UNCOMMITTED | √ | √ | √ |\n| READ-COMMITTED | × | √ | √ |\n| REPEATABLE-READ | × | × | √ |\n| SERIALIZABLE | × | × | × |\n\nMySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。我们可以通过`SELECT @@tx_isolation;`命令来查看，MySQL 8.0 该命令改为`SELECT @@transaction_isolation;`\n\n```sql\nmysql> SELECT @@tx_isolation;\n+-----------------+\n| @@tx_isolation  |\n+-----------------+\n| REPEATABLE-READ |\n+-----------------+\n```\n\n~~这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是 Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以说 InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** 已经可以完全保证事务的隔离性要求，即达到了 SQL 标准的 **SERIALIZABLE(可串行化)** 隔离级别。~~\n\n🐛 问题更正：**MySQL InnoDB 的 REPEATABLE-READ（可重读）并不保证避免幻读，需要应用使用加锁读来保证。而这个加锁度使用到的机制就是 Next-Key Locks。**\n\n因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 **READ-COMMITTED(读取提交内容)** ，但是你要知道的是 InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）** 并不会有任何性能损失。\n\nInnoDB 存储引擎在 **分布式事务** 的情况下一般会用到 **SERIALIZABLE(可串行化)** 隔离级别。\n\n🌈 拓展一下(以下内容摘自《MySQL 技术内幕：InnoDB 存储引擎(第 2 版)》7.7 章)：\n\n> InnoDB 存储引擎提供了对 XA 事务的支持，并通过 XA 事务来支持分布式事务的实现。分布式事务指的是允许多个独立的事务资源（transactional resources）参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求在其中的所有参与的事务要么都提交，要么都回滚，这对于事务原有的 ACID 要求又有了提高。另外，在使用分布式事务时，InnoDB 存储引擎的事务隔离级别必须设置为 SERIALIZABLE。\n\n### 实际情况演示\n\n在下面我会使用 2 个命令行mysql ，模拟多线程（多事务）对同一份数据的脏读问题。\n\nMySQL 命令行的默认配置中事务都是自动提交的，即执行SQL语句后就会马上执行 COMMIT 操作。如果要显式地开启一个事务需要使用命令：`START TARNSACTION`。\n\n我们可以通过下面的命令来设置隔离级别。\n\n```sql\nSET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL [READ UNCOMMITTED|READ COMMITTED|REPEATABLE READ|SERIALIZABLE]\n```\n\n我们再来看一下我们在下面实际操作中使用到的一些并发控制语句:\n\n- `START TARNSACTION` |`BEGIN`：显式地开启一个事务。\n- `COMMIT`：提交事务，使得对数据库做的所有修改成为永久性。\n- `ROLLBACK`：回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。\n\n#### 脏读(读未提交)\n\n![](事务隔离级别(图文详解).assets/2019-31-1脏读(读未提交)实例.jpg)\n\n \n\n\n\n#### 避免脏读(读已提交)\n\n![](事务隔离级别(图文详解).assets/2019-31-2读已提交实例-1635560171416.jpg)\n\n\n\n\n#### 不可重复读\n\n还是刚才上面的读已提交的图，虽然避免了读未提交，但是却出现了，一个事务还没有结束，就发生了 不可重复读问题。\n\n![](事务隔离级别(图文详解).assets/2019-32-1不可重复读实例.jpg)\n\n\n\n#### 可重复读\n\n![](事务隔离级别(图文详解).assets/2019-33-2可重复读.jpg)\n\n\n\n#### 防止幻读(可重复读)\n\n![](事务隔离级别(图文详解).assets/2019-33防止幻读(使用可重复读).jpg)\n\n \n\n \n\n\n一个事务对数据库进行操作，这种操作的范围是数据库的全部行，然后第二个事务也在对这个数据库操作，这种操作可以是插入一行记录或删除一行记录，那么第一个是事务就会觉得自己出现了幻觉，怎么还有没有处理的记录呢? 或者 怎么多处理了一行记录呢?\n\n幻读和不可重复读有些相似之处 ，但是不可重复读的重点是修改，幻读的重点在于新增或者删除。\n\n### 参考\n\n- 《MySQL技术内幕：InnoDB存储引擎》\n- <https://dev.mysql.com/doc/refman/5.7/en/>\n- [Mysql 锁：灵魂七拷问](https://tech.youzan.com/seven-questions-about-the-lock-of-mysql/)\n- [Innodb 中的事务隔离级别和锁的关系](https://tech.meituan.com/2014/08/20/innodb-lock.html)\n"},2767:function(n,r,e){"use strict";e.r(r),r["default"]="# Mysql锁\r\n\r\n面试官：mysql支持哪些级别的锁？\r\n我：支持库锁、表锁、行锁。\r\n\r\n面试官：那先说说库锁吧，锁库有几种方式？\r\n\r\n我：两种，分别是FTWRL（Flush tables with read lock）和 set global readonly=true\r\n\r\n面试官：这两种有什么区别？\r\n\r\n我：首先不管是谁，只要锁库了，那么整个库都处于只读状态，所有的更新操作都将被阻塞，FTWRL模式风险稍微小点，如果客户端异常断开后，FTWRL锁会自动释放，但是global readonly=true不会自动释放锁。\r\n\r\n面试官：那myisam和innodb的锁有什么区别。\r\n\r\n我：myisam不支持行锁，只支持表级的锁，innodb支持更细粒度的行锁。\r\n面试官：表级锁使用过吗?\r\n\r\n我：没有用过，表锁性能差。\r\n\r\n面试官：那你知道MDL锁吗？\r\n\r\n我：了解，MDL（metadata lock）锁是server层的锁，表级锁，它是隐式的，不需要显式的使用，mysql每次读写数据时（insert、update、select、delete）都要先去获取MDL读锁，只有获取到了MDL读锁，才能进行接下来的操作，否则阻塞，其中MDL读锁之间是共享的，当对数据库进行表结构变更的时候，会获取MDL写锁，MDL写锁和任何MDL锁都是互斥的，不管是MDL读锁还是MDL写锁。\r\n\r\n面试官：那MDL锁的作用是什么？\r\n\r\n我：MDL锁是为了解决DDL和DML之间冲突的问题。\r\n\r\n\\1. 假设事务A先查询得到一个数据，然后事务B执行了字段修改，那么事务A再次去查的时候，发现数据对不上了。\r\n\r\n![img](mysql锁.assets/wps1D32.tmp.png) \r\n\r\n\\1. 事务A先更新数据未提交，事务B修改字段提交，slave就会先修改字段，再更新数据，那么就会有问题\r\n\r\n![img](mysql锁.assets/wps1D33.tmp.png) \r\n\r\n当使用了MDL锁后，DDL操作必须要先获得MDL写锁，我们知道写锁和写锁，写锁和读锁是冲突的，那么在DDL之前如果有任何查询或者更新，都必须要阻塞等待，不会让DDL执行的，从而解决了冲突问题。\r\n\r\n面试官：那有了MDL锁，在线DDL是不是就很安全？\r\n\r\n我：不一定。\r\n\r\n![img](mysql锁.assets/wps1D34.tmp.png) \r\n\r\n假设session1先执行查询，但是不提交。session2紧接着执行添加字段的DDL，最后session3再执行查询。此时会发现session2和session3都是阻塞的，如果后面还来了sessionN的查询，那么都将阻塞，严重时将造成大量线程阻塞。\r\n\r\n面试官：那你能解释下为什么这种情况下会阻塞吗？\r\n\r\n我：首先MDL锁一定是在事务提交后才释放的，session1在执行查询后，并没有commit，那么MDL读锁是没有释放的，session2紧接着执行DDL，执行DDL是要获取MDL写锁的，由于写锁和读锁是互斥的，那么session2是卡住的，它在等待session1释放读锁，session3在session2之后执行的，此时session3是需要一个读锁的，但是由于获取锁是有先后顺序的，它们要排队，并且写锁的优先级要高于读锁，这也是为什么session3会卡住。\r\n\r\n面试官：所以是session1执行commit之后，然后session2先执行完，最后session3先执行完？我刚试了下你的例子，看着好像session2和session3几乎同时运行完，你能否具体说说为什么呢？（看你进不进坑）\r\n\r\n![img](mysql锁.assets/wps1D45.tmp.png) \r\n\r\n我：（想给我挖坑，没门），不是的，并不是session2先执行完，其实是session3先执行完，但是session2会先获得MDL写锁，由于session3没有显式的开启一个事务，那么session3默认执行完毕之后自动commit，所以在session1 commit之后，看起来像session2和session3几乎同时进行的。如果让session3显式的开启事务，就能发现运行的细节了。\r\n\r\n![img](mysql锁.assets/wps1D46.tmp.png) \r\n\r\n这样当session1 commit之后可以发现session3先执行，session2依然是卡住的，只有当session3 commit之后，发现session2才能运行。所以真实情况应该是session3先执行，然后session2。\r\n\r\n面试官：那这和你上面说的获取MDL锁排队的问题是不是矛盾了？\r\n\r\n我：不矛盾，这其实涉及到online DDL的知识了，我们知道mysql支持在线DDL，不阻塞用户操作，当执行一个DDL，它的流程大概是这样的：\r\n\r\n\\1. 拿MDL写锁\r\n\r\n\\2. 降级成MDL读锁\r\n\r\n\\3. 真正做DDL\r\n\r\n\\4. 升级成MDL写锁\r\n\r\n\\5. 释放MDL锁\r\n\r\n其中session2在拿到MDL写锁后，会降级成MDL读锁，降级后，session3拿到MDL读锁，然后执行select，但是没有commit，这样MDL读锁就没释放，然后session2在升级成MDL写锁的时候因为session3没释放读锁从而导致session2阻塞。\r\n\r\n面试官：（这小子不错呀），那你知道为什么DDL过程中1-2要降级，而3-4又要升级吗？\r\n\r\n我：（早知道就要问，还好我有准备），\r\n\r\n![img](mysql锁.assets/wps1D47.tmp.png) \r\n\r\n首先在MDL写锁期间，干的事就是创建临时的frm和idb文件，这个过程要安全，是排他的，同时这个过程也是快速的，在临时文件创建好之后，就不需要排他了，那么就降级为读锁，支持正常的增删改查，这也是为什么DDL支持online的原因之一。在新的数据文件写好之后，要替换老的数据文件，这个过程要安全，所以在3执行完后，会尝试升级成MDL写锁，这个过程也是快速的，也是支持online DDL的原因之二。\r\n\r\n面试官：我们知道InnoDB支持行级锁，行锁还分两类你知道吗？\r\n\r\n我：知道，S（共享锁）和X（排他锁），S锁和S锁是共享的，X锁和任意锁互斥。\r\n\r\n面试官：既然X锁和任意锁互斥，那么如果存在两个事务，事务A更新数据后，不提交，那么事务B去查询这条数据是不是就阻塞？\r\n\r\n![img](mysql锁.assets/wps1D48.tmp.png) \r\n\r\n我：不会的，因为InnoDB支持MVCC（多版本控制），当一个事务执行查询的时候，它可以通过undo log查询到一个快照，这样就不用锁。\r\n\r\n面试官：那你知道IS（意向共享锁）和IX（意向排他锁）吗？\r\n\r\n我：首先它俩都是表级别的锁，因为InnoDB是支持行锁的，当某些行已经上了X锁之后，再想对这个表上锁的话，就得确认当前表中没有任何X锁，在没有意向锁的情况下，就得一行一行去判断，这样效率会非常低下，在有了意向锁之后，就不需要一行一行判断了，举个例子：\r\n\r\n***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** ***\\*id\\****=1 ***\\*for\\**** ***\\*update\\****;\r\n\r\n当一个事务对id=1这行数据上了X锁之后，就会对user表也加一个IX锁。\r\n\r\n***\\*LOCK\\**** ***\\*TABLES\\**** ***\\*user\\**** ***\\*READ\\****;\r\n\r\n这时想要给表加上读锁，但是发现表上有IX锁，所以会阻塞无法执行。类似的如果一个事务对一行数据加上共享锁\r\n\r\n***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** ***\\*id\\****=1 ***\\*lock\\**** ***\\*in\\**** ***\\*share\\**** ***\\*mode\\****;\r\n\r\n就会给对应的表加上IS锁。这时候如果执行\r\n\r\n***\\*LOCK\\**** ***\\*TABLES\\**** ***\\*user\\**** WRITE;\r\n\r\n也会因为表上有IS锁而阻塞。\r\n\r\n面试官：那我们来聊聊行锁吧，InnoDB支持哪些行锁？\r\n\r\n我：有记录锁（Record Lock）、间隙锁（Gap Lock）、Next-Key Lock\r\n\r\n面试官：假设有一张表，表里有10条记录，还有个字段user_id，并且user_id是普通索引。\r\n\r\n+----+---------+\r\n| id | user_id |\r\n+----+---------+\r\n| 1 |   10 |\r\n| 2 |   20 |\r\n| 3 |   30 |\r\n| 4 |   40 |\r\n| 5 |   50 |\r\n| 6 |   60 |\r\n| 7 |   70 |\r\n| 8 |   80 |\r\n| 9 |   90 |\r\n| 10 |   100 |\r\n+----+---------+\r\n\r\n如果事务A执行：\r\n\r\n***\\*SELECT\\**** * ***\\*FROM\\**** ***\\*user\\**** ***\\*WHERE\\**** user_id=50 ***\\*FOR\\**** ***\\*UPDATE\\****;\r\n\r\n紧接着事务B执行下面的sql会发生什么？：\r\n\r\n***\\*INSERT\\**** ***\\*INTO\\**** ***\\*user\\**** ***\\*set\\**** user_id=45;\r\n\r\n我：阻塞。\r\n\r\n面试官：能说下原因吗？\r\n\r\n我：因为InnoDB的Next-Key Lock算法，不仅仅会锁住user_id=50这条记录，还会锁住50左右的间隙。Next-Key Lock锁定的范围是左开右闭的，那么理论上最终(40,50],(50,60]的区间数据会被锁定。![img](mysql锁.assets/wps1D49.tmp.png)由于要插入的45在40-50之间，所以就会发生阻塞。\r\n\r\n面试官：那按照你说的区间锁法，是包含60这条数据的是吧，所以如果插入一条60的数据，就会发生阻塞？\r\n\r\n***\\*INSERT\\**** ***\\*INTO\\**** ***\\*user\\**** ***\\*set\\**** user_id=60;\r\n\r\n我：其实不会，这里涉及到next key lock的优化，在等值查询中，向右遍历时且最后一个值不满足等值条件的时候，Next-Key Lock会退化为Gap Lock，所以对于(50,60]这个区间最终会降级为(50,60)，那么60这条数据就不会被锁住，是可以插入成功的。\r\n\r\n面试官：那40这条数据是不在这个锁区间的，所以可以插入40这条数据？\r\n\r\n***\\*INSERT\\**** ***\\*INTO\\**** ***\\*user\\**** ***\\*set\\**** user_id=40;\r\n\r\n我：其实也不会，40这条数据的插入也会阻塞，首先对于非聚集索引user_id它的叶子节点一定是排序的，大概就像(40,4)，（50,5）这样，其次因为主键id是自增的，那么对于再插入一条40的数据，它的主键id一定是大于4的，就目前10条数据来说，下一次插入的id肯定是11，那(40,11)这条数据肯定是要在(40,4)后面的，这样的话，就落入到了间隙锁中，所以会阻塞，其实上面60那条数据可以插入也是同样的道理。\r\n\r\n![img](mysql锁.assets/wps1D4A.tmp.png) \r\n\r\n面试官：那如果我一开始不用select for update了，而用select lock in share mode，那么所有的插入会有什么变化吗？\r\n\r\n我：没有变化，还是一样，因为插入需要X锁，X锁和任何锁都互斥。\r\n\r\n面试官：如果user_id不是普通索引而是唯一索引，那会有什么变化？\r\n\r\n我：当索引是唯一索引时，那么就会发生降级，Next Key Lock会降级成Record Lock，最终只会锁住50这条记录。\r\n\r\n面试官：如果user_id没有索引怎么办？\r\n\r\n我：那就所有的记录都会锁上，任何的插入都会阻塞。\r\n\r\n面试官：那你知道为什么要有间隙锁这个东西吗？\r\n\r\n我：为了解决幻读。比如当事务A执行以下查询时：\r\n\r\n***\\*SELECT\\**** * ***\\*FROM\\**** ***\\*user\\**** ***\\*WHERE\\**** ***\\*id\\****>=9 ***\\*for\\**** ***\\*update\\****\r\n\r\n应该返回两条记录（id=9和id=10），这时候如果另一个事务B执行\r\n\r\n***\\*INSERT\\**** ***\\*INTO\\**** ***\\*user\\**** ***\\*set\\**** user_id=110;\r\n\r\n在没有间隙锁的情况下，那么事务A再次查询会发现多了一条记录，就出现了幻读，如果有了间隙锁，那么[9，+∞)这个区间都会被锁住，事务B的插入就会阻塞。但是只有在事务的隔离级别设置成可重复读的时候，才支持间隙锁。\r\n\r\n面试官：如果某个上了锁的事务一直不提交，那么后面需要获取相关锁的事务就会阻塞，这样会有什么问题？\r\n\r\n我：如果阻塞的事务越来越多，那么阻塞的线程也会越来越多，严重时会造成连接池满了，mysql不能提供服务了。但是InnoDB支持阻塞超时后，会自动放弃这个等待锁的sql命令，这个值默认是50s。\r\n\r\n+--------------------------+-------+\r\n| Variable_name      | Value |\r\n+--------------------------+-------+\r\n| innodb_lock_wait_timeout | 50  |\r\n+--------------------------+-------+\r\n\r\n面试官看了看我：那你知道AUTO-INC Locking吗？\r\n\r\n我：知道，自增长锁，在InnoDB引擎中，每个表都会维护一个表级别的自增长计数器，当对表进行插入的时候，会通过以下的命令来获取当前的自增长的值。\r\n\r\n***\\*SELECT\\**** ***\\*MAX\\****(auto_inc_col) ***\\*FROM\\**** ***\\*user\\**** ***\\*FOR\\**** ***\\*UPDATE\\****;\r\n\r\n插入操作会在这个基础上加1得到即将要插入的自增长id。\r\n\r\n面试官：我们知道事务中的锁是在事务提交后才释放的，那么在更新自增长id后，当事务没来及提交，其它的事务获取自增长id就要等待吗？这样的话效率是不是有点低？\r\n\r\n我：不用等待的，为了提高插入性能，自增长的锁不会等到事务提交之后才释放，而是在相关插入sql语句完成后立刻就释放的，这也是为什么一些事务回滚之后，发现id不连续的原因：\r\n\r\nselect * from user;\r\n+----+---------+\r\n| id | user_id |\r\n+----+---------+\r\n| .. |   .. |\r\n| 9 |   90 |\r\n| 10 |   100 |\r\n| 12 |   120 |\r\n+----+---------+\r\n\\# 11那条数据回滚了，但是id也被消耗了，id不会回滚。\r\n\r\n面试官：虽然AUTO-INC Locking可以不用等事务提交就释放，但是在并发的时候，因为AUTO-INC Locking本身会对自增id上锁的，还是会影响效率，这个该怎么解决？\r\n\r\n我：现在InnoDB支持互斥量的方式来实现自增长，通过互斥量可以对内存中的计数器进行累加操作，比AUTO-INC Locking要快些。\r\n\r\n面试官：那你知道死锁吗？\r\n\r\n我：知道。\r\n\r\n面试官：什么情况下会出现死锁？\r\n\r\n我：死锁出现的条件就是请求和保持，就是每一方都保持着对方的需要的资源同时请求对方占用的资源。比如：\r\n\r\n![img](mysql锁.assets/wps1D5B.tmp.png) \r\n\r\n事务1先锁id=1这条数据，紧接着事务2锁住id=2这条数据，然后事务1再次尝试锁住id=2这条数据，但是发现被事务2占着在，所以此时事务1会阻塞，最后事务2尝试获取id=1的锁，但是发现被事务1占着在，所以也会阻塞，那么此时就陷入僵局了，这就是死锁。\r\n\r\n面试官：那如何解决死锁问题呢？\r\n\r\n我：\r\n\r\n\\1. InnoDB提供锁超时的功能，当一个事务获取锁超时之后会自动放弃，另一个事务就可以执行。\r\n\r\n+--------------------------+-------+\r\n| Variable_name      | Value |\r\n+--------------------------+-------+\r\n| innodb_lock_wait_timeout | 50  |\r\n+--------------------------+-------+\r\n\r\n\\1. 可以让每次更新都按照约定的顺序去更新，这样也可以避免死锁。\r\n\r\n![img](mysql锁.assets/wps1D5C.tmp.png) \r\n\r\n\\1. 通过死锁检测来提前判断，InnoDB默认是开启死锁检测的。\r\n\r\n+------------------------+-------+\r\n| Variable_name     | Value |\r\n+------------------------+-------+\r\n| innodb_deadlock_detect | ON  |\r\n+------------------------+-------+\r\n\r\nInnoDB通过等待图的方式来进行死锁检测的，这要求存储锁的信息链表和事务的等待链表，然后通过链表构造一张等待图，每次获取锁的时候会通过等待图来判断是否会造成死锁。\r\n\r\n "},2787:function(n,r,e){"use strict";e.r(r),r["default"]="# 《面试八股文》之 Redis 16卷\r\n\r\n· \r\n\r\n\r\n1.什么是 redis？它能做什么？\r\n\r\n· \r\n\r\n· \r\n\r\n2.redis 有哪八种数据类型？有哪些应用场景？\r\n\r\n· \r\n\r\n· \r\n\r\n3.redis为什么这么快？\r\n\r\n· \r\n\r\n· \r\n\r\n4.听说 redis 6.0之后又使用了多线程，不会有线程安全的问题吗？\r\n\r\n· \r\n\r\n· \r\n\r\n5.redis 的持久化机制有哪些？优缺点说说\r\n\r\n· \r\n\r\n· \r\n\r\n\\6. Redis的过期键的删除策略有哪些？\r\n\r\n· \r\n\r\n· \r\n\r\n\\7. Redis的内存满了怎么办？\r\n\r\n· \r\n\r\n· \r\n\r\n8.Redis 的热 key 问题怎么解决？\r\n\r\n· \r\n\r\n· \r\n\r\n9.缓存击穿、缓存穿透、缓存雪崩是什么？怎么解决呢？\r\n\r\n· \r\n\r\n· \r\n\r\n10.Redis 有哪些部署方式？\r\n\r\n· \r\n\r\n· \r\n\r\n11.哨兵有哪些作用？\r\n\r\n· \r\n\r\n· \r\n\r\n12.哨兵选举过程是怎么样的？\r\n\r\n· \r\n\r\n· \r\n\r\n13.cluster集群模式是怎么存放数据的？\r\n\r\n· \r\n\r\n· \r\n\r\n14.cluster的故障恢复是怎么做的？\r\n\r\n· \r\n\r\n· \r\n\r\n15.主从同步原理是怎样的？\r\n\r\n· \r\n\r\n· \r\n\r\n16.无硬盘复制是什么？\r\n\r\n· \r\n\r\n## ***\\*1.什么是 redis？它能做什么？\\****\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59D8.tmp.png) \r\n\r\nredis: redis 即 Remote Dictionary Server，用中文翻译过来可以理解为**远程数据服务**或远程字典服务。其是使用 C 语言的编写的key-value**存储系统**\r\n\r\n应用场景:缓存，数据库，消息队列，分布式锁，点赞列表，排行榜等等\r\n\r\n## ***\\*2.redis 有哪八种数据类型？有哪些应用场景？\\****\r\n\r\nredis 总共有**八种数据结构，五种基本数据类型和三种特殊数据类型**。\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59E9.tmp.png)五种基本数据类型:\r\n\r\n· **1.string**:字符串类型，常被用来存储计数器，粉丝数等，简单的分布式锁也会用到该类型\r\n\r\n· **2.hashmap**:key - value 形式的，value 是一个map\r\n\r\n· **3.list**:基本的数据类型，列表。在 Redis 中可以把 list 用作栈、队列、阻塞队列。\r\n\r\n· **4.set**:集合，不能有重复元素，可以做点赞，收藏等\r\n\r\n· **5.zset**:有序集合，不能有重复元素，有序集合中的每个元素都需要指定一个分数，根据分数对元素进行升序排序。可以做排行榜![img](《面试八股文》之 Redis 16卷.assets/wps59EA.tmp.png)三种特殊数据类型:\r\n\r\n· **1.geospatial**: Redis 在 3.2 推出 Geo 类型，该功能**可以推算出地理位置信息，两地之间的距离**。\r\n\r\n· **2.hyperloglog**:基数：数学上集合的元素个数，是不能重复的。这个数据结构**常用于统计网站的 UV**。\r\n\r\n· **3.bitmap**: bitmap 就是通过最小的单位 bit 来进行0或者1的设置，表示某个元素对应的值或者状态。一个 bit 的值，或者是0，或者是1；也就是说一个 bit 能存储的最多信息是2。bitmap **常用于统计用户信息比如活跃粉丝和不活跃粉丝、登录和未登录、是否打卡等**。\r\n\r\n## ***\\*3.redis为什么这么快？\\****\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59EB.tmp.png) \r\n\r\n官方数据 redis 可以做到每秒近10w的并发，这么快的原因主要总结为以下几点：\r\n\r\n· 1:完全基于内存操作\r\n\r\n· 2:使用单线程模型来处理客户端的请求，避免了上下文的切换\r\n\r\n· 3:IO 多路复用机制\r\n\r\n· 4:自身使用 C 语言编写，有很多优化机制，比如动态字符串 sds\r\n\r\n## ***\\*4.听说 redis 6.0之后又使用了多线程，不会有线程安全的问题吗？\\****\r\n\r\n**不会**\r\n\r\n其实 redis **还是使用单线程模型来处理客户端的请求**，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程，所以是不会有线程安全的问题。\r\n\r\n之所以加入了多线程因为 redis 的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。\r\n\r\n## ***\\*5.redis 的持久化机制有哪些？优缺点说说\\****\r\n\r\nredis 有**两种**持久化的方式，AOF 和 RDB.\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59EC.tmp.png) \r\n\r\n**AOF**:\r\n\r\n· redis 每次执行一个命令时,都会把这个「命令原本的语句记录到一个.aod的文件当中,然后通过fsync策略,将命令执行后的数据持久化到磁盘中」(不包括读命令)，\r\n\r\nAOF的优缺点\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59ED.tmp.png) \r\n\r\n· **AOF 的「优点」**:\r\n\r\n§ 1.AOF可以「更好的保护数据不丢失」，一般AOF会以每隔1秒，通过后台的一个线程去执行一次fsync操作，如果redis进程挂掉，**最多丢失1秒的数据**\r\n\r\n§ 2.AOF是将命令直接追加在文件末尾的,**「写入性能非常高」**\r\n\r\n§ 3.AOF日志文件的命令通过非常可读的方式进行记录，这个非常「**适合做灾难性的误删除紧急恢复」**，如果某人不小心用 flushall 命令清空了所有数据，只要这个时候还没有执行 rewrite，那么就可以将日志文件中的 flushall 删除，进行恢复\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59EE.tmp.png) \r\n\r\n· **AOF 的「缺点」**:\r\n\r\n§ 1.对于同一份数据源来说,一般情况下**AOF 文件比 RDB 数据快照要大**\r\n\r\n§ 2.由于 .aof 的**每次命令都会写入**,那么相对于 RDB 来说「需要消耗的性能也就更多」，当然也会有 **aof 重写**将 aof 文件优化。\r\n\r\n§ 3.**「数据恢复比较慢」**，不适合做冷备。\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n**RDB**:\r\n\r\n· 把**某个时间点 redis 内存**中的数据以二进制的形式存储的一个.rdb为后缀的文件当中,也就是「**周期性的备份redis中的整个数据**」,这是redis**默认**的持久化方式,也就是我们说的快照(snapshot)，是采用 fork 子进程的方式来写时同步的。\r\n\r\n**RDB的优缺点**\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59EF.tmp.png) \r\n\r\n· RDB的优点:\r\n\r\n§ \r\n\r\n1.它是将某一时间点redis内的所有数据保存下来,所以当我们做「大型的数据恢复时,RDB的恢复速度会很快」\r\n\r\n§ \r\n\r\n§ \r\n\r\n2.由于RDB的FROK子进程这种机制,队友给客户端提供读写服务的影响会非常小\r\n\r\n§ \r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps59F0.tmp.png) \r\n\r\n· RDB的缺点:\r\n\r\n§ 举个例子假设我们定时5分钟备份一次,在10:00的时候 redis 备份了数据,但是如果在10:04的时候服务挂了,那么我们就会丢失在10:00到10:04的整个数据\r\n\r\n§ 1:「有可能会产生长时间的数据丢失」\r\n\r\n§ 2:可能会有长时间停顿:我们前面讲了,fork 子进程这个过程是和 redis 的数据量有很大关系的,**如果「数据量很大,那么很有可能会使redis暂停几秒」**\r\n\r\n## ***\\*6. Redis的过期键的删除策略有哪些？\\****\r\n\r\n过期策略通常有以下三种：\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A00.tmp.png) \r\n\r\n· **定时过期**：**每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除**。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。\r\n\r\n· **惰性过期**：只有当**访问一个key时，才会判断该key是否已过期**，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。\r\n\r\n· **定期过期**：**每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key**。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。\r\n\r\n## ***\\*7. Redis的内存满了怎么办？\\****\r\n\r\n实际上Redis**定义了「8种内存淘汰策略」用**来处理redis内存满的情况：\r\n\r\n· 1.noeviction：直接返回错误，不淘汰任何已经存在的redis键\r\n\r\n· 2.allkeys-lru：所有的键使用lru算法进行淘汰\r\n\r\n· 3.volatile-lru：有过期时间的使用lru算法进行淘汰\r\n\r\n· 4.allkeys-random：随机删除redis键\r\n\r\n· 5.volatile-random：随机删除有过期时间的redis键\r\n\r\n· 6.volatile-ttl：删除快过期的redis键\r\n\r\n· 7.volatile-lfu：根据lfu算法从有过期时间的键删除\r\n\r\n· 8.allkeys-lfu：根据lfu算法从所有键删除\r\n\r\n## ***\\*8.Redis 的热 key 问题怎么解决？\\****\r\n\r\n热 key  就是说，在某一时刻，有非常多的请求访问某个 key，流量过大，导致该 redi 服务器宕机\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A01.tmp.png) \r\n\r\n解决方案:\r\n\r\n· 可以将结果缓存到本地内存中\r\n\r\n· 将热 key 分散到不同的服务器中\r\n\r\n· 设置永不过期\r\n\r\n## ***\\*9.缓存击穿、缓存穿透、缓存雪崩是什么？怎么解决呢？\\****\r\n\r\n缓存穿透:\r\n\r\n· 缓存穿透是指用户请求的数据**在缓存中不存在并且在数据库中也不存在**，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A02.tmp.png) \r\n\r\n解决方案:\r\n\r\n· 布隆过滤器\r\n\r\n· 返回空对象\r\n\r\n缓存击穿：\r\n\r\n· 缓存击穿，是指一个 key 非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个 key 在**失效的瞬间，持续的大并发就穿破缓存**，直接请求数据库，就像在一个屏障上凿开了一个洞。\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A03.tmp.png) \r\n\r\n解决方案:\r\n\r\n· 互斥锁\r\n\r\n· 永不过期\r\n\r\n缓存雪崩：\r\n\r\n· 缓存雪崩是指缓存中**不同的数据大批量到过期时间**，而查询数据量巨大，请求直接落到数据库上导致宕机。\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A04.tmp.png) \r\n\r\n解决方案:\r\n\r\n· 均匀过期\r\n\r\n· 加互斥锁\r\n\r\n· 缓存永不过期\r\n\r\n· 双层缓存策略\r\n\r\n## ***\\*10.Redis 有哪些部署方式？\\****\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A05.tmp.png) \r\n\r\n· \r\n\r\n单机模式:这也是最基本的部署方式,只需要一台机器,负责读写,一般只用于开发人员自己测试\r\n\r\n· \r\n\r\n· \r\n\r\n哨兵模式:哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。它具备**自动故障转移、集群监控、消息通知**等功能。\r\n\r\n· \r\n\r\n· \r\n\r\ncluster集群模式:在redis3.0版本中支持了cluster集群部署的方式，这种集群部署的方式能**自动将数据进行分片**，每个master上放一部分数据，提供了内置的高可用服务，即使某个master挂了，服务还可以正常地提供。\r\n\r\n· \r\n\r\n· \r\n\r\n主从复制:在主从复制这种集群部署模式中，我们会将数据库分为两类，第一种称为主数据库(master)，另一种称为从数据库(slave)。主数据库会负责我们整个系统中的读写操作，从数据库会负责我们整个数据库中的读操作。其中在职场开发中的真实情况是，我们会让主数据库只负责写操作，让从数据库只负责读操作，就是为了**读写分离**，减轻服务器的压力。\r\n\r\n· \r\n\r\n## ***\\*11.哨兵有哪些作用？\\****\r\n\r\n· \r\n\r\n1.监控整个主数据库和从数据库，观察它们是否正常运行\r\n\r\n· \r\n\r\n· \r\n\r\n2.当主数据库发生异常时，自动的将从数据库升级为主数据库，继续保证整个服务的稳定\r\n\r\n· \r\n\r\n## ***\\*12.哨兵选举过程是怎么样的？\\****\r\n\r\n· \r\n\r\n1.第一个发现该master挂了的哨兵，向每个哨兵发送命令，让对方选举自己成为领头哨兵\r\n\r\n· \r\n\r\n· \r\n\r\n2.其他哨兵如果没有选举过他人，就会将这一票投给第一个发现该master挂了的哨兵\r\n\r\n· \r\n\r\n· \r\n\r\n3.第一个发现该master挂了的哨兵如果发现由超过一半哨兵投给自己，并且其数量也超过了设定的quoram参数，那么该哨兵就成了领头哨兵\r\n\r\n· \r\n\r\n· \r\n\r\n4.如果多个哨兵同时参与这个选举，那么就会重复该过程，知道选出一个领头哨兵\r\n\r\n· \r\n\r\n选出领头哨兵后，就开始了故障修复，会从选出一个从数据库作为新的master\r\n\r\n## ***\\*13.cluster集群模式是怎么存放数据的？\\****\r\n\r\n一个cluster集群中总共有16384个节点，集群会**将这16384个节点平均分配给每个节点**，当然，我这里的节点指的是每个主节点，就如同下图：\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A06.tmp.png) \r\n\r\n## ***\\*14.cluster的故障恢复是怎么做的？\\****\r\n\r\n判断故障的逻辑其实与哨兵模式有点类似，在集群中，每个节点都会**定期的向其他节点发送ping命令**，通过有没有收到回复来判断其他节点是否已经下线。\r\n\r\n如果**长时间没有回复，那么发起ping命令的节点就会认为目标节点疑似下线**，也可以和哨兵一样称作主观下线，当然也需要集群中一定数量的节点都认为该节点下线才可以，我们来说说具体过程：\r\n\r\n![img](《面试八股文》之 Redis 16卷.assets/wps5A17.tmp.png) \r\n\r\n· 1.当A节点发现目标节点疑似下线，就会向集群中的其他节点散播消息，其他节点就会向目标节点发送命令，判断目标节点是否下线\r\n\r\n· 2.如果集群中半数以上的节点都认为目标节点下线，就会对目标节点标记为下线，从而告诉其他节点，让目标节点在整个集群中都下线\r\n\r\n## ***\\*15.主从同步原理是怎样的？\\****\r\n\r\n· \r\n\r\n1.当一个从数据库启动时，它会向**主数据库发送一个SYNC命令**，master收到后，在后台保存快照，也就是我们说的RDB持久化，当然保存快照是需要消耗时间的，并且redis是单线程的，在保存快照期间redis受到的命令会缓存起来\r\n\r\n· \r\n\r\n· \r\n\r\n2.快照完成后会**将缓存的命令以及快照一起打包发给slave节点**，从而保证主从数据库的一致性。\r\n\r\n· \r\n\r\n· \r\n\r\n3.从数据库接受到快照以及缓存的命令后会将这部分数据**写入到硬盘上的临时文件当中**，写入完成后会用这份文件去替换掉RDB快照文件，当然，这个操作是不会阻塞的，可以继续接收命令执行，具体原因其实就是fork了一个子进程，用子进程去完成了这些功能。\r\n\r\n· \r\n\r\n因为不会阻塞，所以，这部分初始化完成后，当主数据库执行了改变数据的命令后，会异步的给slave，这也就是我们说的复制同步阶段，这个阶段会贯穿在整个中从同步的过程中，直到主从同步结束后，复制同步才会终止。\r\n\r\n## ***\\*16.无硬盘复制是什么？\\****\r\n\r\n我们刚刚说了主从之间是通过RDB快照来交互的，虽然看来逻辑很简单，但是还是会存在一些问题，但是会存在着一些问题。\r\n\r\n· \r\n\r\n1.master禁用了RDB快照时，发生了主从同步(复制初始化)操作，也会生成RDB快照，但是之后如果master发成了重启，就会用RDB快照去恢复数据，这份数据可能已经很久了，中间就会丢失数据\r\n\r\n· \r\n\r\n· \r\n\r\n2.在这种一主多从的结构中，master每次和slave同步数据都要进行一次快照，从而在硬盘中生成RDB文件，会影响性能\r\n\r\n· \r\n\r\n为了解决这种问题，redis在后续的更新中也加入了无硬盘复制功能，也就是说**直接通过网络发送给slave**，避免了和硬盘交互，但是也是有io消耗\r\n\r\n "},"28a6":function(n,r,e){"use strict";e.r(r),r["default"]="\n非常感谢《redis实战》真本书，本文大多内容也参考了书中的内容。非常推荐大家看一下《redis实战》这本书，感觉书中的很多理论性东西还是很不错的。\n\n为什么本文的名字要加上春夏秋冬又一春，哈哈 ，这是一部韩国的电影，我感觉电影不错，所以就用在文章名字上了，没有什么特别的含义，然后下面的有些配图也是电影相关镜头。\n\n\n\n**很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后回复数据），或者是为了防止系统故障而将数据备份到一个远程位置。**\n\nRedis不同于Memcached的很重要一点就是，**Redis支持持久化**，而且支持两种不同的持久化操作。Redis的一种持久化方式叫**快照（snapshotting，RDB）**，另一种方式是**只追加文件（append-only file,AOF）**。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。\n\n## 快照（snapshotting）持久化\n\nRedis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。\n\n\n\n**快照持久化是Redis默认采用的持久化方式**，在redis.conf配置文件中默认有此下配置：\n\n```\nsave 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n\nsave 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n\nsave 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n```\n\n根据配置，快照将被写入dbfilename选项指定的文件里面，并存储在dir选项指定的路径上面。如果在新的快照文件创建完毕之前，Redis、系统或者硬件这三者中的任意一个崩溃了，那么Redis将丢失最近一次创建快照写入的所有数据。\n\n举个例子：假设Redis的上一个快照是2：35开始创建的，并且已经创建成功。下午3：06时，Redis又开始创建新的快照，并且在下午3：08快照创建完毕之前，有35个键进行了更新。如果在下午3：06到3：08期间，系统发生了崩溃，导致Redis无法完成新快照的创建工作，那么Redis将丢失下午2：35之后写入的所有数据。另一方面，如果系统恰好在新的快照文件创建完毕之后崩溃，那么Redis将丢失35个键的更新数据。\n\n**创建快照的办法有如下几种：**\n\n- **BGSAVE命令：** 客户端向Redis发送 **BGSAVE命令** 来创建一个快照。对于支持BGSAVE命令的平台来说（基本上所有平台支持，除了Windows平台），Redis会调用fork来创建一个子进程，然后子进程负责将快照写入硬盘，而父进程则继续处理命令请求。\n- **SAVE命令：** 客户端还可以向Redis发送 **SAVE命令** 来创建一个快照，接到SAVE命令的Redis服务器在快照创建完毕之前不会再响应任何其他命令。SAVE命令不常用，我们通常只会在没有足够内存去执行BGSAVE命令的情况下，又或者即使等待持久化操作执行完毕也无所谓的情况下，才会使用这个命令。\n- **save选项：** 如果用户设置了save选项（一般会默认设置），比如 **save 60 10000**，那么从Redis最近一次创建快照之后开始算起，当“60秒之内有10000次写入”这个条件被满足时，Redis就会自动触发BGSAVE命令。\n- **SHUTDOWN命令：**  当Redis通过SHUTDOWN命令接收到关闭服务器的请求时，或者接收到标准TERM信号时，会执行一个SAVE命令，阻塞所有客户端，不再执行客户端发送的任何命令，并在SAVE命令执行完毕之后关闭服务器。\n- **一个Redis服务器连接到另一个Redis服务器：** 当一个Redis服务器连接到另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令\n\n如果系统真的发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于即使丢失一部分数据也不会造成一些大问题的应用程序。不能接受这个缺点的话，可以考虑AOF持久化。\n\n## **AOF（append-only file）持久化**\n与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：\n\n```\nappendonly yes\n```\n\n开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。\n\n\n\n**在Redis的配置文件中存在三种同步方式，它们分别是：**\n\n```\nappendfsync always     #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度\nappendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘\nappendfsync no      #让操作系统决定何时进行同步\n```\n\n**appendfsync always** 可以实现将数据丢失减到最少，不过这种方式需要对硬盘进行大量的写入而且每次只写入一个命令，十分影响Redis的速度。另外使用固态硬盘的用户谨慎使用appendfsync always选项，因为这会明显降低固态硬盘的使用寿命。\n\n为了兼顾数据和写入性能，用户可以考虑 **appendfsync everysec选项** ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。\n\n**appendfsync no**  选项一般不推荐，这种方案会使Redis丢失不定量的数据而且如果用户的硬盘处理写入操作的速度不够的话，那么当缓冲区被等待写入的数据填满时，Redis的写入操作将被阻塞，这会导致Redis的请求速度变慢。\n\n**虽然AOF持久化非常灵活地提供了多种不同的选项来满足不同应用程序对数据安全的不同要求，但AOF持久化也有缺陷——AOF文件的体积太大。**\n\n## 重写/压缩AOF\n\nAOF虽然在某个角度可以将数据丢失降低到最小而且对性能影响也很小，但是极端的情况下，体积不断增大的AOF文件很可能会用完硬盘空间。另外，如果AOF体积过大，那么还原操作执行时间就可能会非常长。\n\n为了解决AOF体积过大的问题，用户可以向Redis发送 **BGREWRITEAOF命令** ，这个命令会通过移除AOF文件中的冗余命令来重写（rewrite）AOF文件来减小AOF文件的体积。BGREWRITEAOF命令和BGSAVE创建快照原理十分相似，所以AOF文件重写也需要用到子进程，这样会导致性能问题和内存占用问题，和快照持久化一样。更糟糕的是，如果不加以控制的话，AOF文件的体积可能会比快照文件大好几倍。\n\n**文件重写流程：**\n\n\n和快照持久化可以通过设置save选项来自动执行BGSAVE一样，AOF持久化也可以通过设置\n\n```\nauto-aof-rewrite-percentage\n```\n\n选项和\n\n```\nauto-aof-rewrite-min-size\n```\n\n选项自动执行BGREWRITEAOF命令。举例：假设用户对Redis设置了如下配置选项并且启用了AOF持久化。那么当AOF文件体积大于64mb，并且AOF的体积比上一次重写之后的体积大了至少一倍（100%）的时候，Redis将执行BGREWRITEAOF命令。\n\n```\nauto-aof-rewrite-percentage 100  \nauto-aof-rewrite-min-size 64mb\n```\n\n无论是AOF持久化还是快照持久化，将数据持久化到硬盘上都是非常有必要的，但除了进行持久化外，用户还必须对持久化得到的文件进行备份（最好是备份到不同的地方），这样才能尽量避免数据丢失事故发生。如果条件允许的话，最好能将快照文件和重新重写的AOF文件备份到不同的服务器上面。\n\n随着负载量的上升，或者数据的完整性变得越来越重要时，用户可能需要使用到复制特性。\n\n## Redis 4.0 对于持久化机制的优化\nRedis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。\n\n如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性较差。\n\n参考：\n\n《Redis实战》\n\n[深入学习Redis（2）：持久化](https://www.cnblogs.com/kismetv/p/9137897.html)\n\n"},"2b74":function(n,r,e){"use strict";e.r(r),r["default"]='# Mysql删除\r\n\r\n#### ***\\*删除并不是真正的删除\\****\r\n\r\n熟悉mysql InnoDB存储引擎的同学都应该知道，当我们执行delete的时候，数据并没有被真正的删除，只是对应数据的删除标识deleteMark被打开了，这样每次执行查询的时候，如果发现数据存在但是deleteMark是开启的话，那么依然返回空，因为这个细节，所以经常会出现“我明明删除了数据，为什么空间没释放”的现象。\r\n\r\n15M 7 6 18:46 user_info.ibd #删除前\r\n15M 10 4 16:47 user_info.ibd #删除后\r\n\r\n#### ***\\*为什么不直接删除，而是打个标记\\****\r\n\r\n我们知道InnoDB存储引擎是支持MVCC的，即多版本控制，得益于MVCC，mysql在事务里查询数据的时候不需要加锁，可以提供很好的并发性，同时提供可重复读这个很重要的特性。那么它是怎么到的呢？答案是undo log，可以简单的理解为，每次更新数据的时候将更新前的数据先写入undo log中，这样当需要回滚的时候，只需要顺着undo log找到历史数据即可。undo log与原始数据之间是用指针链接起来的，即每条数据都有个回滚指针指向undo log。\r\n\r\n![img](mysql删除.assets/wps18BF.tmp.png)如果InnoDB在删除数据的时候，真的是把数据从磁盘上擦除，那么这时候：\r\n\r\n\\1. 别的事务通过undo log是无法找到原始数据\r\n\r\n\\2. 可重复读这个特性会被破坏\r\n\r\n#### ***\\*只是打个标记的话，岂不是很浪费空间\\****\r\n\r\nmysql里面有个purge线程，它的工作中有一项任务就是专门检查这些有deleteMark的数据，当有deleteMark的数据如果没有被其他事务引用时，那么会被标记成可复用，因为叶子节点数据是有序的原因，这样当下次有同样位置的数据插入时，可以直接复用这块磁盘空间。当整个页都可以复用的时候，也不会把它还回去，会把可复用的页留下来，当下次需要新页时可以直接使用，从而减少频繁的页申请。\r\n\r\n![img](mysql删除.assets/wps18C0.tmp.png) \r\n\r\n#### ***\\*基于页的存储方式\\****\r\n\r\n我们知道mysql数据是存储在磁盘上的，磁盘的速度想必大家都知道，特别是当发生随机IO的时候。这里简单解释下什么叫IO，以机械磁盘为例，我们最终的数据都是落在磁盘的一个一个扇区上的，当一个扇区写满了，就得换下一个扇区，这时就要通过盘片的转动找到目标扇区，这是物理运动。如果要写入的下一个扇区和当前的扇区是紧挨着的，这叫顺序IO，如果要写入的扇区和当前的扇区中间隔了几个扇区，这叫随机IO，很明显随机IO需要更长的转动时间。所以查询一个数据的时候，减少IO是非常关键的，特别是随机IO。\r\n\r\n为了减少磁盘IO，mysql采用B+树的索引结构来组织数据，B+树的特点是矮胖，一般树的高度就代表了IO的次数，越矮的话，树的高度越低，那么对应的IO次数就越少，还有一点需要知道的是数据最终都在叶子节点上，所以在B+树上搜索的时候，一定是要检索到最后一层叶子节点上，这是一种稳定性的表现。\r\n\r\n![img](mysql删除.assets/wps18C1.tmp.png) \r\n\r\n***\\*行与页\\****：这里需要知道的是，我们最终通过B+树检索到的**「不是我们的目标行数据，而是目标行数据所在的页」**，这个页上有很多数据，都是索引序号相邻的，当找到目标页后，会把目标页加载到内存中，然后通过二分法找到目标数据，也许你会问，那搜索的开销不仅仅是磁盘IO，还有在二分法查找的开销。这里不可否认，但是我们一般忽略这部分开销，因为cpu在内存里检索的速度很快，并且一页也就16k，数据并不多。\r\n\r\n***\\*IO次数不一定等于树的高度\\****：前面我们说到树的高度等于IO的次数，这其实不是很准确，我们知道树的根节点一定是在内存里的，那么对于一颗高度为3的数据，只用2次IO即可，这其实可以理解，毕竟根节点只占用一页的空间，一页才16K，放在内存里绰绰有余。但有时候树的第二层也可以放在内存里，假设现在主键是bigint，bigint我们知道占用8个字节，对于一个索引来说除了类型本身占用空间之外，还有一个指针，这个指针占用6个字节，那么对于根节点来说它大概能存 16K/(8+6)B = 1170 个数据，每个数据都可以指向一页（也就是它的下一层），这样整个树的第二层大概占用 1170*16K = 18M 的空间，这也不是一个很大的数字，对于机器的内存来说，几乎也是沧海一粟，所以第二层往往也在内存里，所以最终在B+树上检索数据所消耗的IO应该比理论的要低。\r\n\r\n通过上面我们知道检索一条数据的快慢，主要受树的高度影响的，这和你的数据表的大小并没有太大的关系，现实中有人可能在数据表达到百万级别的时就考虑分表，个人认为这有点低估B+树的能力了。还是以bigint类型的主键索引为例，假设一行数据占用1K（理论上已经足够大了），那么一页可以存下 ***\\*16K/1K=16\\**** 条数据，对于一颗高度为3的B+树来说，它可以存下 ***\\*1170\\*1170\\*16=21902400\\**** 的数据，将近2千万，如果你的数据行占用的空间更小，就可以存下更多的数据，所以只是简单的根据数据行数来判断是否需要分表不是那么的合理。\r\n\r\n#### ***\\*可复用的空间一直没有被利用咋办\\****\r\n\r\n前面我们说到删除的数据不会被真的删除，只是打上个deleteMark的标识，然后会被复用，但是如果一直没被复用，那么空间不就是白白的浪费了，更糟糕的是，如果删除的很多数据空间都没有被复用，就会造成页空间存在大量的碎片，为了解决这种情况，mysql内部有个叫页合并的功能，这是什么意思呢？简单理解就是页A现在有很多可以被复用的空间，它的邻居页B也有很多可以复用的空间，此时页A就可以和页B合并，如果合并后能省出来一页，那么多出来的一页就可以被下次使用，从而达到页最大利用的效果。\r\n\r\n![img](mysql删除.assets/wps18C2.tmp.png) \r\n\r\n合并的关键需要当前页的前一页或者后一页也有大量的碎片空间，这里为何要**「大量」**很关键，合并的动作可以简单理解就是把别的页的数据移动过来，如果两个页pageA和pageB都只有少量的可复用空间，那么合并后，即使pageA可以填满，但是另一个页Page也还是有碎片空间的，并且碎片更大，这时候数据移动的开销可能要大于存储的开销，得不偿失。\r\n\r\n![img](mysql删除.assets/wps18C3.tmp.png)而且还会有个严重的问题，pageB可能会和pageC合并，那么pageC的碎片更大...，这样的话似乎是个无底洞，导致很多页都在移动数据。因此一个合理的合并条件很关键，InnoDB中何时合并受MERGE_THRESHOLD这个参数影响，它的默认值是50%，50%的意图很明显，两个50%就可以省出一个页。![img](mysql删除.assets/wps18C4.tmp.png)我们看个例子，pageA已经有50%的数据被删除了，它的邻居pageB只使用了不到50%的数据，这时候会将pageB的数据移动到pageA上，那么整个pageB就是空页了，可以提供给别的数据使用。这里需要知道的是除了删除会触发页合并外，更新可能也会触发页合并。\r\n\r\n#### ***\\*有合并也有分裂\\****\r\n\r\n合并页是提升页的利用率的方式，但是有时候我们又不得不分裂页，我们知道叶子节点的页之间是用双向链表串接起来的，并且页与页之间的数据是有序的。\r\n\r\n![img](mysql删除.assets/wps18D5.tmp.png)以上图为例，当我们要插入5这条数据，按道理应该尝试放在pageA里面，但是pageA目前没有足够的空间来存放一条数据，于是尝试找到pageA的相邻页pageB，但是此时很不幸的是pageB也没有足够的空间来存放一条数据，由于要求数据的连续性，数据5必须在数据4和数据6之间，那么只能新建一个页，新建一个页后，会尝试从pageA中移动一部分数据到新的页上，并且会重新组织页与页之间的关系，即在pageA和pageB之间会隔一道新页pageC。\r\n\r\n![img](mysql删除.assets/wps18D6.tmp.png)页分裂会造成页的利用率降低，造成页分裂的原因有很多，比如：\r\n\r\n\\1. 比如离散的插入，导致数据不连续。\r\n\r\n\\2. 把记录更新成一个更大记录，导致空间不够用\r\n\r\n还有一点需要知道的是：不管是页的合并还是页的分裂，都是相对耗时的操作，除了移动数据的开销外，InnoDB也会在索引树上加锁。\r\n\r\n#### ***\\*手动重建表\\****\r\n\r\n页的合并和分裂主要是在插入、删除或更新的时候，并且正好满足某些条件才发生的，那如果这些条件一直不满足，碎片就无法得到清理，这时候往往会出现"**「我的表明明没多少数据，为什么还占用这么大空间」**"这个现象，针对这个现象有人说重建索引，这个是对的，重建索引可以让数据更加紧凑，页的利用率达到更高。但是如何重建索引？第一时间你可能会想到先drop index然后add index，这个似乎不是那么准确。\r\n***\\*如果要重建的索引是普通索引\\****，使用这种方式还好，需要注意的是假如你的业务TPS很大，建议在业务低峰期执行，因为虽然mysql支持online ddl，但是重建索引的过程还是很耗cpu和io资源的。\r\n***\\*如果你要重建的是主键索引\\****，那么问题来了，首先如果你的主键索引设置的是自增长，是不支持drop的。其次如果你的主键没设置成自增长，直接drop也不是我们想象的那样，我们知道普通索引除了记录本身的索引字段外，还会记录主键的值，如果drop是直接删除索引，那么通过普通引将找不到对应的行记录，所以InnoDB是要求必须有主键索引的，这时InnoDB会尝试去表中找个唯一索引来当主键，如果没有唯一索引，那就自动创建一个默认的主键索引rowid，当新的主键索引建立好之后，还要去修改相关的普通索引让其存储新的主键，但是如果按照这种方法来修改的话，开销会很大，特别是普通索引很多的情况下，于是InnoDB干脆选择重建表。对于紧接着执行的add index操作，同样也会发生主键索引的变更，所以也会选择重建表，最终可以发现在主键索引上的drop和add其实干了一样的事情。\r\n\r\n综上所述，一般在你的表出现很多页碎片的时候，建议使用：\r\n\r\nalter table xx engine=InnoDB\r\n\r\n这个命令可以重建我们这个表，但是前提是我们的表是独占表空间的。基于mysql的online ddl，这个过程它是不影响正常的读写的，它的过程如下：\r\n\r\n\\1. 扫描原表主键索引的所有记录\r\n\r\n\\2. 生成新的b+树记录到临时文件\r\n\r\n\\3. 生成临时文件的过程中，新的变更记录到一个中转日志row log中\r\n\r\n\\4. 在临时文件生成后，将期间row log的变更应用到新的临时文件中\r\n\r\n\\5. 然后替换临时文件为当前文件\r\n\r\n这里需要注意的是重建表的过程涉及到数据的copy，得保证磁盘有足够的空间，至少是现在磁盘空间的1倍，如果磁盘空间不足，那么是不会重建成功的。\r\n\r\n#### ***\\*重建表不一定会收缩空间\\****\r\n\r\n在重建表的过程中，有一点需要知道：InnoDB不会让重建后的页充满数据，会预留个**「1/16」**的空间，这个意图很明显，如果不预留，选择占满整个页，这时候去更新一条需要更大空间的老数据，就会需要新的页，写入新的页后，往往又会造成碎片，所以提前预留一点空间是有用的。\r\n\r\n但是因为这个预留操作，某些情况下会导致重建后的表空间反而会变大。\r\n\r\n\\1. 如果你的表本身就很紧凑，因为预留1/16会变大。\r\n\r\n\\2. 在第一次重建表后，因为新的插入导致用掉了预留空间的一部分（这里需要注意的是预留空间没用完，还剩一部分），但是没有用到新的页，所以整体的空间没有变化，这时候如果再次重建表，就会因为要预留1/16，导致申请的新的页，那么空间就会变大。\r\n\r\n '},"382d":function(n,r,e){"use strict";e.r(r),r["default"]="我们平时开发中不可避免的就是要存储时间，比如我们要记录操作表中这条记录的时间、记录转账的交易时间、记录出发时间等等。你会发现时间这个东西与我们开发的联系还是非常紧密的，用的好与不好会给我们的业务甚至功能带来很大的影响。所以，我们有必要重新出发，好好认识一下这个东西。\n\n这是一篇短小精悍的文章，仔细阅读一定能学到不少东西！\n\n### 1.切记不要用字符串存储日期\n\n我记得我在大学的时候就这样干过，而且现在很多对数据库不太了解的新手也会这样干，可见，这种存储日期的方式的优点还是有的，就是简单直白，容易上手。\n\n但是，这是不正确的做法，主要会有下面两个问题：\n\n1. 字符串占用的空间更大！\n2. 字符串存储的日期效率比较低（逐个字符进行比对），无法用日期相关的 API 进行计算和比较。\n\n### 2.Datetime 和 Timestamp 之间抉择\n\nDatetime 和 Timestamp 是 MySQL 提供的两种比较相似的保存时间的数据类型。他们两者究竟该如何选择呢？\n\n**通常我们都会首选 Timestamp。** 下面说一下为什么这样做!\n\n#### 2.1 DateTime 类型没有时区信息\n\n**DateTime 类型是没有时区信息的（时区无关）** ，DateTime 类型保存的时间都是当前会话所设置的时区对应的时间。这样就会有什么问题呢？当你的时区更换之后，比如你的服务器更换地址或者更换客户端连接时区设置的话，就会导致你从数据库中读出的时间错误。不要小看这个问题，很多系统就是因为这个问题闹出了很多笑话。\n\n**Timestamp 和时区有关**。Timestamp 类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，说简单点就是在不同时区，查询到同一个条记录此字段的值会不一样。\n\n下面实际演示一下！\n\n建表 SQL 语句：\n\n```sql\nCREATE TABLE `time_zone_test` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `date_time` datetime DEFAULT NULL,\n  `time_stamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n\n插入数据：\n\n```sql\nINSERT INTO time_zone_test(date_time,time_stamp) VALUES(NOW(),NOW());\n```\n\n查看数据：\n\n```sql\nselect date_time,time_stamp from time_zone_test;\n```\n\n结果：\n\n```\n+---------------------+---------------------+\n| date_time           | time_stamp          |\n+---------------------+---------------------+\n| 2020-01-11 09:53:32 | 2020-01-11 09:53:32 |\n+---------------------+---------------------+\n```\n\n现在我们运行\n\n修改当前会话的时区:\n\n```sql\nset time_zone='+8:00';\n```\n\n再次查看数据：\n\n```\n+---------------------+---------------------+\n| date_time           | time_stamp          |\n+---------------------+---------------------+\n| 2020-01-11 09:53:32 | 2020-01-11 17:53:32 |\n+---------------------+---------------------+\n```\n\n**扩展：一些关于 MySQL 时区设置的一个常用 sql 命令**\n\n```sql\n# 查看当前会话时区\nSELECT @@session.time_zone;\n# 设置当前会话时区\nSET time_zone = 'Europe/Helsinki';\nSET time_zone = \"+00:00\";\n# 数据库全局时区设置\nSELECT @@global.time_zone;\n# 设置全局时区\nSET GLOBAL time_zone = '+8:00';\nSET GLOBAL time_zone = 'Europe/Helsinki';\n```\n\n#### 2.2 DateTime 类型耗费空间更大\n\nTimestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小。\n\n- DateTime ：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59\n- Timestamp： 1970-01-01 00:00:01 ~ 2037-12-31 23:59:59\n\n> Timestamp 在不同版本的 MySQL 中有细微差别。\n\n### 3 再看 MySQL 日期类型存储空间\n\n下图是 MySQL 5.6 版本中日期类型所占的存储空间：\n\n![](关于数据库存储时间的一点思考.assets/FhRGUVHFK0ujRPNA75f6CuOXQHTE.jpeg)\n\n可以看出 5.6.4 之后的 MySQL 多出了一个需要 0 ～ 3 字节的小数位。DateTime 和 Timestamp 会有几种不同的存储空间占用。\n\n为了方便，本文我们还是默认 Timestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。\n\n### 4.数值型时间戳是更好的选择吗？\n\n很多时候，我们也会使用 int 或者 bigint 类型的数值也就是时间戳来表示时间。\n\n这种存储方式的具有 Timestamp 类型的所具有一些优点，并且使用它的进行日期排序以及对比等操作的效率会更高，跨系统也很方便，毕竟只是存放的数值。缺点也很明显，就是数据的可读性太差了，你无法直观的看到具体时间。\n\n时间戳的定义如下：\n\n> 时间戳的定义是从一个基准时间开始算起，这个基准时间是「1970-1-1 00:00:00 +0:00」，从这个时间开始，用整数表示，以秒计时，随着时间的流逝这个时间整数不断增加。这样一来，我只需要一个数值，就可以完美地表示时间了，而且这个数值是一个绝对数值，即无论的身处地球的任何角落，这个表示时间的时间戳，都是一样的，生成的数值都是一样的，并且没有时区的概念，所以在系统的中时间的传输中，都不需要进行额外的转换了，只有在显示给用户的时候，才转换为字符串格式的本地时间。\n\n数据库中实际操作：\n\n```sql\nmysql> select UNIX_TIMESTAMP('2020-01-11 09:53:32');\n+---------------------------------------+\n| UNIX_TIMESTAMP('2020-01-11 09:53:32') |\n+---------------------------------------+\n|                            1578707612 |\n+---------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> select FROM_UNIXTIME(1578707612);\n+---------------------------+\n| FROM_UNIXTIME(1578707612) |\n+---------------------------+\n| 2020-01-11 09:53:32       |\n+---------------------------+\n1 row in set (0.01 sec)\n```\n\n### 5.总结\n\nMySQL 中时间到底怎么存储才好？Datetime?Timestamp? 数值保存的时间戳？\n\n好像并没有一个银弹，很多程序员会觉得数值型时间戳是真的好，效率又高还各种兼容，但是很多人又觉得它表现的不够直观。这里插一嘴，《高性能 MySQL 》这本神书的作者就是推荐 Timestamp，原因是数值表示时间不够直观。下面是原文：\n\n<img src=\"关于数据库存储时间的一点思考.assets/高性能mysql-不推荐用数值时间戳.jpg\" style=\"zoom:50%;\" />\n\n每种方式都有各自的优势，根据实际场景才是王道。下面再对这三种方式做一个简单的对比，以供大家实际开发中选择正确的存放时间的数据类型：\n\n<img src=\"关于数据库存储时间的一点思考.assets/总结-常用日期存储方式.jpg\" style=\"zoom:50%;\" />\n\n如果还有什么问题欢迎给我留言！如果文章有什么问题的话，也劳烦指出，Guide 哥感激不尽！\n\n后面的文章我会介绍：\n\n- [ ] Java8 对日期的支持以及为啥不能用 SimpleDateFormat。\n- [ ] SpringBoot 中如何实际使用(JPA 为例)"},"3a39":function(n,r,e){"use strict";e.r(r),r["default"]="# mysql┃一条更新语句是怎么执行的？？？\r\n\r\n一条查询语句执行过程当中要经过的模块，有连接器，查询缓存，分析器，优化器，执行器，存储引擎。\r\n\r\n \r\n\r\n那么一条更新语句走完一整个流程又要经过哪些模块呢？\r\n\r\n \r\n\r\n假设一张表里只有一个主键id和一个int字段c\r\n\r\n我们从如下代码开始\r\n\r\n \r\n\r\n· \r\n\r\nupdate T set c=c+1 where ID=2;\r\n\r\n \r\n\r\n![img](mysql一条语句是怎么执行.assets/wps646B.tmp.png) \r\n\r\n \r\n\r\n其实查询语句走的一套流程，基本上更新语句也会走一遍，但是更新语句还会涉及到另外两个重要的日志模块，redolog，binlog。\r\n\r\n\r\n**redolog（重做日志）**\r\n\r\n首先要告诉大家，redolog是innodb独有的，关于它具体做了什么，moon先和大家举个例子，不知道大家有没有了解过从前街边卖小吃老板的记账方式。\r\n\r\n每来一个人，买一份煎饼，老板都会在自己的账单上记住+15元，假如今天第一份收入15元\r\n\r\n \r\n\r\n+15 总金额 15\r\n\r\n然后第二份\r\n\r\n+15 总金额30\r\n\r\n第三份\r\n\r\n+15 总金额45\r\n\r\n \r\n\r\n这样看确实没毛病，记得也很清楚，但是老板生意越来越好，而且做生意也越来越复杂，除了卖煎饼，还会卖其他的东西，价格也不同，物种琳琅满目，并且人也越来越多，老板就没办法实时去计算了，于是老板改了一种方式，分了两个账单。\r\n\r\n \r\n\r\n第一个账单每天只记录一次总的信息（账本）\r\n\r\n2020年5月5号 收入5000 支出 1000 净收入 4000\r\n\r\n第二个账单记录每天的细节信息（账单）\r\n\r\n2020年5月5日\r\n\r\n+15\r\n\r\n+16\r\n\r\n+48\r\n\r\n-23\r\n\r\n...........\r\n\r\n \r\n\r\n这样的话老板在忙的时候就不需要管计算的问题，只需要简单的记录下金额就好，省去了低效率的计算过程，留在生意不忙的空闲时间去做。\r\n\r\n \r\n\r\n没错，redolog在mysql 的日志系统就是类似于这种账单模式，它是先写日志，再写磁盘，也就是先记账，等不忙的时候再去计算写账本。\r\n\r\n\r\n具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了（其实还没有写入磁盘）。同时，InnoDB引擎会在适当的时候（空闲时间），将这个操作记录更新到磁盘里面。如果今天账单的记录不多，掌柜可以等打烊后再整理。但如果某天账单的特别多，账本写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把账单中的一部分赊账记录更新到账本中，然后把这些记录从账单上擦掉。与此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这个“账单”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。\r\n\r\n![img](mysql一条语句是怎么执行.assets/wps646C.tmp.png) \r\n\r\n \r\n\r\n记录点就是记录你要执行的语句是什么，写点就是执行记录点记录的语句，当记录点追上了写点就会发生\"**内存抖动**\"，从表面上看就是mysql宕机了一会儿，其实是innodb在执行redolog中记录的内容。\r\n\r\n \r\n\r\n有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。\r\n\r\n \r\n\r\n**binlog（归档日志）**\r\n\r\n \r\n\r\n我们刚刚说了redolog是innodb独有的，那么我们之前也讲了，mysql其实是分为两块的，一块儿是server层，另一块儿才是存储引擎层，那么server层的日志是什么？其实就是我们接下来要讲的binlog。\r\n\r\n \r\n\r\n其实在最早是只有binlog的，因为在远古时代mysql的存储引擎只有myisam，redolog是在后期innodb出现的时候也跟着一起来的，这两个日志也是有很大区别的。\r\n\r\n \r\n\r\n♠♥redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\r\n\r\n♠♥redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\r\n\r\n♠♥redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\r\n\r\n \r\n\r\n我们来看看这条更新语句的执行流程\r\n\r\n \r\n\r\n· \r\n\r\nupdate T set c=c+1 where ID=2;\r\n\r\n \r\n\r\n \r\n\r\n⑴.执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。\r\n\r\n如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；\r\n\r\n否则，需要先从磁盘读入内存，然后再返回。\r\n\r\n⑵.执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\r\n\r\n⑶.引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。\r\n\r\n⑷.执行器生成这个操作的binlog，并把binlog写入磁盘。\r\n\r\n⑸.执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。\r\n\r\n \r\n\r\n![img](mysql一条语句是怎么执行.assets/wps646D.tmp.png) \r\n\r\n**两阶段提交**\r\n\r\n \r\n\r\n细心的已经发现上图是先写redolog，准备阶段，之后再写binlog，提交事务，commit阶段。\r\n\r\n为什么会有两阶段提交呢？\r\n\r\n我们先来看看，如果不适用两阶段提交会有什么问题呢？\r\n\r\n \r\n\r\n**♠****♥****先写redo log后写binlog**。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。\r\n\r\n但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。\r\n\r\n然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。\r\n\r\n**♠****♥****先写binlog后写redo log**。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。\r\n\r\n \r\n\r\n可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\r\n\r\n \r\n\r\n#  mysql┃送命题！！一条查询语句是怎么执行的？？？\r\n\r\n首先我要告诉大家的是，在我们学习任何一件东西的时候，先要观其整个脉络，要先了解这个东西能做什么，它的整体流程是什么样的，这样能帮助你更好的理解。当你明白了整体的逻辑之后，再去扣他的细节，这样就会异常的轻松了。\r\n我们看一行sql：\r\n\r\n· \r\n\r\nselect name from girlfriends where age = '18';\r\n\r\n\r\n这行代码相信大家一眼就明了了，当然，你只是看到了这行代码，但是你了解它内部的逻辑吗？\r\n\r\n所以，今天moon要和你们好好聊聊，拆解一下mysql，让你了解mysql中各个模块是怎样运作的，这样可以让你在今后遇到一些问题时，能够直击要害，更快速的解决问题。\r\n我们先来看下mysql的基本架构示意图\r\n\r\n![img](mysql一条语句是怎么执行.assets/wpsD335.tmp.png) \r\n\r\n\r\n通过这个示意图，你能够大致的了解mysql中具体有哪些模块，以及每个模块的功能都是什么。\r\n总的来说，mysql分为两个大的模块，一块是服务层，一块是存储引擎层。\r\n\r\nserver层包括了连接器，查询缓存，分析器，优化器，执行器等，覆盖了sql绝大多数核心的功能，比如内置函数，存储过程，示图，触发器等等。\r\n\r\n当然，大家从途中也可以看出，不同的存储引擎是共用一个server层的，接下来，我们就结合开头的sql语句，带大家走一遍过程。\r\n\r\n# ***\\*连接器\\****\r\n\r\n \r\n\r\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。\r\n\r\n \r\n\r\n· \r\n\r\nmysql -h$ip -P$port -u$user -p\r\n\r\n \r\n\r\n连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n**●如果用户名或密码不对**\r\n\r\n你就会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行。\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n**●如果用户名密码认证通过**\r\n\r\n连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n \r\n\r\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时。\r\n\r\n \r\n\r\n如果之后客户端再次请求mysql，此时就会报错，那么我们只能重新再连接一次mysql了。\r\n\r\n \r\n\r\n数据库里面：\r\n\r\n**长连接**是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。\r\n\r\n**短连接**则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\r\n\r\n\r\n但是由于连接的建立是比较消耗资源的，所以在我们的使用过程中要尽可能的减少连接的次数。\r\n\r\n# ***\\*查询缓存\\****\r\n\r\n \r\n\r\n# ***\\*在连接建立完成之后，就开始执行我们的select语句了。\\****\r\n\r\n# ***\\*这个时候mysql就会去\\*******\\*查询缓存中查询\\*******\\*，看看我们刚才有没有执行过这条语句：\\****\r\n\r\n \r\n\r\n# **●如果有的话，就直接将缓存的结果返回给客户端。**\r\n\r\n# **●如果没有，就会进入下一步。**\r\n\r\n \r\n\r\n当进入后续步骤查询出来结果后，会再次将查询出来的结果放入查询缓存当中。\r\n\r\n \r\n\r\n所以，使用查询缓存的效率是非常高的，但是使用查询缓存却有很大的弊端。\r\n\r\n \r\n\r\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。\r\n\r\n \r\n\r\n因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全**清空**了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。\r\n\r\n \r\n\r\n# ***\\*分析器\\****\r\n\r\n \r\n\r\n如果没有命中缓存，接下来就会走到分析器这一步了。\r\n\r\nmysql会根据自己定好的规则针对你的这条语法进行分析，比如select代表查询，where代表条件等等。\r\n\r\n到了这一步：\r\n\r\n \r\n\r\n**●如果你的sql出现了问题，那么mysql就会抛出一个错误：**\r\n\r\n· \r\n\r\nYou have an error in your SQL syntax; check the 。。。。。。。\r\n\r\n**●如果没有问题，那么就会进入下一步**\r\n\r\n \r\n\r\n# ***\\*优化器\\****\r\n\r\n \r\n\r\n到了这一步的时候，mysql已经知道你要做什么了，但是在最终执行你的命令之前，mysql还要进行一遍优化，比如索引的选择。\r\n\r\n \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\nselect name from girlfriends g left join boyfirends b on g.id = b.idwhere a.age = '18' and b.age = '19';\r\n\r\n \r\n\r\n在上述语句中mysql就会去判断，是先从a.age这个索引进入还是b.age这个索引进入，哪种效率高呢？这就是优化器的工作。 \r\n\r\n在优化完成之后，mysql已经确定好了最终的执行方式。\r\n\r\n# ***\\*优化器\\****\r\n\r\n \r\n\r\n于是就到了我们的执行器阶段，到底应该怎么执行。\r\n\r\n首先，会调取用户的权限：\r\n\r\n \r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n**●如果没有权限，则会反回错误**\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n**●如果用户拥有权限，则会打开表继续执行**\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n \r\n\r\n· \r\n\r\nselect name from girlfriends where age = '18';\r\n\r\n\r\n比如我们文章开头这条语句，假如age没有索引，执行流程如下：\r\n①调用InnoDB引擎接口取这个表的第一行，判断age值是不是18，如果不是则跳过，如果是则将这行存在结果集中。②调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。③执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\r\n\r\n \r\n\r\n对于有索引的表，整体流程也差不多，至此，就完成了一条sql语句的查询。\r\n\r\n "},"3fa4":function(n,r,e){"use strict";e.r(r),r["default"]="# 一文搞懂回滚和持久化\r\n\r\n## ***\\*redo log\\****\r\n\r\n事务的支持是数据库区分文件系统的重要特征之一，事务的四大特性：\r\n\r\n· 原子性：所有的操作要么都做，要么都不做，不可分割。\r\n\r\n· 一致性：数据库从一种状态变成另一种状态的的结果最终是一致的，比如A给B转账500，A最终少了500，B最终多了500，但是A+B的值始终没变。\r\n\r\n· 隔离性：事务和事务之前相互隔离，互不干扰。\r\n\r\n· 持久性：事务一旦提交，它对数据的变更是永久性的。\r\n\r\n本篇文章主要说说持久性相关的知识。\r\n\r\n当我们在事务中更新一条记录的时候，比如：\r\n\r\n***\\*update\\**** ***\\*user\\**** ***\\*set\\**** age=11 ***\\*where\\**** user_id=1;\r\n\r\n它的流程大概是这样的：\r\n\r\n\\1. 先判断user_id这条数据所在的页是否在内存里，如果不在的话，先从数据库读取到，然后加载到内存中\r\n\r\n\\2. 修改内存中的age为11\r\n\r\n\\3. 写入redo log，并且redo log处于prepare状态\r\n\r\n\\4. 写入binlog\r\n\r\n\\5. 提交事务，redo log变成commit状态\r\n\r\n![img](回滚和持久化.assets/wps38DF.tmp.png) \r\n\r\n这里面有几个关键的点：redo log是什么？为什么需要redo log？prepare状态的redo log是什么？redo log和binlog是否可以只选其一...?带着这一系列的问题，我们来揭开redo log的面纱。\r\n\r\n***\\*为什么要先更新内存数据，不直接更新磁盘数据？\\****\r\n\r\n我们为什么不每次更新数据的时候，直接更新对应的磁盘数据？首先我们知道磁盘IO是缓慢的，内存是快速的，两者的速度不是一个量级的，那么针对缓慢的磁盘IO，出现了索引，通过索引哪怕数据成百上千万我们依然可以在磁盘上很快速的找我们的数据，这就是索引的作用。但是索引也需要维护，并不是一成不变的，当我们插入一条新数据A的时候，由于这条数据要插入在已存在的数据B之后，那么就要移动B数据，让出一个位置给A，这个有一定的开销。更糟糕的是，本来要插入的页已经满了，那么就要申请一个新的页，然后挪一部分数据过去，这叫做页的分裂，这个开销更大。如果我们的sql变更是直接修改磁盘的数据，恰巧正好出现上面的问题，那么此时的效率就会很低，严重的话会造成超时，这也是上面更新的过程为什么先要加载对应的数据页到内存中，然后先更新内存中的数据的原因。对于mysql来说，所有的变更都必须先更新缓冲池中的数据，然后缓冲池中的脏页会以一定的频率被刷入磁盘（**「checkPoint」**机制），通过缓冲池来优化CPU和磁盘之间的鸿沟，这样就可以保证整体的性能不会下降太快。\r\n\r\n***\\*为什么需要redo log？\\****\r\n\r\n缓冲池可以帮助我们消除CPU和磁盘之间的鸿沟，checkpoint机制可以保证数据的最终落盘，然而由于checkpoint并不是每次变更的时候就触发的，而是master线程隔一段时间去处理的。所以最坏的情况就是刚写完缓冲池，数据库宕机了，那么这段数据就是丢失的，无法恢复。这样的话就不满足ACID中的D，为了解决这种情况下的持久化问题，InnoDB引擎的事务采用了WAL技术（Write-Ahead Logging），这种技术的思想就是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志就是redo log。当发生宕机且数据未刷到磁盘的时候，可以通过redo log来恢复，保证ACID中的D，这就是redo log的作用。\r\n\r\n***\\*redo log是如何实现的？\\****\r\n\r\nredo log的写入并不是直接写入磁盘的，redo log也有缓冲区的，叫做redo log buffer（重做日志缓冲），InnoDB引擎会在写redo log的时候先写redo log buffer，然后也是以一定的频率刷入到真正的redo log中，redo log buffer一般不需要特别大，它只是一个临时的容器，master线程会每秒将redo log buffer刷到redo log文件中，因此我们只要保证redo log buffer能够存下1s内的事务变更的数据量即可，以mysql5.7.23为例，这个默认是16M。\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** '%innodb_log_buffer_size%';\r\n+------------------------+----------+\r\n| Variable_name     | Value  |\r\n+------------------------+----------+\r\n| innodb_log_buffer_size | 16777216 |\r\n+------------------------+----------+\r\n\r\n16M的buffer足够应对大部分应用了，buffer同步到redo log的策略主要有如下几个：\r\n\r\n· master线程每秒将buffer刷到到redo log中\r\n\r\n· 每个事务提交的时候会将buffer刷到redo log中\r\n\r\n· 当buffer剩余空间小于1/2时，会被刷到redo log中\r\n\r\n需要注意的是redo log buffer刷到redo log的过程并不是真正的刷到磁盘中去了，只是刷入到os cache中去，这是现代操作系统为了提高文件写入的效率做的一个优化，真正的写入会交给系统自己来决定（比如os cache足够大了）。那么对于InnoDB来说就存在一个问题，如果交给系统来fsync，同样如果系统宕机，那么数据也丢失了（虽然整个系统宕机的概率还是比较小的）。针对这种情况，InnoDB给出***\\*innodb_flush_log_at_trx_commit\\****策略，让用户自己决定使用哪个。\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'innodb_flush_log_at_trx_commit';\r\n+--------------------------------+-------+\r\n| Variable_name         | Value |\r\n+--------------------------------+-------+\r\n| innodb_flush_log_at_trx_commit | 1   |\r\n+--------------------------------+-------+\r\n\r\n· 0：表示事务提交后，不进行fsync，而是由master每隔1s进行一次重做日志的fysnc\r\n\r\n· 1：默认值，每次事务提交的时候同步进行fsync\r\n\r\n· 2：写入os cache后，交给操作系统自己决定什么时候fsync\r\n\r\n从3种刷入策略来说：\r\n\r\n**「2」**肯定是效率最高的，但是只要操作系统发生宕机，那么就会丢失os cache中的数据，这种情况下无法满足ACID中的D\r\n\r\n**「0」**的话，是一种折中的做法，它的IO效率理论是高于***\\*1\\****的，低于***\\*2\\****的，它的数据安全性理论是要低于***\\*1\\****的，高于***\\*2\\****的，这种策略也有丢失数据的风险，也无法保证D。\r\n\r\n**「1」**是默认值，可以保证D，数据绝对不会丢失，但是效率最差的。个人建议使用默认值，虽然操作系统宕机的概率理论小于数据库宕机的概率，但是一般既然使用了事务，那么数据的安全应该是相对来说更重要些。\r\n\r\n***\\*redo log是对页的物理修改，第x页的第x位置修改成xx\\****，比如：\r\n\r\npage(2,4),offset 64,value 2\r\n\r\n在InnoDB引擎中，redo log都是以512字节为单位进行存储的，每个存储的单位我们称之为redo log block（重做日志块），若一个页中存储的日志量大于512字节，那么就需要逻辑上切割成多个block进行存储。\r\n\r\n一个redo log block是由日志头、日志体、日志尾组成。日志头占用12字节，日志尾占用8字节，所以一个block真正能存储的数据就是512-12-8=492字节。![img](回滚和持久化.assets/wps38E0.tmp.png)多个redo log block组成了我们的redo log。![img](回滚和持久化.assets/wps38E1.tmp.png)\r\n\r\n每个redo log默认大小为48M：\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'innodb_log_file_size';\r\n+----------------------+----------+\r\n| Variable_name    | Value  |\r\n+----------------------+----------+\r\n| innodb_log_file_size | 50331648 |\r\n+----------------------+----------+\r\n\r\nInnoDB默认2个redo log组成一个log组，真正工作的就是这个log组。\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'innodb_log_files_in_group';\r\n+---------------------------+-------+\r\n| Variable_name       | Value |\r\n+---------------------------+-------+\r\n| innodb_log_files_in_group | 2   |\r\n+---------------------------+-------+\r\n\\#ib_logfile0\r\n\\#ib_logfile1\r\n\r\n当ib_logfile0写完之后，会写ib_logfile1，当ib_logfile1写完之后，会重新写ib_logfile0...，就这样一直不停的循环写。\r\n\r\n![img](回滚和持久化.assets/wps38E2.tmp.png) \r\n\r\n***\\*为什么一个block设计成512字节？\\****\r\n\r\n这个和磁盘的扇区有关，机械磁盘默认的扇区就是512字节，如果你要写入的数据大于512字节，那么要写入的扇区肯定不止一个，这时就要涉及到盘片的转动，找到下一个扇区，假设现在需要写入两个扇区A和B，如果扇区A写入成功，而扇区B写入失败，那么就会出现非原子性的写入，而如果每次只写入和扇区的大小一样的512字节，那么每次的写入都是原子性的。\r\n\r\n***\\*为什么要两段式提交？\\****\r\n\r\n从上文我们知道，事务的提交要先写redo log(prepare)，再写binlog，最后再提交(commit)。这里为什么要有个prepare的动作？redo log直接commit状态不行吗？假设redo log直接提交，在写binlog的时候，发生了crash，这时binlog就没有对应的数据，那么所有依靠binlog来恢复数据的slave，就没有对应的数据，导致主从不一致。所以需要通过两段式（2pc）提交来保证redo log和binlog的一致性是非常有必要的。具体的步骤是：处于prepare状态的redo log，会记录2PC的XID，binlog写入后也会记录2PC的XID，同时会在redo log上打上commit标识。\r\n\r\n***\\*redo log和bin log是否可以只需要其中一个？\\****\r\n\r\n不可以。redo log本身大小是固定的，在写满之后，会重头开始写，会覆盖老数据，因为redo log无法保存所有数据，所以在主从模式下，想要通过redo log来同步数据给从库是行不通的。那么binlog是一定需要的，binlog是mysql的server层产生的，和存储引擎无关，binglog又叫归档日志，当一个binlog file写满之后，会写入到一个新的binlog file中。所以我们是不是只需要binlog就行了？redo log可以不需要？当然也不行，redo log的作用是提供crash-safe的能力，首先对于一个数据的修改，是先修改缓冲池中的数据页的，这时修改的数据并没有真正的落盘，这主要是因为磁盘的离散读写能力效率低，真正落盘的工作交给master线程定期来处理，好处就是master可以一次性把多个修改一起写入磁盘。那么此时就有一个问题，当事务commit之后，数据在缓冲区的脏页中，还没来的及刷入磁盘，此时数据库发生了崩溃，那么这条commit的数据即使在数据库恢复后，也无法还原，并不能满足ACID中的D，然后就有了redo log，从流程来看，一个事务的提交必须保证redo log的写入成功，只有redo log写入成功才算事务提交成功，redo log大部分情况是顺序写的磁盘，所以它的效率要高很多。当commit后发生crash的情况下，我们可以通过redo log来恢复数据，这也是为什么需要redo log的原因。但是事务的提交也需要binlog的写入成功，那为什么不可以通过binlog来恢复未落盘的数据？这是因为binlog不知道哪些数据落盘了，所以不知道哪些数据需要恢复。对于redo log而言，在数据落盘后对应的redo log中的数据会被删除，那么在数据库重启后，只要把redo log中剩下的数据都恢复就行了。\r\n\r\n***\\*crash后是如何恢复的？\\****\r\n\r\n通过两段式提交我们知道redo log和binlog在各个阶段会被打上prepare或者commit的标识，同时还会记录事务的XID，有了这些数据，在数据库重启的时候，会先去redo log里检查所有的事务，如果redo log的事务处于commit状态，那么说明在commit后发生了crash，此时直接把redo log的数据恢复就行了，如果redo log是prepare状态，那么说明commit之前发生了crash，此时binlog的状态决定了当前事务的状态，如果binlog中有对应的XID，说明binlog已经写入成功，只是没来的及提交，此时再次执行commit就行了，如果binlog中找不到对应的XID，说明binlog没写入成功就crash了，那么此时应该执行回滚。\r\n\r\n## ***\\*undo log\\****\r\n\r\nredo log是事务持久性的保证，undo log是事务原子性的保证。在事务中更新数据的前置操作其实是要先写入一个undo log中的，所以它的流程大致如下：\r\n\r\n![img](回滚和持久化.assets/wps38F2.tmp.jpg) \r\n\r\n***\\*什么情况下会生成undo log？\\****\r\n\r\nundo log的作用就是mvcc（多版本控制）和回滚，我们这里主要说回滚，当我们在事务里insert、update、delete某些数据的时候，就会产生对应的undo log，当我们执行回滚时，通过undo log就可以回到事务开始的样子。需要注意的是回滚并不是修改的物理页，而是逻辑的恢复到最初的样子，比如一个数据A，在事务里被你修改成B，但是此时有另一个事务已经把它修改成了C，如果回滚直接修改数据页把数据改成A，那么C就被覆盖了。\r\n\r\n对于InnoDB引擎来说，每个行记录除了记录本身的数据之外，还有几个隐藏的列：\r\n\r\n**·** ***\\*DB_ROW_ID\\****：如果没有为表显式的定义主键，并且表中也没有定义唯一索引，那么InnoDB会自动为表添加一个row_id的隐藏列作为主键。\r\n\r\n**·** ***\\*DB_TRX_ID\\****：每个事务都会分配一个事务ID，当对某条记录发生变更时，就会将这个事务的事务ID写入trx_id中。\r\n\r\n**·** ***\\*DB_ROLL_PTR\\****：回滚指针，本质上就是指向 undo log 的指针。\r\n\r\n![img](回滚和持久化.assets/wps38F3.tmp.png) \r\n\r\n当我们执行INSERT时：\r\n\r\n***\\*begin\\****;\r\n***\\*INSERT\\**** ***\\*INTO\\**** ***\\*user\\**** (***\\*name\\****) ***\\*VALUES\\**** (\"tom\")\r\n\r\n插入的数据都会生一条insert undo log，并且数据的回滚指针会指向它。undo log会记录undo log的序号、插入主键的列和值...，那么在进行rollback的时候，通过主键直接把对应的数据删除即可。\r\n\r\n![img](回滚和持久化.assets/wps38F4.tmp.png) \r\n\r\n对于更新的操作会产生update undo log，并且会分更新主键的和不更新的主键的，假设现在执行：\r\n\r\n***\\*UPDATE\\**** ***\\*user\\**** ***\\*SET\\**** ***\\*name\\****=\"Sun\" ***\\*WHERE\\**** ***\\*id\\****=1;\r\n\r\n![img](回滚和持久化.assets/wps38F5.tmp.jpg)这时会把老的记录写入新的undo log，让回滚指针指向新的undo log，它的undo no是1，并且新的undo log会指向老的undo log（undo no=0）。\r\n\r\n假设现在执行：\r\n\r\n***\\*UPDATE\\**** ***\\*user\\**** ***\\*SET\\**** ***\\*id\\****=2 ***\\*WHERE\\**** ***\\*id\\****=1;\r\n\r\n![img](回滚和持久化.assets/wps38F6.tmp.png) \r\n\r\n对于更新主键的操作，会先把原来的数据deletemark标识打开，这时并没有真正的删除数据，真正的删除会交给清理线程去判断，然后在后面插入一条新的数据，新的数据也会产生undo log，并且undo log的序号会递增。\r\n\r\n可以发现每次对数据的变更都会产生一个undo log，当一条记录被变更多次时，那么就会产生多条undo log，undo log记录的是变更前的日志，并且每个undo log的序号是递增的，那么当要回滚的时候，按照序号依次向前推，就可以找到我们的原始数据了。\r\n\r\n***\\*undo log是如何回滚的？\\****\r\n\r\n以上面的例子来说，假设执行rollback，那么对应的流程应该是这样：\r\n\r\n\\1. 通过undo no=3的日志把id=2的数据删除\r\n\r\n\\2. 通过undo no=2的日志把id=1的数据的deletemark还原成0\r\n\r\n\\3. 通过undo no=1的日志把id=1的数据的name还原成Tom\r\n\r\n\\4. 通过undo no=0的日志把id=1的数据删除\r\n\r\n***\\*undo log存在什么地方？\\****\r\n\r\nInnoDB对undo log的管理采用段的方式，也就是回滚段，每个回滚段记录了1024个undo log segment，InnoDB引擎默认支持128个回滚段\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'innodb_undo_logs';\r\n+------------------+-------+\r\n| Variable_name  | Value |\r\n+------------------+-------+\r\n| innodb_undo_logs | 128  |\r\n+------------------+-------+\r\n\r\n那么能支持的最大并发事务就是128*1024。每个undo log segment就像维护一个有1024个元素的数组。\r\n\r\n![img](回滚和持久化.assets/wps38F7.tmp.png) \r\n\r\n当我们开启个事务需要写undo log的时候，就得先去undo log segment中去找到一个空闲的位置，当有空位的时候，就会去申请undo页，最后会在这个申请到的undo页中进行undo log的写入。我们知道mysql默认一页的大小是16k。\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** '%innodb_page_size%';\r\n+------------------+-------+\r\n| Variable_name  | Value |\r\n+------------------+-------+\r\n| innodb_page_size | 16384 |\r\n+------------------+-------+\r\n\r\n那么为一个事务就分配一个页，其实是非常浪费的（除非你的事物非常长），假设你的应用的TPS为1000，那么1s就需要1000个页，大概需要16M的存储，1分钟大概需要1G的存储...，如果照这样下去除非mysql清理的非常勤快，否则随着时间的推移，磁盘空间会增长的非常快，而且很多空间都是浪费的。于是undo页就被设计的可以重用了，当事务提交时，并不会立刻删除undo页，因为重用，这个undo页它可能不干净了，所以这个undo页可能混杂着其他事务的undo log。undo log在commit后，会被放到一个链表中，然后判断undo页的使用空间是否小于3/4，如果小于3/4的话，则表示当前的undo页可以被重用，那么它就不会被回收，其他事务的undo log可以记录在当前undo页的后面。由于undo log是离散的，所以清理对应的磁盘空间时，效率不是那么高。\r\n\r\n "},"42b8":function(n,r,e){"use strict";e.r(r);var s=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[e(""+n.tab,{tag:"component"})],1)},t=[],i=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[n.MainComponent?e("q-markdown",{attrs:{"no-heading-anchor-links":"",extend:n.extendMarkdown,src:n.MainComponent}}):e(""+n.tab,{tag:"component"})],1)},a=[],o=e("9523"),l=e.n(o),d=e("448a"),E=e.n(d),m=(e("99af"),function(){var n=this,r=n.$createElement;n._self._c;return n._m(0)}),c=[function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[e("pre",[n._v("          添加系统变量\nC:\\Program Files\\MySQL\\MySQL Server 8.0\\bin\n\nnet start mysql\n\nmysql restart\n\n\n\n　一、启动方式\n　　1、使用 service 启动：service mysqld start\n　　2、使用 mysqld 脚本启动：/etc/inint.d/mysqld start\n　　3、使用 safe_mysqld 启动：safe_mysqld&\n　　二、停止\n　　1、使用 service 启动：service mysqld stop\n　　2、使用 mysqld 脚本启动：/etc/inint.d/mysqld stop\n　　3、mysqladmin shutdown\n　　三、重启\n　　1、使用 service 启动：service mysqld restart\n　　2、使用 mysqld 脚本启动：/etc/inint.d/mysqld restart\n      ")]),e("hr"),e("pre",[n._v('mysql  my.ini\n\n          [mysql]\ndefault-character-set=utf8\n\n[mysqld]\nport = 3306\ndefault_authentication_plugin=mysql_native_password\nbasedir="C:/Program Files/MySQL/MySQL Server 8.0/"\ndatadir="C:/Program Files/MySQL/MySQL Server 8.0/data/"\ncharacter-set-server = utf8\ndefault-storage-engine = MyISAM\n      ')]),e("hr"),e("pre",[n._v('          mysql  my.ini\n\n          [client]\n#password=your_password\nport=3306\nsocket=/tmp/mysql.sock\n\n[mysqld]\nport=3306\nsocket=/tmp/mysql.sock\nkey_buffer_size=256M\nmax_allowed_packet=512M\ntable_open_cache=256\nsort_buffer_size=1M\nread_buffer_size=1M\nread_rnd_buffer_size=4M\nmyisam_sort_buffer_size=64M\nthread_cache_size=8\n\nsecure-file-priv=""\nexplicit_defaults_for_timestamp=1\ndatadir= "C:/laragon/data/mysql"\n\n\n[mysqldump]\nquick\nmax_allowed_packet=512M\n\n      ')])])}],p={},R=p,L=e("2877"),u=Object(L["a"])(R,m,c,!1,null,"40a0fb39",null),T=u.exports,y=function(){var n=this,r=n.$createElement;n._self._c;return n._m(0)},g=[function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[e("pre",[n._v("         mysql 安装了最新版本8.x版本后的报错： the server requested authentication method unknown to the client\n2018年07月22日 13:11:38 youcijibi 阅读数 10613\n一，在MySQL 8.0.11中，caching_sha2_password是默认的身份验证插件，而不是以往的mysql_native_password。有关此更改对服务器操作的影响以及服务器与客户端和连接器的兼容性的信息，请参阅caching_sha2_password作为首选的身份验证插件。(翻译自https://dev.mysql.com/doc/refman/8.0/en/caching-sha2-pluggable-authentication.html）\n今天在新服务上配置安装mysql8.0.11时，像往常一样设置mysql密码，设置成功后在shell下输入mysql -u root -p，再输入密码能正常进入，但在phpmyadmin或直接用http://php.net/manual/zh/mysqli.real-connect.php上的连接，均提示无法连接，具体报错信息为\nmysqli_real_connect(): The server requested authentication method unknown to the client [sha256_password]  \n \n搜了一圈，找到官方文档才发现从8.0.11版本起，不再像mysql5.7及以前版本那样，设置用户密码时默认的验证方式为caching_sha2_password，如果发现升级mysql8.0.11后原有的程序不能连接mysql，可迅速在mysql command line client客户端用下面的命令设置成mysql5.7及以前版本的密码验证方式，同时MYSQL8.0.11下修改密码的方式与原先也不大一样，原先的部分修改密码的命令在mysql8.0.11下不能使用。\n> use mysql  \n> ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '你的密码';  \n> FLUSH PRIVILEGES;            \n二，\n \nmysql 安装了最新版本8.0.11后创建用户并授权后，授权的用户连接数据库提示\nThe server requested authentication method unknown to the client\n查阅一些相关的资料后发现是由于新版本的mysql账号密码解锁机制不一致导致的\n解决办法：\n删除创建的用户和授权，\n找到mysql配置文件并加入\ndefault_authentication_plugin=mysql_native_password\n变为原来的验证方式，然后从新创建用户并授权即可\n或\nmysql -uroot -p\n \nuse mysql;\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '你的密码';\n三\nThe caching_sha2_password and sha256_password authentication plugins provide more secure \npassword encryption than the mysql_native_password plugin, and caching_sha2_password provides better performance than sha256_password. \nDue to these superior security and performance characteristics of caching_sha2_password, it is as of MySQL 8.0 the preferred authentication plugin,\n and is also the default authentication plugin rather than mysql_native_password.\n翻译：caching_sha2_password和sha256_password认证插件比mysql_native_password插件提供的密码加密更加安全，并且caching_sha2_password加密比sha256_password的加密性能更好。\n由于caching_sha2_password这样优秀的安全和性能特性，让他作为MySQL8.0的首选认证插件，这也是默认的认证插件插件而不是mysql_native_password。\n具体你可以访问这个caching_sha2_password Compatibility Issues and Solutions来了解，已经使用了新的加密方式，访问不了的解决方法，简单总结一下就是\n1、将加密方式改为旧的，在配置文件my.conf中添加如下：\n[mysqld]\ndefault_authentication_plugin=mysql_native_password\n2、使用支持新的加密方式的客户端（Client），比如等于或高于8.0.4版本的libmysqlclient\n3、使用支持新的加密方式的连接驱动（Connector）：\nMySQL Connector/C++ 1.1.11 or higher or 8.0.7 or higher.\n \nMySQL Connector/J 8.0.9 or higher.\n \nMySQL Connector/NET 8.0.10 or higher (through the classic MySQL protocol).\n \nMySQL Connector/Node.js 8.0.9 or higher.\n \nPHP: the X DevAPI PHP extension (mysql_xdevapi) supports caching_sha2_password.\n4、使用了新的加密方式，改为旧的加密方式，而root用户也要进行相应的更改才可以，因为root用户还是新的加方式，所以使用alter语句改为重置密码来覆盖新的加密方式的密码：\nALTER USER 'root'@'localhost'\n  IDENTIFIED WITH mysql_native_password\n  BY 'password';\npassword是你将要设置的root用户的密码。\n参考文章：Changes Affecting Upgrades to MySQL 8.0\n     ")])])}],A={},S=A,I=Object(L["a"])(S,y,g,!1,null,"27f8bf50",null),N=I.exports,h=function(){var n=this,r=n.$createElement;n._self._c;return n._m(0)},O=[function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[e("h4",[n._v("mysql 简单命令")]),e("pre",[n._v("         CREATE TABLE `o2o`.`Untitled`  (\n  `area_id` int(2) NOT NULL AUTO_INCREMENT,\n  `area_name` varchar(255) NOT NULL,\n  `priority` int(2) NOT NULL DEFAULT 0,\n  `create_time` datetime(0) NULL DEFAULT NULL,\n  `last_edit_time` datetime(0) NULL DEFAULT NULL,\n  PRIMARY KEY (`area_id`),\n\tunique key `UK_AREA`(`area_name`)\n)engine=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 ;\n\n     ")]),e("pre",[n._v("         加入服务\n加入 环境变量\n管理员启动 CMD\nmysql -u root -p  输入密码\n命令行要带 ； \nddl\ndml\ndql\ndcl\n\n\ncreate database web01; 创建\ncreate database web01 default character set utf8;\nshow create database web01; 查看结构\nuse web01;  database changed;  使用表\nselect database(); 查看当前正在操作的库 \n\ncreat table user(\nuid int(32) primary key auto_increment,\nuname varchar(32),\nupassword varchar(32)\n);\nshow tables; 展示所有表\ndesc user; 显示user表的详细信息\ndrop table user; 删除表\n改变my.ini 文件重启 mysql 服务 ，防止乱码，设置字符集utf8\nset uname gbk;  在 cmd 中 改变单列数据编码，防止中文乱码，只在CMD显示上有效\nalter table user add uage int(32) not null; 添加一列\nalter table user modify uage varchar(100) null; 改变列属性\nalter table user uage uinfo varchar(100) null; 改变列名\nalter table user drop uinfo; 删除列\n\ninsert into user(uid,uname,upasswod) values(null,'name1','pass1');\ninsert into user values(null,'q','w'); 全字段插入\nupdate user set uname='po', upassword='p1' where uid=5; 更新表数值\ndelete from user where uid=2;\ntruncate table user; 摧毁表并重建一张一样字段的表 ，不可回滚，本质上是两张表\nstart trancation;开启事务\nrollback;  回滚 \n\nselect [distinct] * | 列名... from  表 [where 条件]。\n select *  from user as p; 表别名查询\nselect pname as pn from product ;列别名查询\nselect distinct pq from product; 去掉重复值查询\nselect pname,pr+12 from product; 带运算查询\nselect * from pr where pid>45; 条件查询\nselect * from  pro  where pname like '_新%'； 格式 占位符查询 第二个字是新\nselect * from  pro where pid in (4,8,9,52,44,63);  in  范围查询\nselect * from pro where pr is null ; 根据空值查询 \n and or  not 逻辑查询  where not (pr>100);\n 排序\nselect * from pro where pname like '_新%' order by price desc; 排序\n聚合 sum() avg() count(*) max() min()\nselect sum(price) from pro; 聚合\n分组\nselect cid ,count(*) from product group by cid;\nselect cid ,avg(price) from product group by having avg(price)>60\n根据cid分组，分组统计每组商品的平均价格，并且平均价格大于60；\n\n\n\n\n\n\n\n\n\n\n\n\n     ")])])}],M={},b=M,_=Object(L["a"])(b,h,O,!1,null,"7a04fb73",null),D=_.exports,C=function(){var n=this,r=n.$createElement;n._self._c;return n._m(0)},f=[function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[e("div",[n._v("LINUX 安装 5.7 mysql ")]),e("pre",[n._v("1. 通过secureCRT工具连接Linux系统\n\n2. 上传 mysql 的安装包\n\n    alt + p -------\x3e put d:/setup/mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar\n\n3. 解压 mysql 的安装包\n\n\tmkdir mysql\n    \n\ttar -xvf mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar -C mysql/\n\n\n4. 安装客户端\n    \n\tcd mysql/\n    \n\trpm -ivh mysql-community-client-5.7.27-1.el7.x86_64.rpm --force --nodeps\n\n\n5. 安装服务端\n    \n\trpm -ivh mysql-community-server-5.7.27-1.el7.x86_64.rpm --force --nodeps\n\n\n6. 修改mysql默认字符集\n    \n\tvi /etc/my.cnf\n    \n\t添加如下内容：\n    \n\t[mysqld]\n\tcharacter-set-server=utf8\n\tcollation-server=utf8_general_ci\n \n\t-- 在文件最下方添加\n    \n\t[client]\n\tdefault-character-set=utf8\n\n7. 启动mysql服务\n    \n\tservice mysqld start\n\n8. 登录mysql\n    \n\tmysql -u root -p  敲回车，输入密码\n    \n\t初始密码查看：cat /var/log/mysqld.log\n    \n\t在root@localhost:   后面的就是初始密码\n\n9. 修改mysql登录密码\n    \n\tset global validate_password_policy=0;\n    \n\tset global validate_password_length=1;\n    \n\tset password=password('密码');\n\n\n10. 授予远程连接权限\n    \n\t//授权\n\tgrant all privileges on *.* to 'root' @'%' identified by '密码';\n    \n\t//刷新\n\tflush privileges;\n\n\n11. 关闭Linux系统防火墙\n\tsystemctl stop firewalld\n\n12. 重启mysql服务\n\tservice mysqld restart\n\n13. 使用SQLYog工具连接mysql          \n      ")])])}],B={},U=B,k=Object(L["a"])(U,C,f,!1,null,"136f9661",null),v=k.exports,q=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},w=[],F="\x3c!--\r\n * @Date           : 2021-04-10 16:40:09\r\n * @FilePath       : /jinnian-space/src/pages/sql/md/MySQL基础-01-授课笔记.md\r\n * @Description    : \r\n--\x3e\r\n# MySQL基础-01-授课笔记\r\n\r\n### 一、数据库的基本概念\r\n\r\n#### 1.为什么要学数据库？\r\n\r\n- 之前我们如果想将一些数据实现永久化存储，可以怎么做呢？没错。使用IO流的技术将数据保存到本地文件中\r\n- 但是接下来我有这样一个需求：将下面的user.txt文件中的王五年龄修改为35\r\n\r\n```txt\r\n张三 23 男\r\n李四 24 男\r\n王五 25 女\r\n赵六 26 女\r\n周七 27 男\r\n```\r\n\r\n- 我们要如何实现呢？\r\n  - 可以采用字符缓冲流，将每一行数据读取出来，封装为User对象。将多个User对象保存到集合中\r\n  - 然后遍历集合，将王五对象的年龄修改为35,再重新将集合中的对象信息写回到文件中\r\n- 这一套操作太麻烦了，而现在我们有一种更加方便的方式来完成这个需求了，这种方式就是数据库！\r\n\r\n#### 2.什么是数据库？\r\n\r\n- 用于存储和管理数据的仓库\r\n- 英文单词为：DataBase，简称DB\r\n\r\n#### 3.数据库的好处？\r\n\r\n- 可以持久化存储数据\r\n- 方便存储和管理数据\r\n- 使用了统一的方式操作数据库 -- SQL\r\n\r\n#### 4.常见的数据库有哪些？\r\n\r\n\r\n\x3c!-- ![01](./img/sql/mysql/MySQL基础-01-授课笔记.assets/01.png) --\x3e\r\n\x3c!-- src\\pages\\sql\\md\\MySQL基础-01-授课笔记.md --\x3e\r\n![01](./img/sql/mysql/MySQL基础-01-授课笔记.assets/01.png)\r\n\r\n### 二、MySQL数据库的介绍和安装\r\n\r\n#### 1.MySQL数据库介绍\r\n\r\n- 小型的数据库\r\n- 开源免费(6版本之前免费)\r\n- 所属于Oracle公司\r\n\r\n#### 2.MySQL数据库安装\r\n\r\n1. 通过secureCRT工具连接Linux系统\r\n\r\n2. 上传 mysql 的安装包\r\n\r\n```linux\r\nalt + p -------\x3e put d:/setup/mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar\r\n```\r\n\r\n3. 解压 mysql 的安装包\r\n\r\n```linux\r\nmkdir mysql\r\ntar -xvf mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar -C mysql/\r\n```\r\n\r\n4. 安装客户端\r\n\r\n```linux\r\ncd mysql/\r\nrpm -ivh mysql-community-client-5.7.27-1.el7.x86_64.rpm --force --nodeps\r\n```\r\n\r\n5. 安装服务端\r\n\r\n```\r\nrpm -ivh mysql-community-server-5.7.27-1.el7.x86_64.rpm --force --nodeps\r\n```\r\n\r\n6. 修改mysql默认字符集\r\n\r\n```\r\nvi /etc/my.cnf\r\n\r\n添加如下内容：\r\n[mysqld]\r\ncharacter-set-server=utf8\r\ncollation-server=utf8_general_ci\r\n\r\n-- 需要在最下方填写\r\n[client]\r\ndefault-character-set=utf8\r\n```\r\n\r\n7. 启动mysql服务\r\n\r\n```\r\nservice mysqld start\r\n```\r\n\r\n8. 登录mysql\r\n\r\n```\r\nmysql -u root -p  敲回车，输入密码\r\n初始密码查看：cat /var/log/mysqld.log\r\n在root@localhost:   后面的就是初始密码\r\n```\r\n\r\n9. 修改mysql登录密码\r\n\r\n```\r\nset global validate_password_policy=0;\r\n\r\nset global validate_password_length=1;\r\n\r\nset password=password('密码');\r\n```\r\n\r\n10. 授予远程连接权限\r\n\r\n```\r\n//授权\r\ngrant all privileges on *.* to 'root' @'%' identified by '密码';\r\n//刷新\r\nflush privileges;\r\n```\r\n\r\n11. 关闭Linux系统防火墙\r\n\r\n```\r\nsystemctl stop firewalld.service\r\n```\r\n\r\n#### 3.MySQL数据库登录\r\n\r\n- sqlyog工具登录mysql\r\n\r\n![02](./img/sql/mysql/MySQL基础-01-授课笔记.assets/02.png)\r\n\r\n### 三、SQL语句\r\n\r\n#### 1.数据库、数据表、数据的关系介绍\r\n\r\n- 数据库\r\n  - 用于存储和管理数据的仓库\r\n  - 一个库中可以包含多个数据表\r\n- 数据表\r\n  - 数据库最重要的组成部分之一\r\n  - 它由纵向的列和横向的行组成(类似excel表格)\r\n  - 可以指定列名、数据类型、约束等\r\n  - 一个表中可以存储多条数据\r\n- 数据\r\n  - 想要永久化存储的数据\r\n\r\n![03](./img/sql/mysql/MySQL基础-01-授课笔记.assets/03.png)\r\n\r\n#### 2.SQL介绍\r\n\r\n- 什么是SQL\r\n\r\n  - Structured Query Language：结构化查询语言\r\n  - 其实就是定义了操作所有关系型数据库的规则。每一种数据库操作的方式可能会存在一些不一样的地方，我们称为“方言”。\r\n\r\n- SQL通用语法\r\n\r\n  - SQL 语句可以单行或多行书写，以分号结尾。\r\n  - 可使用空格和缩进来增强语句的可读性。\r\n  - MySQL 数据库的 SQL 语句不区分大小写，关键字建议使用大写。\r\n  - 数据库的注释：\r\n    - 单行注释：-- 注释内容       #注释内容(mysql特有)\r\n    - 多行注释：/* 注释内容 */\r\n\r\n- SQL分类\r\n\r\n  - DDL(Data Definition Language)数据定义语言\r\n    - 用来定义数据库对象：数据库，表，列等。关键字：create, drop,alter 等\r\n  - DML(Data Manipulation Language)数据操作语言\r\n    - 用来对数据库中表的数据进行增删改。关键字：insert, delete, update 等\r\n  - DQL(Data Query Language)数据查询语言\r\n    - 用来查询数据库中表的记录(数据)。关键字：select, where 等\r\n  - DCL(Data Control Language)数据控制语言(了解)\r\n    - 用来定义数据库的访问权限和安全级别，及创建用户。关键字：GRANT， REVOKE 等\r\n\r\n  ![04](./img/sql/mysql/MySQL基础-01-授课笔记.assets/04.png)\r\n\r\n#### 3.DDL-操作数据库\r\n\r\n- R(Retrieve)：查询\r\n\r\n  - 查询所有数据库\r\n\r\n  ```mysql\r\n  -- 查询所有数据库\r\n  SHOW DATABASES;\r\n  ```\r\n\r\n  - 查询某个数据库的创建语句\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SHOW CREATE DATABASE 数据库名称;\r\n  \r\n  -- 查看mysql数据库的创建格式\r\n  SHOW CREATE DATABASE mysql;\r\n  ```\r\n\r\n- C(Create)：创建\r\n\r\n  - 创建数据库\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  CREATE DATABASE 数据库名称;\r\n  \r\n  -- 创建db1数据库\r\n  CREATE DATABASE db1;\r\n  \r\n  -- 创建一个已存在的数据库会报错\r\n  -- 错误代码：1007  Can't create database 'db1'; database exists\r\n  CREATE DATABASE db1;\r\n  ```\r\n\r\n  - 创建数据库(判断，如果不存在则创建)\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  CREATE DATABASE IF NOT EXISTS 数据库名称;\r\n  \r\n  -- 创建数据库db2(判断，如果不存在则创建)\r\n  CREATE DATABASE IF NOT EXISTS db2;\r\n  ```\r\n\r\n  - 创建数据库、并指定字符集\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  CREATE DATABASE 数据库名称 CHARACTER SET 字符集名称;\r\n  \r\n  -- 创建数据库db3、并指定字符集utf8\r\n  CREATE DATABASE db3 CHARACTER SET utf8;\r\n  \r\n  -- 查看db3数据库的字符集\r\n  SHOW CREATE DATABASE db3;\r\n  ```\r\n\r\n  - 练习：创建db4数据库、如果不存在则创建，指定字符集为gbk\r\n\r\n  ```mysql\r\n  -- 创建db4数据库、如果不存在则创建，指定字符集为gbk\r\n  CREATE DATABASE IF NOT EXISTS db4 CHARACTER SET gbk;\r\n  \r\n  -- 查看db4数据库的字符集\r\n  SHOW CREATE DATABASE db4;\r\n  ```\r\n\r\n- U(Update)：修改\r\n\r\n  - 修改数据库的字符集\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  ALTER DATABASE 数据库名称 CHARACTER SET 字符集名称;\r\n  \r\n  -- 修改数据库db4的字符集为utf8\r\n  ALTER DATABASE db4 CHARACTER SET utf8;\r\n  \r\n  -- 查看db4数据库的字符集\r\n  SHOW CREATE DATABASE db4;\r\n  ```\r\n\r\n- D(Delete)：删除\r\n\r\n  - 删除数据库\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DROP DATABASE 数据库名称;\r\n  \r\n  -- 删除db1数据库\r\n  DROP DATABASE db1;\r\n  \r\n  -- 删除一个不存在的数据库会报错\r\n  -- 错误代码：1008  Can't drop database 'db1'; database doesn't exist\r\n  DROP DATABASE db1;\r\n  ```\r\n\r\n  - 删除数据库(判断，如果存在则删除)\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DROP DATABASE IF EXISTS 数据库名称;\r\n  \r\n  -- 删除数据库db2，如果存在\r\n  DROP DATABASE IF EXISTS db2;\r\n  ```\r\n\r\n- 使用数据库\r\n\r\n  - 查询当前正在使用的数据库名称\r\n\r\n  ```mysql\r\n  -- 查询当前正在使用的数据库\r\n  SELECT DATABASE();\r\n  ```\r\n\r\n  - 使用数据库\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  USE 数据库名称；\r\n  \r\n  -- 使用db4数据库\r\n  USE db4;\r\n  ```\r\n\r\n#### 4.DDL-操作数据表\r\n\r\n- R(Retrieve)：查询\r\n\r\n  - 查询数据库中所有的数据表\r\n\r\n  ```mysql\r\n  -- 使用mysql数据库\r\n  USE mysql;\r\n  \r\n  -- 查询库中所有的表\r\n  SHOW TABLES;\r\n  ```\r\n\r\n  - 查询表结构\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DESC 表名;\r\n  \r\n  -- 查询user表结构\r\n  DESC user;\r\n  ```\r\n\r\n  - 查询表字符集\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SHOW TABLE STATUS FROM 库名 LIKE '表名';\r\n  \r\n  -- 查看mysql数据库中user表字符集\r\n  SHOW TABLE STATUS FROM mysql LIKE 'user';\r\n  ```\r\n\r\n- C(Create)：创建\r\n\r\n  - 创建数据表\r\n\r\n    - 标准语法\r\n\r\n    ```mysql\r\n    CREATE TABLE 表名(\r\n        列名1 数据类型1,\r\n        列名2 数据类型2,\r\n        ....\r\n        列名n 数据类型n\r\n    );\r\n    -- 注意：最后一列，不需要加逗号\r\n    ```\r\n\r\n    - 数据类型\r\n\r\n    ```mysql\r\n    1. int：整数类型\r\n    \t* age int\r\n    2. double:小数类型\r\n    \t* score double(5,2)\r\n    \t* price double\r\n    3. date:日期，只包含年月日     yyyy-MM-dd\r\n    4. datetime:日期，包含年月日时分秒\t yyyy-MM-dd HH:mm:ss\r\n    5. timestamp:时间戳类型\t包含年月日时分秒\t yyyy-MM-dd HH:mm:ss\t\r\n    \t* 如果将来不给这个字段赋值，或赋值为null，则默认使用当前的系统时间，来自动赋值\r\n    6. varchar：字符串\r\n    \t* name varchar(20):姓名最大20个字符\r\n    \t* zhangsan 8个字符  张三 2个字符\r\n    ```\r\n\r\n    - 创建数据表\r\n\r\n    ```mysql\r\n    -- 使用db3数据库\r\n    USE db3;\r\n    \r\n    -- 创建一个product商品表\r\n    CREATE TABLE product(\r\n    \tid INT,\t\t\t\t-- 商品编号\r\n    \tNAME VARCHAR(30),\t-- 商品名称\r\n    \tprice DOUBLE,\t\t-- 商品价格\r\n    \tstock INT,\t\t\t-- 商品库存\r\n    \tinsert_time DATE    -- 上架时间\r\n    );\r\n    ```\r\n\r\n    - 复制表\r\n\r\n    ```mysql\r\n    -- 标准语法\r\n    CREATE TABLE 表名 LIKE 被复制的表名;\r\n    \r\n    -- 复制product表到product2表\r\n    CREATE TABLE product2 LIKE product;\r\n    ```\r\n\r\n- U(Update)：修改\r\n\r\n  - 修改表名\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  ALTER TABLE 表名 RENAME TO 新的表名;\r\n  \r\n  -- 修改product2表名为product3\r\n  ALTER TABLE product2 RENAME TO product3;\r\n  ```\r\n\r\n  - 修改表的字符集\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  ALTER TABLE 表名 CHARACTER SET 字符集名称;\r\n  \r\n  -- 查看db3数据库中product3数据表字符集\r\n  SHOW TABLE STATUS FROM db3 LIKE 'product3';\r\n  -- 修改product3数据表字符集为gbk\r\n  ALTER TABLE product3 CHARACTER SET gbk;\r\n  -- 查看db3数据库中product3数据表字符集\r\n  SHOW TABLE STATUS FROM db3 LIKE 'product3';\r\n  ```\r\n\r\n  - 添加一列\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  ALTER TABLE 表名 ADD 列名 数据类型;\r\n  \r\n  -- 给product3表添加一列color\r\n  ALTER TABLE product3 ADD color VARCHAR(10);\r\n  ```\r\n\r\n  - 修改列名称和数据类型\r\n\r\n  ```mysql\r\n  -- 修改数据类型 标准语法\r\n  ALTER TABLE 表名 MODIFY 列名 新数据类型;\r\n  \r\n  -- 将color数据类型修改为int\r\n  ALTER TABLE product3 MODIFY color INT;\r\n  -- 查看product3表详细信息\r\n  DESC product3;\r\n  \r\n  \r\n  -- 修改列名和数据类型 标准语法\r\n  ALTER TABLE 表名 CHANGE 列名 新列名 新数据类型;\r\n  \r\n  -- 将color修改为address,数据类型为varchar\r\n  ALTER TABLE product3 CHANGE color address VARCHAR(30);\r\n  -- 查看product3表详细信息\r\n  DESC product3;\r\n  ```\r\n\r\n  - 删除列\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  ALTER TABLE 表名 DROP 列名;\r\n  \r\n  -- 删除address列\r\n  ALTER TABLE product3 DROP address;\r\n  ```\r\n\r\n- D(Delete)：删除\r\n\r\n  - 删除数据表\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DROP TABLE 表名;\r\n  \r\n  -- 删除product3表\r\n  DROP TABLE product3;\r\n  \r\n  -- 删除不存在的表，会报错\r\n  -- 错误代码：1051  Unknown table 'product3'\r\n  DROP TABLE product3;\r\n  ```\r\n\r\n  - 删除数据表(判断，如果存在则删除)\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DROP TABLE IF EXISTS 表名;\r\n  \r\n  -- 删除product3表，如果存在则删除\r\n  DROP TABLE IF EXISTS product3;\r\n  ```\r\n\r\n#### 5.DML-INSERT语句\r\n\r\n- 新增表数据语法\r\n\r\n  - 新增格式1：给指定列添加数据\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  INSERT INTO 表名(列名1,列名2,...) VALUES (值1,值2,...);\r\n  \r\n  -- 向product表添加一条数据\r\n  INSERT INTO product(id,NAME,price,stock,insert_time) VALUES (1,'手机',1999,22,'2099-09-09');\r\n  \r\n  -- 向product表添加指定列数据\r\n  INSERT INTO product (id,NAME,price) VALUES (2,'电脑',4999);\r\n  \r\n  -- 查看表中所有数据\r\n  SELECT * FROM product;\r\n  ```\r\n\r\n  - 新增格式2：默认给全部列添加数据\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  INSERT INTO 表名 VALUES (值1,值2,值3,...);\r\n  \r\n  -- 默认给全部列添加数据\r\n  INSERT INTO product VALUES (3,'电视',2999,18,'2099-06-06');\r\n  \r\n  -- 查看表中所有数据\r\n  SELECT * FROM product;\r\n  ```\r\n\r\n  - 新增格式3：批量添加数据\r\n\r\n  ```mysql\r\n  -- 默认添加所有列数据 标准语法\r\n  INSERT INTO 表名 VALUES (值1,值2,值3,...),(值1,值2,值3,...),(值1,值2,值3,...);\r\n  \r\n  -- 批量添加数据\r\n  INSERT INTO product VALUES (4,'冰箱',999,26,'2099-08-08'),(5,'洗衣机',1999,32,'2099-05-10');\r\n  -- 查看表中所有数据\r\n  SELECT * FROM product;\r\n  \r\n  \r\n  -- 给指定列添加数据 标准语法\r\n  INSERT INTO 表名(列名1,列名2,...) VALUES (值1,值2,...),(值1,值2,...),(值1,值2,...);\r\n  \r\n  -- 批量添加指定列数据\r\n  INSERT INTO product (id,NAME,price) VALUES (6,'微波炉',499),(7,'电磁炉',899);\r\n  -- 查看表中所有数据\r\n  SELECT * FROM product;\r\n  ```\r\n\r\n- 注意事项\r\n\r\n  - 列名和值的数量以及数据类型要对应\r\n  - 除了数字类型，其他数据类型的数据都需要加引号(单引双引都可以，推荐单引)\r\n\r\n#### 6.DML-UPDATE语句\r\n\r\n- 修改表数据语法\r\n\r\n```mysql\r\n-- 标准语法\r\nUPDATE 表名 SET 列名1 = 值1,列名2 = 值2,... [where 条件];\r\n\r\n-- 修改手机的价格为3500\r\nUPDATE product SET price=3500 WHERE NAME='手机';\r\n\r\n-- 查看所有数据\r\nSELECT * FROM product;\r\n\r\n-- 修改电视的价格为1800、库存为36\r\nUPDATE product SET price=1800,stock=36 WHERE NAME='电视';\r\n\r\n-- 修改电磁炉的库存为10\r\nUPDATE product SET stock=10 WHERE id=7;\r\n```\r\n\r\n- 注意事项\r\n  - 修改语句中必须加条件\r\n  - 如果不加条件，则将所有数据都修改\r\n\r\n#### 7.DML-DELETE语句\r\n\r\n- 删除表数据语法\r\n\r\n```mysql\r\n-- 标准语法\r\nDELETE FROM 表名 [WHERE 条件];\r\n\r\n-- 删除product表中的微波炉信息\r\nDELETE FROM product WHERE NAME='微波炉';\r\n\r\n-- 删除product表中库存为10的商品信息\r\nDELETE FROM product WHERE stock=10;\r\n\r\n-- 查看所有商品信息\r\nSELECT * FROM product;\r\n```\r\n\r\n- 注意事项\r\n  - 删除语句中必须加条件\r\n  - 如果不加条件，则将所有数据删除\r\n\r\n#### 8.DQL-单表查询\r\n\r\n- 数据准备(直接复制执行即可)\r\n\r\n```mysql\r\n-- 创建db1数据库\r\nCREATE DATABASE db1;\r\n\r\n-- 使用db1数据库\r\nUSE db1;\r\n\r\n-- 创建数据表\r\nCREATE TABLE product(\r\n\tid INT,\t\t\t\t-- 商品编号\r\n\tNAME VARCHAR(20),\t-- 商品名称\r\n\tprice DOUBLE,\t\t-- 商品价格\r\n\tbrand VARCHAR(10),\t-- 商品品牌\r\n\tstock INT,\t\t\t-- 商品库存\r\n\tinsert_time DATE    -- 添加时间\r\n);\r\n\r\n-- 添加数据\r\nINSERT INTO product VALUES (1,'华为手机',3999,'华为',23,'2088-03-10'),\r\n(2,'小米手机',2999,'小米',30,'2088-05-15'),\r\n(3,'苹果手机',5999,'苹果',18,'2088-08-20'),\r\n(4,'华为电脑',6999,'华为',14,'2088-06-16'),\r\n(5,'小米电脑',4999,'小米',26,'2088-07-08'),\r\n(6,'苹果电脑',8999,'苹果',15,'2088-10-25'),\r\n(7,'联想电脑',7999,'联想',NULL,'2088-11-11');\r\n```\r\n\r\n- 查询语法\r\n\r\n```mysql\r\nselect\r\n\t字段列表\r\nfrom\r\n\t表名列表\r\nwhere\r\n\t条件列表\r\ngroup by\r\n\t分组字段\r\nhaving\r\n\t分组之后的条件\r\norder by\r\n\t排序\r\nlimit\r\n\t分页限定\r\n```\r\n\r\n- 查询全部\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT * FROM 表名;\r\n\r\n-- 查询product表所有数据\r\nSELECT * FROM product;\r\n```\r\n\r\n- 查询部分\r\n\r\n  - 多个字段查询\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名1,列名2,... FROM 表名;\r\n  \r\n  -- 查询名称、价格、品牌\r\n  SELECT NAME,price,brand FROM product;\r\n  ```\r\n\r\n  - 去除重复查询\r\n    - 注意：只有全部重复的才可以去除\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT DISTINCT 列名1,列名2,... FROM 表名;\r\n  \r\n  -- 查询品牌\r\n  SELECT brand FROM product;\r\n  -- 查询品牌，去除重复\r\n  SELECT DISTINCT brand FROM product;\r\n  ```\r\n\r\n  - 计算列的值(四则运算)\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名1 运算符(+ - * /) 列名2 FROM 表名;\r\n  \r\n  /*\r\n  \t计算列的值\r\n  \t标准语法：\r\n  \t\tSELECT 列名1 运算符(+ - * /) 列名2 FROM 表名;\r\n  \t\t\r\n  \t如果某一列为null，可以进行替换\r\n  \tifnull(表达式1,表达式2)\r\n  \t表达式1：想替换的列\r\n  \t表达式2：想替换的值\r\n  */\r\n  -- 查询商品名称和库存，库存数量在原有基础上加10\r\n  SELECT NAME,stock+10 FROM product;\r\n  \r\n  -- 查询商品名称和库存，库存数量在原有基础上加10。进行null值判断\r\n  SELECT NAME,IFNULL(stock,0)+10 FROM product;\r\n  ```\r\n\r\n  - 起别名\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名1,列名2,... AS 别名 FROM 表名;\r\n  \r\n  -- 查询商品名称和库存，库存数量在原有基础上加10。进行null值判断。起别名为getSum\r\n  SELECT NAME,IFNULL(stock,0)+10 AS getsum FROM product;\r\n  SELECT NAME,IFNULL(stock,0)+10 getsum FROM product;\r\n  ```\r\n\r\n- 条件查询\r\n\r\n  - 条件分类\r\n\r\n  | 符号                | 功能                                   |\r\n  | ------------------- | -------------------------------------- |\r\n  | >                   | 大于                                   |\r\n  | <                   | 小于                                   |\r\n  | >=                  | 大于等于                               |\r\n  | <=                  | 小于等于                               |\r\n  | =                   | 等于                                   |\r\n  | <> 或 !=            | 不等于                                 |\r\n  | BETWEEN ... AND ... | 在某个范围之内(都包含)                 |\r\n  | IN(...)             | 多选一                                 |\r\n  | LIKE 占位符         | 模糊查询  _单个任意字符  %多个任意字符 |\r\n  | IS NULL             | 是NULL                                 |\r\n  | IS NOT NULL         | 不是NULL                               |\r\n  | AND 或 &&           | 并且                                   |\r\n  | OR 或 \\|\\|          | 或者                                   |\r\n  | NOT 或 !            | 非，不是                               |\r\n\r\n  - 条件查询语法\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名 FROM 表名 WHERE 条件;\r\n  \r\n  -- 查询库存大于20的商品信息\r\n  SELECT * FROM product WHERE stock > 20;\r\n  \r\n  -- 查询品牌为华为的商品信息\r\n  SELECT * FROM product WHERE brand='华为';\r\n  \r\n  -- 查询金额在4000 ~ 6000之间的商品信息\r\n  SELECT * FROM product WHERE price >= 4000 AND price <= 6000;\r\n  SELECT * FROM product WHERE price BETWEEN 4000 AND 6000;\r\n  \r\n  -- 查询库存为14、30、23的商品信息\r\n  SELECT * FROM product WHERE stock=14 OR stock=30 OR stock=23;\r\n  SELECT * FROM product WHERE stock IN(14,30,23);\r\n  \r\n  -- 查询库存为null的商品信息\r\n  SELECT * FROM product WHERE stock IS NULL;\r\n  -- 查询库存不为null的商品信息\r\n  SELECT * FROM product WHERE stock IS NOT NULL;\r\n  \r\n  -- 查询名称以小米为开头的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '小米%';\r\n  \r\n  -- 查询名称第二个字是为的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '_为%';\r\n  \r\n  -- 查询名称为四个字符的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '____';\r\n  \r\n  -- 查询名称中包含电脑的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '%电脑%';\r\n  ```\r\n\r\n- 聚合函数\r\n\r\n  - 将一列数据作为一个整体，进行纵向的计算\r\n  - 聚合函数分类\r\n\r\n  | 函数名      | 功能                           |\r\n  | ----------- | ------------------------------ |\r\n  | count(列名) | 统计数量(一般选用不为null的列) |\r\n  | max(列名)   | 最大值                         |\r\n  | min(列名)   | 最小值                         |\r\n  | sum(列名)   | 求和                           |\r\n  | avg(列名)   | 平均值                         |\r\n\r\n  - 聚合函数语法\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 函数名(列名) FROM 表名 [WHERE 条件];\r\n  \r\n  -- 计算product表中总记录条数\r\n  SELECT COUNT(*) FROM product;\r\n  \r\n  -- 获取最高价格\r\n  SELECT MAX(price) FROM product;\r\n  -- 获取最高价格的商品名称\r\n  SELECT NAME,price FROM product WHERE price = (SELECT MAX(price) FROM product);\r\n  \r\n  -- 获取最低库存\r\n  SELECT MIN(stock) FROM product;\r\n  -- 获取最低库存的商品名称\r\n  SELECT NAME,stock FROM product WHERE stock = (SELECT MIN(stock) FROM product);\r\n  \r\n  -- 获取总库存数量\r\n  SELECT SUM(stock) FROM product;\r\n  -- 获取品牌为苹果的总库存数量\r\n  SELECT SUM(stock) FROM product WHERE brand='苹果';\r\n  \r\n  -- 获取品牌为小米的平均商品价格\r\n  SELECT AVG(price) FROM product WHERE brand='小米';\r\n  ```\r\n\r\n- 排序查询\r\n\r\n  - 排序分类\r\n    - 注意：多个排序条件，当前边的条件值一样时，才会判断第二条件\r\n\r\n  | 关键词                                   | 功能                                    |\r\n  | ---------------------------------------- | --------------------------------------- |\r\n  | ORDER BY 列名1 排序方式1,列名2 排序方式2 | 对指定列排序，ASC升序(默认的)  DESC降序 |\r\n\r\n  - 排序语法\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名 FROM 表名 [WHERE 条件] ORDER BY 列名1 排序方式1,列名2 排序方式2;\r\n  \r\n  -- 按照库存升序排序\r\n  SELECT * FROM product ORDER BY stock ASC;\r\n  \r\n  -- 查询名称中包含手机的商品信息。按照金额降序排序\r\n  SELECT * FROM product WHERE NAME LIKE '%手机%' ORDER BY price DESC;\r\n  \r\n  -- 按照金额升序排序，如果金额相同，按照库存降序排列\r\n  SELECT * FROM product ORDER BY price ASC,stock DESC;\r\n  ```\r\n\r\n- 分组查询\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT 列名 FROM 表名 [WHERE 条件] GROUP BY 分组列名 [HAVING 分组后条件过滤] [ORDER BY 排序列名 排序方式];\r\n\r\n-- 按照品牌分组，获取每组商品的总金额\r\nSELECT brand,SUM(price) FROM product GROUP BY brand;\r\n\r\n-- 对金额大于4000元的商品，按照品牌分组,获取每组商品的总金额\r\nSELECT brand,SUM(price) FROM product WHERE price > 4000 GROUP BY brand;\r\n\r\n-- 对金额大于4000元的商品，按照品牌分组，获取每组商品的总金额，只显示总金额大于7000元的\r\nSELECT brand,SUM(price) AS getSum FROM product WHERE price > 4000 GROUP BY brand HAVING getSum > 7000;\r\n\r\n-- 对金额大于4000元的商品，按照品牌分组，获取每组商品的总金额，只显示总金额大于7000元的、并按照总金额的降序排列\r\nSELECT brand,SUM(price) AS getSum FROM product WHERE price > 4000 GROUP BY brand HAVING getSum > 7000 ORDER BY getSum DESC;\r\n```\r\n\r\n- 分页查询\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT 列名 FROM 表名 [WHERE 条件] GROUP BY 分组列名 [HAVING 分组后条件过滤] [ORDER BY 排序列名 排序方式] LIMIT 开始索引,查询条数;\r\n-- 公式：开始索引 = (当前页码-1) * 每页显示的条数\r\n\r\n-- 每页显示2条数据\r\nSELECT * FROM product LIMIT 0,2;  -- 第一页 开始索引=(1-1) * 2\r\nSELECT * FROM product LIMIT 2,2;  -- 第二页 开始索引=(2-1) * 2\r\nSELECT * FROM product LIMIT 4,2;  -- 第三页 开始索引=(3-1) * 2\r\nSELECT * FROM product LIMIT 6,2;  -- 第四页 开始索引=(4-1) * 2\r\n```\r\n\r\n- 分页查询图解\r\n\r\n![05](./img/sql/mysql/MySQL基础-01-授课笔记.assets/05.png)\r\n\r\n### 四、约束\r\n\r\n#### 1.约束的概念和分类\r\n\r\n- 约束的概念\r\n  - 对表中的数据进行限定，保证数据的正确性、有效性、完整性！\r\n- 约束的分类\r\n\r\n| 约束                          | 说明           |\r\n| ----------------------------- | -------------- |\r\n| PRIMARY KEY                   | 主键约束       |\r\n| PRIMARY KEY AUTO_INCREMENT    | 主键、自动增长 |\r\n| UNIQUE                        | 唯一约束       |\r\n| NOT NULL                      | 非空约束       |\r\n| FOREIGN KEY                   | 外键约束       |\r\n| FOREIGN KEY ON UPDATE CASCADE | 外键级联更新   |\r\n| FOREIGN KEY ON DELETE CASCADE | 外键级联删除   |\r\n\r\n#### 2.主键约束\r\n\r\n- 主键约束特点\r\n  - 主键约束包含：非空和唯一两个功能\r\n  - 一张表只能有一个列作为主键\r\n  - 主键一般用于表中数据的唯一标识\r\n- 建表时添加主键约束\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE TABLE 表名(\r\n\t列名 数据类型 PRIMARY KEY,\r\n    列名 数据类型,\r\n    ...\r\n);\r\n\r\n-- 创建student表\r\nCREATE TABLE student(\r\n\tid INT PRIMARY KEY  -- 给id添加主键约束\r\n);\r\n\r\n-- 添加数据\r\nINSERT INTO student VALUES (1),(2);\r\n-- 主键默认唯一，添加重复数据，会报错\r\nINSERT INTO student VALUES (2);\r\n-- 主键默认非空，不能添加null的数据\r\nINSERT INTO student VALUES (NULL);\r\n\r\n-- 查询student表\r\nSELECT * FROM student;\r\n-- 查询student表详细\r\nDESC student;\r\n```\r\n\r\n- 删除主键\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 DROP PRIMARY KEY;\r\n\r\n-- 删除主键\r\nALTER TABLE student DROP PRIMARY KEY;\r\n```\r\n\r\n- 建表后单独添加主键\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 MODIFY 列名 数据类型 PRIMARY KEY;\r\n\r\n-- 添加主键\r\nALTER TABLE student MODIFY id INT PRIMARY KEY;\r\n```\r\n\r\n#### 3.主键自动增长约束\r\n\r\n- 建表时添加主键自增约束\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE TABLE 表名(\r\n\t列名 数据类型 PRIMARY KEY AUTO_INCREMENT,\r\n    列名 数据类型,\r\n    ...\r\n);\r\n\r\n-- 创建student2表\r\nCREATE TABLE student2(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT    -- 给id添加主键自增约束\r\n);\r\n\r\n-- 添加数据\r\nINSERT INTO student2 VALUES (1),(2);\r\n-- 添加null值，会自动增长\r\nINSERT INTO student2 VALUES (NULL),(NULL);\r\n\r\n-- 查询student2表\r\nSELECT * FROM student2;\r\n-- student2表详细\r\nDESC student2;\r\n```\r\n\r\n- 删除自动增长\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 MODIFY 列名 数据类型;\r\n\r\n-- 删除自动增长\r\nALTER TABLE student2 MODIFY id INT;\r\n```\r\n\r\n- 建表后单独添加自动增长\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 MODIFY 列名 数据类型 AUTO_INCREMENT;\r\n\r\n-- 添加自动增长\r\nALTER TABLE student2 MODIFY id INT AUTO_INCREMENT;\r\n```\r\n\r\n#### 4.唯一约束\r\n\r\n- 建表时添加唯一约束\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE TABLE 表名(\r\n\t列名 数据类型 UNIQUE,\r\n    列名 数据类型,\r\n    ...\r\n);\r\n\r\n-- 创建student3表\r\nCREATE TABLE student3(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\ttel VARCHAR(20) UNIQUE    -- 给tel列添加唯一约束\r\n);\r\n\r\n-- 添加数据\r\nINSERT INTO student3 VALUES (NULL,'18888888888'),(NULL,'18666666666');\r\n-- 添加重复数据，会报错\r\nINSERT INTO student3 VALUES (NULL,'18666666666');\r\n\r\n-- 查询student3数据表\r\nSELECT * FROM student3;\r\n-- student3表详细\r\nDESC student3;\r\n```\r\n\r\n- 删除唯一约束\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 DROP INDEX 列名;\r\n\r\n-- 删除唯一约束\r\nALTER TABLE student3 DROP INDEX tel;\r\n```\r\n\r\n- 建表后单独添加唯一约束\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 MODIFY 列名 数据类型 UNIQUE;\r\n\r\n-- 添加唯一约束\r\nALTER TABLE student3 MODIFY tel VARCHAR(20) UNIQUE;\r\n```\r\n\r\n#### 5.非空约束\r\n\r\n- 建表时添加非空约束\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE TABLE 表名(\r\n\t列名 数据类型 NOT NULL,\r\n    列名 数据类型,\r\n    ...\r\n);\r\n\r\n-- 创建student4表\r\nCREATE TABLE student4(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(20) NOT NULL    -- 给name添加非空约束\r\n);\r\n\r\n-- 添加数据\r\nINSERT INTO student4 VALUES (NULL,'张三'),(NULL,'李四');\r\n-- 添加null值，会报错\r\nINSERT INTO student4 VALUES (NULL,NULL);\r\n```\r\n\r\n- 删除非空约束\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 MODIFY 列名 数据类型;\r\n\r\n-- 删除非空约束\r\nALTER TABLE student4 MODIFY NAME VARCHAR(20);\r\n```\r\n\r\n- 建表后单独添加非空约束\r\n\r\n  ```SQL\r\n  -- 标准语法\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型 NOT NULL;\r\n  \r\n  -- 添加非空约束\r\n  ALTER TABLE student4 MODIFY NAME VARCHAR(20) NOT NULL;\r\n  ```\r\n\r\n  ",x={data:function(){return{MainComponent:F}}},Q=x,H=Object(L["a"])(Q,q,w,!1,null,"4ca93e75",null),P=H.exports,V=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},Y=[],G="\x3c!--\r\n * @Date           : 2021-04-10 22:51:38\r\n * @FilePath       : /jinnian-space/src/pages/sql/md/MySQL数据类型.md\r\n * @Description    : \r\n--\x3e\r\n# MySQL数据类型\r\n### 各数据类型及字节长度一览表：\r\n\r\n| 数据类型           | 字节长度 | 范围或用法                                                   |\r\n| ------------------ | -------- | ------------------------------------------------------------ |\r\n| Bit                | 1        | 无符号[0,255]，有符号[-128,127]，天缘博客备注：BIT和BOOL布尔型都占用1字节 |\r\n| TinyInt            | 1        | 整数[0,255]                                                  |\r\n| SmallInt           | 2        | 无符号[0,65535]，有符号[-32768,32767]                        |\r\n| MediumInt          | 3        | 无符号[0,2^24-1]，有符号[-2^23,2^23-1]]                      |\r\n| Int                | 4        | 无符号[0,2^32-1]，有符号[-2^31,2^31-1]                       |\r\n| BigInt             | 8        | 无符号[0,2^64-1]，有符号[-2^63 ,2^63 -1]                     |\r\n| Float(M,D)         | 4        | 单精度浮点数。天缘博客提醒这里的D是精度，如果D<=24则为默认的FLOAT，如果D>24则会自动被转换为DOUBLE型。 |\r\n| Double(M,D)        | 8        | 双精度浮点。                                                 |\r\n| Decimal(M,D)       | M+1或M+2 | 未打包的浮点数，用法类似于FLOAT和DOUBLE，天缘博客提醒您如果在ASP中使用到Decimal数据类型，直接从数据库读出来的Decimal可能需要先转换成Float或Double类型后再进行运算。 |\r\n| Date               | 3        | 以YYYY-MM-DD的格式显示，比如：2009-07-19                     |\r\n| Date Time          | 8        | 以YYYY-MM-DD HH:MM:SS的格式显示，比如：2009-07-19 11：22：30 |\r\n| TimeStamp          | 4        | 以YYYY-MM-DD的格式显示，比如：2009-07-19                     |\r\n| Time               | 3        | 以HH:MM:SS的格式显示。比如：11：22：30                       |\r\n| Year               | 1        | 以YYYY的格式显示。比如：2009                                 |\r\n| Char(M)            | M        | 定长字符串。                                                 |\r\n| VarChar(M)         | M        | 变长字符串，要求M<=255                                       |\r\n| Binary(M)          | M        | 类似Char的二进制存储，特点是插入定长不足补0                  |\r\n| VarBinary(M)       | M        | 类似VarChar的变长二进制存储，特点是定长不补0                 |\r\n| Tiny Text          | Max:255  | 大小写不敏感                                                 |\r\n| Text               | Max:64K  | 大小写不敏感                                                 |\r\n| Medium Text        | Max:16M  | 大小写不敏感                                                 |\r\n| Long Text          | Max:4G   | 大小写不敏感                                                 |\r\n| TinyBlob           | Max:255  | 大小写敏感                                                   |\r\n| Blob               | Max:64K  | 大小写敏感                                                   |\r\n| MediumBlob         | Max:16M  | 大小写敏感                                                   |\r\n| LongBlob           | Max:4G   | 大小写敏感                                                   |\r\n| Enum               | 1或2     | 最大可达65535个不同的枚举值                                  |\r\n| Set                | 可达8    | 最大可达64个不同的值                                         |\r\n| Geometry           |          |                                                              |\r\n| Point              |          |                                                              |\r\n| LineString         |          |                                                              |\r\n| Polygon            |          |                                                              |\r\n| MultiPoint         |          |                                                              |\r\n| MultiLineString    |          |                                                              |\r\n| MultiPolygon       |          |                                                              |\r\n| GeometryCollection |          |                                                              |\r\n\r\n",W={data:function(){return{MainComponent:G}}},K=W,j=Object(L["a"])(K,V,Y,!1,null,"3286d78d",null),X=j.exports,z=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},J=[],$="# MySQL进阶-02-授课笔记\r\n\r\n### 一、约束\r\n\r\n#### 1.外键约束\r\n\r\n- 外键约束概念\r\n\r\n  - 让表和表之间产生关系，从而保证数据的准确性！\r\n\r\n- 建表时添加外键约束\r\n\r\n  - 为什么要有外键约束\r\n\r\n  ```mysql\r\n  -- 创建db2数据库\r\n  CREATE DATABASE db2;\r\n  -- 使用db2数据库\r\n  USE db2;\r\n  \r\n  -- 创建user用户表\r\n  CREATE TABLE USER(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,    -- id\r\n  \tNAME VARCHAR(20) NOT NULL             -- 姓名\r\n  );\r\n  -- 添加用户数据\r\n  INSERT INTO USER VALUES (NULL,'张三'),(NULL,'李四'),(NULL,'王五');\r\n  \r\n  -- 创建orderlist订单表\r\n  CREATE TABLE orderlist(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,    -- id\r\n  \tnumber VARCHAR(20) NOT NULL,          -- 订单编号\r\n  \tuid INT                               -- 订单所属用户\r\n  );\r\n  -- 添加订单数据\r\n  INSERT INTO orderlist VALUES (NULL,'hm001',1),(NULL,'hm002',1),\r\n  (NULL,'hm003',2),(NULL,'hm004',2),\r\n  (NULL,'hm005',3),(NULL,'hm006',3);\r\n  \r\n  -- 添加一个订单，但是没有所属用户。这合理吗？\r\n  INSERT INTO orderlist VALUES (NULL,'hm007',8);\r\n  -- 删除王五这个用户，但是订单表中王五还有很多个订单呢。这合理吗？\r\n  DELETE FROM USER WHERE NAME='王五';\r\n  \r\n  -- 所以我们需要添加外键约束，让两张表产生关系\r\n  ```\r\n\r\n  - 外键约束格式\r\n\r\n  ```mysql\r\n  CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主表主键列名)\r\n  ```\r\n\r\n  - 创建表添加外键约束\r\n\r\n  ```mysql\r\n  -- 创建user用户表\r\n  CREATE TABLE USER(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,    -- id\r\n  \tNAME VARCHAR(20) NOT NULL             -- 姓名\r\n  );\r\n  -- 添加用户数据\r\n  INSERT INTO USER VALUES (NULL,'张三'),(NULL,'李四'),(NULL,'王五');\r\n  \r\n  -- 创建orderlist订单表\r\n  CREATE TABLE orderlist(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,    -- id\r\n  \tnumber VARCHAR(20) NOT NULL,          -- 订单编号\r\n  \tuid INT,                              -- 订单所属用户\r\n  \tCONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id)   -- 添加外键约束\r\n  );\r\n  -- 添加订单数据\r\n  INSERT INTO orderlist VALUES (NULL,'hm001',1),(NULL,'hm002',1),\r\n  (NULL,'hm003',2),(NULL,'hm004',2),\r\n  (NULL,'hm005',3),(NULL,'hm006',3);\r\n  \r\n  -- 添加一个订单，但是没有所属用户。无法添加\r\n  INSERT INTO orderlist VALUES (NULL,'hm007',8);\r\n  -- 删除王五这个用户，但是订单表中王五还有很多个订单呢。无法删除\r\n  DELETE FROM USER WHERE NAME='王五';\r\n  ```\r\n\r\n- 删除外键约束\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 DROP FOREIGN KEY 外键名;\r\n\r\n-- 删除外键\r\nALTER TABLE orderlist DROP FOREIGN KEY ou_fk1;\r\n```\r\n\r\n- 建表后添加外键约束\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主键列名);\r\n\r\n-- 添加外键约束\r\nALTER TABLE orderlist ADD CONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id);\r\n```\r\n\r\n#### 2.外键的级联更新和级联删除(了解)\r\n\r\n- 什么是级联更新和级联删除\r\n  - 当我想把user用户表中的某个用户删掉，我希望该用户所有的订单也随之被删除\r\n  - 当我想把user用户表中的某个用户id修改，我希望订单表中该用户所属的订单用户编号也随之修改\r\n- 添加级联更新和级联删除\r\n\r\n```mysql\r\n-- 添加外键约束，同时添加级联更新  标准语法\r\nALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主键列名) ON UPDATE CASCADE;\r\n\r\n-- 添加外键约束，同时添加级联删除  标准语法\r\nALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主键列名) ON DELETE CASCADE;\r\n\r\n-- 添加外键约束，同时添加级联更新和级联删除  标准语法\r\nALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主键列名) ON UPDATE CASCADE ON DELETE CASCADE;\r\n\r\n\r\n-- 删除外键约束\r\nALTER TABLE orderlist DROP FOREIGN KEY ou_fk1;\r\n\r\n-- 添加外键约束，同时添加级联更新和级联删除\r\nALTER TABLE orderlist ADD CONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id) ON UPDATE CASCADE ON DELETE CASCADE;\r\n\r\n-- 将王五用户的id修改为5    订单表中的uid也随之被修改\r\nUPDATE USER SET id=5 WHERE id=3;\r\n\r\n-- 将王五用户删除     订单表中该用户所有订单也随之删除\r\nDELETE FROM USER WHERE id=5;\r\n```\r\n\r\n### 二、多表设计\r\n\r\n#### 1.一对一(了解)\r\n\r\n- 分析\r\n  - 人和身份证。一个人只有一个身份证，一个身份证只能对应一个人！\r\n- 实现原则\r\n  - 在任意一个表建立外键，去关联另外一个表的主键\r\n- SQL演示\r\n\r\n```mysql\r\n-- 创建db5数据库\r\nCREATE DATABASE db5;\r\n-- 使用db5数据库\r\nUSE db5;\r\n\r\n-- 创建person表\r\nCREATE TABLE person(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(20)\r\n);\r\n-- 添加数据\r\nINSERT INTO person VALUES (NULL,'张三'),(NULL,'李四');\r\n\r\n-- 创建card表\r\nCREATE TABLE card(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tnumber VARCHAR(50),\r\n\tpid INT UNIQUE,\r\n\tCONSTRAINT cp_fk1 FOREIGN KEY (pid) REFERENCES person(id) -- 添加外键\r\n);\r\n-- 添加数据\r\nINSERT INTO card VALUES (NULL,'12345',1),(NULL,'56789',2);\r\n```\r\n\r\n- 图解\r\n\r\n![01](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/01.png)\r\n\r\n#### 2.一对多\r\n\r\n- 分析\r\n  - 用户和订单。一个用户可以有多个订单！\r\n  - 商品分类和商品。一个分类下可以有多个商品！\r\n- 实现原则\r\n  - 在多的一方，建立外键约束，来关联一的一方主键\r\n- SQL演示\r\n\r\n```mysql\r\n/*\r\n\t用户和订单\r\n*/\r\n-- 创建user表\r\nCREATE TABLE USER(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(20)\r\n);\r\n-- 添加数据\r\nINSERT INTO USER VALUES (NULL,'张三'),(NULL,'李四');\r\n\r\n-- 创建orderlist表\r\nCREATE TABLE orderlist(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tnumber VARCHAR(20),\r\n\tuid INT,\r\n\tCONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id)  -- 添加外键约束\r\n);\r\n-- 添加数据\r\nINSERT INTO orderlist VALUES (NULL,'hm001',1),(NULL,'hm002',1),(NULL,'hm003',2),(NULL,'hm004',2);\r\n\r\n\r\n/*\r\n\t商品分类和商品\r\n*/\r\n-- 创建category表\r\nCREATE TABLE category(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(10)\r\n);\r\n-- 添加数据\r\nINSERT INTO category VALUES (NULL,'手机数码'),(NULL,'电脑办公');\r\n\r\n-- 创建product表\r\nCREATE TABLE product(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(30),\r\n\tcid INT,\r\n\tCONSTRAINT pc_fk1 FOREIGN KEY (cid) REFERENCES category(id)  -- 添加外键约束\r\n);\r\n-- 添加数据\r\nINSERT INTO product VALUES (NULL,'华为P30',1),(NULL,'小米note3',1),\r\n(NULL,'联想电脑',2),(NULL,'苹果电脑',2);\r\n```\r\n\r\n- 图解\r\n\r\n![02](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/02.png)\r\n\r\n#### 3.多对多\r\n\r\n- 分析\r\n  - 学生和课程。一个学生可以选择多个课程，一个课程也可以被多个学生选择！\r\n- 实现原则\r\n  - 需要借助第三张表中间表，中间表至少包含两个列，这两个列作为中间表的外键，分别关联两张表的主键\r\n- SQL演示\r\n\r\n```mysql\r\n-- 创建student表\r\nCREATE TABLE student(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(20)\r\n);\r\n-- 添加数据\r\nINSERT INTO student VALUES (NULL,'张三'),(NULL,'李四');\r\n\r\n-- 创建course表\r\nCREATE TABLE course(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(10)\r\n);\r\n-- 添加数据\r\nINSERT INTO course VALUES (NULL,'语文'),(NULL,'数学');\r\n\r\n-- 创建中间表\r\nCREATE TABLE stu_course(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tsid INT, -- 用于和student表的id进行外键关联\r\n\tcid INT, -- 用于和course表的id进行外键关联\r\n\tCONSTRAINT sc_fk1 FOREIGN KEY (sid) REFERENCES student(id), -- 添加外键约束\r\n\tCONSTRAINT sc_fk2 FOREIGN KEY (cid) REFERENCES course(id)   -- 添加外键约束\r\n);\r\n-- 添加数据\r\nINSERT INTO stu_course VALUES (NULL,1,1),(NULL,1,2),(NULL,2,1),(NULL,2,2);\r\n```\r\n\r\n- 图解\r\n\r\n![03](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/03.png)\r\n\r\n### 三、多表查询\r\n\r\n#### 1.多表查询-数据准备\r\n\r\n- SQL语句\r\n\r\n```mysql\r\n-- 创建db6数据库\r\nCREATE DATABASE db6;\r\n-- 使用db6数据库\r\nUSE db6;\r\n\r\n-- 创建user表\r\nCREATE TABLE USER(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 用户id\r\n\tNAME VARCHAR(20),\t\t\t        -- 用户姓名\r\n\tage INT                             -- 用户年龄\r\n);\r\n-- 添加数据\r\nINSERT INTO USER VALUES (1,'张三',23);\r\nINSERT INTO USER VALUES (2,'李四',24);\r\nINSERT INTO USER VALUES (3,'王五',25);\r\nINSERT INTO USER VALUES (4,'赵六',26);\r\n\r\n\r\n-- 订单表\r\nCREATE TABLE orderlist(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 订单id\r\n\tnumber VARCHAR(30),\t\t\t\t\t-- 订单编号\r\n\tuid INT,    -- 外键字段\r\n\tCONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id)\r\n);\r\n-- 添加数据\r\nINSERT INTO orderlist VALUES (1,'hm001',1);\r\nINSERT INTO orderlist VALUES (2,'hm002',1);\r\nINSERT INTO orderlist VALUES (3,'hm003',2);\r\nINSERT INTO orderlist VALUES (4,'hm004',2);\r\nINSERT INTO orderlist VALUES (5,'hm005',3);\r\nINSERT INTO orderlist VALUES (6,'hm006',3);\r\nINSERT INTO orderlist VALUES (7,'hm007',NULL);\r\n\r\n\r\n-- 商品分类表\r\nCREATE TABLE category(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,  -- 商品分类id\r\n\tNAME VARCHAR(10)                    -- 商品分类名称\r\n);\r\n-- 添加数据\r\nINSERT INTO category VALUES (1,'手机数码');\r\nINSERT INTO category VALUES (2,'电脑办公');\r\nINSERT INTO category VALUES (3,'烟酒茶糖');\r\nINSERT INTO category VALUES (4,'鞋靴箱包');\r\n\r\n\r\n-- 商品表\r\nCREATE TABLE product(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,   -- 商品id\r\n\tNAME VARCHAR(30),                    -- 商品名称\r\n\tcid INT, -- 外键字段\r\n\tCONSTRAINT cp_fk1 FOREIGN KEY (cid) REFERENCES category(id)\r\n);\r\n-- 添加数据\r\nINSERT INTO product VALUES (1,'华为手机',1);\r\nINSERT INTO product VALUES (2,'小米手机',1);\r\nINSERT INTO product VALUES (3,'联想电脑',2);\r\nINSERT INTO product VALUES (4,'苹果电脑',2);\r\nINSERT INTO product VALUES (5,'中华香烟',3);\r\nINSERT INTO product VALUES (6,'玉溪香烟',3);\r\nINSERT INTO product VALUES (7,'计生用品',NULL);\r\n\r\n\r\n-- 中间表\r\nCREATE TABLE us_pro(\r\n\tupid INT PRIMARY KEY AUTO_INCREMENT,  -- 中间表id\r\n\tuid INT, -- 外键字段。需要和用户表的主键产生关联\r\n\tpid INT, -- 外键字段。需要和商品表的主键产生关联\r\n\tCONSTRAINT up_fk1 FOREIGN KEY (uid) REFERENCES USER(id),\r\n\tCONSTRAINT up_fk2 FOREIGN KEY (pid) REFERENCES product(id)\r\n);\r\n-- 添加数据\r\nINSERT INTO us_pro VALUES (NULL,1,1);\r\nINSERT INTO us_pro VALUES (NULL,1,2);\r\nINSERT INTO us_pro VALUES (NULL,1,3);\r\nINSERT INTO us_pro VALUES (NULL,1,4);\r\nINSERT INTO us_pro VALUES (NULL,1,5);\r\nINSERT INTO us_pro VALUES (NULL,1,6);\r\nINSERT INTO us_pro VALUES (NULL,1,7);\r\nINSERT INTO us_pro VALUES (NULL,2,1);\r\nINSERT INTO us_pro VALUES (NULL,2,2);\r\nINSERT INTO us_pro VALUES (NULL,2,3);\r\nINSERT INTO us_pro VALUES (NULL,2,4);\r\nINSERT INTO us_pro VALUES (NULL,2,5);\r\nINSERT INTO us_pro VALUES (NULL,2,6);\r\nINSERT INTO us_pro VALUES (NULL,2,7);\r\nINSERT INTO us_pro VALUES (NULL,3,1);\r\nINSERT INTO us_pro VALUES (NULL,3,2);\r\nINSERT INTO us_pro VALUES (NULL,3,3);\r\nINSERT INTO us_pro VALUES (NULL,3,4);\r\nINSERT INTO us_pro VALUES (NULL,3,5);\r\nINSERT INTO us_pro VALUES (NULL,3,6);\r\nINSERT INTO us_pro VALUES (NULL,3,7);\r\nINSERT INTO us_pro VALUES (NULL,4,1);\r\nINSERT INTO us_pro VALUES (NULL,4,2);\r\nINSERT INTO us_pro VALUES (NULL,4,3);\r\nINSERT INTO us_pro VALUES (NULL,4,4);\r\nINSERT INTO us_pro VALUES (NULL,4,5);\r\nINSERT INTO us_pro VALUES (NULL,4,6);\r\nINSERT INTO us_pro VALUES (NULL,4,7);\r\n```\r\n\r\n- 架构器图解\r\n\r\n![04](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/04.png)\r\n\r\n#### 2.多表查询-笛卡尔积查询(了解)\r\n\r\n- 有两张表，获取这两个表的所有组合情况\r\n- 要完成多表查询，需要消除这些没有用的数据\r\n- 多表查询格式\r\n\r\n```mysql\r\nSELECT\r\n\t列名列表\r\nFROM\r\n\t表名列表\r\nWHERE\r\n\t条件...\r\n```\r\n\r\n- 笛卡尔积查询\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT 列名 FROM 表名1,表名2,...;\r\n\r\n-- 查询user表和orderlist表\r\nSELECT * FROM USER,orderlist;\r\n```\r\n\r\n#### 3.多表查询-内连接查询\r\n\r\n- 查询原理\r\n  - 内连接查询的是两张表有交集的部分数据(有主外键关联的数据)\r\n- 显式内连接\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT 列名 FROM 表名1 [INNER] JOIN 表名2 ON 条件;\r\n\r\n-- 查询用户信息和对应的订单信息\r\nSELECT * FROM USER INNER JOIN orderlist ON user.id=orderlist.uid;\r\nSELECT * FROM USER JOIN orderlist ON user.id=orderlist.uid;\r\n\r\n-- 查询用户信息和对应的订单信息，起别名\r\nSELECT * FROM USER u JOIN orderlist o ON u.id=o.uid;\r\n\r\n-- 查询用户姓名，年龄。和订单编号\r\nSELECT\r\n\tu.`name`,\t-- 姓名\r\n\tu.`age`,\t-- 年龄\r\n\to.`number`\t-- 订单编号\r\nFROM\r\n\tUSER u          -- 用户表\r\nJOIN\r\n\torderlist o     -- 订单表\r\nON \r\n\tu.`id` = o.`uid`;\r\n```\r\n\r\n- 隐式内连接\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT 列名 FROM 表名1,表名2 WHERE 条件;\r\n\r\n-- 查询用户姓名，年龄。和订单编号\r\nSELECT\r\n\tu.`name`,\t-- 姓名\r\n\tu.`age`,\t-- 年龄\r\n\to.`number`\t-- 订单编号\r\nFROM\r\n\tUSER u,\t\t-- 用户表\r\n\torderlist o     -- 订单表\r\nWHERE\r\n\tu.`id`=o.`uid`;\r\n```\r\n\r\n#### 4.多表查询-外连接查询\r\n\r\n- 左外连接\r\n\r\n  - 查询原理\r\n    - 查询左表的全部数据，和左右两张表有交集部分的数据\r\n  - 基本演示\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名 FROM 表名1 LEFT [OUTER] JOIN 表名2 ON 条件;\r\n  \r\n  -- 查询所有用户信息，以及用户对应的订单信息\r\n  SELECT\r\n  \tu.`name`,\t-- 姓名\r\n  \tu.`age`,\t-- 年龄\r\n  \to.`number`\t-- 订单编号\r\n  FROM\r\n  \tUSER u          -- 用户表\r\n  LEFT OUTER JOIN\r\n  \torderlist o     -- 订单表\r\n  ON\r\n  \tu.`id`=o.`uid`;\r\n  ```\r\n\r\n- 右外连接\r\n\r\n  - 查询原理\r\n    - 查询右表的全部数据，和左右两张表有交集部分的数据\r\n  - 基本演示\r\n\r\n  ```mysql\r\n  -- 基本语法\r\n  SELECT 列名 FROM 表名1 RIGHT [OUTER] JOIN 表名2 ON 条件;\r\n  \r\n  -- 查询所有订单信息，以及订单所属的用户信息\r\n  SELECT\r\n  \tu.`name`,\t-- 姓名\r\n  \tu.`age`,\t-- 年龄\r\n  \to.`number`\t-- 订单编号\r\n  FROM\r\n  \tUSER u          -- 用户表\r\n  RIGHT OUTER JOIN\r\n  \torderlist o     -- 订单表\r\n  ON\r\n  \tu.`id`=o.`uid`;\r\n  ```\r\n\r\n#### 5.多表查询-子查询\r\n\r\n- 子查询介绍\r\n\r\n  - 查询语句中嵌套了查询语句。我们就将嵌套查询称为子查询！\r\n\r\n- 子查询-结果是单行单列的\r\n\r\n  - 可以作为条件，使用运算符进行判断！\r\n  - 基本演示\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名 FROM 表名 WHERE 列名=(SELECT 聚合函数(列名) FROM 表名 [WHERE 条件]);\r\n  \r\n  -- 查询年龄最高的用户姓名\r\n  SELECT MAX(age) FROM USER;              -- 查询出最高年龄\r\n  SELECT NAME,age FROM USER WHERE age=26; -- 根据查询出来的最高年龄，查询姓名和年龄\r\n  SELECT NAME,age FROM USER WHERE age = (SELECT MAX(age) FROM USER);\r\n  ```\r\n\r\n- 子查询-结果是多行单列的\r\n\r\n  - 可以作为条件，使用运算符in或not in进行判断！\r\n  - 基本演示\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名 FROM 表名 WHERE 列名 [NOT] IN (SELECT 列名 FROM 表名 [WHERE 条件]); \r\n  \r\n  -- 查询张三和李四的订单信息\r\n  SELECT id FROM USER WHERE NAME='张三' OR NAME='李四';   -- 查询张三和李四用户的id\r\n  SELECT number,uid FROM orderlist WHERE uid=1 OR uid=2; -- 根据id查询订单\r\n  SELECT number,uid FROM orderlist WHERE uid IN (SELECT id FROM USER WHERE NAME='张三' OR NAME='李四');\r\n  ```\r\n\r\n- 子查询-结果是多行多列的\r\n\r\n  - 可以作为一张虚拟表参与查询！\r\n  - 基本演示\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 列名 FROM 表名 [别名],(SELECT 列名 FROM 表名 [WHERE 条件]) [别名] [WHERE 条件];\r\n  \r\n  -- 查询订单表中id大于4的订单信息和所属用户信息\r\n  SELECT * FROM USER u,(SELECT * FROM orderlist WHERE id>4) o WHERE u.id=o.uid;\r\n  ```\r\n\r\n#### 6.多表查询练习\r\n\r\n- 查询用户的编号、姓名、年龄。订单编号\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄  user表     订单编号 orderlist表\r\n\t条件：user.id = orderlist.uid\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户姓名\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`number`\t-- 订单编号\r\nFROM\r\n\tUSER t1,       -- 用户表\r\n\torderlist t2   -- 订单表\r\nWHERE\r\n\tt1.`id` = t2.`uid`;\r\n```\r\n\r\n- 查询所有的用户。用户的编号、姓名、年龄。订单编号\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄 user表     订单编号 orderlist表\r\n\t条件：user.id = orderlist.uid\r\n\t查询所有用户，使用左外连接\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户姓名\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`number`\t-- 订单编号\r\nFROM\r\n\tUSER t1        -- 用户表\r\nLEFT OUTER JOIN\r\n\torderlist t2   -- 订单表\r\nON\r\n\tt1.`id` = t2.`uid`;\r\n```\r\n\r\n- 查询所有的订单。用户的编号、姓名、年龄。订单编号\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄 user表     订单编号 orderlist表\r\n\t条件：user.id = orderlist.uid\r\n\t查询所有订单，使用右外连接\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户姓名\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`number`\t-- 订单编号\r\nFROM\r\n\tUSER t1         -- 用户表\r\nRIGHT OUTER JOIN\r\n\torderlist t2    -- 订单表\r\nON\r\n\tt1.`id` = t2.`uid`;\r\n```\r\n\r\n- 查询用户年龄大于23岁的信息。显示用户的编号、姓名、年龄。订单编号\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄 user表     订单编号 orderlist表\r\n\t条件：user.age > 23 AND user.id = orderlist.uid\r\n*/\r\n/*\r\nselect\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户姓名\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`number`\t-- 订单编号\r\nfrom\r\n\tuser t1,     -- 用户表\r\n\torderlist t2 -- 订单表\r\nwhere\r\n\tt1.`age` > 23\r\n\tand\r\n\tt1.`id` = t2.`uid`;\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户姓名\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`number`\t-- 订单编号\r\nFROM\r\n\tUSER t1       -- 用户表\r\nLEFT OUTER JOIN\r\n\torderlist t2  -- 订单表\r\nON\r\n\tt1.`id` = t2.`uid`\r\nWHERE\r\n\tt1.`age` > 23;\r\n```\r\n\r\n- 查询张三和李四用户的信息。显示用户的编号、姓名、年龄。订单编号\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄 user表     订单编号 orderlist表\r\n\t条件：user.id = orderlist.uid AND user.name IN ('张三','李四');\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户姓名\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`number`\t-- 订单编号\r\nFROM\r\n\tUSER t1,        -- 用户表\r\n\torderlist t2    -- 订单表\r\nWHERE\r\n\tt1.`id` = t2.`uid`\r\n\tAND\r\n\t-- (t1.`name` = '张三' OR t1.`name` = '李四');\r\n\tt1.`name` IN ('张三','李四');\r\n```\r\n\r\n- 查询商品分类的编号、分类名称。分类下的商品名称\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t商品分类的编号、分类名称 category表     分类下的商品名称 product表\r\n\t条件：category.id = product.cid\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 分类编号\r\n\tt1.`name`,\t-- 分类名称\r\n\tt2.`name`\t-- 商品名称\r\nFROM\r\n\tcategory t1,\t-- 商品分类表\r\n\tproduct t2\t    -- 商品表\r\nWHERE\r\n\tt1.`id` = t2.`cid`;\r\n```\r\n\r\n- 查询所有的商品分类。商品分类的编号、分类名称。分类下的商品名称\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t商品分类的编号、分类名称 category表     分类下的商品名称 product表\r\n\t条件：category.id = product.cid\r\n\t查询所有的商品分类，使用左外连接\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 分类编号\r\n\tt1.`name`,\t-- 分类名称\r\n\tt2.`name`\t-- 商品名称\r\nFROM\r\n\tcategory t1\t-- 商品分类表\r\nLEFT OUTER JOIN\r\n\tproduct t2\t-- 商品表\r\nON\r\n\tt1.`id` = t2.`cid`;\r\n```\r\n\r\n- 查询所有的商品信息。商品分类的编号、分类名称。分类下的商品名称\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t商品分类的编号、分类名称 category表     分类下的商品名称 product表\r\n\t条件：category.id = product.cid\r\n\t查询所有的商品信息，使用右外连接\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 分类编号\r\n\tt1.`name`,\t-- 分类名称\r\n\tt2.`name`\t-- 商品名称\r\nFROM\r\n\tcategory t1\t-- 商品分类表\r\nRIGHT OUTER JOIN\r\n\tproduct t2\t-- 商品表\r\nON\r\n\tt1.`id` = t2.`cid`;\r\n```\r\n\r\n- 查询所有的用户和所有的商品。显示用户的编号、姓名、年龄。商品名称\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄 user表   商品名称 product表   中间表 us_pro\r\n\t条件：us_pro.uid = user.id AND us_pro.pid = product.id\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户名称\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`name`\t-- 商品名称\r\nFROM\r\n\tUSER t1,\t-- 用户表\r\n\tproduct t2,\t-- 商品表\r\n\tus_pro t3\t-- 中间表\r\nWHERE\r\n\tt3.`uid` = t1.`id`\r\n\tAND\r\n\tt3.`pid` = t2.`id`;\r\n```\r\n\r\n- 查询张三和李四这两个用户可以看到的商品。显示用户的编号、姓名、年龄。商品名称\r\n\r\n```mysql\r\n/*\r\n分析：\r\n\t用户的编号、姓名、年龄 user表   商品名称 product表   中间表 us_pro\r\n\t条件：us_pro.uid = user.id AND us_pro.pid = product.id AND user.name IN ('张三','李四')\r\n*/\r\nSELECT\r\n\tt1.`id`,\t-- 用户编号\r\n\tt1.`name`,\t-- 用户名称\r\n\tt1.`age`,\t-- 用户年龄\r\n\tt2.`name`\t-- 商品名称\r\nFROM\r\n\tUSER t1,\t-- 用户表\r\n\tproduct t2,\t-- 商品表\r\n\tus_pro t3\t-- 中间表\r\nWHERE\r\n\t(t3.`uid` = t1.`id` AND t3.`pid` = t2.`id`)\r\n\tAND\r\n\t-- (t1.`name` = '张三' or t1.`name` = '李四');\r\n\tt1.`name` IN ('张三','李四');\r\n```\r\n\r\n#### 7.多表查询-自关联查询\r\n\r\n- 自关联查询介绍\r\n  - 同一张表中有数据关联。可以多次查询这同一个表！\r\n- 自关联查询演示\r\n\r\n```mysql\r\n-- 创建员工表\r\nCREATE TABLE employee(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(20),\r\n\tmgr INT,\r\n\tsalary DOUBLE\r\n);\r\n-- 添加数据\r\nINSERT INTO employee VALUES (1001,'孙悟空',1005,9000.00),\r\n(1002,'猪八戒',1005,8000.00),\r\n(1003,'沙和尚',1005,8500.00),\r\n(1004,'小白龙',1005,7900.00),\r\n(1005,'唐僧',NULL,15000.00),\r\n(1006,'武松',1009,7600.00),\r\n(1007,'李逵',1009,7400.00),\r\n(1008,'林冲',1009,8100.00),\r\n(1009,'宋江',NULL,16000.00);\r\n\r\n-- 查询所有员工的姓名及其直接上级的姓名，没有上级的员工也需要查询\r\n/*\r\n分析：\r\n\t员工姓名 employee表        直接上级姓名 employee表\r\n\t条件：employee.mgr = employee.id\r\n\t查询左表的全部数据，和左右两张表交集部分数据，使用左外连接\r\n*/\r\nSELECT\r\n\tt1.name,\t-- 员工姓名\r\n\tt1.mgr,\t\t-- 上级编号\r\n\tt2.id,\t\t-- 员工编号\r\n\tt2.name     -- 员工姓名\r\nFROM\r\n\temployee t1  -- 员工表\r\nLEFT OUTER JOIN\r\n\temployee t2  -- 员工表\r\nON\r\n\tt1.mgr = t2.id;\r\n```\r\n\r\n### 四、视图\r\n\r\n#### 1.视图的概念\r\n\r\n- 视图是一种虚拟存在的数据表\r\n- 这个虚拟的表并不在数据库中实际存在\r\n- 作用是将一些比较复杂的查询语句的结果，封装到一个虚拟表中。后期再有相同复杂查询时，直接查询这张虚拟表即可\r\n- 说白了，视图就是将一条SELECT查询语句的结果封装到了一个虚拟表中，所以我们在创建视图的时候，工作重心就要放在这条SELECT查询语句上\r\n\r\n#### 2.视图的好处\r\n\r\n- 简单\r\n  - 对于使用视图的用户不需要关心表的结构、关联条件和筛选条件。因为这张虚拟表中保存的就是已经过滤好条件的结果集\r\n- 安全\r\n  - 视图可以设置权限 , 致使访问视图的用户只能访问他们被允许查询的结果集\r\n- 数据独立\r\n  - 一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响\r\n\r\n#### 3.视图数据准备\r\n\r\n```mysql\r\n-- 创建db7数据库\r\nCREATE DATABASE db7;\r\n\r\n-- 使用db7数据库\r\nUSE db7;\r\n\r\n-- 创建country表\r\nCREATE TABLE country(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tcountry_name VARCHAR(30)\r\n);\r\n-- 添加数据\r\nINSERT INTO country VALUES (NULL,'中国'),(NULL,'美国'),(NULL,'俄罗斯');\r\n\r\n-- 创建city表\r\nCREATE TABLE city(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tcity_name VARCHAR(30),\r\n\tcid INT, -- 外键列。关联country表的主键列id\r\n\tCONSTRAINT cc_fk1 FOREIGN KEY (cid) REFERENCES country(id)\r\n);\r\n-- 添加数据\r\nINSERT INTO city VALUES (NULL,'北京',1),(NULL,'上海',1),(NULL,'纽约',2),(NULL,'莫斯科',3);\r\n```\r\n\r\n#### 4.视图的创建\r\n\r\n- 创建视图语法\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE VIEW 视图名称 [(列名列表)] AS 查询语句;\r\n```\r\n\r\n- 普通多表查询，查询城市和所属国家\r\n\r\n```mysql\r\n-- 普通多表查询，查询城市和所属国家\r\nSELECT\r\n\tt1.*,\r\n\tt2.country_name\r\nFROM\r\n\tcity t1,\r\n\tcountry t2\r\nWHERE\r\n\tt1.cid = t2.id;\r\n\t\r\n-- 经常需要查询这样的数据，就可以创建一个视图\r\n```\r\n\r\n- 创建视图基本演示\r\n\r\n```mysql\r\n-- 创建一个视图。将查询出来的结果保存到这张虚拟表中\r\nCREATE\r\nVIEW\r\n\tcity_country\r\nAS\r\n\tSELECT t1.*,t2.country_name FROM city t1,country t2 WHERE t1.cid=t2.id;\r\n```\r\n\r\n- 创建视图并指定列名基本演示\r\n\r\n```mysql\r\n-- 创建一个视图，指定列名。将查询出来的结果保存到这张虚拟表中\r\nCREATE\r\nVIEW\r\n\tcity_country2 (city_id,city_name,cid,country_name) \r\nAS\r\n\tSELECT t1.*,t2.country_name FROM city t1,country t2 WHERE t1.cid=t2.id;\r\n\r\n```\r\n\r\n#### 5.视图的查询\r\n\r\n- 查询视图语法\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT * FROM 视图名称;\r\n```\r\n\r\n- 查询视图基本演示\r\n\r\n```mysql\r\n-- 查询视图。查询这张虚拟表，就等效于查询城市和所属国家\r\nSELECT * FROM city_country;\r\n\r\n-- 查询指定列名的视图\r\nSELECT * FROM city_country2;\r\n\r\n-- 查询所有数据表，视图也会查询出来\r\nSHOW TABLES;\r\n```\r\n\r\n- 查询视图创建语法\r\n\r\n```mysql\r\n-- 标准语法\r\nSHOW CREATE VIEW 视图名称;\r\n```\r\n\r\n- 查询视图创建语句基本演示\r\n\r\n```mysql\r\nSHOW CREATE VIEW city_country;\r\n```\r\n\r\n#### 6.视图的修改\r\n\r\n- 修改视图表中的数据\r\n\r\n```mysql\r\n-- 标准语法\r\nUPDATE 视图名称 SET 列名=值 WHERE 条件;\r\n\r\n-- 修改视图表中的城市名称北京为北京市\r\nUPDATE city_country SET city_name='北京市' WHERE city_name='北京';\r\n\r\n-- 查询视图\r\nSELECT * FROM city_country;\r\n\r\n-- 查询city表,北京也修改为了北京市\r\nSELECT * FROM city;\r\n\r\n-- 注意：视图表数据修改，会自动修改源表中的数据\r\n```\r\n\r\n- 修改视图表结构\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER VIEW 视图名称 [(列名列表)] AS 查询语句;\r\n\r\n-- 查询视图2\r\nSELECT * FROM city_country2;\r\n\r\n-- 修改视图2的列名city_id为id\r\nALTER\r\nVIEW\r\n\tcity_country2 (id,city_name,cid,country_name)\r\nAS\r\n\tSELECT t1.*,t2.country_name FROM city t1,country t2 WHERE t1.cid=t2.id;\r\n```\r\n\r\n#### 7.视图的删除\r\n\r\n- 删除视图\r\n\r\n```mysql\r\n-- 标准语法\r\nDROP VIEW [IF EXISTS] 视图名称;\r\n\r\n-- 删除视图\r\nDROP VIEW city_country;\r\n\r\n-- 删除视图2，如果存在则删除\r\nDROP VIEW IF EXISTS city_country2;\r\n```\r\n\r\n#### 8.视图的总结\r\n\r\n- 视图是一种虚拟存在的数据表\r\n- 这个虚拟的表并不在数据库中实际存在\r\n- 说白了，视图就是将一条SELECT查询语句的结果封装到了一个虚拟表中，所以我们在创建视图的时候，工作重心就要放在这条SELECT查询语句上\r\n- 视图的好处\r\n  - 简单\r\n  - 安全\r\n  - 数据独立\r\n\r\n### 五、备份与还原\r\n\r\n#### 1.命令行方式\r\n\r\n- 备份\r\n\r\n  - 使用SecureCRT工具连接到Linux系统，输入：mysqldump -u root -p 数据库名称 > 文件保存路径\r\n\r\n  ![12](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/12.png)\r\n\r\n  - 进入文件保存路径，查看文件是否存在\r\n\r\n  ![13](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/13.png)\r\n\r\n  ![14](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/14.png)\r\n\r\n- 恢复\r\n\r\n  - 登录mysql数据库\r\n\r\n  ![15](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/15.png)\r\n\r\n  - 删除已经备份的数据库\r\n\r\n  ![16](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/16.png)\r\n\r\n  - 重新创建名称相同的数据库\r\n\r\n  ![17](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/17.png)\r\n\r\n  - 使用该数据库\r\n\r\n  ![18](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/18.png)\r\n\r\n  - 导入文件执行：source 备份文件路径;\r\n\r\n  ![19](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/19.png)\r\n\r\n#### 2.图形化界面方式\r\n\r\n- 备份\r\n\r\n![05](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/05.png)\r\n\r\n![06](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/06.png)\r\n\r\n![07](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/07.png)\r\n\r\n- 恢复\r\n\r\n![08](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/08.png)\r\n\r\n![09](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/09.png)\r\n\r\n![10](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/10.png)\r\n\r\n![11](./img/sql/mysql/MySQL进阶-02-授课笔记.assets/11.png)\r\n\r\n",Z={data:function(){return{MainComponent:$}}},nn=Z,rn=Object(L["a"])(nn,z,J,!1,null,"1d3266e3",null),en=rn.exports,sn=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},tn=[],an="# MySQL高级-03-授课笔记\r\n\r\n### 一、MySQL存储过程和函数\r\n\r\n#### 1.存储过程和函数的概念\r\n\r\n- 存储过程和函数是  事先经过编译并存储在数据库中的一段 SQL 语句的集合\r\n\r\n#### 2.存储过程和函数的好处\r\n\r\n- 存储过程和函数可以重复使用，减轻开发人员的工作量。类似于java中方法可以多次调用\r\n- 减少网络流量，存储过程和函数位于服务器上，调用的时候只需要传递名称和参数即可\r\n- 减少数据在数据库和应用服务器之间的传输，可以提高数据处理的效率\r\n- 将一些业务逻辑在数据库层面来实现，可以减少代码层面的业务处理\r\n\r\n#### 3.存储过程和函数的区别\r\n\r\n- 函数必须有返回值\r\n- 存储过程没有返回值\r\n\r\n#### 4.创建存储过程\r\n\r\n- 小知识\r\n\r\n```mysql\r\n/*\r\n\t该关键字用来声明sql语句的分隔符，告诉MySQL该段命令已经结束！\r\n\tsql语句默认的分隔符是分号，但是有的时候我们需要一条功能sql语句中包含分号，但是并不作为结束标识。\r\n\t这个时候就可以使用DELIMITER来指定分隔符了！\r\n*/\r\n-- 标准语法\r\nDELIMITER 分隔符\r\n```\r\n\r\n- 数据准备\r\n\r\n```mysql\r\n-- 创建db8数据库\r\nCREATE DATABASE db8;\r\n\r\n-- 使用db8数据库\r\nUSE db8;\r\n\r\n-- 创建学生表\r\nCREATE TABLE student(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 学生id\r\n\tNAME VARCHAR(20),\t\t\t\t\t-- 学生姓名\r\n\tage INT,\t\t\t\t\t\t\t-- 学生年龄\r\n\tgender VARCHAR(5),\t\t\t\t\t-- 学生性别\r\n\tscore INT                           -- 学生成绩\r\n);\r\n-- 添加数据\r\nINSERT INTO student VALUES (NULL,'张三',23,'男',95),(NULL,'李四',24,'男',98),\r\n(NULL,'王五',25,'女',100),(NULL,'赵六',26,'女',90);\r\n\r\n-- 按照性别进行分组，查询每组学生的总成绩。按照总成绩的升序排序\r\nSELECT gender,SUM(score) getSum FROM student GROUP BY gender ORDER BY getSum ASC;\r\n```\r\n\r\n- 创建存储过程语法\r\n\r\n```mysql\r\n-- 修改分隔符为$\r\nDELIMITER $\r\n\r\n-- 标准语法\r\nCREATE PROCEDURE 存储过程名称(参数...)\r\nBEGIN\r\n\tsql语句;\r\nEND$\r\n\r\n-- 修改分隔符为分号\r\nDELIMITER ;\r\n```\r\n\r\n- 创建存储过程\r\n\r\n```mysql\r\n-- 修改分隔符为$\r\nDELIMITER $\r\n\r\n-- 创建存储过程，封装分组查询学生总成绩的sql语句\r\nCREATE PROCEDURE stu_group()\r\nBEGIN\r\n\tSELECT gender,SUM(score) getSum FROM student GROUP BY gender ORDER BY getSum ASC;\r\nEND$\r\n\r\n-- 修改分隔符为分号\r\nDELIMITER ;\r\n```\r\n\r\n#### 5.调用存储过程\r\n\r\n- 调用存储过程语法\r\n\r\n```mysql\r\n-- 标准语法\r\nCALL 存储过程名称(实际参数);\r\n\r\n-- 调用stu_group存储过程\r\nCALL stu_group();\r\n```\r\n\r\n#### 6.查看存储过程\r\n\r\n- 查看存储过程语法\r\n\r\n```mysql\r\n-- 查询数据库中所有的存储过程 标准语法\r\nSELECT * FROM mysql.proc WHERE db='数据库名称';\r\n```\r\n\r\n#### 7.删除存储过程\r\n\r\n- 删除存储过程语法\r\n\r\n```mysql\r\n-- 标准语法\r\nDROP PROCEDURE [IF EXISTS] 存储过程名称;\r\n\r\n-- 删除stu_group存储过程\r\nDROP PROCEDURE stu_group;\r\n```\r\n\r\n#### 8.存储过程语法\r\n\r\n##### 8.1存储过程语法介绍\r\n\r\n- 存储过程是可以进行编程的。意味着可以使用变量、表达式、条件控制语句、循环语句等，来完成比较复杂的功能！\r\n\r\n##### 8.2变量的使用\r\n\r\n- 定义变量\r\n\r\n```mysql\r\n-- 标准语法\r\nDECLARE 变量名 数据类型 [DEFAULT 默认值];\r\n-- 注意： DECLARE定义的是局部变量，只能用在BEGIN END范围之内\r\n\r\n-- 定义一个int类型变量、并赋默认值为10\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test1()\r\nBEGIN\r\n\tDECLARE num INT DEFAULT 10;   -- 定义变量\r\n\tSELECT num;                   -- 查询变量\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test1存储过程\r\nCALL pro_test1();\r\n```\r\n\r\n- 变量的赋值1\r\n\r\n```mysql\r\n-- 标准语法\r\nSET 变量名 = 变量值;\r\n\r\n-- 定义字符串类型变量，并赋值\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test2()\r\nBEGIN\r\n\tDECLARE NAME VARCHAR(10);   -- 定义变量\r\n\tSET NAME = '存储过程';       -- 为变量赋值\r\n\tSELECT NAME;                -- 查询变量\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test2存储过程\r\nCALL pro_test2();\r\n```\r\n\r\n- 变量的赋值2\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT 列名 INTO 变量名 FROM 表名 [WHERE 条件];\r\n\r\n-- 定义两个int变量，用于存储男女同学的总分数\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test3()\r\nBEGIN\r\n\tDECLARE men,women INT;  -- 定义变量\r\n\tSELECT SUM(score) INTO men FROM student WHERE gender='男';    -- 计算男同学总分数赋值给men\r\n\tSELECT SUM(score) INTO women FROM student WHERE gender='女';  -- 计算女同学总分数赋值给women\r\n\tSELECT men,women;           -- 查询变量\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test3存储过程\r\nCALL pro_test3();\r\n```\r\n\r\n##### 8.3if语句的使用\r\n\r\n- 标准语法\r\n\r\n```mysql\r\n-- 标准语法\r\nIF 判断条件1 THEN 执行的sql语句1;\r\n[ELSEIF 判断条件2 THEN 执行的sql语句2;]\r\n...\r\n[ELSE 执行的sql语句n;]\r\nEND IF;\r\n```\r\n\r\n- 案例演示\r\n\r\n```mysql\r\n/*\r\n\t定义一个int变量，用于存储班级总成绩\r\n\t定义一个varchar变量，用于存储分数描述\r\n\t根据总成绩判断：\r\n\t\t380分及以上    学习优秀\r\n\t\t320 ~ 380     学习不错\r\n\t\t320以下       学习一般\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test4()\r\nBEGIN\r\n\t-- 定义总分数变量\r\n\tDECLARE total INT;\r\n\t-- 定义分数描述变量\r\n\tDECLARE description VARCHAR(10);\r\n\t-- 为总分数变量赋值\r\n\tSELECT SUM(score) INTO total FROM student;\r\n\t-- 判断总分数\r\n\tIF total >= 380 THEN \r\n\t\tSET description = '学习优秀';\r\n\tELSEIF total >= 320 AND total < 380 THEN \r\n\t\tSET description = '学习不错';\r\n\tELSE \r\n\t\tSET description = '学习一般';\r\n\tEND IF;\r\n\t\r\n\t-- 查询总成绩和描述信息\r\n\tSELECT total,description;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test4存储过程\r\nCALL pro_test4();\r\n```\r\n\r\n##### 8.4参数的传递\r\n\r\n- 参数传递的语法\r\n\r\n```mysql\r\nDELIMITER $\r\n\r\n-- 标准语法\r\nCREATE PROCEDURE 存储过程名称([IN|OUT|INOUT] 参数名 数据类型)\r\nBEGIN\r\n\t执行的sql语句;\r\nEND$\r\n/*\r\n\tIN:代表输入参数，需要由调用者传递实际数据。默认的\r\n\tOUT:代表输出参数，该参数可以作为返回值\r\n\tINOUT:代表既可以作为输入参数，也可以作为输出参数\r\n*/\r\nDELIMITER ;\r\n```\r\n\r\n- 输入参数\r\n\r\n  - 标准语法\r\n\r\n  ```mysql\r\n  DELIMITER $\r\n  \r\n  -- 标准语法\r\n  CREATE PROCEDURE 存储过程名称(IN 参数名 数据类型)\r\n  BEGIN\r\n  \t执行的sql语句;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n  - 案例演示\r\n\r\n  ```mysql\r\n  /*\r\n  \t输入总成绩变量，代表学生总成绩\r\n  \t定义一个varchar变量，用于存储分数描述\r\n  \t根据总成绩判断：\r\n  \t\t380分及以上  学习优秀\r\n  \t\t320 ~ 380    学习不错\r\n  \t\t320以下      学习一般\r\n  */\r\n  DELIMITER $\r\n  \r\n  CREATE PROCEDURE pro_test5(IN total INT)\r\n  BEGIN\r\n  \t-- 定义分数描述变量\r\n  \tDECLARE description VARCHAR(10);\r\n  \t-- 判断总分数\r\n  \tIF total >= 380 THEN \r\n  \t\tSET description = '学习优秀';\r\n  \tELSEIF total >= 320 AND total < 380 THEN \r\n  \t\tSET description = '学习不错';\r\n  \tELSE \r\n  \t\tSET description = '学习一般';\r\n  \tEND IF;\r\n  \t\r\n  \t-- 查询总成绩和描述信息\r\n  \tSELECT total,description;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 调用pro_test5存储过程\r\n  CALL pro_test5(390);\r\n  CALL pro_test5((SELECT SUM(score) FROM student));\r\n  ```\r\n\r\n- 输出参数\r\n\r\n  - 标准语法\r\n\r\n  ```mysql\r\n  DELIMITER $\r\n  \r\n  -- 标准语法\r\n  CREATE PROCEDURE 存储过程名称(OUT 参数名 数据类型)\r\n  BEGIN\r\n  \t执行的sql语句;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n  - 案例演示\r\n\r\n  ```mysql\r\n  /*\r\n  \t输入总成绩变量，代表学生总成绩\r\n  \t输出分数描述变量，代表学生总成绩的描述\r\n  \t根据总成绩判断：\r\n  \t\t380分及以上  学习优秀\r\n  \t\t320 ~ 380    学习不错\r\n  \t\t320以下      学习一般\r\n  */\r\n  DELIMITER $\r\n  \r\n  CREATE PROCEDURE pro_test6(IN total INT,OUT description VARCHAR(10))\r\n  BEGIN\r\n  \t-- 判断总分数\r\n  \tIF total >= 380 THEN \r\n  \t\tSET description = '学习优秀';\r\n  \tELSEIF total >= 320 AND total < 380 THEN \r\n  \t\tSET description = '学习不错';\r\n  \tELSE \r\n  \t\tSET description = '学习一般';\r\n  \tEND IF;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 调用pro_test6存储过程\r\n  CALL pro_test6(310,@description);\r\n  \r\n  -- 查询总成绩描述\r\n  SELECT @description;\r\n  ```\r\n\r\n  - 小知识\r\n\r\n  ```mysql\r\n  @变量名:  这种变量要在变量名称前面加上“@”符号，叫做用户会话变量，代表整个会话过程他都是有作用的，这个类似于全局变量一样。\r\n  \r\n  @@变量名: 这种在变量前加上 \"@@\" 符号, 叫做系统变量 \r\n  ```\r\n\r\n##### 8.5case语句的使用\r\n\r\n- 标准语法1\r\n\r\n```mysql\r\n-- 标准语法\r\nCASE 表达式\r\nWHEN 值1 THEN 执行sql语句1;\r\n[WHEN 值2 THEN 执行sql语句2;]\r\n...\r\n[ELSE 执行sql语句n;]\r\nEND CASE;\r\n```\r\n\r\n- 标准语法2\r\n\r\n```mysql\r\n-- 标准语法\r\nCASE\r\nWHEN 判断条件1 THEN 执行sql语句1;\r\n[WHEN 判断条件2 THEN 执行sql语句2;]\r\n...\r\n[ELSE 执行sql语句n;]\r\nEND CASE;\r\n```\r\n\r\n- 案例演示\r\n\r\n```mysql\r\n/*\r\n\t输入总成绩变量，代表学生总成绩\r\n\t定义一个varchar变量，用于存储分数描述\r\n\t根据总成绩判断：\r\n\t\t380分及以上  学习优秀\r\n\t\t320 ~ 380    学习不错\r\n\t\t320以下      学习一般\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test7(IN total INT)\r\nBEGIN\r\n\t-- 定义变量\r\n\tDECLARE description VARCHAR(10);\r\n\t-- 使用case判断\r\n\tCASE\r\n\tWHEN total >= 380 THEN\r\n\t\tSET description = '学习优秀';\r\n\tWHEN total >= 320 AND total < 380 THEN\r\n\t\tSET description = '学习不错';\r\n\tELSE \r\n\t\tSET description = '学习一般';\r\n\tEND CASE;\r\n\t\r\n\t-- 查询分数描述信息\r\n\tSELECT description;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test7存储过程\r\nCALL pro_test7(390);\r\nCALL pro_test7((SELECT SUM(score) FROM student));\r\n```\r\n\r\n##### 8.6while循环\r\n\r\n- 标准语法\r\n\r\n```mysql\r\n-- 标准语法\r\n初始化语句;\r\nWHILE 条件判断语句 DO\r\n\t循环体语句;\r\n\t条件控制语句;\r\nEND WHILE;\r\n```\r\n\r\n- 案例演示\r\n\r\n```mysql\r\n/*\r\n\t计算1~100之间的偶数和\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test8()\r\nBEGIN\r\n\t-- 定义求和变量\r\n\tDECLARE result INT DEFAULT 0;\r\n\t-- 定义初始化变量\r\n\tDECLARE num INT DEFAULT 1;\r\n\t-- while循环\r\n\tWHILE num <= 100 DO\r\n\t\t-- 偶数判断\r\n\t\tIF num%2=0 THEN\r\n\t\t\tSET result = result + num; -- 累加\r\n\t\tEND IF;\r\n\t\t\r\n\t\t-- 让num+1\r\n\t\tSET num = num + 1;         \r\n\tEND WHILE;\r\n\t\r\n\t-- 查询求和结果\r\n\tSELECT result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test8存储过程\r\nCALL pro_test8();\r\n```\r\n\r\n##### 8.7repeat循环\r\n\r\n- 标准语法\r\n\r\n```mysql\r\n-- 标准语法\r\n初始化语句;\r\nREPEAT\r\n\t循环体语句;\r\n\t条件控制语句;\r\n\tUNTIL 条件判断语句\r\nEND REPEAT;\r\n\r\n-- 注意：repeat循环是条件满足则停止。while循环是条件满足则执行\r\n```\r\n\r\n- 案例演示\r\n\r\n```mysql\r\n/*\r\n\t计算1~10之间的和\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test9()\r\nBEGIN\r\n\t-- 定义求和变量\r\n\tDECLARE result INT DEFAULT 0;\r\n\t-- 定义初始化变量\r\n\tDECLARE num INT DEFAULT 1;\r\n\t-- repeat循环\r\n\tREPEAT\r\n\t\t-- 累加\r\n\t\tSET result = result + num;\r\n\t\t-- 让num+1\r\n\t\tSET num = num + 1;\r\n\t\t\r\n\t\t-- 停止循环\r\n\t\tUNTIL num>10\r\n\tEND REPEAT;\r\n\t\r\n\t-- 查询求和结果\r\n\tSELECT result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test9存储过程\r\nCALL pro_test9();\r\n```\r\n\r\n##### 8.8loop循环\r\n\r\n- 标准语法\r\n\r\n```mysql\r\n-- 标准语法\r\n初始化语句;\r\n[循环名称:] LOOP\r\n\t条件判断语句\r\n\t\t[LEAVE 循环名称;]\r\n\t循环体语句;\r\n\t条件控制语句;\r\nEND LOOP 循环名称;\r\n\r\n-- 注意：loop可以实现简单的循环，但是退出循环需要使用其他的语句来定义。我们可以使用leave语句完成！\r\n--      如果不加退出循环的语句，那么就变成了死循环。\r\n```\r\n\r\n- 案例演示\r\n\r\n```mysql\r\n/*\r\n\t计算1~10之间的和\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test10()\r\nBEGIN\r\n\t-- 定义求和变量\r\n\tDECLARE result INT DEFAULT 0;\r\n\t-- 定义初始化变量\r\n\tDECLARE num INT DEFAULT 1;\r\n\t-- loop循环\r\n\tl:LOOP\r\n\t\t-- 条件成立，停止循环\r\n\t\tIF num > 10 THEN\r\n\t\t\tLEAVE l;\r\n\t\tEND IF;\r\n\t\r\n\t\t-- 累加\r\n\t\tSET result = result + num;\r\n\t\t-- 让num+1\r\n\t\tSET num = num + 1;\r\n\tEND LOOP l;\r\n\t\r\n\t-- 查询求和结果\r\n\tSELECT result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test10存储过程\r\nCALL pro_test10();\r\n```\r\n\r\n##### 8.9游标\r\n\r\n- 游标的概念\r\n\r\n  - 游标可以遍历返回的多行结果，每次拿到一整行数据\r\n  - 在存储过程和函数中可以使用游标对结果集进行循环的处理\r\n  - 简单来说游标就类似于集合的迭代器遍历\r\n  - MySQL中的游标只能用在存储过程和函数中\r\n\r\n- 游标的语法\r\n\r\n  - 创建游标\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DECLARE 游标名称 CURSOR FOR 查询sql语句;\r\n  ```\r\n\r\n  - 打开游标\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  OPEN 游标名称;\r\n  ```\r\n\r\n  - 使用游标获取数据\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  FETCH 游标名称 INTO 变量名1,变量名2,...;\r\n  ```\r\n\r\n  - 关闭游标\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  CLOSE 游标名称;\r\n  ```\r\n\r\n- 游标的基本使用\r\n\r\n```mysql\r\n-- 创建stu_score表\r\nCREATE TABLE stu_score(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tscore INT\r\n);\r\n\r\n/*\r\n\t将student表中所有的成绩保存到stu_score表中\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test11()\r\nBEGIN\r\n\t-- 定义成绩变量\r\n\tDECLARE s_score INT;\r\n\t-- 创建游标,查询所有学生成绩数据\r\n\tDECLARE stu_result CURSOR FOR SELECT score FROM student;\r\n\t\r\n\t-- 开启游标\r\n\tOPEN stu_result;\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第1行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第2行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第3行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第4行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 关闭游标\r\n\tCLOSE stu_result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test11存储过程\r\nCALL pro_test11();\r\n\r\n-- 查询stu_score表\r\nSELECT * FROM stu_score;\r\n\r\n\r\n-- ===========================================================\r\n/*\r\n\t出现的问题：\r\n\t\tstudent表中一共有4条数据，我们在游标遍历了4次，没有问题！\r\n\t\t但是在游标中多遍历几次呢？就会出现问题\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test11()\r\nBEGIN\r\n\t-- 定义成绩变量\r\n\tDECLARE s_score INT;\r\n\t-- 创建游标,查询所有学生成绩数据\r\n\tDECLARE stu_result CURSOR FOR SELECT score FROM student;\r\n\t\r\n\t-- 开启游标\r\n\tOPEN stu_result;\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第1行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第2行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第3行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第4行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 使用游标，遍历结果,拿到第5行数据\r\n\tFETCH stu_result INTO s_score;\r\n\t-- 将数据保存到stu_score表中\r\n\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\t\r\n\t-- 关闭游标\r\n\tCLOSE stu_result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test11存储过程\r\nCALL pro_test11();\r\n\r\n-- 查询stu_score表,虽然数据正确，但是在执行存储过程时会报错\r\nSELECT * FROM stu_score;\r\n```\r\n\r\n- 游标的优化使用(配合循环使用)\r\n\r\n```mysql\r\n/*\r\n\t当游标结束后，会触发游标结束事件。我们可以通过这一特性来完成循环操作\r\n\t加标记思想：\r\n\t\t1.定义一个变量，默认值为0(意味着有数据)\r\n\t\t2.当游标结束后，将变量值改为1(意味着没有数据了)\r\n*/\r\n-- 1.定义一个变量，默认值为0(意味着有数据)\r\nDECLARE flag INT DEFAULT 0;\r\n-- 2.当游标结束后，将变量值改为1(意味着没有数据了)\r\nDECLARE EXIT HANDLER FOR NOT FOUND SET flag = 1;\r\n```\r\n\r\n```mysql\r\n/*\r\n\t将student表中所有的成绩保存到stu_score表中\r\n*/\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test12()\r\nBEGIN\r\n\t-- 定义成绩变量\r\n\tDECLARE s_score INT;\r\n\t-- 定义标记变量\r\n\tDECLARE flag INT DEFAULT 0;\r\n\t-- 创建游标，查询所有学生成绩数据\r\n\tDECLARE stu_result CURSOR FOR SELECT score FROM student;\r\n\t-- 游标结束后，将标记变量改为1\r\n\tDECLARE EXIT HANDLER FOR NOT FOUND SET flag = 1;\r\n\t\r\n\t-- 开启游标\r\n\tOPEN stu_result;\r\n\t\r\n\t-- 循环使用游标\r\n\tREPEAT\r\n\t\t-- 使用游标，遍历结果,拿到数据\r\n\t\tFETCH stu_result INTO s_score;\r\n\t\t-- 将数据保存到stu_score表中\r\n\t\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n\tUNTIL flag=1\r\n\tEND REPEAT;\r\n\t\r\n\t-- 关闭游标\r\n\tCLOSE stu_result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用pro_test12存储过程\r\nCALL pro_test12();\r\n\r\n-- 查询stu_score表\r\nSELECT * FROM stu_score;\r\n```\r\n\r\n#### 9.存储过程的总结\r\n\r\n- 存储过程是 事先经过编译并存储在数据库中的一段 SQL 语句的集合。可以在数据库层面做一些业务处理\r\n- 说白了存储过程其实就是将sql语句封装为方法，然后可以调用方法执行sql语句而已\r\n- 存储过程的好处\r\n  - 安全\r\n  - 高效\r\n  - 复用性强\r\n\r\n#### 10.存储函数\r\n\r\n- 存储函数和存储过程是非常相似的。存储函数可以做的事情，存储过程也可以做到！\r\n\r\n- 存储函数有返回值，存储过程没有返回值(参数的out其实也相当于是返回数据了)\r\n\r\n- 标准语法\r\n\r\n  - 创建存储函数\r\n\r\n  ```mysql\r\n  DELIMITER $\r\n  \r\n  -- 标准语法\r\n  CREATE FUNCTION 函数名称([参数 数据类型])\r\n  RETURNS 返回值类型\r\n  BEGIN\r\n  \t执行的sql语句;\r\n  \tRETURN 结果;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n  - 调用存储函数\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT 函数名称(实际参数);\r\n  ```\r\n\r\n  - 删除存储函数\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  DROP FUNCTION 函数名称;\r\n  ```\r\n\r\n- 案例演示\r\n\r\n```mysql\r\n/*\r\n\t定义存储函数，获取学生表中成绩大于95分的学生数量\r\n*/\r\nDELIMITER $\r\n\r\nCREATE FUNCTION fun_test1()\r\nRETURNS INT\r\nBEGIN\r\n\t-- 定义统计变量\r\n\tDECLARE result INT;\r\n\t-- 查询成绩大于95分的学生数量，给统计变量赋值\r\n\tSELECT COUNT(*) INTO result FROM student WHERE score > 95;\r\n\t-- 返回统计结果\r\n\tRETURN result;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用fun_test1存储函数\r\nSELECT fun_test1();\r\n```\r\n\r\n### 二、MySQL触发器\r\n\r\n#### 1.触发器的概念\r\n\r\n- 触发器是与表有关的数据库对象，可以在 insert/update/delete 之前或之后，触发并执行触发器中定义的SQL语句。触发器的这种特性可以协助应用在数据库端确保数据的完整性 、日志记录 、数据校验等操作 。\r\n- 使用别名 NEW 和 OLD 来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。\r\n\r\n| 触发器类型      | OLD的含义                      | NEW的含义                      |\r\n| --------------- | ------------------------------ | ------------------------------ |\r\n| INSERT 型触发器 | 无 (因为插入前状态无数据)      | NEW 表示将要或者已经新增的数据 |\r\n| UPDATE 型触发器 | OLD 表示修改之前的数据         | NEW 表示将要或已经修改后的数据 |\r\n| DELETE 型触发器 | OLD 表示将要或者已经删除的数据 | 无 (因为删除后状态无数据)      |\r\n\r\n#### 2.创建触发器\r\n\r\n- 标准语法\r\n\r\n```mysql\r\nDELIMITER $\r\n\r\nCREATE TRIGGER 触发器名称\r\nBEFORE|AFTER INSERT|UPDATE|DELETE\r\nON 表名\r\n[FOR EACH ROW]  -- 行级触发器\r\nBEGIN\r\n\t触发器要执行的功能;\r\nEND$\r\n\r\nDELIMITER ;\r\n```\r\n\r\n- 触发器演示。通过触发器记录账户表的数据变更日志。包含：增加、修改、删除\r\n\r\n  - 创建账户表\r\n\r\n  ```mysql\r\n  -- 创建db9数据库\r\n  CREATE DATABASE db9;\r\n  \r\n  -- 使用db9数据库\r\n  USE db9;\r\n  \r\n  -- 创建账户表account\r\n  CREATE TABLE account(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 账户id\r\n  \tNAME VARCHAR(20),\t\t\t\t\t-- 姓名\r\n  \tmoney DOUBLE\t\t\t\t\t\t-- 余额\r\n  );\r\n  -- 添加数据\r\n  INSERT INTO account VALUES (NULL,'张三',1000),(NULL,'李四',2000);\r\n  ```\r\n\r\n  - 创建日志表\r\n\r\n  ```mysql\r\n  -- 创建日志表account_log\r\n  CREATE TABLE account_log(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 日志id\r\n  \toperation VARCHAR(20),\t\t\t\t-- 操作类型 (insert update delete)\r\n  \toperation_time DATETIME,\t\t\t-- 操作时间\r\n  \toperation_id INT,\t\t\t\t\t-- 操作表的id\r\n  \toperation_params VARCHAR(200)       -- 操作参数\r\n  );\r\n  ```\r\n\r\n  - 创建INSERT触发器\r\n\r\n  ```mysql\r\n  -- 创建INSERT触发器\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER account_insert\r\n  AFTER INSERT\r\n  ON account\r\n  FOR EACH ROW\r\n  BEGIN\r\n  \tINSERT INTO account_log VALUES (NULL,'INSERT',NOW(),new.id,CONCAT('插入后{id=',new.id,',name=',new.name,',money=',new.money,'}'));\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 向account表添加记录\r\n  INSERT INTO account VALUES (NULL,'王五',3000);\r\n  \r\n  -- 查询account表\r\n  SELECT * FROM account;\r\n  \r\n  -- 查询日志表\r\n  SELECT * FROM account_log;\r\n  ```\r\n\r\n  - 创建UPDATE触发器\r\n\r\n  ```mysql\r\n  -- 创建UPDATE触发器\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER account_update\r\n  AFTER UPDATE\r\n  ON account\r\n  FOR EACH ROW\r\n  BEGIN\r\n  \tINSERT INTO account_log VALUES (NULL,'UPDATE',NOW(),new.id,CONCAT('修改前{id=',old.id,',name=',old.name,',money=',old.money,'}','修改后{id=',new.id,',name=',new.name,',money=',new.money,'}'));\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 修改account表\r\n  UPDATE account SET money=3500 WHERE id=3;\r\n  \r\n  -- 查询account表\r\n  SELECT * FROM account;\r\n  \r\n  -- 查询日志表\r\n  SELECT * FROM account_log;\r\n  ```\r\n\r\n  - 创建DELETE触发器\r\n\r\n  ```mysql\r\n  -- 创建DELETE触发器\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER account_delete\r\n  AFTER DELETE\r\n  ON account\r\n  FOR EACH ROW\r\n  BEGIN\r\n  \tINSERT INTO account_log VALUES (NULL,'DELETE',NOW(),old.id,CONCAT('删除前{id=',old.id,',name=',old.name,',money=',old.money,'}'));\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 删除account表数据\r\n  DELETE FROM account WHERE id=3;\r\n  \r\n  -- 查询account表\r\n  SELECT * FROM account;\r\n  \r\n  -- 查询日志表\r\n  SELECT * FROM account_log;\r\n  ```\r\n\r\n#### 3.查看触发器\r\n\r\n```mysql\r\n-- 标准语法\r\nSHOW TRIGGERS;\r\n\r\n-- 查看触发器\r\nSHOW TRIGGERS;\r\n```\r\n\r\n#### 4.删除触发器\r\n\r\n```mysql\r\n-- 标准语法\r\nDROP TRIGGER 触发器名称;\r\n\r\n-- 删除DELETE触发器\r\nDROP TRIGGER account_delete;\r\n```\r\n\r\n#### 5.触发器的总结\r\n\r\n- 触发器是与表有关的数据库对象\r\n- 可以在 insert/update/delete 之前或之后，触发并执行触发器中定义的SQL语句\r\n- 触发器的这种特性可以协助应用在数据库端确保数据的完整性 、日志记录 、数据校验等操作 \r\n- 使用别名 NEW 和 OLD 来引用触发器中发生变化的记录内容\r\n\r\n### 三、MySQL事务\r\n\r\n#### 1.事务的概念\r\n\r\n- 一条或多条 SQL 语句组成一个执行单元，其特点是这个单元要么同时成功要么同时失败，单元中的每条 SQL 语句都相互依赖，形成一个整体，如果某条 SQL 语句执行失败或者出现错误，那么整个单元就会回滚，撤回到事务最初的状态，如果单元中所有的 SQL 语句都执行成功，则事务就顺利执行。\r\n\r\n#### 2.事务的数据准备\r\n\r\n```mysql\r\n-- 创建db10数据库\r\nCREATE DATABASE db10;\r\n\r\n-- 使用db10数据库\r\nUSE db10;\r\n\r\n-- 创建账户表\r\nCREATE TABLE account(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 账户id\r\n\tNAME VARCHAR(20),\t\t\t-- 账户名称\r\n\tmoney DOUBLE\t\t\t\t-- 账户余额\r\n);\r\n-- 添加数据\r\nINSERT INTO account VALUES (NULL,'张三',1000),(NULL,'李四',1000);\r\n```\r\n\r\n#### 3.未管理事务演示\r\n\r\n```mysql\r\n-- 张三给李四转账500元\r\n-- 1.张三账户-500\r\nUPDATE account SET money=money-500 WHERE NAME='张三';\r\n-- 2.李四账户+500\r\n出错了...\r\nUPDATE account SET money=money+500 WHERE NAME='李四';\r\n\r\n-- 该场景下，这两条sql语句要么同时成功，要么同时失败。就需要被事务所管理！\r\n```\r\n\r\n#### 4.管理事务演示\r\n\r\n- 操作事务的三个步骤\r\n  1. 开启事务：记录回滚点，并通知服务器，将要执行一组操作，要么同时成功、要么同时失败\r\n  2. 执行sql语句：执行具体的一条或多条sql语句\r\n  3. 结束事务(提交|回滚)\r\n     - 提交：没出现问题，数据进行更新\r\n     - 回滚：出现问题，数据恢复到开启事务时的状态\r\n- 开启事务\r\n\r\n```mysql\r\n-- 标准语法\r\nSTART TRANSACTION;\r\n```\r\n\r\n- 回滚事务\r\n\r\n```mysql\r\n-- 标准语法\r\nROLLBACK;\r\n```\r\n\r\n- 提交事务\r\n\r\n```mysql\r\n-- 标准语法\r\nCOMMIT;\r\n```\r\n\r\n- 管理事务演示\r\n\r\n```mysql\r\n-- 开启事务\r\nSTART TRANSACTION;\r\n\r\n-- 张三给李四转账500元\r\n-- 1.张三账户-500\r\nUPDATE account SET money=money-500 WHERE NAME='张三';\r\n-- 2.李四账户+500\r\n-- 出错了...\r\nUPDATE account SET money=money+500 WHERE NAME='李四';\r\n\r\n-- 回滚事务(出现问题)\r\nROLLBACK;\r\n\r\n-- 提交事务(没出现问题)\r\nCOMMIT;\r\n```\r\n\r\n#### 5.事务的提交方式\r\n\r\n- 提交方式\r\n\r\n  - 自动提交(MySQL默认为自动提交)\r\n  - 手动提交\r\n\r\n- 修改提交方式\r\n\r\n  - 查看提交方式\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SELECT @@AUTOCOMMIT;  -- 1代表自动提交    0代表手动提交\r\n  ```\r\n\r\n  - 修改提交方式\r\n\r\n  ```mysql\r\n  -- 标准语法\r\n  SET @@AUTOCOMMIT=数字;\r\n  \r\n  -- 修改为手动提交\r\n  SET @@AUTOCOMMIT=0;\r\n  \r\n  -- 查看提交方式\r\n  SELECT @@AUTOCOMMIT;\r\n  ```\r\n\r\n#### 6.事务的四大特征(ACID)\r\n\r\n- 原子性(atomicity)\r\n  - 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响\r\n- 一致性(consistency)\r\n  - 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态\r\n  - 拿转账来说，假设张三和李四两者的钱加起来一共是2000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是2000，这就是事务的一致性\r\n- 隔离性(isolcation)\r\n  - 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离\r\n- 持久性(durability)\r\n  - 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作\r\n\r\n#### 7.事务的隔离级别\r\n\r\n- 隔离级别的概念\r\n  - 多个客户端操作时 ,各个客户端的事务之间应该是隔离的，相互独立的 , 不受影响的。\r\n  - 而如果多个事务操作同一批数据时，则需要设置不同的隔离级别 , 否则就会产生问题 。\r\n  - 我们先来了解一下四种隔离级别的名称 , 再来看看可能出现的问题\r\n- 四种隔离级别\r\n\r\n| 1     | 读未提交     | read uncommitted    |\r\n| ----- | ------------ | ------------------- |\r\n| **2** | **读已提交** | **read committed**  |\r\n| **3** | **可重复读** | **repeatable read** |\r\n| **4** | **串行化**   | **serializable**    |\r\n\r\n- 可能引发的问题\r\n\r\n| 问题           | 现象                                                         |\r\n| -------------- | ------------------------------------------------------------ |\r\n| **脏读**       | **是指在一个事务处理过程中读取了另一个未提交的事务中的数据 , 导致两次查询结果不一致** |\r\n| **不可重复读** | **是指在一个事务处理过程中读取了另一个事务中修改并已提交的数据, 导致两次查询结果不一致** |\r\n| **幻读**       | **select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入。或不存在执行delete删除，却发现删除成功** |\r\n\r\n- 查询数据库隔离级别\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT @@TX_ISOLATION;\r\n```\r\n\r\n- 修改数据库隔离级别\r\n\r\n```mysql\r\n-- 标准语法\r\nSET GLOBAL TRANSACTION ISOLATION LEVEL 级别字符串;\r\n\r\n-- 修改数据库隔离级别为read uncommitted\r\nSET GLOBAL TRANSACTION ISOLATION LEVEL read uncommitted;\r\n\r\n-- 查看隔离级别\r\nSELECT @@TX_ISOLATION;   -- 修改后需要断开连接重新开\r\n```\r\n\r\n#### 8.事务隔离级别演示\r\n\r\n- 脏读的问题\r\n\r\n  - 窗口1\r\n\r\n  ```mysql\r\n  -- 查询账户表\r\n  select * from account;\r\n  \r\n  -- 设置隔离级别为read uncommitted\r\n  set global transaction isolation level read uncommitted;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 转账\r\n  update account set money = money - 500 where id = 1;\r\n  update account set money = money + 500 where id = 2;\r\n  \r\n  -- 窗口2查询转账结果 ,出现脏读(查询到其他事务未提交的数据)\r\n  \r\n  -- 窗口2查看转账结果后，执行回滚\r\n  rollback;\r\n  ```\r\n\r\n  - 窗口2\r\n\r\n  ```mysql\r\n  -- 查询隔离级别\r\n  select @@tx_isolation;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 查询账户表\r\n  select * from account;\r\n  ```\r\n\r\n- 解决脏读的问题和演示不可重复读的问题\r\n\r\n  - 窗口1\r\n\r\n  ```mysql\r\n  -- 设置隔离级别为read committed\r\n  set global transaction isolation level read committed;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 转账\r\n  update account set money = money - 500 where id = 1;\r\n  update account set money = money + 500 where id = 2;\r\n  \r\n  -- 窗口2查看转账结果，并没有发生变化(脏读问题被解决了)\r\n  \r\n  -- 执行提交事务。\r\n  commit;\r\n  \r\n  -- 窗口2查看转账结果，数据发生了变化(出现了不可重复读的问题，读取到其他事务已提交的数据)\r\n  ```\r\n\r\n  - 窗口2\r\n\r\n  ```mysql\r\n  -- 查询隔离级别\r\n  select @@tx_isolation;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 查询账户表\r\n  select * from account;\r\n  ```\r\n\r\n- 解决不可重复读的问题\r\n\r\n  - 窗口1\r\n\r\n  ```mysql\r\n  -- 设置隔离级别为repeatable read\r\n  set global transaction isolation level repeatable read;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 转账\r\n  update account set money = money - 500 where id = 1;\r\n  update account set money = money + 500 where id = 2;\r\n  \r\n  -- 窗口2查看转账结果，并没有发生变化\r\n  \r\n  -- 执行提交事务\r\n  commit;\r\n  \r\n  -- 这个时候窗口2只要还在上次事务中，看到的结果都是相同的。只有窗口2结束事务，才能看到变化(不可重复读的问题被解决)\r\n  ```\r\n\r\n  - 窗口2\r\n\r\n  ```mysql\r\n  -- 查询隔离级别\r\n  select @@tx_isolation;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 查询账户表\r\n  select * from account;\r\n  \r\n  -- 提交事务\r\n  commit;\r\n  \r\n  -- 查询账户表\r\n  select * from account;\r\n  ```\r\n\r\n- 幻读的问题和解决\r\n\r\n  - 窗口1\r\n\r\n  ```mysql\r\n  -- 设置隔离级别为repeatable read\r\n  set global transaction isolation level repeatable read;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 添加一条记录\r\n  INSERT INTO account VALUES (3,'王五',1500);\r\n  \r\n  -- 查询账户表，本窗口可以查看到id为3的结果\r\n  SELECT * FROM account;\r\n  \r\n  -- 提交事务\r\n  COMMIT;\r\n  ```\r\n\r\n  - 窗口2\r\n\r\n  ```mysql\r\n  -- 查询隔离级别\r\n  select @@tx_isolation;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 查询账户表，查询不到新添加的id为3的记录\r\n  select * from account;\r\n  \r\n  -- 添加id为3的一条数据，发现添加失败。出现了幻读\r\n  INSERT INTO account VALUES (3,'测试',200);\r\n  \r\n  -- 提交事务\r\n  COMMIT;\r\n  \r\n  -- 查询账户表，查询到了新添加的id为3的记录\r\n  select * from account;\r\n  ```\r\n\r\n  - 解决幻读的问题\r\n\r\n  ```mysql\r\n  /*\r\n  \t窗口1\r\n  */\r\n  -- 设置隔离级别为serializable\r\n  set global transaction isolation level serializable;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 添加一条记录\r\n  INSERT INTO account VALUES (4,'赵六',1600);\r\n  \r\n  -- 查询账户表，本窗口可以查看到id为4的结果\r\n  SELECT * FROM account;\r\n  \r\n  -- 提交事务\r\n  COMMIT;\r\n  \r\n  \r\n  \r\n  /*\r\n  \t窗口2\r\n  */\r\n  -- 查询隔离级别\r\n  select @@tx_isolation;\r\n  \r\n  -- 开启事务\r\n  start transaction;\r\n  \r\n  -- 查询账户表，发现查询语句无法执行，数据表被锁住！只有窗口1提交事务后，才可以继续操作\r\n  select * from account;\r\n  \r\n  -- 添加id为4的一条数据，发现已经存在了，就不会再添加了！幻读的问题被解决\r\n  INSERT INTO account VALUES (4,'测试',200);\r\n  \r\n  -- 提交事务\r\n  COMMIT;\r\n  ```\r\n\r\n#### 9.隔离级别总结\r\n\r\n|      | 隔离级别             | 名称     | 出现脏读 | 出现不可重复读 | 出现幻读 | 数据库默认隔离级别  |\r\n| ---- | -------------------- | -------- | -------- | -------------- | -------- | ------------------- |\r\n| 1    | **read uncommitted** | 读未提交 | 是       | 是             | 是       |                     |\r\n| 2    | **read committed**   | 读已提交 | 否       | 是             | 是       | Oracle / SQL Server |\r\n| 3    | **repeatable read**  | 可重复读 | 否       | 否             | 是       | MySQL               |\r\n| 4    | **serializable **    | 串行化   | 否       | 否             | 否       |                     |\r\n\r\n> 注意：隔离级别从小到大安全性越来越高，但是效率越来越低 , 所以不建议使用READ UNCOMMITTED 和 SERIALIZABLE 隔离级别.\r\n\r\n#### 10.事务的总结\r\n\r\n- 一条或多条 SQL 语句组成一个执行单元，其特点是这个单元要么同时成功要么同时失败。例如转账操作\r\n- 开启事务：start transaction;\r\n- 回滚事务：rollback;\r\n- 提交事务：commit;\r\n- 事务四大特征\r\n  - 原子性\r\n  - 持久性\r\n  - 隔离性\r\n  - 一致性\r\n- 事务的隔离级别\r\n  - read uncommitted(读未提交)\r\n  - read committed (读已提交)\r\n  - repeatable read (可重复读)\r\n  - serializable (串行化)\r\n\r\n",on={data:function(){return{MainComponent:an}}},ln=on,dn=Object(L["a"])(ln,sn,tn,!1,null,"5d098122",null),En=dn.exports,mn=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},cn=[],pn='\x3c!--\r\n * @Date           : 2021-04-11 02:20:56\r\n * @FilePath       : /jinnian-space/src/pages/sql/module/mysql/md/MySQL高级-04-授课笔记.md\r\n * @Description    : \r\n--\x3e\r\n# MySQL高级-04-授课笔记\r\n\r\n### 一、MySQL存储引擎\r\n\r\n#### 1.MySQL体系结构\r\n\r\n- 体系结构的概念\r\n\r\n  - 任何一套系统当中，每个部件都能起到一定的作用！\r\n\r\n- MySQL的体系结构\r\n\r\n![02](./img/sql/mysql/MySQL高级-04-授课笔记.assets/02.png)\r\n\r\n- 体系结构详解\r\n  - 客户端连接\r\n    - 支持接口：支持的客户端连接，例如C、Java、PHP等语言来连接MySQL数据库\r\n  - 第一层：网络连接层\r\n    - 连接池：管理、缓冲用户的连接，线程处理等需要缓存的需求。\r\n    - 例如：当客户端发送一个请求连接，会从连接池中获取一个连接进行使用。\r\n  - 第二层：核心服务层\r\n    - 管理服务和工具：系统的管理和控制工具，例如备份恢复、复制、集群等。 \r\n    - SQL接口：接受SQL命令，并且返回查询结果。\r\n    - 查询解析器：验证和解析SQL命令，例如过滤条件、语法结构等。 \r\n    - 查询优化器：在执行查询之前，使用默认的一套优化机制进行优化sql语句\r\n    - 缓存：如果缓存当中有想查询的数据，则直接将缓存中的数据返回。没有的话再重新查询！\r\n  - 第三层：存储引擎层\r\n    - 插件式存储引擎：管理和操作数据的一种机制，包括(存储数据、如何更新、查询数据等)\r\n  - 第四层：系统文件层\r\n    - 文件系统：配置文件、数据文件、日志文件、错误文件、二进制文件等等的保存\r\n\r\n#### 2.MySQL存储引擎\r\n\r\n- 引擎的概念\r\n\r\n  - 生活中，引擎就是整个机器运行的核心，不同的引擎具备不同的功能。\r\n\r\n- MySQL存储引擎的概念\r\n  - MySQL数据库使用不同的机制存取表文件 , 机制的差别在于不同的存储方式、索引技巧、锁定水平以及广泛的不同的功能和能力，在MySQL中 , 将这些不同的技术及配套的功能称为**存储引擎**\r\n  - 在关系型数据库中数据的存储是以表的形式存进行储的，所以存储引擎也可以称为**表类型**（即存储和操作此表的类型）。\r\n  - Oracle , SqlServer等数据库只有一种存储引擎 , 而MySQL针对不同的需求, 配置MySQL的不同的存储引擎 , 就会让数据库采取了不同的处理数据的方式和扩展功能。\r\n  - 通过选择不同的引擎 ,能够获取最佳的方案 ,  也能够获得额外的速度或者功能，提高程序的整体效果。所以了解引擎的特性 , 才能贴合我们的需求 , 更好的发挥数据库的性能。\r\n- MySQL支持的存储引擎\r\n  - MySQL5.7支持的引擎包括：InnoDB、MyISAM、MEMORY、Archive、Federate、CSV、BLACKHOLE等\r\n  - 其中较为常用的有三种：InnoDB、MyISAM、MEMORY\r\n\r\n#### 3.常用引擎的特性对比\r\n\r\n- 常用的存储引擎\r\n  - MyISAM存储引擎\r\n    - 访问快,不支持事务和外键。表结构保存在.frm文件中，表数据保存在.MYD文件中，索引保存在.MYI文件中。\r\n  - InnoDB存储引擎(MySQL5.5版本后默认的存储引擎)\r\n    - 支持事务 ,占用磁盘空间大 ,支持并发控制。表结构保存在.frm文件中，如果是共享表空间，数据和索引保存在 innodb_data_home_dir 和 innodb_data_file_path定义的表空间中，可以是多个文件。如果是多表空间存储，每个表的数据和索引单独保存在 .ibd 中。\r\n  - MEMORY存储引擎\r\n    - 内存存储 , 速度快 ,不安全 ,适合小量快速访问的数据。表结构保存在.frm中。\r\n- 特性对比\r\n\r\n| 特性         | MyISAM                       | InnoDB        | MEMORY             |\r\n| ------------ | ---------------------------- | ------------- | ------------------ |\r\n| 存储限制     | 有(平台对文件系统大小的限制) | 64TB          | 有(平台的内存限制) |\r\n| **事务安全** | **不支持**                   | **支持**      | **不支持**         |\r\n| **锁机制**   | **表锁**                     | **表锁/行锁** | **表锁**           |\r\n| B+Tree索引   | 支持                         | 支持          | 支持               |\r\n| 哈希索引     | 不支持                       | 不支持        | 支持               |\r\n| 全文索引     | 支持                         | 支持          | 不支持             |\r\n| **集群索引** | **不支持**                   | **支持**      | **不支持**         |\r\n| 数据索引     | 不支持                       | 支持          | 支持               |\r\n| 数据缓存     | 不支持                       | 支持          | N/A                |\r\n| 索引缓存     | 支持                         | 支持          | N/A                |\r\n| 数据可压缩   | 支持                         | 不支持        | 不支持             |\r\n| 空间使用     | 低                           | 高            | N/A                |\r\n| 内存使用     | 低                           | 高            | 中等               |\r\n| 批量插入速度 | 高                           | 低            | 高                 |\r\n| **外键**     | **不支持**                   | **支持**      | **不支持**         |\r\n\r\n#### 4.引擎的操作\r\n\r\n- 查询数据库支持的引擎\r\n\r\n```mysql\r\n-- 标准语法\r\nSHOW ENGINES;\r\n\r\n-- 查询数据库支持的存储引擎\r\nSHOW ENGINES;\r\n```\r\n\r\n```mysql\r\n-- 表含义:\r\n  - support : 指服务器是否支持该存储引擎\r\n  - transactions : 指存储引擎是否支持事务\r\n  - XA : 指存储引擎是否支持分布式事务处理\r\n  - Savepoints : 指存储引擎是否支持保存点\r\n```\r\n\r\n- 查询某个数据库中所有数据表的引擎\r\n\r\n```mysql\r\n-- 标准语法\r\nSHOW TABLE STATUS FROM 数据库名称;\r\n\r\n-- 查看db9数据库所有表的存储引擎\r\nSHOW TABLE STATUS FROM db9;\r\n```\r\n\r\n- 查询某个数据库中某个数据表的引擎\r\n\r\n```mysql\r\n-- 标准语法\r\nSHOW TABLE STATUS FROM 数据库名称 WHERE NAME = \'数据表名称\';\r\n\r\n-- 查看db9数据库中stu_score表的存储引擎\r\nSHOW TABLE STATUS FROM db9 WHERE NAME = \'stu_score\';\r\n```\r\n\r\n- 创建数据表，指定存储引擎\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE TABLE 表名(\r\n\t列名,数据类型,\r\n    ...\r\n)ENGINE = 引擎名称;\r\n\r\n-- 创建db11数据库\r\nCREATE DATABASE db11;\r\n\r\n-- 使用db11数据库\r\nUSE db11;\r\n\r\n-- 创建engine_test表，指定存储引擎为MyISAM\r\nCREATE TABLE engine_test(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(10)\r\n)ENGINE = MYISAM;\r\n\r\n-- 查询engine_test表的引擎\r\nSHOW TABLE STATUS FROM db11 WHERE NAME = \'engine_test\';\r\n```\r\n\r\n- 修改表的存储引擎\r\n\r\n```mysql\r\n-- 标准语法\r\nALTER TABLE 表名 ENGINE = 引擎名称;\r\n\r\n-- 修改engine_test表的引擎为InnoDB\r\nALTER TABLE engine_test ENGINE = INNODB;\r\n\r\n-- 查询engine_test表的引擎\r\nSHOW TABLE STATUS FROM db11 WHERE NAME = \'engine_test\';\r\n```\r\n\r\n#### 5.总结：引擎的选择\r\n\r\n- MyISAM ：由于MyISAM不支持事务、不支持外键、支持全文检索和表级锁定，读写相互阻塞，读取速度快，节约资源，所以如果应用是以**查询操作**和**插入操作**为主，只有很少的**更新和删除**操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的。\r\n- InnoDB : 是MySQL的默认存储引擎， 由于InnoDB支持事务、支持外键、行级锁定 ，支持所有辅助索引(5.5.5后不支持全文检索)，高缓存，所以用于对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，读写频繁的操作，那么InnoDB存储引擎是比较合适的选择，比如BBS、计费系统、充值转账等\r\n- MEMORY：将所有数据保存在RAM中，在需要快速定位记录和其他类似数据环境下，可以提供更快的访问。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，其次是要确保表的数据可以恢复，数据库异常终止后表中的数据是可以恢复的。MEMORY表通常用于更新不太频繁的小表，用以快速得到访问结果。\r\n- 总结：针对不同的需求场景，来选择最适合的存储引擎即可！如果不确定、则使用数据库默认的存储引擎！\r\n\r\n### 二、MySQL索引\r\n\r\n#### 1.索引的概念\r\n\r\n- 我们之前学习过集合，其中的ArrayList集合的特点之一就是有索引。那么有索引会带来哪些好处呢？\r\n- 没错，查询数据快！我们可以通过索引来快速查找到想要的数据。那么对于我们的MySQL数据库中的索引功能也是类似的！\r\n- MySQL数据库中的索引：是帮助MySQL高效获取数据的一种数据结构！所以，索引的本质就是数据结构。\r\n- 在表数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式指向数据， 这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。\r\n- 一张数据表，用于保存数据。   一个索引配置文件，用于保存索引，每个索引都去指向了某一个数据(表格演示)\r\n- 举例，无索引和有索引的查找原理\r\n\r\n![04](./img/sql/mysql/MySQL高级-04-授课笔记.assets/04.png)\r\n\r\n#### 2.索引的分类\r\n\r\n- 功能分类 \r\n  - 普通索引： 最基本的索引，它没有任何限制。\r\n  - 唯一索引：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值组合必须唯一。\r\n  - 主键索引：一种特殊的唯一索引，不允许有空值。一般在建表时同时创建主键索引。\r\n  - 组合索引：顾名思义，就是将单列索引进行组合。\r\n  - 外键索引：只有InnoDB引擎支持外键索引，用来保证数据的一致性、完整性和实现级联操作。\r\n  - 全文索引：快速匹配全部文档的方式。InnoDB引擎5.6版本后才支持全文索引。MEMORY引擎不支持。\r\n- 结构分类\r\n  - B+Tree索引 ：MySQL使用最频繁的一个索引数据结构，是InnoDB和MyISAM存储引擎默认的索引类型。\r\n  - Hash索引 : MySQL中Memory存储引擎默认支持的索引类型。\r\n\r\n#### 3.索引的操作\r\n\r\n- 数据准备\r\n\r\n```mysql\r\n-- 创建db12数据库\r\nCREATE DATABASE db12;\r\n\r\n-- 使用db12数据库\r\nUSE db12;\r\n\r\n-- 创建student表\r\nCREATE TABLE student(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(10),\r\n\tage INT,\r\n\tscore INT\r\n);\r\n-- 添加数据\r\nINSERT INTO student VALUES (NULL,\'张三\',23,98),(NULL,\'李四\',24,95),\r\n(NULL,\'王五\',25,96),(NULL,\'赵六\',26,94),(NULL,\'周七\',27,99);\r\n```\r\n\r\n- 创建索引\r\n  - 注意：如果一个表中有一列是主键，那么就会默认为其创建主键索引！(主键列不需要单独创建索引)\r\n\r\n```mysql\r\n-- 标准语法\r\nCREATE [UNIQUE|FULLTEXT] INDEX 索引名称\r\n[USING 索引类型]  -- 默认是B+TREE\r\nON 表名(列名...);\r\n\r\n-- 为student表中姓名列创建一个普通索引\r\nCREATE INDEX idx_name ON student(NAME);\r\n\r\n-- 为student表中年龄列创建一个唯一索引\r\nCREATE UNIQUE INDEX idx_age ON student(age);\r\n```\r\n\r\n- 查看索引\r\n\r\n```mysql\r\n-- 标准语法\r\nSHOW INDEX FROM 表名;\r\n\r\n-- 查看student表中的索引\r\nSHOW INDEX FROM student;\r\n```\r\n\r\n- alter语句添加索引\r\n\r\n```mysql\r\n-- 普通索引\r\nALTER TABLE 表名 ADD INDEX 索引名称(列名);\r\n\r\n-- 组合索引\r\nALTER TABLE 表名 ADD INDEX 索引名称(列名1,列名2,...);\r\n\r\n-- 主键索引\r\nALTER TABLE 表名 ADD PRIMARY KEY(主键列名); \r\n\r\n-- 外键索引(添加外键约束，就是外键索引)\r\nALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主键列名);\r\n\r\n-- 唯一索引\r\nALTER TABLE 表名 ADD UNIQUE 索引名称(列名);\r\n\r\n-- 全文索引(mysql只支持文本类型)\r\nALTER TABLE 表名 ADD FULLTEXT 索引名称(列名);\r\n\r\n\r\n-- 为student表中name列添加全文索引\r\nALTER TABLE student ADD FULLTEXT idx_fulltext_name(name);\r\n\r\n-- 查看student表中的索引\r\nSHOW INDEX FROM student;\r\n```\r\n\r\n- 删除索引\r\n\r\n```mysql\r\n-- 标准语法\r\nDROP INDEX 索引名称 ON 表名;\r\n\r\n-- 删除student表中的idx_score索引\r\nDROP INDEX idx_score ON student;\r\n\r\n-- 查看student表中的索引\r\nSHOW INDEX FROM student;\r\n```\r\n\r\n#### 4.索引效率的测试\r\n\r\n```mysql\r\n-- 创建product商品表\r\nCREATE TABLE product(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,  -- 商品id\r\n\tNAME VARCHAR(10),\t\t    -- 商品名称\r\n\tprice INT                           -- 商品价格\r\n);\r\n\r\n-- 定义存储函数，生成长度为10的随机字符串并返回\r\nDELIMITER $\r\n\r\nCREATE FUNCTION rand_string() \r\nRETURNS VARCHAR(255)\r\nBEGIN\r\n\tDECLARE big_str VARCHAR(100) DEFAULT \'abcdefghijklmnopqrstuvwxyzABCDEFGHIGKLMNOPQRSTUVWXYZ\';\r\n\tDECLARE small_str VARCHAR(255) DEFAULT \'\';\r\n\tDECLARE i INT DEFAULT 1;\r\n\t\r\n\tWHILE i <= 10 DO\r\n\t\tSET small_str =CONCAT(small_str,SUBSTRING(big_str,FLOOR(1+RAND()*52),1));\r\n\t\tSET i=i+1;\r\n\tEND WHILE;\r\n\t\r\n\tRETURN small_str;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n\r\n\r\n-- 定义存储过程，添加100万条数据到product表中\r\nDELIMITER $\r\n\r\nCREATE PROCEDURE pro_test()\r\nBEGIN\r\n\tDECLARE num INT DEFAULT 1;\r\n\t\r\n\tWHILE num <= 1000000 DO\r\n\t\tINSERT INTO product VALUES (NULL,rand_string(),num);\r\n\t\tSET num = num + 1;\r\n\tEND WHILE;\r\nEND$\r\n\r\nDELIMITER ;\r\n\r\n-- 调用存储过程\r\nCALL pro_test();\r\n\r\n\r\n-- 查询总记录条数\r\nSELECT COUNT(*) FROM product;\r\n\r\n\r\n\r\n-- 查询product表的索引\r\nSHOW INDEX FROM product;\r\n\r\n-- 查询name为OkIKDLVwtG的数据   (0.049)\r\nSELECT * FROM product WHERE NAME=\'OkIKDLVwtG\';\r\n\r\n-- 通过id列查询OkIKDLVwtG的数据  (1毫秒)\r\nSELECT * FROM product WHERE id=999998;\r\n\r\n-- 为name列添加索引\r\nALTER TABLE product ADD INDEX idx_name(NAME);\r\n\r\n-- 查询name为OkIKDLVwtG的数据   (0.001)\r\nSELECT * FROM product WHERE NAME=\'OkIKDLVwtG\';\r\n\r\n\r\n/*\r\n\t范围查询\r\n*/\r\n-- 查询价格为800~1000之间的所有数据 (0.052)\r\nSELECT * FROM product WHERE price BETWEEN 800 AND 1000;\r\n\r\n/*\r\n\t排序查询\r\n*/\r\n-- 查询价格为800~1000之间的所有数据,降序排列  (0.083)\r\nSELECT * FROM product WHERE price BETWEEN 800 AND 1000 ORDER BY price DESC;\r\n\r\n-- 为price列添加索引\r\nALTER TABLE product ADD INDEX idx_price(price);\r\n\r\n-- 查询价格为800~1000之间的所有数据 (0.011)\r\nSELECT * FROM product WHERE price BETWEEN 800 AND 1000;\r\n\r\n-- 查询价格为800~1000之间的所有数据,降序排列  (0.001)\r\nSELECT * FROM product WHERE price BETWEEN 800 AND 1000 ORDER BY price DESC;\r\n```\r\n\r\n#### 5.索引的实现原则\r\n\r\n- 索引是在MySQL的存储引擎中实现的，所以每种存储引擎的索引不一定完全相同，也不是所有的引擎支持所有的索引类型。这里我们主要介绍InnoDB引擎的实现的**B+Tree索引**。\r\n- B+Tree是一种树型数据结构，是B-Tree的变种。通常使用在数据库和操作系统中的文件系统，特点是能够保持数据稳定有序。我们逐步的来了解一下。\r\n\r\n##### 5.1磁盘存储\r\n\r\n- 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的\r\n- 位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。\r\n- InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16KB。\r\n- InnoDB引擎将若干个地址连接磁盘块，以此来达到页的大小16KB，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。\r\n\r\n##### 5.2BTree\r\n\r\n- BTree结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述BTree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data为一行记录中除主键外的数据。对于不同的记录，key值互不相同。BTree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的BTree： \r\n\r\n  ![05](./img/sql/mysql/MySQL高级-04-授课笔记.assets/05.png)\r\n\r\n- 根据图中结构显示，每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。\r\n\r\n查找顺序：\r\n\r\n```mysql\r\n模拟查找15的过程 : \r\n\r\n1.根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】\r\n\t比较关键字15在区间（<17），找到磁盘块1的指针P1。\r\n2.P1指针找到磁盘块2，读入内存。【磁盘I/O操作第2次】\r\n\t比较关键字15在区间（>12），找到磁盘块2的指针P3。\r\n3.P3指针找到磁盘块7，读入内存。【磁盘I/O操作第3次】\r\n\t在磁盘块7中找到关键字15。\r\n\t\r\n-- 分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。\r\n-- 由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个BTree查找效率的决定因素。BTree使用较少的节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。\r\n```\r\n\r\n##### 5.3B+Tree\r\n\r\n- B+Tree是在BTree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。\r\n- 从上一节中的BTree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。\r\n- B+Tree相对于BTree区别：\r\n  - 非叶子节点只存储键值信息。\r\n  - 所有叶子节点之间都有一个连接指针。\r\n  - 数据记录都存放在叶子节点中。\r\n- 将上一节中的BTree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示：\r\n\r\n![06](./img/sql/mysql/MySQL高级-04-授课笔记.assets/06.png)\r\n\r\n通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对B+Tree进行两种查找运算：\r\n\r\n- 【有范围】对于主键的范围查找和分页查找\r\n- 【有顺序】从根节点开始，进行随机查找\r\n\r\n实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2~4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。\r\n\r\n#### 6.总结：索引的设计原则\r\n\r\n索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率，更高效的使用索引。\r\n\r\n- 创建索引时的原则\r\n  - 对查询频次较高，且数据量比较大的表建立索引。\r\n  - 使用唯一索引，区分度越高，使用索引的效率越高。\r\n  - 索引字段的选择，最佳候选列应当从where子句的条件中提取，如果where子句中的组合比较多，那么应当挑选最常用、过滤效果最好的列的组合。\r\n  - 使用短索引，索引创建之后也是使用硬盘来存储的，因此提升索引访问的I/O效率，也可以提升总体的访问效率。假如构成索引的字段总长度比较短，那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升MySQL访问索引的I/O效率。\r\n  - 索引可以有效的提升查询数据的效率，但索引数量不是多多益善，索引越多，维护索引的代价自然也就水涨船高。对于插入、更新、删除等DML操作比较频繁的表来说，索引过多，会引入相当高的维护代价，降低DML操作的效率，增加相应操作的时间消耗。另外索引过多的话，MySQL也会犯选择困难病，虽然最终仍然会找到一个可用的索引，但无疑提高了选择的代价。\r\n- 联合索引的特点\r\n\r\n在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，\r\n对列name列、address和列phone列建一个联合索引\r\n\r\n```mysql\r\nALTER TABLE user ADD INDEX index_three(name,address,phone);\r\n```\r\n\r\n联合索引index_three实际建立了(name)、(name,address)、(name,address,phone)三个索引。所以下面的三个SQL语句都可以命中索引。\r\n\r\n```mysql\r\nSELECT * FROM user WHERE address = \'北京\' AND phone = \'12345\' AND name = \'张三\';\r\nSELECT * FROM user WHERE name = \'张三\' AND address = \'北京\';\r\nSELECT * FROM user WHERE name = \'张三\';\r\n```\r\n\r\n上面三个查询语句执行时会依照最左前缀匹配原则，检索时分别会使用索引\r\n\r\n```\r\n(name,address,phone)\r\n(name,address)\r\n(name)\r\n```\r\n\r\n进行数据匹配。\r\n\r\n索引的字段可以是任意顺序的，如：\r\n\r\n```mysql\r\n-- 优化器会帮助我们调整顺序，下面的SQL语句都可以命中索引\r\nSELECT * FROM user WHERE address = \'北京\' AND phone = \'12345\' AND name = \'张三\';\r\n```\r\n\r\nMysql的优化器会帮助我们调整where条件中的顺序，以匹配我们建立的索引。\r\n\r\n联合索引中最左边的列不包含在条件查询中，所以根据上面的原则，下面的SQL语句就不会命中索引。\r\n\r\n```mysql\r\n-- 联合索引中最左边的列不包含在条件查询中，下面的SQL语句就不会命中索引\r\nSELECT * FROM user WHERE address = \'北京\' AND phone = \'12345\';\r\n```\r\n\r\n### 三、MySQL锁\r\n\r\n#### 1.锁的概念\r\n\r\n- 之前我们学习过多线程，多线程当中如果想保证数据的准确性是如何实现的呢？没错，通过同步实现。同步就相当于是加锁。加了锁以后有什么好处呢？当一个线程真正在操作数据的时候，其他线程只能等待。当一个线程执行完毕后，释放锁。其他线程才能进行操作！\r\n\r\n- 那么我们的MySQL数据库中的锁的功能也是类似的。在我们学习事务的时候，讲解过事务的隔离性，可能会出现脏读、不可重复读、幻读的问题，当时我们的解决方式是通过修改事务的隔离级别来控制，但是数据库的隔离级别呢我们并不推荐修改。所以，锁的作用也可以解决掉之前的问题！\r\n\r\n- 锁机制 : 数据库为了保证数据的一致性，而使用各种共享的资源在被并发访问时变得有序所设计的一种规则。\r\n\r\n- 举例，在电商网站购买商品时，商品表中只存有1个商品，而此时又有两个人同时购买，那么谁能买到就是一个关键的问题。\r\n\r\n  这里会用到事务进行一系列的操作：\r\n\r\n  1. 先从商品表中取出物品的数据\r\n  2. 然后插入订单\r\n  3. 付款后，再插入付款表信息\r\n  4. 更新商品表中商品的数量\r\n\r\n  以上过程中，使用锁可以对商品数量数据信息进行保护，实现隔离，即只允许第一位用户完成整套购买流程，而其他用户只能等待，这样就解决了并发中的矛盾问题。\r\n\r\n- 在数据库中，数据是一种供许多用户共享访问的资源，如何保证数据并发访问的一致性、有效性，是所有数据库必须解决的一个问题，MySQL由于自身架构的特点，在不同的存储引擎中，都设计了面对特定场景的锁定机制，所以引擎的差别，导致锁机制也是有很大差别的。\r\n\r\n#### 2.锁的分类\r\n\r\n- 按操作分类：\r\n  - 共享锁：也叫读锁。针对同一份数据，多个事务读取操作可以同时加锁而不互相影响 ，但是不能修改数据记录。\r\n  - 排他锁：也叫写锁。当前的操作没有完成前,会阻断其他操作的读取和写入\r\n- 按粒度分类：\r\n  - 表级锁：操作时，会锁定整个表。开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低。偏向于MyISAM存储引擎！\r\n  - 行级锁：操作时，会锁定当前操作行。开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高。偏向于InnoDB存储引擎！\r\n  - 页级锁：锁的粒度、发生冲突的概率和加锁的开销介于表锁和行锁之间，会出现死锁，并发性能一般。\r\n- 按使用方式分类：\r\n  - 悲观锁：每次查询数据时都认为别人会修改，很悲观，所以查询时加锁。\r\n  - 乐观锁：每次查询数据时都认为别人不会修改，很乐观，但是更新时会判断一下在此期间别人有没有去更新这个数据\r\n- 不同存储引擎支持的锁\r\n\r\n| 存储引擎 | 表级锁 | 行级锁 | 页级锁 |\r\n| -------- | ------ | ------ | ------ |\r\n| MyISAM   | 支持   | 不支持 | 不支持 |\r\n| InnoDB   | 支持   | 支持   | 不支持 |\r\n| MEMORY   | 支持   | 不支持 | 不支持 |\r\n| BDB      | 支持   | 不支持 | 支持   |\r\n\r\n#### 3.演示InnoDB锁\r\n\r\n- 数据准备\r\n\r\n```mysql\r\n-- 创建db13数据库\r\nCREATE DATABASE db13;\r\n\r\n-- 使用db13数据库\r\nUSE db13;\r\n\r\n-- 创建student表\r\nCREATE TABLE student(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(10),\r\n\tage INT,\r\n\tscore INT\r\n);\r\n-- 添加数据\r\nINSERT INTO student VALUES (NULL,\'张三\',23,99),(NULL,\'李四\',24,95),\r\n(NULL,\'王五\',25,98),(NULL,\'赵六\',26,97);\r\n```\r\n\r\n- 共享锁\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT语句 LOCK IN SHARE MODE;\r\n```\r\n\r\n```mysql\r\n-- 窗口1\r\n/*\r\n\t共享锁：数据可以被多个事务查询，但是不能修改\r\n*/\r\n-- 开启事务\r\nSTART TRANSACTION;\r\n\r\n-- 查询id为1的数据记录。加入共享锁\r\nSELECT * FROM student WHERE id=1 LOCK IN SHARE MODE;\r\n\r\n-- 查询分数为99分的数据记录。加入共享锁\r\nSELECT * FROM student WHERE score=99 LOCK IN SHARE MODE;\r\n\r\n-- 提交事务\r\nCOMMIT;\r\n```\r\n\r\n```mysql\r\n-- 窗口2\r\n-- 开启事务\r\nSTART TRANSACTION;\r\n\r\n-- 查询id为1的数据记录(普通查询，可以查询)\r\nSELECT * FROM student WHERE id=1;\r\n\r\n-- 查询id为1的数据记录，并加入共享锁(可以查询。共享锁和共享锁兼容)\r\nSELECT * FROM student WHERE id=1 LOCK IN SHARE MODE;\r\n\r\n-- 修改id为1的姓名为张三三(不能修改，会出现锁的情况。只有窗口1提交事务后，才能修改成功)\r\nUPDATE student SET NAME=\'张三三\' WHERE id = 1;\r\n\r\n-- 修改id为2的姓名为李四四(修改成功，InnoDB引擎默认是行锁)\r\nUPDATE student SET NAME=\'李四四\' WHERE id = 2;\r\n\r\n-- 修改id为3的姓名为王五五(注意：InnoDB引擎如果不采用带索引的列。则会提升为表锁)\r\nUPDATE student SET NAME=\'王五五\' WHERE id = 3;\r\n\r\n-- 提交事务\r\nCOMMIT;\r\n```\r\n\r\n- 排他锁\r\n\r\n```mysql\r\n-- 标准语法\r\nSELECT语句 FOR UPDATE;\r\n```\r\n\r\n```mysql\r\n-- 窗口1\r\n/*\r\n\t排他锁：加锁的数据，不能被其他事务加锁查询或修改\r\n*/\r\n-- 开启事务\r\nSTART TRANSACTION;\r\n\r\n-- 查询id为1的数据记录，并加入排他锁\r\nSELECT * FROM student WHERE id=1 FOR UPDATE;\r\n\r\n-- 提交事务\r\nCOMMIT;\r\n```\r\n\r\n```mysql\r\n-- 窗口2\r\n-- 开启事务\r\nSTART TRANSACTION;\r\n\r\n-- 查询id为1的数据记录(普通查询没问题)\r\nSELECT * FROM student WHERE id=1;\r\n\r\n-- 查询id为1的数据记录，并加入共享锁(不能查询。因为排他锁不能和其他锁共存)\r\nSELECT * FROM student WHERE id=1 LOCK IN SHARE MODE;\r\n\r\n-- 查询id为1的数据记录，并加入排他锁(不能查询。因为排他锁不能和其他锁共存)\r\nSELECT * FROM student WHERE id=1 FOR UPDATE;\r\n\r\n-- 修改id为1的姓名为张三(不能修改，会出现锁的情况。只有窗口1提交事务后，才能修改成功)\r\nUPDATE student SET NAME=\'张三\' WHERE id=1;\r\n\r\n-- 提交事务\r\nCOMMIT;\r\n```\r\n\r\n- 注意：锁的兼容性\r\n  - 共享锁和共享锁     兼容\r\n  - 共享锁和排他锁     冲突\r\n  - 排他锁和排他锁     冲突\r\n  - 排他锁和共享锁     冲突\r\n\r\n#### 4.演示MyISAM锁\r\n\r\n- 数据准备\r\n\r\n```mysql\r\n-- 创建product表\r\nCREATE TABLE product(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\r\n\tNAME VARCHAR(20),\r\n\tprice INT\r\n)ENGINE = MYISAM;  -- 指定存储引擎为MyISAM\r\n\r\n-- 添加数据\r\nINSERT INTO product VALUES (NULL,\'华为手机\',4999),(NULL,\'小米手机\',2999),\r\n(NULL,\'苹果\',8999),(NULL,\'中兴\',1999);\r\n```\r\n\r\n- 读锁\r\n\r\n```mysql\r\n-- 标准语法\r\n-- 加锁\r\nLOCK TABLE 表名 READ;\r\n\r\n-- 解锁(将当前会话所有的表进行解锁)\r\nUNLOCK TABLES;\r\n```\r\n\r\n```mysql\r\n-- 窗口1\r\n/*\r\n\t读锁：所有连接只能读取数据，不能修改\r\n*/\r\n-- 为product表加入读锁\r\nLOCK TABLE product READ;\r\n\r\n-- 查询product表(查询成功)\r\nSELECT * FROM product;\r\n\r\n-- 修改华为手机的价格为5999(修改失败)\r\nUPDATE product SET price=5999 WHERE id=1;\r\n\r\n-- 解锁\r\nUNLOCK TABLES;\r\n```\r\n\r\n```mysql\r\n-- 窗口2\r\n-- 查询product表(查询成功)\r\nSELECT * FROM product;\r\n\r\n-- 修改华为手机的价格为5999(不能修改，窗口1解锁后才能修改成功)\r\nUPDATE product SET price=5999 WHERE id=1;\r\n```\r\n\r\n- 写锁\r\n\r\n```mysql\r\n-- 标准语法\r\n-- 加锁\r\nLOCK TABLE 表名 WRITE;\r\n\r\n-- 解锁(将当前会话所有的表进行解锁)\r\nUNLOCK TABLES;\r\n```\r\n\r\n```mysql\r\n-- 窗口1\r\n/*\r\n\t写锁：其他连接不能查询和修改数据\r\n*/\r\n-- 为product表添加写锁\r\nLOCK TABLE product WRITE;\r\n\r\n-- 查询product表(查询成功)\r\nSELECT * FROM product;\r\n\r\n-- 修改小米手机的金额为3999(修改成功)\r\nUPDATE product SET price=3999 WHERE id=2;\r\n\r\n-- 解锁\r\nUNLOCK TABLES;\r\n```\r\n\r\n```mysql\r\n-- 窗口2\r\n-- 查询product表(不能查询。只有窗口1解锁后才能查询成功)\r\nSELECT * FROM product;\r\n\r\n-- 修改小米手机的金额为2999(不能修改。只有窗口1解锁后才能修改成功)\r\nUPDATE product SET price=2999 WHERE id=2;\r\n```\r\n\r\n#### 5.演示悲观锁和乐观锁\r\n\r\n- 悲观锁的概念\r\n\r\n  - 就是很悲观，它对于数据被外界修改的操作持保守态度，认为数据随时会修改。\r\n  - 整个数据处理中需要将数据加锁。悲观锁一般都是依靠关系型数据库提供的锁机制。\r\n  - 我们之前所学的行锁，表锁不论是读写锁都是悲观锁。\r\n\r\n- 乐观锁的概念\r\n\r\n  - 就是很乐观，每次自己操作数据的时候认为没有人会来修改它，所以不去加锁。\r\n  - 但是在更新的时候会去判断在此期间数据有没有被修改。\r\n  - 需要用户自己去实现，不会发生并发抢占资源，只有在提交操作的时候检查是否违反数据完整性。\r\n\r\n- 悲观锁和乐观锁使用前提\r\n\r\n  - 对于读的操作远多于写的操作的时候，这时候一个更新操作加锁会阻塞所有的读取操作，降低了吞吐量。最后还要释放锁，锁是需要一些开销的，这时候可以选择乐观锁。\r\n  - 如果是读写比例差距不是非常大或者系统没有响应不及时，吞吐量瓶颈的问题，那就不要去使用乐观锁，它增加了复杂度，也带来了业务额外的风险。这时候可以选择悲观锁。\r\n\r\n- 乐观锁的实现方式\r\n\r\n  - 版本号\r\n\r\n    - 给数据表中添加一个version列，每次更新后都将这个列的值加1。\r\n    - 读取数据时，将版本号读取出来，在执行更新的时候，比较版本号。\r\n    - 如果相同则执行更新，如果不相同，说明此条数据已经发生了变化。\r\n    - 用户自行根据这个通知来决定怎么处理，比如重新开始一遍，或者放弃本次更新。\r\n\r\n    ```mysql\r\n    -- 创建city表\r\n    CREATE TABLE city(\r\n    \tid INT PRIMARY KEY AUTO_INCREMENT,  -- 城市id\r\n    \tNAME VARCHAR(20),                   -- 城市名称\r\n    \tVERSION INT                         -- 版本号\r\n    );\r\n    \r\n    -- 添加数据\r\n    INSERT INTO city VALUES (NULL,\'北京\',1),(NULL,\'上海\',1),(NULL,\'广州\',1),(NULL,\'深圳\',1);\r\n    \r\n    -- 修改北京为北京市\r\n    -- 1.查询北京的version\r\n    SELECT VERSION FROM city WHERE NAME=\'北京\';\r\n    -- 2.修改北京为北京市，版本号+1。并对比版本号\r\n    UPDATE city SET NAME=\'北京市\',VERSION=VERSION+1 WHERE NAME=\'北京\' AND VERSION=1;\r\n    ```\r\n\r\n  - 时间戳\r\n\r\n    - 和版本号方式基本一样，给数据表中添加一个列，名称无所谓，数据类型需要是timestamp\r\n    - 每次更新后都将最新时间插入到此列。\r\n    - 读取数据时，将时间读取出来，在执行更新的时候，比较时间。\r\n    - 如果相同则执行更新，如果不相同，说明此条数据已经发生了变化。\r\n\r\n#### 6.锁的总结\r\n\r\n- 表锁和行锁\r\n\r\n  - 行锁：锁的粒度更细，加行锁的性能损耗较大。并发处理能力较高。InnoDB引擎默认支持！\r\n  - 表锁：锁的粒度较粗，加表锁的性能损耗较小。并发处理能力较低。InnoDB、MyISAM引擎支持！\r\n\r\n- InnoDB锁优化建议\r\n\r\n  - 尽量通过带索引的列来完成数据查询，从而避免InnoDB无法加行锁而升级为表锁。\r\n\r\n  - 合理设计索引，索引要尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定。\r\n  - 尽可能减少基于范围的数据检索过滤条件。\r\n  - 尽量控制事务的大小，减少锁定的资源量和锁定时间长度。\r\n  - 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率。\r\n  - 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁的产生。\r\n\r\n### 四、集群\r\n\r\n#### 1.集群的概念\r\n\r\n- 如今随着互联网的发展，数据的量级也是成指数的增长，从GB到TB到PB。对数据的各种操作也是愈加的困难，传统的关系型数据库已经无法满足快速查询与插入数据的需求。一台数据库服务器已经无法满足海量数据的存储需求，所以由多台数据库构成的数据库集群成了必然的方式。不过，为了保证数据的一致性，查询效率等，同时又要解决多台服务器间的通信、负载均衡等问题。\r\n- MyCat是一款数据库集群软件，是阿里曾经开源的知名产品——Cobar，简单的说，MyCAT就是：一个新颖的数据库中间件产品支持MySQL集群，提供高可用性数据分片集群。你可以像使用mysql一样使用mycat。对于开发人员来说根本感觉不到mycat的存在。MyCat不单单是支持MySQL，像常用的关系型数据库Oracle、SqlServer都支持。\r\n\r\n![07](./img/sql/mysql/MySQL高级-04-授课笔记.assets/07.png)\r\n\r\n#### 2.集群的原理\r\n\r\n- 我们来说个例子，大海捞针和一个水瓶里捞针，毋庸置疑水瓶里一定能更快找到针，因为它需要检索的范围更小。数据库集群也是如此原理，我们可以将一个数据量为300G的数据库数据平均拆分成3部分，每个数据库中只存储100G数据，此时用户搜索，先经过我们中间代理层，中间代理层同时发出3个请求执行查询，比如第1台返回100条数据，耗时3秒，第2台返回200条数据，耗时3秒，第3台返回500条数据，耗时3秒，此时中间件只需要在800条记录中进行筛选，即可检索出用户要的结果，此时耗时其实一共只有3秒，因为每台机器做运算的时候，都是同时执行。如果我们此时直接在300G的数据库查询，耗时10秒，那使用中间件进行集群的效率就非常明显\r\n\r\n![08](./img/sql/mysql/MySQL高级-04-授课笔记.assets/08.png)\r\n\r\n- MyCat的实现流程和这个流程大致相似。MyCat自身不存储数据，但用户每次链接数据库的时候，直接连接MyCat即可.所以我们MyCat自身其实就是个逻辑数据库，它自身还有表结构，表结构叫逻辑表。\r\n\r\n#### 3.Mycat环境搭建\r\n\r\n##### 3.1 Mycat下载和安装\r\n\r\n- 官网：`http://www.mycat.io/`\r\n\r\n  ![09](./img/sql/mysql/MySQL高级-04-授课笔记.assets/09.png)\r\n\r\n- 下载地址 : `http://dl.mycat.io/`\r\n\r\n  ![10](./img/sql/mysql/MySQL高级-04-授课笔记.assets/10.png)\r\n\r\n- 选择1.6.7.1的版本，下载到D盘，安装包入下图：\r\n\r\n  ![11](./img/sql/mysql/MySQL高级-04-授课笔记.assets/11.png)\r\n\r\n- 上传：使用SecureCRT的SFTP命令，将文件发送到Linux虚拟机root目录下：\r\n\r\n  ```java\r\n  sftp> put D:\\Mycat-server-1.6.7.1-release-20190627191042-linux.tar.gz \r\n  ```\r\n\r\n- 解压：解压mycat.tar.gz并查看\r\n\r\n  ```java\r\n  tar -zxvf mycat.tar.gz\r\n  cd mycat\r\n  ll\r\n  ```\r\n\r\n  ![12](./img/sql/mysql/MySQL高级-04-授课笔记.assets/12.png)\r\n\r\n- 授权：设置mycat权限\r\n\r\n  ```java\r\n  chmod -R 777 mycat\r\n  ```\r\n\r\n- 环境变量：配置环境变量\r\n\r\n  ```java\r\n  vi /etc/profile \r\n  // 添加\r\n  export MYCAT_HOME=/root/mycat\r\n  \r\n  // 使环境变量生效\r\n  source /etc/profile\r\n  ```\r\n\r\n- 启动mycat\r\n\r\n  ```java\r\n  // 进入bin目录\r\n  [root@localhost]# cd /root/mycat/bin\r\n  \r\n  // 执行启动命令\r\n  [root@localhost bin]# ./mycat start\r\n  ```\r\n\r\n- 查看：检测端口监听状况，Mycat的端口号是8066\r\n\r\n  ```java\r\n  [root@localhost bin]# netstat -ant|grep 8066\r\n  ```\r\n\r\n  ![13](./img/sql/mysql/MySQL高级-04-授课笔记.assets/13.png)\r\n\r\n- 连接：使用SQLYog连接Mycat\r\n\r\n![14](./img/sql/mysql/MySQL高级-04-授课笔记.assets/14.png)\r\n\r\n- 连接后显示：\r\n\r\n  ![15](./img/sql/mysql/MySQL高级-04-授课笔记.assets/15.png)\r\n\r\n##### 3.2 环境准备\r\n\r\n- 配置模型\r\n\r\n![16](./img/sql/mysql/MySQL高级-04-授课笔记.assets/16.png)\r\n\r\n- 克隆虚拟机\r\n\r\n![17](./img/sql/mysql/MySQL高级-04-授课笔记.assets/17.png)\r\n\r\n![18](./img/sql/mysql/MySQL高级-04-授课笔记.assets/18.png)\r\n\r\n![19](./img/sql/mysql/MySQL高级-04-授课笔记.assets/19.png)\r\n\r\n![20](./img/sql/mysql/MySQL高级-04-授课笔记.assets/20.png)\r\n\r\n![21](./img/sql/mysql/MySQL高级-04-授课笔记.assets/21.png)\r\n\r\n![22](./img/sql/mysql/MySQL高级-04-授课笔记.assets/22.png)\r\n\r\n![23](./img/sql/mysql/MySQL高级-04-授课笔记.assets/23.png)\r\n\r\n- 修改配置网卡\r\n\r\n  - 在第二个虚拟机中，生成全新mac地址\r\n\r\n  ![24](./img/sql/mysql/MySQL高级-04-授课笔记.assets/24.png)\r\n\r\n  ![25](./img/sql/mysql/MySQL高级-04-授课笔记.assets/25.png)\r\n\r\n  - 重启网络\r\n\r\n  ```linux\r\n  // 重启网络\r\n  service network restart\r\n  //查看ip地址\r\n  ip addr\r\n  ```\r\n\r\n- 修改mysql配置文件,更改uuid\r\n\r\n  - 在第二个服务器上，修改mysql的uuid\r\n\r\n  ```\r\n  // 编辑配置文件\r\n  vi /var/lib/mysql/auto.cnf\r\n  // 将server-uuid更改\r\n  ```\r\n\r\n- 启动MySQL并查看\r\n\r\n```\r\n//将两台服务器的防火墙关闭\r\nsystemctl stop firewalld\r\n\r\n//启动两台服务器的mysql\r\nservice mysqld restart\r\n\r\n//启动两台服务器的mycat\r\ncd /root/mycat/bin\r\n./mycat restart\r\n\r\n//查看监听端口\r\nnetstat -ant|grep 3306\r\nnetstat -ant|grep 8066\r\n\r\n//使用sqlyog测试连接\r\n```\r\n\r\n#### 4.主从复制\r\n\r\n- 主从复制的概念\r\n\r\n  - 为了使用Mycat进行读写分离，我们先要配置MySQL数据库的主从复制。\r\n  - 从服务器自动同步主服务器的数据，从而达到数据一致。\r\n  - 进而，我们可以写操作时，只操作主服务器，而读操作，就可以操作从服务器了。\r\n  - 原理：主服务器在处理数据时，生成binlog日志，通过对日志的备份，实现从服务器的数据同步。\r\n\r\n  ![26](./img/sql/mysql/MySQL高级-04-授课笔记.assets/26.png)\r\n\r\n- 主服务器的配置\r\n\r\n  - 在第一个服务器上，编辑mysql配置文件\r\n\r\n  ```\r\n  // 编辑mysql配置文件\r\n  vi /etc/my.cnf\r\n  \r\n  //在[mysqld]下面加上：\r\n  log-bin=mysql-bin # 开启复制操作\r\n  server-id=1 # master is 1\r\n  innodb_flush_log_at_trx_commit=1\r\n  sync_binlog=1\r\n  ```\r\n\r\n  - 登录mysql，创建用户并授权\r\n\r\n  ```\r\n  // 登录mysql\r\n  mysql -u root -p\r\n  \r\n  // 去除密码权限\r\n  SET GLOBAL validate_password_policy=0;\r\n  SET GLOBAL validate_password_length=1;\r\n  \r\n  // 创建用户\r\n  CREATE USER \'hm\'@\'%\' IDENTIFIED BY \'itheima\';\r\n  \r\n  // 授权\r\n  GRANT ALL ON *.* TO \'hm\'@\'%\';\r\n  ```\r\n\r\n  - 重启mysql服务，登录mysql服务\r\n\r\n  ```\r\n  // 重启mysql\r\n  service mysqld restart\r\n  \r\n  // 登录mysql\r\n  mysql -u root -p\r\n  ```\r\n\r\n  - 查看主服务器的配置\r\n\r\n  ```\r\n  // 查看主服务器配置\r\n  show master status;\r\n  ```\r\n\r\n  ![27](./img/sql/mysql/MySQL高级-04-授课笔记.assets/27.png)\r\n\r\n- 从服务器的配置\r\n\r\n  - 在第二个服务器上，编辑mysql配置文件\r\n\r\n  ```\r\n  // 编辑mysql配置文件\r\n  vi /etc/my.cnf\r\n  \r\n  // 在[mysqld]下面加上：\r\n  server-id=2\r\n  ```\r\n\r\n  - 登录mysql\r\n\r\n  ```\r\n  // 登录mysql\r\n  mysql -u root -p\r\n  \r\n  // 执行\r\n  use mysql;\r\n  drop table slave_master_info;\r\n  drop table slave_relay_log_info;\r\n  drop table slave_worker_info;\r\n  drop table innodb_index_stats;\r\n  drop table innodb_table_stats;\r\n  source /usr/share/mysql/mysql_system_tables.sql;\r\n  ```\r\n\r\n  - 重启mysql，重新登录，配置从节点\r\n\r\n  ```\r\n  // 重启mysql\r\n  service mysqld restart\r\n  \r\n  // 重新登录mysql\r\n  mysql -u root -p\r\n  \r\n  // 执行\r\n  change master to master_host=\'主服务器ip地址\',master_port=3306,master_user=\'hm\',master_password=\'itheima\',master_log_file=\'mysql-bin.000001\',master_log_pos=4642;\r\n  ```\r\n\r\n  - 重启mysql，重新登录，开启从节点\r\n\r\n  ```\r\n  // 重启mysql\r\n  service mysqld restart\r\n  \r\n  // 重新登录mysql\r\n  mysql -u root -p\r\n  \r\n  // 开启从节点\r\n  start slave;\r\n  \r\n  // 查询结果\r\n  show slave status\\G;\r\n  //Slave_IO_Running和Slave_SQL_Running都为yes才表示同步成功。\r\n  ```\r\n\r\n  ![28](./img/sql/mysql/MySQL高级-04-授课笔记.assets/28.png)\r\n\r\n- 测试\r\n\r\n  - sqlyog连接主服务器\r\n\r\n  ```mysql\r\n  -- 主服务器创建db1数据库,从服务器会自动同步\r\n  CREATE DATABASE db1;\r\n  ```\r\n\r\n  - sqlyog连接从服务器\r\n\r\n  ```mysql\r\n  -- 从服务器创建db2数据库,主服务器不会自动同步\r\n  CREATE DATABASE db2;\r\n  ```\r\n\r\n- 启动失败的解决方案\r\n\r\n```\r\n启动失败：Slave_IO_Running为 NO \r\n方法一:重置slave\r\nslave stop;\r\nreset slave;\r\nstart slave ;\r\n方法二:重设同步日志文件及读取位置\r\nslave stop;\r\nchange master to master_log_file=’mysql-bin.000001’, master_log_pos=1;\r\nstart slave ;\r\n```\r\n\r\n#### 5.读写分离\r\n\r\n- 读写分离的概念\r\n  - 写操作只写入主服务器，读操作读取从服务器。\r\n\r\n- 在主服务器上修改server.xml\r\n  - user标签主要用于定义登录mycat的用户和权限。如上面定义用户名mycat和密码123456，该用户可以访问的schema的HEIMADB逻辑库。\r\n\r\n```xml\r\n<user name="root" defaultAccount="true">\r\n\t\t<property name="password">123456</property>\r\n\t\t<property name="schemas">HEIMADB</property>\r\n\t\t\r\n\t\t\x3c!-- 表级 DML 权限设置 --\x3e\r\n\t\t\x3c!-- \t\t\r\n\t\t<privileges check="false">\r\n\t\t\t<schema name="TESTDB" dml="0110" >\r\n\t\t\t\t<table name="tb01" dml="0000"></table>\r\n\t\t\t\t<table name="tb02" dml="1111"></table>\r\n\t\t\t</schema>\r\n\t\t</privileges>\t\t\r\n\t\t --\x3e\r\n</user>\r\n```\r\n\r\n- 在主服务器上修改schema.xml\r\n\r\n```xml\r\n<?xml version="1.0"?>\r\n<!DOCTYPE mycat:schema SYSTEM "schema.dtd">\r\n<mycat:schema xmlns:mycat="http://io.mycat/">\r\n\r\n\t<schema name="HEIMADB" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1"></schema>\r\n\t\r\n\t<dataNode name="dn1" dataHost="localhost1" database="db1" />\r\n\t\r\n\t<dataHost name="localhost1" maxCon="1000" minCon="10" balance="1"\r\n\t\t\t  writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">\r\n\t\t<heartbeat>select user()</heartbeat>\r\n\t\t\x3c!-- 主服务器进行写操作 --\x3e\r\n\t\t<writeHost host="hostM1" url="localhost:3306" user="root"\r\n\t\t\t\t   password="itheima">\r\n\t\t\x3c!-- 从服务器负责读操作 --\x3e\r\n\t\t<readHost host="hostS1" url="192.168.203.135:3306" user="root" password="itheima" />\r\n\t\t</writeHost>\r\n\t</dataHost>\r\n\t\r\n</mycat:schema>\r\n```\r\n\r\n- 配置详解\r\n\r\n  - schema标签逻辑库的概念和mysql数据库中Datebase的概念相同，我们在查询这两个逻辑库中的表的时候，需要切换到该逻辑库下才可以查到所需要的表。\r\n  - dataNode属性：该属性用于绑定逻辑库到某个具体的database上。\r\n  - dataNode标签： dataNode标签定义了mycat中的数据节点，也就是数据分片。一个dataNode标签就是一个独立的数据分片。\r\n  - name属性：定义数据节点的名字，这个名字需要是唯一的，我们需要在table标签上应用这个名字，来建立表与分片对应的关系。\r\n  - dataHost属性：该属性用于定义该分片属于那个数据库实例，属性值是引用datahost标签定义的name属性。\r\n  - database属性：该属性用于定义该分片属于那个具体数据库实例上的具体库，因为这里使用两个纬度来定义分片，就是：实例+具体的库。因为每个库上建立的表和表结构是一样的。所以这样做就可以轻松的对表进行水平拆分。\r\n  - dataHost标签：该标签在mycat逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。\r\n\r\n  - balance属性： 负载均衡类型\r\n    ​    balance=0: 不开启读写分离，所有读操作都发送到当前可用的writeHost上。\r\n    ​    balance=1: 全部的readHost与Stand by writeHost都参与select语句的负载均衡\r\n    ​     balance=2: 所有的读操作都随机在writeHost，readHost上分发。\r\n    ​     balance=3: 所有的读请求都随机分配到writeHost对应的readHost上执行，writeHost不负担读压力。\r\n  - switchType属性： \r\n    ​    -1：表示不自动切换。\r\n    ​    1  ：默认值，表示自动切换\r\n    ​    2：表示基于MySQL主从同步状态决定是否切换，心跳语句： show slave status.\r\n    ​    3:表示基于mysql galary cluster的切换机制，适合mycat1.4之上的版本，心跳语句show status like "%esrep%";\r\n  - writeHost标签，readHost标签：这两个标签指定后端数据库的相关配置给mycat，用于实例化后端连接池。唯一不同的是，writeHost指定写实例、readHost指定读实例，组合这些读写实例来满足系统的要求。\r\n    - host属性：用于标识不同的实例，对于writehost，一般使用*M1；对于readhost一般使用*S1.\r\n    - url属性：后端实例连接地址，如果使用native的dbDriver，则一般为address:port这种形式，用JDBC或其他的dbDriver，则需要特殊指定。当使用JDBC时则可以这么写：jdbc:mysql://localhost:3306/。\r\n    - user属性：后端存储实例的用户名。\r\n    - password属性：后端存储实例的密码\r\n\r\n- 测试\r\n\r\n  - 重启主服务器的mycat\r\n\r\n  ```\r\n  // 重启mycat\r\n  cd /root/mycat/bin\r\n  \r\n  ./mycat restart\r\n  \r\n  // 查看端口监听\r\n  netstat -ant|grep 8066\r\n  ```\r\n\r\n  - sqlyog连接mycat\r\n\r\n  ```mysql\r\n  -- 创建学生表\r\n  CREATE TABLE student(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n  \tNAME VARCHAR(10)\r\n  );\r\n  -- 查询学生表\r\n  SELECT * FROM student;\r\n  \r\n  -- 添加两条记录\r\n  INSERT INTO student VALUES (NULL,\'张三\'),(NULL,\'李四\');\r\n  \r\n  -- 停止主从复制后，添加的数据只会保存到主服务器上。\r\n  INSERT INTO student VALUES (NULL,\'王五\');\r\n  ```\r\n\r\n  - sqlyog连接主服务器\r\n\r\n  ```mysql\r\n  -- 主服务器：查询学生表，可以看到数据\r\n  SELECT * FROM student;\r\n  ```\r\n\r\n  - sqlyog连接从服务器\r\n\r\n  ```mysql\r\n  -- 从服务器：查询学生表，可以看到数据(因为有主从复制)\r\n  SELECT * FROM student;\r\n  \r\n  -- 从服务器：删除一条记录。(主服务器并没有删除，mycat中间件查询的结果是从服务器的数据)\r\n  DELETE FROM student WHERE id=2;\r\n  ```\r\n\r\n#### 6.分库分表\r\n\r\n- 分库分表的概念\r\n\r\n  - 将庞大的数据进行拆分\r\n  - 水平拆分：根据表的数据逻辑关系，将同一表中的数据按照某种条件，拆分到多台数据库服务器上，也叫做横向拆分。例如：一张1000万的大表，按照一模一样的结构，拆分成4个250万的小表，分别保存到4个数据库中。\r\n  - 垂直拆分：根据业务的维度，将不同的表切分到不同的数据库之上，也叫做纵向拆分。例如：所有的订单都保存到订单库中，所有的用户都保存到用户库中，同类型的表保存在同一库，不同的表分散在不同的库中。\r\n\r\n- Mycat水平拆分\r\n\r\n  - 修改主服务器的server.xml\r\n\r\n    - 0：本地文件方式\r\n\r\n      在mycat/conf/sequence_conf.properties文件中：\r\n      GLOBAL.MINDI=10000最小值\r\n      GLOBAL.MAXID=20000最大值，建议修改到9999999999\r\n\r\n    - 1：数据库方式\r\n\r\n      分库分表中保证全局主键自增唯一，但是需要执行mycat函数，配置sequence_db_conf.properties\r\n\r\n    - 2：时间戳方式\r\n\r\n      mycat实现的时间戳，建议varchar类型，要注意id的长度\r\n\r\n  ```xml\r\n  \x3c!-- 修改主键的方式 --\x3e\r\n  <property name="sequnceHandlerType">0</property>\r\n  ```\r\n\r\n  - 修改主服务器的sequence_conf.properties\r\n\r\n  ```properties\r\n  #default global sequence\r\n  GLOBAL.HISIDS=      # 可以自定义关键字\r\n  GLOBAL.MINID=10001  # 最小值\r\n  GLOBAL.MAXID=20000  # 最大值\r\n  GLOBAL.CURID=10000\r\n  ```\r\n\r\n  - 修改主服务器的schema.xml\r\n    - table标签定义了逻辑表，所有需要拆分的表都需要在这个标签中定义。 \r\n    - rule属性：拆分规则。mod-long是拆分规则之一，主键根据服务器数量取模，在rule.xml中指定。如果是3个数据库，那么数据取模后，平均分配到三个库中。\r\n    - name属性：定义逻辑表的表名，这个名字就如同在数据库中执行create table命令指定的名字一样，同一个schema标签中定义的表名必须是唯一的。\r\n    - dataNode属性： 定义这个逻辑表所属的dataNode，该属性的值需要和dataNode标签中name属性的值相互对应。\r\n\r\n  ```xml\r\n  <?xml version="1.0"?>\r\n  <!DOCTYPE mycat:schema SYSTEM "schema.dtd">\r\n  <mycat:schema xmlns:mycat="http://io.mycat/">\r\n  \r\n  \t<schema name="HEIMADB" checkSQLschema="false" sqlMaxLimit="100">\r\n  \t\t<table name="product" primaryKey="id" dataNode="dn1,dn2,dn3" rule="mod-long"/>\r\n  \t</schema>\r\n  \t\r\n  \t<dataNode name="dn1" dataHost="localhost1" database="db1" />\r\n  \t<dataNode name="dn2" dataHost="localhost1" database="db2" />\r\n  \t<dataNode name="dn3" dataHost="localhost1" database="db3" />\r\n  \t\r\n  \t<dataHost name="localhost1" maxCon="1000" minCon="10" balance="1"\r\n  \t\t\t  writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">\r\n  \t\t<heartbeat>select user()</heartbeat>\r\n  \t\t\x3c!-- write --\x3e\r\n  \t\t<writeHost host="hostM1" url="localhost:3306" user="root"\r\n  \t\t\t\t   password="itheima">\r\n  \t\t\x3c!-- read --\x3e\r\n  \t\t<readHost host="hostS1" url="192.168.203.135:3306" user="root" password="itheima" />\r\n  \t\t</writeHost>\r\n  \t</dataHost>\r\n  \t\r\n  </mycat:schema>\r\n  ```\r\n\r\n  - 修改主服务器的rule.xml\r\n\r\n  ```xml\r\n  <function name="mod-long" class="io.mycat.route.function.PartitionByMod">\r\n  \t\t\x3c!-- 数据库的数量 --\x3e\r\n  \t\t<property name="count">3</property>\r\n  </function>\r\n  ```\r\n\r\n  - 测试\r\n\r\n    - mycat操作\r\n\r\n    ```mysql\r\n    -- 创建product表\r\n    CREATE TABLE product(\r\n    \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n    \tNAME VARCHAR(20),\r\n    \tprice INT\r\n    );\r\n    \r\n    -- 添加6条数据\r\n    INSERT INTO product(id,NAME,price) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'苹果手机\',6999);\r\n    INSERT INTO product(id,NAME,price) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'华为手机\',5999); \r\n    INSERT INTO product(id,NAME,price) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'三星手机\',4999); \r\n    INSERT INTO product(id,NAME,price) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'小米手机\',3999); \r\n    INSERT INTO product(id,NAME,price) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'中兴手机\',2999); \r\n    INSERT INTO product(id,NAME,price) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'OOPO手机\',1999); \r\n    \r\n    -- 查询product表\r\n    SELECT * FROM product; \r\n    ```\r\n\r\n    - 主服务器操作\r\n\r\n    ```mysql\r\n    -- 在不同数据库中查询product表\r\n    SELECT * FROM product;\r\n    ```\r\n\r\n    - 从服务器操作\r\n\r\n    ```mysql\r\n    -- 在不同数据库中查询product表\r\n    SELECT * FROM product;\r\n    ```\r\n\r\n- Mycat垂直拆分\r\n\r\n  - 修改主服务器的schema\r\n\r\n  ```xml\r\n  <?xml version="1.0"?>\r\n  <!DOCTYPE mycat:schema SYSTEM "schema.dtd">\r\n  <mycat:schema xmlns:mycat="http://io.mycat/">\r\n  \r\n  \t<schema name="HEIMADB" checkSQLschema="false" sqlMaxLimit="100">\r\n  \t\t<table name="product" primaryKey="id" dataNode="dn1,dn2,dn3" rule="mod-long"/>\r\n  \t\t\r\n  \t\t\x3c!-- 动物类数据表 --\x3e\r\n  \t\t<table name="dog" primaryKey="id" autoIncrement="true" dataNode="dn4" />\r\n  \t\t<table name="cat" primaryKey="id" autoIncrement="true" dataNode="dn4" />\r\n      \r\n         \x3c!-- 水果类数据表 --\x3e\r\n  \t\t<table name="apple" primaryKey="id" autoIncrement="true" dataNode="dn5" />\r\n  \t\t<table name="banana" primaryKey="id" autoIncrement="true" dataNode="dn5" />\r\n  \t</schema>\r\n  \t\r\n  \t<dataNode name="dn1" dataHost="localhost1" database="db1" />\r\n  \t<dataNode name="dn2" dataHost="localhost1" database="db2" />\r\n  \t<dataNode name="dn3" dataHost="localhost1" database="db3" />\r\n  \t\r\n  \t<dataNode name="dn4" dataHost="localhost1" database="db4" />\r\n  \t<dataNode name="dn5" dataHost="localhost1" database="db5" />\r\n  \t\r\n  \t<dataHost name="localhost1" maxCon="1000" minCon="10" balance="1"\r\n  \t\t\t  writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">\r\n  \t\t<heartbeat>select user()</heartbeat>\r\n  \t\t\x3c!-- write --\x3e\r\n  \t\t<writeHost host="hostM1" url="localhost:3306" user="root"\r\n  \t\t\t\t   password="itheima">\r\n  \t\t\x3c!-- read --\x3e\r\n  \t\t<readHost host="hostS1" url="192.168.203.135:3306" user="root" password="itheima" />\r\n  \t\t</writeHost>\r\n  \t</dataHost>\r\n  \t\r\n  </mycat:schema>\r\n  ```\r\n\r\n  - 测试\r\n\r\n    - sqlyog连接mycat\r\n\r\n    ```mysql\r\n    -- 创建dog表\r\n    CREATE TABLE dog(\r\n    \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n    \tNAME VARCHAR(10)\r\n    );\r\n    -- 添加数据\r\n    INSERT INTO dog(id,NAME) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'哈士奇\');\r\n    -- 查询dog表\r\n    SELECT * FROM dog;\r\n    \r\n    \r\n    -- 创建cat表\r\n    CREATE TABLE cat(\r\n    \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n    \tNAME VARCHAR(10)\r\n    );\r\n    -- 添加数据\r\n    INSERT INTO cat(id,NAME) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'波斯猫\');\r\n    -- 查询cat表\r\n    SELECT * FROM cat;\r\n    \r\n    \r\n    \r\n    -- 创建apple表\r\n    CREATE TABLE apple(\r\n    \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n    \tNAME VARCHAR(10)\r\n    );\r\n    -- 添加数据\r\n    INSERT INTO apple(id,NAME) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'红富士\');\r\n    -- 查询apple表\r\n    SELECT * FROM apple;\r\n    \r\n    \r\n    -- 创建banana表\r\n    CREATE TABLE banana(\r\n    \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n    \tNAME VARCHAR(10)\r\n    );\r\n    -- 添加数据\r\n    INSERT INTO banana(id,NAME) VALUES (NEXT VALUE FOR MYCATSEQ_GLOBAL,\'香蕉\');\r\n    -- 查询banana表\r\n    SELECT * FROM banana;\r\n    ```\r\n\r\n    - sqlyog连接主服务器\r\n\r\n    ```mysql\r\n    -- 查询dog表\r\n    SELECT * FROM dog;\r\n    -- 查询cat表\r\n    SELECT * FROM cat;\r\n    \r\n    \r\n    -- 查询apple表\r\n    SELECT * FROM apple;\r\n    -- 查询banana表\r\n    SELECT * FROM banana;\r\n    ```\r\n\r\n    - sqlyog连接从服务器\r\n\r\n    ```mysql\r\n    -- 查询dog表\r\n    SELECT * FROM dog;\r\n    -- 查询cat表\r\n    SELECT * FROM cat;\r\n    \r\n    \r\n    -- 查询apple表\r\n    SELECT * FROM apple;\r\n    -- 查询banana表\r\n    SELECT * FROM banana;\r\n    ```\r\n',Rn={data:function(){return{MainComponent:pn}}},Ln=Rn,un=Object(L["a"])(Ln,mn,cn,!1,null,"7e0780d0",null),Tn=un.exports,yn=e("3686"),gn=e("1b62"),An=Object(yn["a"])(e("e778"),"md",!0),Sn=An.all_components,In=An.all_modules,Nn={mixins:[gn["c"],gn["b"]],components:{m1:T,m2:N,m3:D,m5:v,m6:P,m7:X,m8:en,m9:En,m10:Tn},data:function(){var n;return n={tab_level:1,MainComponent:"",img_prefix:"./books/sql/mysql/",tab:"m1"},l()(n,"tab_level",2),l()(n,"tabs",[{label:"基本",value:"m1"},{label:"常见错误",value:"m2"},{label:"常规语句",value:"m3"},{label:"LINUX 安装 5.7 mysql",value:"m5"},{label:"MySQL数据类型",value:"m7"},{label:"MySQL基础",value:"m6"},{label:"MySQL进阶",value:"m8"},{label:"MySQL高级1",value:"m9"},{label:"MySQL高级2",value:"m10"}].concat(E()(In))),n},watch:{tab:function(n,r){this.MainComponent=Sn[this.tab]}}},hn=Nn,On=Object(L["a"])(hn,i,a,!1,null,"60fb19f4",null),Mn=On.exports,bn=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",[n.MainComponent?e("q-markdown",{attrs:{"no-heading-anchor-links":"",extend:n.extendMarkdown,src:n.MainComponent}}):e(""+n.tab,{tag:"component"})],1)},_n=[],Dn=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},Cn=[],fn='\x3c!--\n * @Date           : 2021-04-19 00:11:26\n * @FilePath       : /jinnian-space/src/pages/sql/module/redis/md/第一章 Redis基础.md\n * @Description    : \n--\x3e\n\n\n# 第一章 Redis基础\n\n**课程计划**\n\n| 1. Redis 入 门         | **（了解）** | **（操作）** |              |\n| ---------------------- | ------------ | ------------ | ------------ |\n| 2. 数据类型            | **（重点）** | **（操作）** | **（理解）** |\n| 3. 常用指令            |              | **（操作）** |              |\n| 4. Jedis               | **（重点）** | **（操作）** |              |\n| 5. 持 久 化            | **（重点）** |              | **（理解）** |\n| 6. 数据删除与淘汰策略  |              |              | **（理解）** |\n| 7. 主从复制            | **（重点）** | **（操作）** | **（理解）** |\n| 8. 哨 兵               | **（重点）** | **（操作）** | **（理解）** |\n| 9. Cluster集群方案     | **（重点）** | **（操作）** | **（理解）** |\n| 10. 企业级缓存解决方案 | **（重点）** |              | **（理解）** |\n| 11. 性能指标监控       | **（了解）** |              |              |\n\n## 学习目标：\n\n目标1：能够说出NoSQL的概念，redis的应用场景，能够完成redis的下载安装与启动以及一些常用的配置\n\n目标2：能够说出redis常用的5种数据类型，对应这些数据类型的基本操作，应用场景及对应的解决方案\n\n目标3：能够说出redis中常用的一些基本指令\n\n目标4：能够使用jedis完成客户端应用程序的开发\n\n目标5：能够说出redis数据持久化的两种方式，各自相关的操作配置及指令，以及两种方式的优缺点比较\n\n## 1. Redis 简介\n\n在这个部分，我们将学习以下3个部分的内容，分别是：\n\n◆ Redis 简介（NoSQL概念、Redis概念）\n\n◆ Redis 的下载与安装\n\n◆ Redis 的基本操作\n\n### 1.1 NoSQL概念\n\n#### 1.1.1 问题现象\n\n在讲解NoSQL的概念之前呢，我们先来看一个现象：\n\n（1）问题现象\n\n每年到了过年期间，大家都会自觉自发的组织一场活动，叫做春运！以前我们买票都是到火车站排队，后来呢有了12306，有了他以后就更方便了，我们可以在网上买票，但是带来的问题，大家也很清楚，春节期间买票进不去，进去了刷不着票。什么原因呢，人太多了！\n  ![112555588888](./img/sql/redis/第一章Redis基础/java/redis/第一章Redis基础/12306-淘宝.png)\n\n除了这种做铁路的，它系统做的不专业以外，还有马爸爸做的淘宝，它面临一样的问题。淘宝也崩，也是用户量太大！作为我们整个电商界的东哥来说，他第一次做图书促销的时候，也遇到了服务器崩掉的这样一个现象，原因同样是因为用户量太大！\n  ![](./img/sql/redis/第一章Redis基础/京东翻车案.png)\n\n（2）现象特征\n\n再来看这几个现象，有两个非常相似的特征：\n\n第一，用户比较多，海量用户\n\n第二，高并发\n\n这两个现象出现以后，对应的就会造成我们的服务器瘫痪。核心本质是什么呢？其实并不是我们的应用服务器，而是我们的关系型数据库。关系型数据库才是最终的罪魁祸首！\n\n（3）造成原因\n\n什么样的原因导致的整个系统崩掉的呢：\n\n1.性能瓶颈：磁盘IO性能低下\n\n关系型数据库菜存取数据的时候和读取数据的时候他要走磁盘IO。磁盘这个性能本身是比较低的。\n\n2.扩展瓶颈：数据关系复杂，扩展性差，不便于大规模集群\n\n我们说关系型数据库，它里面表与表之间的关系非常复杂，不知道大家能不能想象一点，就是一张表，通过它的外键关联了七八张表，这七八张表又通过她的外件，每张又关联了四五张表。你想想，查询一下，你要想拿到数据，你就要从A到B、B到C、C到D的一直这么关联下去，最终非常影响查询的效率。同时，你想扩展下，也很难!\n\n（4）解决思路\n\n面对这样的现象，我们要想解决怎么版呢。两方面：\n\n一，降低磁盘IO次数，越低越好。\n\n二，去除数据间关系，越简单越好。\n\n降低磁盘IO次数，越低越好，怎么搞？我不用你磁盘不就行了吗？于是，内存存储的思想就提出来了，我数据不放到你磁盘里边，放内存里，这样是不是效率就高了。\n\n第二，你的数据关系很复杂，那怎么办呢？干脆简单点，我断开你的关系，我不存关系了，我只存数据，这样不就没这事了吗？\n\n把这两个特征一合并一起，就出来了一个新的概念：NoSQL\n\n#### 1.1.2 NoSQL的概念\n\n（1）概念\n\nNoSQL：即 Not-Only SQL（ 泛指非关系型的数据库），作为关系型数据库的补充。 作用：应对基于海量用户和海量数据前提下的数据处理问题。\n\n他说这句话说的非常客气，什么意思呢？就是我们数据存储要用SQL，但是呢可以不仅仅用SQL，还可以用别的东西，那别的东西叫什么呢？于是他定义了一句话叫做NoSQL。这个意思就是说我们存储数据，可以不光使用SQL，我们还可以使用非SQL的这种存储方案，这就是所谓的NoSQL。\n\n（2）特征\n\n可扩容，可伸缩。SQL数据关系过于复杂，你扩容一下难度很高，那我们Nosql 这种的，不存关系，所以它的扩容就简单一些。\n\n大数据量下高性能。包数据非常多的时候，它的性能高，因为你不走磁盘IO，你走的是内存，性能肯定要比磁盘IO的性能快一些。\n\n灵活的数据模型、高可用。他设计了自己的一些数据存储格式，这样能保证效率上来说是比较高的，最后一个高可用，我们等到集群内部分再去它！\n\n（3）常见 Nosql 数据库\n\n目前市面上常见的Nosql产品：Redis、memcache、HBase、MongoDB\n\n（4）应用场景-电商为例\n\n我们以电商为例，来看一看他在这里边起到的作用。\n\n第一类，在电商中我们的基础数据一定要存储起来，比如说商品名称，价格，生产厂商，这些都属于基础数据，这些数据放在MySQL数据库。\n\n第二类，我们商品的附加信息，比如说，你买了一个商品评价了一下，这个评价它不属于商品本身。就像你买一个苹果，“这个苹果很好吃”就是评论，但是你能说很好吃是这个商品的属性嘛？不能这么说，那只是一个人对他的评论而已。这一类数据呢，我们放在另外一个地方，我们放到MongoDB。它也可以用来加快我们的访问，他属于NoSQL的一种。\n\n第三，图片内的信息。注意这种信息相对来说比较固定，他有专用的存储区，我们一般用文件系统来存储。至于是不是分布式，要看你的系统的一个整个   瓶颈   了？如果说你发现你需要做分布式，那就做，不需要的话，一台主机就搞定了。\n\n第四，搜索关键字。为了加快搜索，我们会用到一些技术，有些人可能了解过，像分ES、Lucene、solr都属于搜索技术。那说的这么热闹，我们的电商解决方案中还没出现我们的redis啊！注意第五类信息。\n\n第五，热点信息。访问频度比较高的信息，这种东西的第二特征就是它具有波段性。换句话说他不是稳定的，它具有一个时效性的。那么这类信息放哪儿了，放到我们的redis这个解决方案中来进行存储。\n\n具体的我们从我们的整个数据存储结构的设计上来看一下。\n\n![](./img/sql/redis/第一章Redis基础/电商场景解决方案.png)\n\n我们的基础数据都存MySQL,在它的基础之上，我们把它连在一块儿，同时对外提供服务。向上走，有一些信息加载完以后,要放到我们的MongoDB中。还有一类信息，我们放到我们专用的文件系统中（比如图片），就放到我们的这个搜索专用的，如Lucene、solr及集群里边，或者用ES的这种技术里边。那么剩下来的热点信息，放到我们的redis里面。\n\n### 1.2 Redis概念\n\n#### 1.2.1 redis概念\n\n概念：Redis (REmote DIctionary Server) 是用 C 语言开发的一个开源的高性能键值对（key-value）数据库。\n\n特征：\n\n（1）数据间没有必然的关联关系；\n\n（2）内部采用单线程机制进行工作；\n\n（3）高性能。官方提供测试数据，50个并发执行100000 个请求,读的速度是110000 次/s,写的速度是81000次/s。\n\n（4）多数据类型支持\n\n \n\n|     类型       |                     |\n| -------------- | -------------------- | \n| 字符串类型   |    string            |\n| 列表类型     |     list             |\n| 散列类型     |     hash             |\n| 集合类型       |      set             |\n| 有序集合类型   |    zset/sorted_set   |\n\n（5）支持持久化，可以进行数据灾难恢复\n\n#### 1.2.2 redis的应用场景\n\n（1）为热点数据加速查询（主要场景）。如热点商品、热点新闻、热点资讯、推广类等高访问量信息等。\n\n（2）即时信息查询。如各位排行榜、各类网站访问统计、公交到站信息、在线人数信息（聊天室、网站）、设备信号等。\n\n（3）时效性信息控制。如验证码控制、投票控制等。\n\n（4）分布式数据共享。如分布式集群架构中的 session 分离\n\n（5）消息队列.\n\n### 1.3 Redis 的下载与安装\n\n后期所有资料分4中不同色块显示，详情如下：\n\n![](./img/sql/redis/第一章Redis基础/约定格式.png)\n\n#### 1.3.1 Redis 的下载与安装\n\n本课程所示，均基于Center OS7安装Redis。\n\n（1)下载Redis\n\n下载安装包：\n\n```bash\nwget http://download.redis.io/releases/redis-5.0.0.tar.gz\n```\n\n解压安装包：\n\n```bash\ntar –xvf redis-5.0.0.tar.gz\n```\n\n编译（在解压的目录中执行）：\n\n```bash\nmake\n```\n\n安装（在解压的目录中执行）：\n\n```bash\nmake install\n```\n\n（2）安装 Redis\n\nredis-server，服务器启动命令 客户端启动命令\n\nredis-cli，redis核心配置文件\n\nredis.conf，RDB文件检查工具（快照持久化文件）\n\nredis-check-dump，AOF文件修复工具\n\nredis-check-aof\n\n### 1.4 Redis服务器启动\n\n#### 1.4.1 Redis服务器启动\n\n启动服务器——参数启动\n\n```bash\nredis-server [--port port]\n```\n\n范例\n\n```bash\nredis-server --port 6379\n```\n\n启动服务器——配置文件启动\n\n```bash\nredis-server config_file_name\n```\n\n范例\n\n```bash\nredis-server redis.conf\n```\n\n#### 1.4.2 Redis客户端启动\n\n启动客户端\n\n```bash\nredis-cli [-h host] [-p port]\n```\n\n范 例\n\n```bash\nredis-cli –h 61.129.65.248 –p 6384\n```\n\n注意：服务器启动指定端口使用的是--port，客户端启动指定端口使用的是-p。-的数量不同。\n\n#### 1.4.3 Redis基础环境设置约定\n\n创建配置文件存储目录\n\n```bash\nmkdir conf\n```\n\n创建服务器文件存储目录（包含日志、数据、临时配置文件等）\n\n```bash\nmkdir data\n```\n\n创建快速访问链接\n\n```bash\nln -s redis-5.0.0 redis\n```\n\n### 1.5 配置文件启动与常用配置\n\n#### 1.5.1 服务器端设定\n\n设置服务器以守护进程的方式运行，开启后服务器控制台中将打印服务器运行信息（同日志内容相同）\n\n```bash\ndaemonize yes|no\n```\n\n绑定主机地址\n\n```bash\nbind ip\n```\n\n设置服务器端口\n\n```bash\nport port\n```\n\n设置服务器文件保存地址\n\n```bash\ndir path\n```\n\n#### 1.5.2  客户端配置\n\n 服务器允许客户端连接最大数量，默认0，表示无限制。当客户端连接到达上限后，Redis会拒绝新的连接\n\n```bash\nmaxclients count\n```\n\n客户端闲置等待最大时长，达到最大值后关闭对应连接。如需关闭该功能，设置为 0\n\n```bash\ntimeout seconds\n```\n\n#### 1.5.3  日志配置\n\n设置服务器以指定日志记录级别\n\n```bash\nloglevel debug|verbose|notice|warning\n```\n\n日志记录文件名\n\n```bash\nlogfile filename\n```\n\n注意：日志级别开发期设置为verbose即可，生产环境中配置为notice，简化日志输出量，降低写日志IO的频度。\n\n### 1.6 Redis基本操作\n\n#### 1.6.1  命令行模式工具使用思考\n\n功能性命令\n\n帮助信息查阅\n\n退出指令\n\n清除屏幕信息\n\n#### 1.6.2  信息读写\n\n设置 key，value 数据\n\n```bash\nset key value\n```\n\n范例\n\n```bash\nset name itheima\n```\n\n根据 key 查询对应的 value，如果不存在，返回空（nil）\n\n```bash\nget key\n```\n\n范例\n\n```bash\nget name\n```\n\n#### 1.6.3  帮助信息\n\n获取命令帮助文档\n\n```bash\nhelp [command]\n```\n\n范例\n\n```bash\nhelp set\n```\n\n获取组中所有命令信息名称\n\n```bash\nhelp [@group-name]\n```\n\n范例\n\n```bash\nhelp @string\n```\n\n1.6.4  退出命令行客户端模式\n\n退出客户端\n\n````bash\nquit\nexit\n````\n\n快捷键\n\n```bash\nCtrl+C\n```\n\n#### 1.6.4  redis入门总结\n\n到这里，Redis 入门的相关知识，我们就全部学习完了，再来回顾一下，这个部分我们主要讲解了哪些内容呢？\n\n首先，我们对Redis进行了一个简单介绍，包括NoSQL的概念、Redis的概念等。\n\n然后，我们介绍了Redis 的下载与安装。包括下载与安装、服务器与客户端启动、以及相关配置文件（3类）。\n\n最后，我们介绍了Redis 的基本操作。包括数据读写、退出与帮助信息获取。\n\n## 2. 数据类型\n\n在这个部分，我们将学习一共要学习三大块内容，首先需要了解一下数据类型，接下来将针对着我们要学习的数据类型进行逐一的讲解，如string、hash、list、set等，最后我们通过一个案例来总结前面的数据类型的使用场景。\n\n### 2.1  数据存储类型介绍\n\n#### 2.1.1  业务数据的特殊性\n\n在讲解数据类型之前，我们得先思考一个问题，数据类型既然是用来描述数据的存储格式的，如果你不知道哪些数据未来会进入到我们来的redis中，那么对应的数据类型的选择，你就会出现问题，我们一块来看一下：\n\n（1）原始业务功能设计\n\n秒杀。他这个里边数据变化速度特别的快，访问量也特别的高，用户大量涌入以后都会针对着一部分数据进行操作，这一类要记住。\n\n618活动。对于我们京东的618活动、以及天猫的双11活动，相信大家不用说都知道这些数据一定要进去，因为他们的访问频度实在太高了。\n\n排队购票。我们12306的票务信息。这些信息在原始设计的时候，他们就注定了要进redis。\n\n（2）运营平台监控到的突发高频访问数据\n\n此类平台临时监控到的这些数据，比如说现在出来的一个八卦的信息，这个新闻一旦出现以后呢，顺速的被围观了，那么这个时候，这个数据就会变得访量特别高，那么这类信息也要进入进去。\n\n（3）高频、复杂的统计数据\n\n在线人数。比如说直播现在很火，直播里边有很多数据，例如在线人数。进一个人出一个人，这个数据就要跳动，那么这个访问速度非常的快，而且访量很高，并且它里边有一个复杂的数据统计，在这里这种信息也要进入到我们的redis中。\n\n投票排行榜。投票投票类的信息他的变化速度也比较快，为了追求一个更快的一个即时投票的名次变化，这种数据最好也放到redis中。\n\n#### 2.1.2  Redis 数据类型(5种常用)\n\n基于以上数据特征我们进行分析，最终得出来我们的Redis中要设计5种 数据类型：\n\nstring、hash、list、set、sorted_set/zset（应用性较低）\n\n### 2.2  string数据类型\n\n在学习第一个数据类型之前，先给大家介绍一下，在随后这部分内容的学习过程中，我们每一种数据类型都分成三块来讲：首先是讲下它的基本操作，接下来讲一些它的扩展操作，最后我们会去做一个小的案例分析。\n\n#### 2.2.1Redis 数据存储格式\n\n在学习string这个数据形式之前，我们先要明白string到底是修饰什么的。我们知道redis 自身是一个 Map，其中所有的数据都是采用 key : value 的形式存储。\n\n对于这种结构来说，我们用来存储数据一定是一个值前面对应一个名称。我们通过名称来访问后面的值。按照这种形势，我们可以对出来我们的存储格式。前面这一部分我们称为key。后面的一部分称为value，而我们的数据类型，他一定是修饰value的。\n\n![](./img/sql/redis/第一章Redis基础/redis存储空间.png)\n\n数据类型指的是存储的数据的类型，也就是 value 部分的类型，key 部分永远都是字符串。\n\n#### 2.2.2  string 类型\n\n（1）存储的数据：单个数据，最简单的数据存储类型，也是最常用的数据存储类型。\n\nstring，他就是存一个字符串儿，注意是value那一部分是一个字符串，它是redis中最基本、最简单的存储数据的格式。\n\n（2）存储数据的格式：一个存储空间保存一个数据\n\n每一个空间中只能保存一个字符串信息，这个信息里边如果是存的纯数字，他也能当数字使用，我们来看一下，这是我们的数据的存储空间。\n\n（3）存储内容：通常使用字符串，如果字符串以整数的形式展示，可以作为数字操作使用.\n\n![](./img/sql/redis/第一章Redis基础/redis存储空间2.png)\n\n一个key对一个value，而这个itheima就是我们所说的string类型，当然它也可以是一个纯数字的格式。\n\n#### 2.2.3  string 类型数据的基本操作\n\n（1）基础指令\n\n添加/修改数据添加/修改数据\n\n```\nset key value\n```\n\n获取数据\n\n```\nget key\n```\n\n删除数据\n\n```\ndel key\n```\n\n判定性添加数据\n\n```\nsetnx key value\n```\n\n添加/修改多个数据\n\n```\nmset key1 value1 key2 value2 …\n```\n\n获取多个数据\n\n```\nmget key1 key2 …\n```\n\n获取数据字符个数（字符串长度）\n\n```\nstrlen key\n```\n\n追加信息到原始信息后部（如果原始信息存在就追加，否则新建）\n\n```\nappend key value\n```\n\n（2）单数据操作与多数据操作的选择之惑\n\n即set 与mset的关系。这对于这两个操作来说，没有什么你应该选哪个，而是他们自己的特征是什么，你要根据这个特征去比对你的业务，看看究竟适用于哪个。\n\n![](./img/sql/redis/第一章Redis基础/set.png)\n\n假如说这是我们现在的服务器，他要向redis要数据的话，它会发出一条指令。那么当这条指令发过来的时候，比如说是这个set指令过来，那么它会把这个结果返回给你，这个时候我们要思考这里边一共经过了多长时间。\n\n首先，发送set指令要时间，这是网络的一个时间，接下来redis要去运行这个指令要消耗时间，最终把这个结果返回给你又有一个时间，这个时间又是一个网络的时间，那我们可以理解为：一个指令发送的过程中需要消耗这样的时间.\n\n但是如果说现在不是一条指令了，你要发3个set的话，还要多长时间呢？对应的发送时间要乘3了，因为这是三个单条指令,而运行的操作时间呢，它也要乘3了，但最终返回的也要发3次，所以这边也要乘3。\n\n于是我们可以得到一个结论：单指令发3条它需要的时间，假定他们两个一样，是6个网络时间加3个处理时间，如果我们把它合成一个mset呢，我们想一想。\n\n假如说用多指令发3个指令的话，其实只需要发一次就行了。这样我们可以得到一个结论，多指令发3个指令的话，其实它是两个网络时间加上3个redis的操作时间，为什么这写一个小加号呢，就是因为毕竟发的信息量变大了，所以网络时间有可能会变长。\n\n那么通过这张图，你就可以得到一个结论，我们单指令和多指令他们的差别就在于你发送的次数是多还是少。当你影响的数据比较少的时候，你可以用单指令，也可以用多指令。但是一旦这个量大了，你就要选择多指令了，他的效率会高一些。\n\n### 2.3  string 类型数据的扩展操作\n\n#### 2.3.1  string 类型数据的扩展操作\n\n下面我们来看一string的扩展操作，分成两大块：一块是对数字进行操作的，第二块是对我们的key的时间进行操作的。\n\n设置数值数据增加指定范围的值\n\n```bash\nincr key\nincrby key increment\nincrbyfloat key increment\n```\n\n设置数值数据减少指定范围的值\n\n```bash\ndecr key\ndecrby key increment\n```\n\n设置数据具有指定的生命周期\n\n```bash\nsetex key seconds value\npsetex key milliseconds value\n```\n\n#### 2.3.2  string 类型数据操作的注意事项\n\n(1)数据操作不成功的反馈与数据正常操作之间的差异\n\n表示运行结果是否成功\n\n(integer) 0  → false                 失败\n\n(integer) 1  → true                  成功\n\n表示运行结果值\n\n(integer) 3  → 3                        3个\n\n(integer) 1  → 1                         1个\n\n(2)数据未获取到时，对应的数据为（nil），等同于null\n\n(3)数据最大存储量：512MB\n\n(4)string在redis内部存储默认就是一个字符串，当遇到增减类操作incr，decr时会转成数值型进行计算\n\n(5)按数值进行操作的数据，如果原始数据不能转成数值，或超越了redis 数值上限范围，将报错\n9223372036854775807（java中Long型数据最大值，Long.MAX_VALUE）\n\n(6)redis所有的操作都是原子性的，采用单线程处理所有业务，命令是一个一个执行的，因此无需考虑并发带来的数据影响.\n\n### 2.4string应用场景与key命名约定\n\n#### 2.4.1  应用场景\n\n它的应用场景在于：主页高频访问信息显示控制，例如新浪微博大V主页显示粉丝数与微博数量。\n\n![](./img/sql/redis/第一章Redis基础/string应用场景.png)\n\n我们来思考一下：这些信息是不是你进入大V的页面儿以后就要读取这写信息的啊，那这种信息一定要存储到我们的redis中，因为他的访问量太高了！那这种数据应该怎么存呢？我们来一块儿看一下方案！\n\n#### 2.4.2  解决方案\n\n（1）在redis中为大V用户设定用户信息，以用户主键和属性值作为key，后台设定定时刷新策略即可。\n\n```markdown\neg:\tuser:id:3506728370:fans\t\t→\t12210947\neg:\tuser:id:3506728370:blogs\t→\t6164\neg:\tuser:id:3506728370:focuses\t→\t83\n```\n\n（2）也可以使用json格式保存数据\n\n```markdown\neg:\tuser:id:3506728370    →\t{“fans”：12210947，“blogs”：6164，“ focuses ”：83 }\n```\n\n（3） key 的设置约定\n\n数据库中的热点数据key命名惯例\n\n|       | **表名** | **主键名** | 主键值    | **字段名** |\n| ----- | -------- | ---------- | --------- | ---------- |\n| eg1： | order    | id         | 29437595  | name       |\n| eg2： | equip    | id         | 390472345 | type       |\n| eg3： | news     | id         | 202004150 | title      |\n\n### 2.5  hash的基本操作\n\n下面我们来学习第二个数据类型hash。\n\n#### 2.5.1  数据存储的困惑\n\n对象类数据的存储如果具有较频繁的更新需求操作会显得笨重！\n\n在正式学习之前，我们先来看一个关于数据存储的困惑：\n\n![](./img/sql/redis/第一章Redis基础/hash存储.png)\n\n比如说前面我们用以上形式存了数据，如果我们用单条去存的话，它存的条数会很多。但如果我们用json格式，它存一条数据就够了。问题来了，假如说现在粉丝数量发生变化了，你要把整个值都改了。但是用单条存的话就不存在这个问题，你只需要改其中一个就行了。这个时候我们就想，有没有一种新的存储结构，能帮我们解决这个问题呢。\n\n我们一块儿来分析一下：\n\n![](./img/sql/redis/第一章Redis基础/数据.png)\n\n如上图所示：单条的话是对应的数据在后面放着。仔细观察：我们看左边是不是长得都一模一样啊，都是对应的表名、ID等的一系列的东西。我们可以将右边红框中的这个区域给他封起来。\n\n那如果要是这样的形式的话，如下图，我们把它一合并，并把右边的东西给他变成这个格式，这不就行了吗？\n\n![](./img/sql/redis/第一章Redis基础/hash数据.png)\n\n这个图其实大家并不陌生，第一，你前面学过一个东西叫hashmap不就这格式吗？第二，redis自身不也是这格式吗？那是什么意思呢？注意，这就是我们要讲的第二种格式，hash。\n\n![](./img/sql/redis/第一章Redis基础/hash结构.png)\n\n在右边对应的值，我们就存具体的值，那左边儿这就是我们的key。问题来了，那中间的这一块叫什么呢？这个东西我们给他起个名儿，叫做field字段。那么右边儿整体这块儿空间我们就称为hash，也就是说hash是存了一个key value的存储空间。\n\n#### 2.5.2  hash 类型\n\n新的存储需求：对一系列存储的数据进行编组，方便管理，典型应用存储对象信息\n\n需要的存储结构：一个存储空间保存多个键值对数据\n\nhash类型：底层使用哈希表结构实现数据存储\n\n![](./img/sql/redis/第一章Redis基础/hash结构图.png)\n\n如上图所示，这种结构叫做hash，左边一个key，对右边一个存储空间。这里要明确一点，右边这块儿存储空间叫hash，也就是说hash是指的一个数据类型，他指的不是一个数据，是这里边的一堆数据，那么它底层呢，是用hash表的结构来实现的。\n\n值得注意的是：\n\n如果field数量较少，存储结构优化为类数组结构\n\n如果field数量较多，存储结构使用HashMap结构\n\n#### 2.5.3  hash 类型数据的基本操作\n\n添加/修改数据\n\n```bash\nhset key field value\n```\n\n获取数据\n\n```bash\nhget key field\nhgetall key\n```\n\n删除数据\n\n```bash\nhdel key field1 [field2]\n```\n\n设置field的值，如果该field存在则不做任何操作\n\n```bash\nhsetnx key field value\n```\n\n添加/修改多个数据\n\n```bash\nhmset key field1 value1 field2 value2 …\n```\n\n获取多个数据\n\n```bash\nhmget key field1 field2 …\n```\n\n获取哈希表中字段的数量\n\n```bash\nhlen key\n```\n\n获取哈希表中是否存在指定的字段\n\n```bash\nhexists key field\n```\n\n### 2.6  hash的拓展操作\n\n在看完hash的基本操作后，我们再来看他的拓展操作，他的拓展操作相对比较简单：\n\n#### 2.6.1  hash 类型数据扩展操作\n\n获取哈希表中所有的字段名或字段值\n\n```\nhkeys key\nhvals key\n```\n\n设置指定字段的数值数据增加指定范围的值\n\n```\nhincrby key field increment\nhincrbyfloat key field increment\n```\n\n#### 2.6.2  hash类型数据操作的注意事项\n\n(1)hash类型中value只能存储字符串，不允许存储其他数据类型，不存在嵌套现象。如果数据未获取到，对应的值为（nil）。\n\n(2）每个 hash 可以存储 232 - 1 个键值对\nhash类型十分贴近对象的数据存储形式，并且可以灵活添加删除对象属性。但hash设计初衷不是为了存储大量对象而设计 的，切记不可滥用，更不可以将hash作为对象列表使用。\n\n(3)hgetall 操作可以获取全部属性，如果内部field过多，遍历整体数据效率就很会低，有可能成为数据访问瓶颈。\n\n### 2.7  hash应用场景\n\n#### 2.7.1  应用场景\n\n双11活动日，销售手机充值卡的商家对移动、联通、电信的30元、50元、100元商品推出抢购活动，每种商品抢购上限1000  张。\n\n![](./img/sql/redis/第一章Redis基础/hash应用.png)\n\n也就是商家有了，商品有了，数量有了。最终我们的用户买东西就是在改变这个数量。那你说这个结构应该怎么存呢？对应的商家的ID作为key，然后这些充值卡的ID作为field，最后这些数量作为value。而我们所谓的操作是其实就是increa这个操作，只不过你传负值就行了。看一看对应的解决方案：\n\n#### 2.7.2  解决方案\n\n以商家id作为key\n\n将参与抢购的商品id作为field\n\n将参与抢购的商品数量作为对应的value\n\n抢购时使用降值的方式控制产品数量\n\n注意：实际业务中还有超卖等实际问题，这里不做讨论\n\n### 2.8  list基本操作\n\n前面我们存数据的时候呢，单个数据也能存，多个数据也能存，但是这里面有一个问题，我们存多个数据用hash的时候它是没有顺序的。我们平时操作，实际上数据很多情况下都是有顺序的，那有没有一种能够用来存储带有顺序的这种数据模型呢，list就专门来干这事儿。\n\n#### 2.8.1  list 类型\n\n数据存储需求：存储多个数据，并对数据进入存储空间的顺序进行区分\n\n需要的存储结构：一个存储空间保存多个数据，且通过数据可以体现进入顺序\n\nlist类型：保存多个数据，底层使用双向链表存储结构实现\n\n先来通过一张图，回忆一下顺序表、链表、双向链表。\n\n![](./img/sql/redis/第一章Redis基础/list1.png)\n\nlist对应的存储结构是什么呢？里边存的这个东西是个列表，他有一个对应的名称。就是key存一个list的这样结构。对应的基本操作，你其实是可以想到的。\n\n![](./img/sql/redis/第一章Redis基础/list2.png)\n\n来看一下，因为它是双向的，所以他左边右边都能操作，它对应的操作结构两边都能进数据。这就是链表的一个存储结构。往外拿数据的时候怎么拿呢？通常是从一端拿，当然另一端也能拿。如果两端都能拿的话，这就是个双端队列，两边儿都能操作。如果只能从一端进一端出，这个模型咱们前面了解过，叫做栈。\n\n#### 2.8.2 list 类型数据基本操作\n\n最后看一下他的基本操作\n\n添加/修改数据\n\n```bash\nlpush key value1 [value2] ……\nrpush key value1 [value2] ……\n```\n\n获取数据\n\n```bash\nlrange key start stop\nlindex key index\nllen key\n```\n\n获取并移除数据\n\n```bash\nlpop key\nrpop key\n```\n\n### 2.9  list扩展操作\n\n#### 2.9.1  list 类型数据扩展操作\n\n移除指定数据\n\n```\nlrem key count value\n```\n\n规定时间内获取并移除数据\n\n```\nblpop key1 [key2] timeout\nbrpop key1 [key2] timeout\nbrpoplpush source destination timeout\n```\n\n#### 2.9.2  list 类型数据操作注意事项\n\n（1）list中保存的数据都是string类型的，数据总容量是有限的，最多232 - 1 个元素(4294967295)。\n\n（2）list具有索引的概念，但是操作数据时通常以队列的形式进行入队出队操作，或以栈的形式进行入栈出栈操作\n\n（3）获取全部数据操作结束索引设置为-1\n\n（4）list可以对数据进行分页操作，通常第一页的信息来自于list，第2页及更多的信息通过数据库的形式加载\n\n\n\n### 2.10 list 应用场景\n\n#### 2.10.1  应用场景\n\n企业运营过程中，系统将产生出大量的运营数据，如何保障多台服务器操作日志的统一顺序输出？\n\n![](./img/sql/redis/第一章Redis基础/list应用.png)\n\n假如现在你有多台服务器，每一台服务器都会产生它的日志，假设你是一个运维人员，你想看它的操作日志，你怎么看呢？打开A机器的日志看一看，打开B机器的日志再看一看吗？这样的话你会可能会疯掉的！因为左边看的有可能它的时间是11:01，右边11:02，然后再看左边11:03，它们本身是连续的，但是你在看的时候就分成四个文件了，这个时候你看起来就会很麻烦。能不能把他们合并呢？答案是可以的！怎么做呢？建立起redis服务器。当他们需要记日志的时候，记在哪儿,全部发给redis。等到你想看的时候，通过服务器访问redis获取日志。然后得到以后，就会得到一个完整的日志信息。那么这里面就可以获取到完整的日志了，依靠什么来实现呢？就依靠我们的list的模型的顺序来实现。进来一组数据就往里加，谁先进来谁先加进去，它是有一定的顺序的。\n\n#### 2.10.2  解决方案\n\n依赖list的数据具有顺序的特征对信息进行管理\n\n使用队列模型解决多路信息汇总合并的问题\n\n使用栈模型解决最新消息的问题\n\n### 2.11  set 基本操作\n\n#### 2.11.1 set类型\n\n新的存储需求：存储大量的数据，在查询方面提供更高的效率\n\n需要的存储结构：能够保存大量的数据，高效的内部存储机制，便于查询\n\nset类型：与hash存储结构完全相同，仅存储键，不存储值（nil），并且值是不允许重复的\n\n![](./img/sql/redis/第一章Redis基础/set模型.png)\n\n通过这个名称，大家也基本上能够认识到和我们Java中的set完全一样。我们现在要存储大量的数据，并且要求提高它的查询效率。用list这种链表形式，它的查询效率是不高的，那怎么办呢？这时候我们就想，有没有高效的存储机制。其实前面咱讲Java的时候说过hash表的结构就非常的好，但是这里边我们已经有hash了，他做了这么一个设定，干嘛呢，他把hash的存储空间给改一下，右边你原来存数据改掉,全部存空，那你说数据放哪儿了？放到原来的filed的位置，也就在这里边存真正的值，那么这个模型就是我们的set 模型。\n\nset类型：与hash存储结构完全相同，仅存储键，不存储值（nil），并且值是不允许重复的。\n\n看一下它的整个结构：\n\n![](./img/sql/redis/第一章Redis基础/set4.png)\n\n#### 2.11.2 set类型数据的基本操作\n\n添加数据\n\n```bash\nsadd key member1 [member2]\n```\n\n获取全部数据\n\n```bash\nsmembers key\n```\n\n删除数据\n\n```bash\nsrem key member1 [member2]\n```\n\n获取集合数据总量\n\n```bash\nscard key\n```\n\n判断集合中是否包含指定数据\n\n```bash\nsismember key member\n```\n\n随机获取集合中指定数量的数据\n\n```bash\nsrandmember key [count]\n```\n\n随机获取集中的某个数据并将该数据移除集合\n\n```bash\nspop key [count]\n```\n\n### 2.12  set 类型数据的扩展操作\n\n#### 2.12.1  set 类型数据的扩展操作\n\n求两个集合的交、并、差集\n\n```\nsinter key1 [key2 …]  \nsunion key1 [key2 …]  \nsdiff key1 [key2 …]\n```\n\n求两个集合的交、并、差集并存储到指定集合中\n\n```\nsinterstore destination key1 [key2 …]  \nsunionstore destination key1 [key2 …]  \nsdiffstore destination key1 [key2 …]\n```\n\n将指定数据从原始集合中移动到目标集合中\n\n```\nsmove source destination member\n```\n\n通过下面一张图回忆一下交、并、差\n\n![](./img/sql/redis/第一章Redis基础/交并差.png)\n\n#### 2.12.2  set 类型数据操作的注意事项\n\nset 类型不允许数据重复，如果添加的数据在 set 中已经存在，将只保留一份。\n\nset 虽然与hash的存储结构相同，但是无法启用hash中存储值的空间。\n\n### 2.13  set应用场景\n\n#### 2.13.1  set应用场景\n\n（1）黑名单\n\n资讯类信息类网站追求高访问量，但是由于其信息的价值，往往容易被不法分子利用，通过爬虫技术，  快速获取信息，个别特种行业网站信息通过爬虫获取分析后，可以转换成商业机密进行出售。例如第三方火 车票、机票、酒店刷票代购软件，电商刷评论、刷好评。\n\n同时爬虫带来的伪流量也会给经营者带来错觉，产生错误的决策，有效避免网站被爬虫反复爬取成为每个网站都要考虑的基本问题。在基于技术层面区分出爬虫用户后，需要将此类用户进行有效的屏蔽，这就是黑名单的典型应用。\n\nps:不是说爬虫一定做摧毁性的工作，有些小型网站需要爬虫为其带来一些流量。\n\n（2）白名单\n\n对于安全性更高的应用访问，仅仅靠黑名单是不能解决安全问题的，此时需要设定可访问的用户群体， 依赖白名单做更为苛刻的访问验证。\n\n#### 2.13.2  解决方案\n\n基于经营战略设定问题用户发现、鉴别规则\n\n周期性更新满足规则的用户黑名单，加入set集合\n\n用户行为信息达到后与黑名单进行比对，确认行为去向\n\n黑名单过滤IP地址：应用于开放游客访问权限的信息源\n\n黑名单过滤设备信息：应用于限定访问设备的信息源\n\n黑名单过滤用户：应用于基于访问权限的信息源\n\n### 2.14  实践案例\n\n#### 2.14.1业务场景\n\n使用微信的过程中，当微信接收消息后，会默认将最近接收的消息置顶，当多个好友及关注的订阅号同时发 送消息时，该排序会不停的进行交替。同时还可以将重要的会话设置为置顶。一旦用户离线后，再次打开微信时，消息该按照什么样的顺序显示。\n\n我们分析一下：\n\n![](./img/sql/redis/第一章Redis基础/set案例.png)\n\n100这台手机代表你。而200、300、400这三台代表你好友的手机。在这里有一些东西需要交代一下，因为我们每个人的都会对自己的微信中的一些比较重要的人设置会话置顶，将他的那条对话放在最上面。我们假定这个人有两个会话置顶的好友，分别是400和500，而这里边就包含400.\n\n下面呢，我们就来发这个消息，第一个发消息的是300，他发了个消息给100。发完以后，这个东西应该怎么存储呢？在这里面一定要分开，记录置顶的这些人的会话，对应的会话显示顺序和非置顶的一定要分两。\n\n这里面我们创建两个模型，一个是普通的，一个是置顶的，而上面的这个置顶的用户呢，我们用set来存储，因为不重复。而下面这些因为有顺序，很容易想到用list去存储,不然你怎么表达顺序呢？\n\n![](./img/sql/redis/第一章Redis基础/300.png)\n\n那当300发给消息给100以后，这个时候我们先判定你在置顶人群中吗？不在,那好，300的消息对应的顺序就应该放在普通的列表里边。而在这里边，我们把300加进去。第一个数据也就是现在300。\n\n![](./img/sql/redis/第一章Redis基础/400.png)\n\n接下来400，发了个消息。判断一下，他是需要置顶的，所以400将进入list的置顶里边放着。当前还没有特殊的地方。\n\n![](./img/sql/redis/第一章Redis基础/200.png)\n\n再来200发消息了，和刚才的判定方法一样，先看在不在置顶里，不在的话进普通，然后在普通里边把200加入就行了，OK，到这里目前还没有顺序变化。\n\n接下来200又发消息过来，同一个人给你连发了两条，那这个时候200的消息到达以后，先判断是否在置顶范围，不在，接下来他要放在list普通中，这里你要注意一点，因为这里边已经有200，所以进来以后先干一件事儿，把200杀掉，没有200，然后再把200加进来，那你想一下，现在这个位置顺序是什么呢？就是新的都在右边，对不对？\n\n还记得我们说list模型，如果是一个双端队列，它是可以两头进两头出。当然我们双端从一头进一头出，这就是栈模型，现在咱们运用的就是list模型中的栈模型。\n\n![](./img/sql/redis/第一章Redis基础/3002.png)\n\n现在300发消息，先判定他在不在，不在，用普通的队列，接下来按照刚才的操作，不管你里边原来有没有300，我先把300杀掉，没了，200自然就填到300的位置了，他现在是list里面唯一一个，然后让300进来，注意是从右侧进来的，那么现在300就是最新的。\n\n![](./img/sql/redis/第一章Redis基础/分析.png)\n\n那么到这里呢，我们让100来读取消息。你觉得这个消息顺序应该是什么样的？首先置顶的400有一个，他跑在最上面，然后list普通如果出来的话，300是最新的消息，而200在他后面的。用这种形式，我们就可以做出来他的消息顺序来。\n\n#### 2.14.2  解决方案\n\n看一下最终的解决方案：\n\n依赖list的数据具有顺序的特征对消息进行管理，将list结构作为栈使用\n\n置顶与普通会话分别创建独立的list分别管理\n\n当某个list中接收到用户消息后，将消息发送方的id从list的一侧加入list（此处设定左侧）\n\n多个相同id发出的消息反复入栈会出现问题，在入栈之前无论是否具有当前id对应的消息，先删除对应id\n\n推送消息时先推送置顶会话list，再推送普通会话list，推送完成的list清除所有数据\n消息的数量，也就是微信用户对话数量采用计数器的思想另行记录，伴随list操作同步更新\n\n#### 2.14.3  数据类型总结\n\n总结一下，在整个数据类型的部分，我们主要介绍了哪些内容：\n\n首先我们了解了一下数据类型，接下来针对着我们要学习的数据类型，进行逐一讲解了string、hash、list、set等，最后通过一个案例总结了一下前面的数据类型的使用场景。\n\n## 3. 常用指令\n\n在这部分中呢，我们家学习两个知识，第一个是key的常用指令，第二个是数据库的常用指令。和前面我们学数据类型做一下区分，前面你学的那些指令呢，都是针对某一个数据类型操作的，现在学的都是对所有的操作的，来看一下，我们在学习Key的操作的时候，我们先想一下的操作我们应该学哪些东西:\n\n### 3.1  key 操作分析\n\n#### 3.1.1  key应该设计哪些操作？\n\nkey是一个字符串，通过key获取redis中保存的数据\n\n对于key自身状态的相关操作，例如：删除，判定存在，获取类型等\n\n对于key有效性控制相关操作，例如：有效期设定，判定是否有效，有效状态的切换等\n\n对于key快速查询操作，例如：按指定策略查询key\n\n#### 3.1.2  key 基本操作\n\n删除指定key\n\n```bash\ndel key\n```\n\n获取key是否存在\n\n```bash\nexists key\n```\n\n获取key的类型\n\n```bash\ntype key\n```\n\n3.1.3  拓展操作\n\n排序\n\n```bash\nsort\n```\n\n改名\n\n```bash\nrename key newkey\nrenamenx key newkey\n```\n\n#### 3.1.3  key 扩展操作（时效性控制）\n\n为指定key设置有效期\n\n```bash\nexpire key seconds\npexpire key milliseconds\nexpireat key timestamp\npexpireat key milliseconds-timestamp\n```\n\n获取key的有效时间\n\n```bash\nttl key\npttl key\n```\n\n切换key从时效性转换为永久性\n\n```bash\npersist key\n```\n\n#### 3.1.4  key 扩展操作（查询模式）\n\n查询key\n\n```bash\nkeys pattern\n```\n\n查询模式规则\n\n*匹配任意数量的任意符号      ?\t配合一个任意符号\t[]\t匹配一个指定符号\n\n```bash\nkeys *  keys    查询所有\nit*  keys       查询所有以it开头\n*heima          查询所有以heima结尾\nkeys ??heima    查询所有前面两个字符任意，后面以heima结尾 查询所有以\nkeys user:?     user:开头，最后一个字符任意\nkeys u[st]er:1  查询所有以u开头，以er:1结尾，中间包含一个字母，s或t\n```\n\n### 3.2  数据库指令\n\n#### 3.2.1  key 的重复问题\n\n在这个地方我们来讲一下数据库的常用指令，在讲这个东西之前，我们先思考一个问题：\n\n假如说你们十个人同时操作redis，会不会出现key名字命名冲突的问题。\n\n一定会，为什么?因为你的key是由程序而定义的。你想写什么写什么，那在使用的过程中大家都在不停的加，早晚有一天他会冲突的。\n\nredis在使用过程中，伴随着操作数据量的增加，会出现大量的数据以及对应的key。\n\n那这个问题我们要不要解决？要！怎么解决呢？我们最好把数据进行一个分类，除了命名规范我们做统一以外，如果还能把它分开，这样是不是冲突的机率就会小一些了，这就是咱们下面要说的解决方案！\n\n#### 3.2.2  解决方案\n\nredis为每个服务提供有16个数据库，编号从0到15\n\n每个数据库之间的数据相互独立\n\n![](./img/sql/redis/第一章Redis基础/数据库.png)\n\n在对应的数据库中划出一块区域，说他就是几，你就用几那块，同时，其他的这些都可以进行定义，一共是16个，这里边需要注意一点，他们这16个共用redis的内存。没有说谁大谁小，也就是说数字只是代表了一块儿区域，区域具体多大未知。这是数据库的一个分区的一个策略！\n\n#### 3.2.3   数据库的基本操作\n\n切换数据库\n\n```\nselect index\n```\n\n其他操作\n\n```\nping\n```\n\n#### 3.2.4  数据库扩展操作\n\n数据移动\n\n```\nmove key db\n```\n\n数据总量\n\n```\ndbsize\n```\n\n数据清除\n\n```\nflushdb  flushall\n```\n\n## 4. Jedis\n\n在学习完redis后，我们现在就要用Java来连接redis了，也就是我们的这一章要学的Jedis了。在这个部分，我们主要讲解以下3个内容：\n\nHelloWorld（Jedis版）\n\nJedis简易工具类开发\n\n可视化客户端\n\n### 4.1  Jedis简介\n\n#### 4.1.1  编程语言与redis\n\n![](./img/sql/redis/第一章Redis基础/jedis1.png)\n\n对于我们现在的数据来说，它是在我们的redis中，而最终我们是要做程序。那么程序就要和我们的redis进行连接。干什么事情呢？两件事：程序中有数据的时候，我们要把这些数据全部交给redis管理。同时，redis中的数据还能取出来，回到我们的应用程序中。那在这个过程中，在Java与redis之间打交道的这个东西就叫做Jedis.简单说，Jedis就是提供了Java与redis的连接服务的，里边有各种各样的API接口，你可以去调用它。\n\n除了Jedis外，还有没有其他的这种连接服务呢？其实还有很多，了解一下：\n\nJava语言连接redis服务 Jedis（SpringData、Redis 、 Lettuce）\n\n其它语言：C 、C++ 、C# 、Erlang、Lua 、Objective-C 、Perl 、PHP 、Python 、Ruby 、Scala\n\n#### 4.1.2  准备工作\n\n(1)jar包导入\n\n下载地址：https://mvnrepository.com/artifact/redis.clients/jedis\n\n基于maven\n\n```xml\n<dependency>\n<groupId>redis.clients</groupId>\n<artifactId>jedis</artifactId>\n<version>2.9.0</version>\n</dependency>\n```\n\n(2)客户端连接redis\n\n连接redis\n\n```\nJedis jedis = new Jedis("localhost", 6379);\n```\n\n操作redis\n\n```\njedis.set("name", "itheima");  jedis.get("name");\n```\n\n关闭redis连接\n\n```\njedis.close();\n```\n\nAPI文档\n\nhttp://xetorthio.github.io/jedis/\n\n#### 4.1.3 代码实现\n\n创建：com.itheima.JedisTest\n\n```java\npublic class JedisTest {\n\n    public static void main(String[] args) {\n        //1.获取连接对象\n        Jedis jedis = new Jedis("192.168.40.130",6379);\n        //2.执行操作\n        jedis.set("age","39");\n        String hello = jedis.get("hello");\n        System.out.println(hello);\n        jedis.lpush("list1","a","b","c","d");\n        List<String> list1 = jedis.lrange("list1", 0, -1);\n        for (String s:list1 ) {\n            System.out.println(s);\n        }\n        jedis.sadd("set1","abc","abc","def","poi","cba");\n        Long len = jedis.scard("set1");\n        System.out.println(len);\n        //3.关闭连接\n        jedis.close();\n    }\n}\n```\n\n\n\n### 4.2  Jedis简易工具类开发\n\n前面我们做的程序还是有点儿小问题，就是我们的Jedis对象的管理是我们自己创建的，真实企业开发中是不可能让你去new一个的，那接下来咱们就要做一个工具类，简单来说，就是做一个创建Jedis的这样的一个工具。\n\n#### 4.2.1  基于连接池获取连接\n\nJedisPool：Jedis提供的连接池技术 \n\npoolConfig:连接池配置对象 \n\nhost:redis服务地址\n\nport:redis服务端口号\n\n\n\nJedisPool的构造器如下：\n\n```java\npublic JedisPool(GenericObjectPoolConfig poolConfig, String host, int port) {\nthis(poolConfig, host, port, 2000, (String)null, 0, (String)null);\n}\n```\n\n#### 4.2.2  封装连接参数\n\n创建jedis的配置文件：jedis.properties\n\n```properties\njedis.host=192.168.40.130  \njedis.port=6379  \njedis.maxTotal=50  \njedis.maxIdle=10\n```\n\n#### 4.2.3  加载配置信息\n\n 创建JedisUtils：com.itheima.util.JedisUtils，使用静态代码块初始化资源\n\n```java\npublic class JedisUtils {\n    private static int maxTotal;\n    private static int maxIdel;\n    private static String host;\n    private static int port;\n    private static JedisPoolConfig jpc;\n    private static JedisPool jp;\n\n    static {\n        ResourceBundle bundle = ResourceBundle.getBundle("redis");\n        maxTotal = Integer.parseInt(bundle.getString("redis.maxTotal"));\n        maxIdel = Integer.parseInt(bundle.getString("redis.maxIdel"));\n        host = bundle.getString("redis.host");\n        port = Integer.parseInt(bundle.getString("redis.port"));\n        //Jedis连接池配置\n        jpc = new JedisPoolConfig();\n        jpc.setMaxTotal(maxTotal);\n        jpc.setMaxIdle(maxIdel);\n        jp = new JedisPool(jpc,host,port);\n    }\n\n}\n```\n\n#### 4.2.4  获取连接\n\n 对外访问接口，提供jedis连接对象，连接从连接池获取，在JedisUtils中添加一个获取jedis的方法：getJedis\n\n```java\npublic static Jedis getJedis(){\n\tJedis jedis = jedisPool.getResource();\n\treturn jedis;\n}\n```\n\n\n\n### 4.3  可视化客户端\n\n4.3.1  Redis Desktop Manager\n\n![](./img/sql/redis/第一章Redis基础/可视化.png)\n\n## 5. 持久化\n\n下面呢，进入到持久化的学习.这部分内容理解的东西多，操作的东西少。在这个部分，我们将讲解四个东西：\n\n持久化简介\n\nRDB\n\nAOF\n\nRDB与AOF区别\n\n### 5.1  持久化简介\n\n#### 5.1.1  场景-意外断电\n\n不知道大家有没有遇见过，就是正工作的时候停电了，如果你用的是笔记本电脑还好，你有电池，但如果你用的是台式机呢，那恐怕就比较灾难了，假如你现在正在写一个比较重要的文档，如果你要使用的是word，这种办公自动化软件的话，他一旦遇到停电，其实你不用担心，因为它会给你生成一些其他的文件。\n\n![](./img/sql/redis/第一章Redis基础/持久化案例1.png)\n\n其实他们都在做一件事儿，帮你自动恢复，有了这个文件，你前面的东西就不再丢了。那什么是自动恢复呢？你要先了解他的整个过程。\n\n我们说自动恢复，其实基于的一个前提就是他提前把你的数据给存起来了。你平常操作的所有信息都是在内存中的，而我们真正的信息是保存在硬盘中的，内存中的信息断电以后就消失了，硬盘中的信息断电以后还可以保留下来！\n\n![](./img/sql/redis/第一章Redis基础/备份.png)\n\n我们将文件由内存中保存到硬盘中的这个过程，我们叫做数据保存，也就叫做持久化。但是把它保存下来不是你的目的，最终你还要把它再读取出来，它加载到内存中这个过程，我们叫做数据恢复，这就是我们所说的word为什么断电以后还能够给你保留文件，因为它执行了一个自动备份的过程，也就是通过自动的形式，把你的数据存储起来，那么有了这种形式以后，我们的数据就可以由内存到硬盘上实现保存。\n\n#### 5.1.2  什么是持久化\n\n(1)什么是持久化\n\n利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化 。\n\n持久化用于防止数据的意外丢失，确保数据安全性。\n\n(2)持久化过程保存什么？\n\n我们知道一点，计算机中的数据全部都是二进制，如果现在我要你给我保存一组数据的话，你有什么样的方式呢，其实最简单的就是现在长什么样，我就记下来就行了，那么这种是记录纯粹的数据，也叫做快照存储，也就是它保存的是某一时刻的数据状态。\n\n还有一种形式，它不记录你的数据，它记录你所有的操作过程，比如说大家用idea的时候，有没有遇到过写错了ctrl+z撤销，然后ctrl+y还能恢复，这个地方它也是在记录，但是记录的是你所有的操作过程，那我想问一下，操作过程，我都给你留下来了，你说数据还会丢吗？肯定不会丢，因为你所有的操作过程我都保存了。这种保存操作过程的存储，用专业术语来说可以说是日志，这是两种不同的保存数据的形式啊。\n\n![](./img/sql/redis/第一章Redis基础/持久化2.png)\n\n\n\n总结一下：\n\n第一种：将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据。\n\n第二种：将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程。\n\n### 5.2  RDB\n\n#### 5.2.1  save指令\n\n手动执行一次保存操作\n\n```\nsave\n```\n\n**save指令相关配置**\n\n设置本地数据库文件名，默认值为 dump.rdb，通常设置为dump-端口号.rdb\n\n```\ndbfilename filename\n```\n\n设置存储.rdb文件的路径，通常设置成存储空间较大的目录中，目录名称data\n\n```\ndir path\n```\n\n设置存储至本地数据库时是否压缩数据，默认yes，设置为no，节省 CPU 运行时间，但存储文件变大\n\n```\nrdbcompression yes|no\n```\n\n设置读写文件过程是否进行RDB格式校验，默认yes，设置为no，节约读写10%时间消耗，单存在数据损坏的风险\n\n```\nrdbchecksum yes|no\n```\n\n**save指令工作原理**\n\n![](./img/sql/redis/第一章Redis基础/rdb启动方式.png)\n\n![](./img/sql/redis/第一章Redis基础/启动方式2.png)\n\n需要注意一个问题，来看一下，现在有四个客户端各自要执行一个指令，把这些指令发送到redis服务器后，他们执行有一个先后顺序问题，假定就是按照1234的顺序放过去的话，那会是什么样的？\n\n记得redis是个单线程的工作模式，它会创建一个任务队列，所有的命令都会进到这个队列里边，在这儿排队执行，执行完一个消失一个，当所有的命令都执行完了，OK，结果达到了。\n\n但是如果现在我们执行的时候save指令保存的数据量很大会是什么现象呢？\n\n他会非常耗时，以至于影响到它在执行的时候，后面的指令都要等，所以说这种模式是不友好的，这是save指令对应的一个问题，当cpu执行的时候会阻塞redis服务器，直到他执行完毕，所以说我们不建议大家在线上环境用save指令。\n\n#### 5.2.2  bgsave指令\n\n之前我们讲到了当save指令的数据量过大时，单线程执行方式造成效率过低，那应该如何处理？\n\n此时我们可以使用：**bgsave**指令，bg其实是background的意思，后台执行的意思\n\n手动启动后台保存操作，但不是立即执行\n\n```properties\nbgsave\n```\n\n**bgsave指令相关配置**\n\n后台存储过程中如果出现错误现象，是否停止保存操作，默认yes\n\n```properties\nstop-writes-on-bgsave-error yes|no\n```\n\n其 他\n\n```properties\ndbfilename filename  \ndir path  \nrdbcompression yes|no  \nrdbchecksum yes|no\n```\n\n**bgsave指令工作原理**\n\n![](./img/sql/redis/第一章Redis基础/rdb启动方式3.png)\n\n当执行bgsave的时候，客户端发出bgsave指令给到redis服务器。注意，这个时候服务器马上回一个结果告诉客户端后台已经开始了，与此同时它会创建一个子进程，使用Linux的fork函数创建一个子进程，让这个子进程去执行save相关的操作，此时我们可以想一下，我们主进程一直在处理指令，而子进程在执行后台的保存，它会不会干扰到主进程的执行吗？\n\n答案是不会，所以说他才是主流方案。子进程开始执行之后，它就会创建啊RDB文件把它存起来，操作完以后他会把这个结果返回，也就是说bgsave的过程分成两个过程，第一个是服务端拿到指令直接告诉客户端开始执行了；另外一个过程是一个子进程在完成后台的保存操作，操作完以后回一个消息。\n\n#### 5.2.3 save配置自动执行\n\n设置自动持久化的条件，满足限定时间范围内key的变化数量达到指定数量即进行持久化\n\n```properties\nsave second changes\n```\n\n参数\n\nsecond：监控时间范围\n\nchanges：监控key的变化量\n\n范例：\n\n```markdown\nsave 900 1\nsave 300 10\nsave 60 10000\n```\n\n其他相关配置：\n\n```markdown\ndbfilename filename\ndir path\nrdbcompression yes|no\nrdbchecksum yes|no\nstop-writes-on-bgsave-error yes|no\n```\n\n**save配置工作原理**\n\n![](./img/sql/redis/第一章Redis基础/启动方式4.png)\n\n#### 5.2.4 RDB三种启动方式对比\n\n| 方式           | save指令 | bgsave指令 |\n| -------------- | -------- | ---------- |\n| 读写           | 同步     | 异步       |\n| 阻塞客户端指令 | 是       | 否         |\n| 额外内存消耗   | 否       | 是         |\n| 启动新进程     | 否       | 是         |\n\n**RDB特殊启动形式**\n\n服务器运行过程中重启\n\n```bash\ndebug reload\n```\n\n关闭服务器时指定保存数据\n\n```bash\nshutdown save\n```\n\n全量复制（在主从复制中详细讲解）\n\n\n\n**RDB优点：**\n\n- RDB是一个紧凑压缩的二进制文件，存储效率较高\n- RDB内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景\n- RDB恢复数据的速度要比AOF快很多\n- 应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于灾难恢复。\n\n**RDB缺点**\n\n- RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性丢失数据\n- bgsave指令每次运行要执行fork操作创建子进程，要牺牲掉一些性能\n- Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现各版本服务之间数据格式无法兼容现象\n\n\n\n### 5.3  AOF\n\n为什么要有AOF,这得从RDB的存储的弊端说起：\n\n- 存储数据量较大，效率较低，基于快照思想，每次读写都是全部数据，当数据量巨大时，效率非常低\n- 大数据量下的IO性能较低\n- 基于fork创建子进程，内存产生额外消耗\n- 宕机带来的数据丢失风险\n\n\n\n那解决的思路是什么呢？\n\n- 不写全数据，仅记录部分数据\n- 降低区分数据是否改变的难度，改记录数据为记录操作过程\n- 对所有操作均进行记录，排除丢失数据的风险\n\n#### 5.3.1 AOF概念\n\n**AOF**(append only file)持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令 达到恢复数据的目的。**与RDB相比可以简单理解为由记录数据改为记录数据产生的变化**\n\nAOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式\n\n**AOF写数据过程**\n\n![](./img/sql/redis/第一章Redis基础/1.png)\n\n**启动AOF相关配置**\n\n开启AOF持久化功能，默认no，即不开启状态\n\n```properties\nappendonly yes|no\n```\n\nAOF持久化文件名，默认文件名为appendonly.aof，建议配置为appendonly-端口号.aof\n\n```properties\nappendfilename filename\n```\n\nAOF持久化文件保存路径，与RDB持久化文件保持一致即可\n\n```properties\ndir\n```\n\nAOF写数据策略，默认为everysec\n\n```properties\nappendfsync always|everysec|no\n```\n\n\n\n#### 5.3.2 AOF执行策略\n\nAOF写数据三种策略(appendfsync)\n\n- **always**(每次）：每次写入操作均同步到AOF文件中数据零误差，性能较低，不建议使用。\n\n\n- **everysec**（每秒）：每秒将缓冲区中的指令同步到AOF文件中，在系统突然宕机的情况下丢失1秒内的数据 数据准确性较高，性能较高，建议使用，也是默认配置\n\n\n- **no**（系统控制）：由操作系统控制每次同步到AOF文件的周期，整体过程不可控\n\n#### 5.3.3 AOF重写\n\n场景：AOF写数据遇到的问题，如果连续执行如下指令该如何处理\n\n![](./img/sql/redis/第一章Redis基础/2.png)\n\n**什么叫AOF重写？**\n\n随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积。AOF文件重 写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。简单说就是将对同一个数据的若干个条命令执行结 果转化成最终结果数据对应的指令进行记录。\n\n**AOF重写作用**\n\n- 降低磁盘占用量，提高磁盘利用率\n- 提高持久化效率，降低持久化写时间，提高IO性能\n- 降低数据恢复用时，提高数据恢复效率\n\n**AOF重写规则**\n\n- 进程内具有时效性的数据，并且数据已超时将不再写入文件\n\n\n- 非写入类的无效指令将被忽略，只保留最终数据的写入命令\n\n  如del key1、 hdel key2、srem key3、set key4 111、set key4 222等\n\n  如select指令虽然不更改数据，但是更改了数据的存储位置，此类命令同样需要记录\n\n- 对同一数据的多条写命令合并为一条命令\n\n如lpushlist1 a、lpush list1 b、lpush list1 c可以转化为：lpush list1 a b c。\n\n为防止数据量过大造成客户端缓冲区溢出，对list、set、hash、zset等类型，每条指令最多写入64个元素\n\n\n\n**AOF重写方式**\n\n- 手动重写\n\n```properties\nbgrewriteaof\n```\n\n**手动重写原理分析：**\n\n![](./img/sql/redis/第一章Redis基础/3.png)\n\n\n\n- 自动重写\n\n```properties\nauto-aof-rewrite-min-size size\nauto-aof-rewrite-percentage percentage\n```\n\n自动重写触发条件设置\n\n```properties\nauto-aof-rewrite-min-size size\nauto-aof-rewrite-percentage percent\n```\n\n自动重写触发比对参数（ 运行指令info Persistence获取具体信息 ）\n\n```properties\naof_current_size  \naof_base_size\n```\n\n 自动重写触发条件公式：\n\n![](./img/sql/redis/第一章Redis基础/4.png)\n\n\n\n\n\n#### 5.3.4 AOF工作流程及重写流程\n\n![](./img/sql/redis/第一章Redis基础/AOF工作流程.png)\n\n\n\n![](./img/sql/redis/第一章Redis基础/AOF流程2.png)\n\n\n\n![](./img/sql/redis/第一章Redis基础/AOF3.png)\n\n\n\n\n\n### 5.4  RDB与AOF区别\n\n#### 5.4.1 RDB与AOF对比（优缺点）\n\n| 持久化方式   | RDB                | AOF                |\n| ------------ | ------------------ | ------------------ |\n| 占用存储空间 | 小（数据级：压缩） | 大（指令级：重写） |\n| 存储速度     | 慢                 | 快                 |\n| 恢复速度     | 快                 | 慢                 |\n| 数据安全性   | 会丢失数据         | 依据策略决定       |\n| 资源消耗     | 高/重量级          | 低/轻量级          |\n| 启动优先级   | 低                 | 高                 |\n\n#### 5.4.2 RDB与AOF应用场景\n\nRDB与AOF的选择之惑\n\n- 对数据非常敏感，建议使用默认的AOF持久化方案\n\nAOF持久化策略使用everysecond，每秒钟fsync一次。该策略redis仍可以保持很好的处理性能，当出 现问题时，最多丢失0-1秒内的数据。\n\n注意：由于AOF文件存储体积较大，且恢复速度较慢\n\n- 数据呈现阶段有效性，建议使用RDB持久化方案\n\n数据可以良好的做到阶段内无丢失（该阶段是开发者或运维人员手工维护的），且恢复速度较快，阶段 点数据恢复通常采用RDB方案\n\n注意：利用RDB实现紧凑的数据持久化会使Redis降的很低，慎重总结：\n\n\n\n**综合比对**\n\n- RDB与AOF的选择实际上是在做一种权衡，每种都有利有弊\n- 如不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用AOF\n- 如能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用RDB\n- 灾难恢复选用RDB\n- 双保险策略，同时开启 RDB和 AOF，重启后，Redis优先使用 AOF 来恢复数据，降低丢失数据的量',Bn={data:function(){return{MainComponent:fn}}},Un=Bn,kn=Object(L["a"])(Un,Dn,Cn,!1,null,"b294cb22",null),vn=kn.exports,qn=function(){var n=this,r=n.$createElement,e=n._self._c||r;return e("div",{},[e("q-markdown",{attrs:{"no-heading-anchor-links":"",src:n.MainComponent}})],1)},wn=[],Fn="\x3c!--\r\n * @Date           : 2020-11-05 21:36:01\r\n * @FilePath       : /jinnian-space/src/pages/sql/module/redis/md/redis.md\r\n * @Description    : \r\n--\x3e\r\n# redis\r\n\r\n## Redis\r\n\r\n### 启动Redis服务\r\n\r\n- redis-server（默认配置）\r\n- redis-server --configKey1 configValue1 --configKey2 configValue2（根据配置项启动）\r\n- redis-server /opt/redis/redis.conf（配置文件启动）\r\n\r\n### 连接Redis服务器\r\n\r\n- redis-cli -h {host} -p {port} (交互方式)\r\n- redis-cli -h {host} -p {port} {command}\t(命令方式)\r\n\r\n### 停止Redis服务\r\n\r\n- redis-cli shutdown nosave|save（断开与客户端连接、持久化文件生成）\r\n- kill -9 redis（强制杀死Redis服务）\r\n\r\n### 全局命令\r\n\r\n- keys * ：查看所有键\r\n- dbsize:  键总数\r\n- exists key: \t检查键是否存在\r\n- del key [key ...]:\t删除键\r\n- expire key seconds:\t设置键过期时间\r\n- ttl key:\t查看键剩余过期时间 \r\n- type key: 获取键的数据结构类型\r\n\r\n\t- string\r\n\t- list\r\n\t- set\r\n\t- zset\r\n\t- hash\r\n\r\n- object encoding key:\t查询键的内部编码\r\n\r\n### 字符串\r\n\r\n- set key value [ex seconds] [px milliseconds] [nx|xx]:\t设置值\r\n- get key:\t获取值\r\n- mset key value [key value ...]:\t批量设置值\r\n- mget key [key...]:\t\t批量获取值\r\n- incr key:\t值自增\r\n\r\n\t- 值不是整数，报错\r\n\t- 键不存在，默认为0，自增后返回1\r\n\t- 值是整数，返回自增后的结果\r\n\r\n- decr: 值自减\r\n- incrby、decrby、incrbyfloat\r\n- append key value: 追加值\r\n- strlen key: 字符串长度\r\n- getset: 设置并返回原值\r\n- setrange key offeset value: 设置指定位置的字符\r\n- getrange key start end：获取部分字符串\r\n\r\n### 哈希\r\n\r\n- hset key field value：\t设置值\r\n- hget key field:\t获取值\r\n- hdel key field [field ...]:\t\t删除field\r\n- hlen key:\t计算field个数\r\n- hmget key field [field ...]:\t批量获取\r\n- hmset key field [field value ...]:\t批量设置\r\n- hexists key field:\t\t检查field是否存在\r\n- hkeys key:\t\t获取所有field\r\n- hvals key：\t\t获取所有value\r\n- hgetall key:\t\t获取所有field-value\r\n- hincrby key field、hincrbyfloat key field\r\n- hstrlen key field:\t\t计算value的字符串长度\r\n\r\n### 列表\r\n\r\n- 添加\r\n\r\n\t- rpush key value [value...]:\t从右边插入元素\r\n\t- lpush key value [value...]:\t从左边插入元素\r\n\t- linsert key before/after pivot value:\t在值为pivot的前面或后面插入元素\r\n\r\n- 查找\r\n\r\n\t- lrange key start end:\t获取指定范围内的元素列表\r\n\t- lindex key index:\t获取列表指定索引下标的元素\r\n\t- llen key:\t获取列表长度\r\n\r\n- 删除\r\n\r\n\t- lpop key:\t从列表左侧弹出元素\r\n\t- rpop key:\t从列表右侧弹出元素\r\n\t- lrem  key count value:\t删除值等于value的元素\r\n\r\n\t\t- count>0:\t从左到右，删除最多count个元素\r\n\t\t- count<0:\t从右往左，删除最多count绝对值个元素\r\n\t\t- count=0:\t删除所有元素\r\n\r\n\t- ltrim key start end:\t按照索引范围修剪列表\r\n\r\n- 修改\r\n\r\n\t- lset key index newValue:\t修改指定索引下标的元素\r\n\r\n- 阻塞\r\n\r\n\t- blpop/brpop key [key...] timeout\r\n\r\n\t\t- 列表为空\r\n\r\n\t\t\t- timeout=n:\tn秒后返回\r\n\t\t\t- timeout=0\r\n\r\n\t\t\t\t- 客户端一直阻塞\r\n\t\t\t\t- 如果列表有值插入则立即返回\r\n\r\n\t\t- 列表非空\r\n\r\n\t\t\t- 客户端立即返回\r\n\r\n\t\t- brpop两点注意\r\n\r\n\t\t\t- 多个键，brpop会从左往右遍历键，一旦有一个键能弹出元素，客户端立即返回\r\n\t\t\t- 多个客户端对一个键执行brpop，最先执行brpop命令的客户端可以获取到弹出的值\r\n\r\n### 集合\r\n\r\n- sadd key member [...member]:\t添加元素\r\n- srem key member [...member]:\t删除元素\r\n- sismember key member:\t判断是否为集合元素\r\n- scard key:\t计算集合大小\r\n- srandmember key [count]:\t随机返回count个元素\r\n- spop key [count]:\t随机弹出count个元素\r\n- smembers key: 返回集合所有元素\r\n- sinter key [key...]:\t返回多个集合交集\r\n- sunion key [key...]:\t返回多个集合并集\r\n- sdiff key [key...]:\t返回多个集合差集\r\n- sinterstore/sunionstore/sdiffstore destination key [...key]:\t将返回的集合存储在destination中\r\n\r\n### 有序集合\r\n\r\n- zadd key [NX|XX] [CH] [INCR] score member [...score member]:\t添加元素\r\n\r\n\t- NX: 添加\r\n\t- XX：更新\r\n\t- CH：返回这次操作后发生变化的个数\r\n\t- INCR：对score做增加\r\n\r\n- zrem key member [...member]:\t删除元素\r\n- zcard key:\t计算有序集合大小\r\n- zscore key member:\t返回某个元素的分数\r\n- zrank/zrevrank key member:\t返回某个元素的排名(升序、降序)\r\n- zincrby key increment member:\t增加成员分数\r\n- zrange/zrevrange key start end:\t返回指定排名（升序、降序）范围内的元素\r\n- zrangebyscore/zrevrangebyscore key mix max:\t返回指定分数（升序、降序）范围内的元素\r\n- zcount key min max:\t返回指定分数范围成员个数\r\n- zremrangebyrank key start end:\t删除指定排名内的升序元素\r\n- zremrangebyscore key min max:\t删除指定分数范围内的元素\r\n- zinterstore destination numkeys key [...key] [weights weight [...weight]] [aggrerate sum|min|max]:\t交集\r\n- zunionstore destination numkeys key [...key] [weights weight [...weight]] [aggrerate sum|min|max]:\t\t并集\r\n\r\n## 核心\r\n\r\n### Redis\r\n\r\n- 单线程模型\r\n\r\n\t- 请求\r\n\r\n\t\t- 步骤\r\n\r\n\t\t\t- 发送命令\r\n\t\t\t- 执行命令\r\n\t\t\t- 返回结果\r\n\r\n\t\t- 重点\r\n\r\n\t\t\t- 一条命令从客户端达到服务端不会立刻被执行， 所有命令都会进入一个队列中，然后逐个执行。\r\n\r\n- 单线程为什么可以这么快\r\n\r\n\t- 纯内存访问\r\n\t- 非阻塞I/O，Redis使用epoll作为I/O多路复用技术的实现，加上Redis自身的时间处理模型（Redis Event Loop）\r\n\t- 避免线程切换和静态条件的消耗\r\n\r\n## 数据结构\r\n\r\n### 字符串\r\n\r\n- 内部编码\r\n\r\n\t- int：\t8个字节的长整型\r\n\t- embstr：小于等于39个字节的字符串\r\n\t- raw：大于39个字节的字符串\r\n\r\n- 使用场景\r\n\r\n\t- 缓存：Redis作为缓存层，MySQL作为存储层。\r\n\r\n\t\t- 加速读写和降低后端压力的作用\r\n\r\n\t- 计数：使用Redis作为计数的基础工具。\r\n\r\n\t\t- 实现快速计数、查询缓存且数据可以异步落地到其他数据源\r\n\r\n\t- 共享Session：使用Redis将用户的Session集中管理。\r\n\r\n\t\t- 出于负载均衡的考虑，分布式服务会将用户的访问均衡到不同服务器，用户每刷新一次就有可能发现需要重新登录\r\n\r\n\t- 限速：限制用户单位时间内访问次数\r\n\r\n### 哈希\r\n\r\n- 内部编码\r\n\r\n\t- ziplist(压缩表)\r\n\t- hashtable（哈希表）\r\n\r\n- 使用场景\r\n\r\n\t- 缓存用户信息\r\n\r\n### 列表\r\n\r\n- 内部编码\r\n\r\n\t- ziplist\r\n\t- linkedlist\r\n\r\n- 使用场景\r\n\r\n\t- 消息队列\r\n\r\n\t\t- 生产者使用lpush从列表左侧插入元素，消费者使用brpop命令阻塞式的‘抢’列表尾部的元素\r\n\r\n\t- 文章列表\r\n\r\n\t\t- 存储用户文章列表，分页获取文章\r\n\r\n### 集合\r\n\r\n- 内部编码\r\n\r\n\t- intset:\r\n\t- hashtable:\r\n\r\n- 使用场景\r\n\r\n\t- 用户标签\r\n\r\n### 有序集合\r\n\r\n- 内部编码\r\n\r\n\t- ziplist\r\n\t- skiplist\r\n\r\n- 使用场景\r\n\r\n\t- 排行榜系统\r\n\r\n",xn={data:function(){return{MainComponent:Fn}}},Qn=xn,Hn=Object(L["a"])(Qn,qn,wn,!1,null,"159db876",null),Pn=Hn.exports,Vn=Object(yn["a"])(e("6b79"),"md",!0),Yn=Vn.all_components,Gn=Vn.all_modules,Wn={mixins:[gn["c"],gn["b"]],components:{m1:vn,m2:Pn},data:function(){return{MainComponent:"",img_prefix:"./books/sql/redis/",tab:"m1",tab_level:2,tabs:[{label:"Redis基础",value:"m1"},{label:"Redis",value:"m2"}].concat(E()(Gn))}},watch:{tab:function(n,r){this.MainComponent=Yn[this.tab]}}},Kn=Wn,jn=Object(L["a"])(Kn,bn,_n,!1,null,"d334ed4a",null),Xn=jn.exports,zn={mixins:[gn["c"]],components:{m1:Mn,m2:Xn},data:function(){return{tab:"m1",tab_level:1,tabs:[{label:"mysql",value:"m1"},{label:"redis",value:"m2"}]}}},Jn=zn,$n=Object(L["a"])(Jn,s,t,!1,null,"829c150c",null);r["default"]=$n.exports},"53f6":function(n,r,e){"use strict";e.r(r),r["default"]="# 《面试八股文》之 MySql 35卷\r\n1.说一说三大范式\r\n2.MyISAM 与 InnoDB 的区别是什么？\r\n3.为什么推荐使用自增 id 作为主键？\r\n4.一条查询语句是怎么执行的?\r\n5.使用 Innodb 的情况下，一条更新语句是怎么执行的?\r\n6.Innodb 事务为什么要两阶段提交?\r\n7.什么是索引?\r\n8.索引失效的场景有哪些?\r\n9.为什么采用 B+ 树,而不是 B-树\r\n10.WAl 是什么?有什么好处?\r\n11.什么是回表?\r\n12.什么是索引下推?\r\n13.什么是覆盖索引?\r\n14.什么是最左前缀原则?\r\n15.普通索引和唯一索引该怎么选择?\r\n16.什么是事务?其特性是什么?\r\n17.事务的隔离级别?\r\n18.binlog 是做什么的?\r\n19.undolog 是做什么的?\r\n20.relaylog 是做什么的?\r\n21.redolog 是做什么的?\r\n22.redolog 是怎么记录日志的?\r\n23.redolog 和 binlog 的区别是什么?\r\n24.说一说 mvcc 吧，有什么作用?\r\n25.一条 Sql 语句查询一直慢会是什么原因?\r\n26.一条 Sql 语句查询偶尔慢会是什么原因?\r\n27.Mysql 主从之间是怎么同步数据的?\r\n28.主从延迟要怎么解决?\r\n29.删除表数据后表的大小却没有变动,这是为什么?\r\n30.为什么 VarChar 建议不要超过255?\r\n31.分布式式事务怎么实现?\r\n32.Mysql 中有哪些锁?\r\n33.为什么不要使用长事务?\r\n34.buffer pool 是做什么的?\r\n35.说说你的 Sql 调优思路吧\r\n------\r\n## **1.说一说三大范式**\r\n**「第一范式」**：数据库中的字段具有**「原子性」**，不可再分，并且是单一职责\r\n**「第二范式」**：**「建立在第一范式的基础上」**，第二范式要求数据库表中的每个实例或行必须**「可以被惟一地区分」**。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主键\r\n**「第三范式」**：**「建立在第一，第二范式的基础上」**，确保每列都和主键列直接相关，而不是间接相关不存在其他表的非主键信息\r\n但是在我们的日常开发当中，**「并不是所有的表一定要满足三大范式」**，有时候冗余几个字段可以少关联几张表，带来的查询效率的提升有可能是质变的\r\n## **2.MyISAM 与 InnoDB 的区别是什么？**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9524.tmp.png) \r\n\\1. **「InnoDB支持事务，MyISAM不支持」**。\r\n\\1. **「InnoDB 支持外键，而 MyISAM 不支持」**。\r\n\\1. **「InnoDB是聚集索引」**，使用B+Tree作为索引结构，数据文件是和索引绑在一起的，必须要有主键。**「MyISAM是非聚集索引」**，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。\r\n\\1. **「InnoDB 不保存表的具体行数」**。**「MyISAM 用一个变量保存了整个表的行数」**。\r\n5.Innodb 有 **「redolog」** 日志文件，MyISAM 没有\r\n6.**「Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI」**\r\n§ Innodb：frm是表定义文件，ibd是数据文件\r\n§ Myisam：frm是表定义文件，myd是数据文件，myi是索引文件\r\n\\1. **「InnoDB 支持表、行锁，而 MyISAM 支持表级锁」**\r\n8、**「InnoDB 必须有唯一索引(主键)」**,如果没有指定的话 InnoDB 会自己生成一个隐藏列Row_id来充当默认主键，**「MyISAM 可以没有」**\r\n## **3.为什么推荐使用自增 id 作为主键？**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9525.tmp.png) \r\n１.普通索引的 B+ 树上存放的是主键索引的值，如果该值较大，会**「导致普通索引的存储空间较大」**\r\n２.使用自增 id 做主键索引新插入数据只要放在该页的最尾端就可以，直接**「按照顺序插入」**，不用刻意维护\r\n3.页分裂容易维护，当插入数据的当前页快满时，会发生页分裂的现象，如果主键索引不为自增 id，那么数据就可能从页的中间插入，页的数据会频繁的变动，**「导致页分裂维护成本较高」**\r\n## **4.一条查询语句是怎么执行的?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9526.tmp.png) \r\n1.通过连接器跟客户端**「建立连接」**\r\n2.通过查询**「缓存查询」**之前是否有查询过该 sql\r\n§ 有则直接返回结果\r\n§ 没有则执行第三步\r\n3.通过分析器**「分析该 sql 的语义」**是否正确，包括格式，表等等\r\n4.通过优化器**「优化该语句」**，比如选择索引，join 表的连接顺序\r\n5.**「验证权限」**，验证是否有该表的查询权限\r\n§ 没有则返回无权限的错误\r\n§ 有则执行第六步\r\n6.通过执行器调用存储引擎执行该 sql，然后返回**「执行结果」**\r\n## **5.使用 Innodb 的情况下，一条更新语句是怎么执行的?**\r\n用以下语句来举例，c 字段无索引，id 为主键索引\r\nupdate T set c=c+1 where id=2;\r\n1.执行器先找引擎取 id=2 这一行。id 是主键，引擎直接用树搜索找到这一行\r\n§ 如果 id=2 这一行所在的数据页本来就**「在内存中」**，就**「直接返回」**给执行器\r\n§ **「不在内存」**中，需要先从磁盘**「读入内存」**，然后再**「返回」**\r\n2.执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口**「写入这行新数据」**\r\n3.引擎将这行新数据更新到内存中，同时将这个更新操作**「记录到 redlog 里面」**，此时 redlog 处于 **「prepare」** 状态。然后告知执行器执行完成了，随时可以提交事务\r\n4.执行器**「生成这个操作的 binlog」**，并把 binlog **「写入磁盘」**\r\n5.执行器调用引擎的**「提交事务」**接口，引擎把刚刚写入的 redlog 改成提交（commit）状态，**「更新完成」**\r\n## **6.Innodb 事务为什么要两阶段提交?**\r\n先写 redolog 后写binlog。假设在 redolog 写完，binlog 还没有写完的时候，MySQL 进程异常重启，这时候 binlog 里面就没有记录这个语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 **「binlog 丢失」**，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\r\n先写 binlog 后写 redolog。如果在 binlog 写完之后 crash，由于 redolog 还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是 binlog 里面已经记录了“把c从0改成1”这个日志。所以，在之后用 binlog 来恢复的时候就**「多了一个事务出来」**，恢复出来的这一行 c 的值就是 1，与原库的值不同。\r\n可以看到，**「如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致」**。\r\n## **7.什么是索引?**\r\n相信大家小时候学习汉字的时候都会查字典，想想你查字典的步骤，我们是通过汉字的首字母 a～z 一个一个在字典目录中查找，最终找到该字的页数。想想，如果没有目录会怎么样，最差的结果是你有可能翻到字典的最后一页才找到你想要找的字。\r\n索引就**「相当于我们字典中的目录」**，可以极大的提高我们在数据库的查询效率。\r\n## **8.索引失效的场景有哪些?**\r\n以下随便列举几个，不同版本的 mysql 场景不一\r\n1.最左前缀法则（带头索引不能死，中间索引不能断\r\n2.不要在索引上做任何操作（计算、函数、自动/手动类型转换），不然会导致索引失效而转向全表扫描\r\n3.不能继续使用索引中范围条件（bettween、<、>、in等）右边的列，如：\r\nselect a from user where c > 5 and b = 4；\r\n4.索引字段上使用（！= 或者 < >）判断时，会导致索引失效而转向全表扫描\r\n5.索引字段上使用 is null / is not null 判断时，会导致索引失效而转向全表扫描。\r\n6.索引字段使用like以通配符开头（‘%字符串’）时，会导致索引失效而转向全表扫描，也是最左前缀原则。\r\n7.索引字段是字符串，但查询时不加单引号，会导致索引失效而转向全表扫描\r\n8.索引字段使用 or 时，会导致索引失效而转向全表扫描\r\n## **9.为什么采用 B+ 树,而不是 B-树**\r\nB+ 树只在叶子结点储存数据，非叶子结点不存具体数据，只存 key，查询更稳定，增大了广度，而一个节点就是磁盘一个内存页，内存页大小固定，那么相比 B 树，B- 树这些**「可以存更多的索引结点」**，宽度更大，树高矮，节点小，拉取一次数据的磁盘 I次数少，并且 B+ 树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，效率更高。\r\n## **10.WAl 是什么?有什么好处?**\r\nWAL 就是 Write-Ahead Logging，其实就是**「所有的修改都先被写入到日志中，然后再写磁盘」**，用于保证数据操作的原子性和持久性。\r\n好处:\r\n1.**「读和写可以完全地并发执行」**，不会互相阻塞\r\n2.先写入 log 中，磁盘写入从**「随机写变为顺序写」**，降低了 client 端的延迟就。并且，由于顺序写入大概率是在一个磁盘块内，这样产生的 i次数也大大降低\r\n3.写入日志当数据库崩溃的时候**「可以使用日志来恢复磁盘数据」**\r\n## **11.什么是回表?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9527.tmp.png) \r\n回表就是先通过数据库索引扫描出该索引树中数据所在的行，取到主键 id，再通过主键 id 取出主键索引数中的数据，即基于非主键索引的查询需要多扫描一棵索引树.\r\n## **12.什么是索引下推?**\r\n如果存在某些被索引的列的判断条件时，MySQL 将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合 MySQL 服务器传递的条件，**「只有当索引符合条件时才会将数据检索出来返回给 MySQL 服务器」** 。\r\n## **13.什么是覆盖索引?**\r\n覆盖索引（covering index）指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取，可以减少回表的次数。比如:\r\nselect id from t where age = 1;\r\nid 为主键索引，age 为普通索引，age 这个索引树存储的就是逐渐信息，可以直接返回\r\n## **14.什么是最左前缀原则?**\r\n最左前缀其实说的是，在 where 条件中出现的字段，**「如果只有组合索引中的部分列，则这部分列的触发索引顺序」**，是按照定义索引的时候的顺序从前到后触发，最左面一个列触发不了，之后的所有列索引都无法触发。\r\n比如**「有一个 (a,b,c) 的组合索引」**\r\nwhere a = 1 and b = 1\r\n此时 a,b 会命中该组合索引\r\nwhere a = 1 and c = 1\r\n此时 a 会命中该组合索引, c 不会\r\nwhere b = 1 and c = 1\r\n此时不会命中该组合索引\r\n## **15.普通索引和唯一索引该怎么选择?**\r\n查询\r\n§ 当普通索引为条件时查询到数据会一直扫描,直到扫完整张表\r\n§ 当唯一索引为查询条件时,查到该数据会直接返回,不会继续扫表\r\n更新\r\n§ 普通索引会直接将操作更新到 change buffer 中,然后结束\r\n§ 唯一索引需要判断数据是否冲突\r\n所以**「唯一索引更加适合查询的场景,普通索引更适合插入的场景」**\r\n## **16.什么是事务?其特性是什么?**\r\n事务是指是程序中一系列操作必须全部成功完成，有一个失败则全部失败。\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9537.tmp.png) \r\n特性\r\n**「1.原子性（Atomicity）」**：要么全部执行成功，要么全部不执行。\r\n**「2.一致性（Consistency）」**：事务前后数据的完整性必须保持一致。\r\n**「3.隔离性（Isolation）」**：隔离性是当多个事务同事触发时，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。\r\n**「4.持久性（Durability）」**：事务完成之后的改变是永久的。\r\n## **17.事务的隔离级别?**\r\n1.**「读提交」**:即能够**「读取到那些已经提交」**的数据\r\n2.**「读未提交」**:即能够**「读取到没有被提交」**的数据\r\n3.**「可重复读」**:可重复读指的是在一个事务内，最开始读到的数据和事务结束前的**「任意时刻读到的同一批数据都是一致的」**\r\n4.**「可串行化」**:最高事务隔离级别，不管多少事务，都是**「依次按序一个一个执行」**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9538.tmp.png) \r\n**「脏读」**\r\n§ 脏读指的是**「读到了其他事务未提交的数据」**，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读\r\n**「不可重复读」**\r\n§ 对比可重复读，不可重复读指的是在同一事务内，**「不同的时刻读到的同一批数据可能是不一样的」**。\r\n**「幻读」**\r\n§ 幻读是针对数据插入（INSERT）操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现**「好像刚刚的更改对于某些数据未起作用」**，但其实是事务B刚插入进来的这就叫幻读\r\n## **18.binlog 是做什么的?**\r\nbinlog 是归档日志，属于 Server 层的日志，是一个二进制格式的文件，用于**「记录用户对数据库更新的SQL语句信息」**。\r\n主要作用\r\n主从复制\r\n数据恢复\r\n## **19.undolog 是做什么的?**\r\nundolog 是 InnoDB 存储引擎的日志，用于保证数据的原子性，**「保存了事务发生之前的数据的一个版本，也就是说记录的是数据是修改之前的数据，可以用于回滚」**，同时可以提供多版本并发控制下的读（MVCC）。\r\n主要作用\r\n事务回滚\r\n实现多版本控制(MVCC)\r\n## **20.relaylog 是做什么的?**\r\nrelaylog 是中继日志，**「在主从同步的时候使用到」**，它是一个中介临时的日志文件，用于存储从master节点同步过来的binlog日志内容。\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9539.tmp.png) \r\nmaster 主节点的 binlog 传到 slave 从节点后，被写入 relay log 里，从节点的 slave sql 线程从 relaylog 里读取日志然后应用到 slave 从节点本地。从服务器 I/线程将主服务器的二进制日志读取过来记录到从服务器本地文件，然后 SQL 线程会读取 relay-log 日志的内容并应用到从服务器，从而**「使从服务器和主服务器的数据保持一致」**。\r\n## **21.redolog 是做什么的?**\r\nredolog 是 **「InnoDB 存储引擎所特有的一种日志」**，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。\r\n可以做**「数据恢复并且提供 crash-safe 能力」**\r\n当有增删改相关的操作时，会先记录到 Innodb 中，并修改缓存页中的数据，**「等到 mysql 闲下来的时候才会真正的将 redolog 中的数据写入到磁盘当中」**。\r\n## **22.redolog 是怎么记录日志的?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps953A.tmp.png) \r\nInnoDB 的 redlog 是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共就可以记录4GB的操作。**「从头开始写，写到末尾就又回到开头循环写」**。\r\n所以，如果数据写满了但是还没有来得及将数据真正的刷入磁盘当中，那么就会发生**「内存抖动」**现象，从肉眼的角度来观察会发现 mysql 会宕机一会儿，此时就是正在刷盘了。\r\n## **23.redolog 和 binlog 的区别是什么?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps953B.tmp.png) \r\n1.**「redolog」** 是 **「Innodb」** 独有的日志，而 **「binlog」** 是 **「server」** 层的，所有的存储引擎都有使用到\r\n2.**「redolog」** 记录了**「具体的数值」**，对某个页做了什么修改，**「binlog」** 记录的**「操作内容」**\r\n3.**「binlog」** 大小达到上限或者 flush log **「会生成一个新的文件」**，而 **「redolog」** 有固定大小**「只能循环利用」**\r\n4.**「binlog 日志没有 crash-safe 的能力」**，只能用于归档。而 redlog 有 crash-safe 能力。\r\n## **24.说一说 mvcc 吧，有什么作用?**\r\nMVCC:多版本并发控制，是现代数据库(包括 MySQL、Oracle、PostgreSQL 等)引擎实现中常用的处理读写冲突的手段，目的在于**「提高数据库高并发场景下的吞吐性能」**。\r\n在 MVCC 协议下，每个读操作会看到一个一致性的快照，**「这个快照是基于整个库的」**，并且可以实现非阻塞的读，用于**「支持读提交和可重复读隔离级别的实现」**。\r\nMVCC 允许数据具有多个版本，这个版本可以是时间戳或者是全局递增的事务 ID，在同一个时间点，不同的事务看到的数据是不同的，这个修改的数据是**「记录在 undolog 中」**的。\r\n## **25.一条 Sql 语句查询一直慢会是什么原因?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps953C.tmp.png) \r\n**「1.没有用到索引」**\r\n§ 比如函数导致的索引失效，或者本身就没有加索引\r\n**「2.表数据量太大」**\r\n§ 考虑分库分表吧\r\n**「3.优化器选错了索引」**\r\n§ **「考虑使用」** force index 强制走索引\r\n## **26.一条 Sql 语句查询偶尔慢会是什么原因?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps953D.tmp.png) \r\n**「1. 数据库在刷新脏页」**\r\n§ 比如 **「redolog 写满了」**，**「内存不够用了」**释放内存如果是脏页也需要刷，mysql **「正常空闲状态刷脏页」**\r\n**「2. 没有拿到锁」**\r\n## **27.Mysql 主从之间是怎么同步数据的?**\r\n1.master 主库将此次更新的事件类型**「写入到主库的 binlog 文件」**中\r\n2.master **「创建 log dump 线程通知 slave」** 需要更新数据\r\n3.**「slave」** 向 master 节点发送请求，**「将该 binlog 文件内容存到本地的 relaylog 中」**\r\n4.**「slave 开启 sql 线程」**读取 relaylog 中的内容，**「将其中的内容在本地重新执行一遍」**，完成主从数据同步\r\n![img](《面试八股文》之 MySql 35卷.assets/wps953E.tmp.png) \r\n**「同步策略」**：\r\n1.**「全同步复制」**：主库强制同步日志到从库，等全部从库执行完才返回客户端，性能差\r\n2.**「半同步复制」**：主库收到至少一个从库确认就认为操作成功，从库写入日志成功返回ack确认\r\n## **28.主从延迟要怎么解决?**\r\n1.MySQL 5.6 版本以后，提供了一种**「并行复制」**的方式，通过将 SQL 线程转换为多个 work 线程来进行重放\r\n2.**「提高机器配置」**(王道)\r\n3.在业务初期就选择合适的分库、分表策略，**「避免单表单库过大」**带来额外的复制压力\r\n4.**「避免长事务」**\r\n5.**「避免让数据库进行各种大量运算」**\r\n6.对于一些对延迟很敏感的业务**「直接使用主库读」**\r\n## **29.删除表数据后表的大小却没有变动,这是为什么?**\r\n在使用 delete 删除数据时，其实对应的数据行并不是真正的删除，是**「逻辑删除」**，InnoDB 仅仅是将其**「标记成可复用的状态」**，所以表空间不会变小\r\n## **30.为什么 VarChar 建议不要超过255?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps953F.tmp.png) \r\n当定义varchar长度小于等于255时，长度标识位需要一个字节(utf-8编码)\r\n当大于255时，长度标识位需要两个字节，并且建立的**「索引也会失效」**\r\n## **31.分布式式事务怎么实现?**\r\n1.**「本地消息表」**\r\n2.**「消息事务」**\r\n3.**「二阶段提交」**\r\n4.**「三阶段提交」**\r\n5.**「TCC」**\r\n6.**「最大努力通知」**\r\n7.**「Seata 框架」**\r\n[**七种分布式事务的解决方案，一次讲给你听**](#wechat_redirect)\r\n## **32.Mysql 中有哪些锁?**\r\n以下并不全，主要理解下锁的意义即可\r\n基于锁的属性分类：共享锁、排他锁\r\n基于锁的粒度分类：表锁、行锁、记录锁、间隙锁、临键锁\r\n基于锁的状态分类：意向共享锁、意向排它锁、死锁\r\n## **33.为什么不要使用长事务?**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9550.tmp.png) \r\n1.并发情况下，数据库**「连接池容易被撑爆」**\r\n2.**「容易造成大量的阻塞和锁超时」**\r\n§ 长事务还占用锁资源，也可能拖垮整个库，\r\n3.执行时间长，容易造成**「主从延迟」**\r\n4.**「回滚所需要的时间比较长」**\r\n§ 事务越长整个时间段内的事务也就越多\r\n5.**「undolog 日志越来越大」**\r\n§ 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\r\n## **34.buffer pool 是做什么的?**\r\nbuffer pool 是一块内存区域，为了**「提高数据库的性能」**，当数据库操作数据的时候，把硬盘上的数据加载到 buffer pool，不直接和硬盘打交道，操作的是 buffer pool 里面的数据，数据库的增删改查都是在 buffer pool 上进行\r\nbuffer pool 里面缓存的数据内容也是一个个数据页\r\n其中**「有三大双向链表」**:\r\n**「free 链表」**\r\n§ 用于帮助我们找到空闲的缓存页\r\n**「flush 链表」**\r\n§ 用于找到脏缓存页，也就是需要刷盘的缓存页\r\n**「lru 链表」**\r\n§ 用来淘汰不常被访问的缓存页，分为热数据区和冷数据区，冷数据区主要存放那些不常被用到的数据\r\n预读机制:\r\nBuffer Pool 有一项特技叫预读，存储引擎的接口在被 Server 层调用时，会在响应的同时进行预判，将下次可能用到的数据和索引加载到 Buffer Pool\r\n## **35.说说你的 Sql 调优思路吧**\r\n![img](《面试八股文》之 MySql 35卷.assets/wps9551.tmp.png) \r\n1.**「表结构优化」**\r\n§ 1.1拆分字段\r\n§ 1.2字段类型的选择\r\n§ 1.3字段类型大小的限制\r\n§ 1.4合理的增加冗余字段\r\n§ 1.5新建字段一定要有默认值\r\n2.**「索引方面」**\r\n§ 2.1索引字段的选择\r\n§ 2.2利用好mysql支持的索引下推，覆盖索引等功能\r\n§ 2.3唯一索引和普通索引的选择\r\n3.**「查询语句方面」**\r\n§ 3.1避免索引失效\r\n§ 3.2合理的书写where条件字段顺序\r\n§ 3.3小表驱动大表\r\n§ 3.4可以使用force index()防止优化器选错索引\r\n4.**「分库分表」**\r\n"},"55aa":function(n,r,e){"use strict";e.r(r),r["default"]="数据库知识基础，这部分内容一定要理解记忆。虽然这部分内容只是理论知识，但是非常重要，这是后面学习 MySQL 数据库的基础。PS:这部分内容由于涉及太多概念性内容，所以参考了维基百科和百度百科相应的介绍。\n\n## 什么是数据库,数据库管理系统,数据库系统,数据库管理员?\n\n- **数据库** :数据库(DataBase 简称 DB)就是信息的集合或者说数据库是由数据库管理系统管理的数据的集合。\n- **数据库管理系统** : 数据库管理系统(Database Management System 简称 DBMS)是一种操纵和管理数据库的大型软件，通常用于建立、使用和维护数据库。\n- **数据库系统** : 数据库系统(Data Base System，简称 DBS)通常由软件、数据库和数据管理员(DBA)组成。\n- **数据库管理员** : 数据库管理员(Database Administrator,简称 DBA)负责全面管理和控制数据库系统。\n\n数据库系统基本构成如下图所示：\n\n![数据库系统基本构成](数据库基础知识.assets/e21120184e63406526a4e873cacd23f2.png)\n\n## 什么是元组,码,候选码,主码,外码,主属性,非主属性？\n\n- **元组** ： 元组（tuple）是关系数据库中的基本概念，关系是一张表，表中的每行（即数据库中的每条记录）就是一个元组，每列就是一个属性。 在二维表里，元组也称为行。\n- **码** ：码就是能唯一标识实体的属性，对应表中的列。\n- **候选码** ： 若关系中的某一属性或属性组的值能唯一的标识一个元组，而其任何、子集都不能再标识，则称该属性组为候选码。例如：在学生实体中，“学号”是能唯一的区分学生实体的，同时又假设“姓名”、“班级”的属性组合足以区分学生实体，那么{学号}和{姓名，班级}都是候选码。\n- **主码** : 主码也叫主键。主码是从候选码中选出来的。 一个实体集中只能有一个主码，但可以有多个候选码。\n- **外码** : 外码也叫外键。如果一个关系中的一个属性是另外一个关系中的主码则这个属性为外码。\n- **主属性** ： 候选码中出现过的属性称为主属性。比如关系 工人（工号，身份证号，姓名，性别，部门）.显然工号和身份证号都能够唯一标示这个关系，所以都是候选码。工号、身份证号这两个属性就是主属性。如果主码是一个属性组，那么属性组中的属性都是主属性。\n- **非主属性：** 不包含在任何一个候选码中的属性称为非主属性。比如在关系——学生（学号，姓名，年龄，性别，班级）中，主码是“学号”，那么其他的“姓名”、“年龄”、“性别”、“班级”就都可以称为非主属性。\n\n## 主键和外键有什么区别?\n\n- **主键(主码)** ：主键用于唯一标识一个元组，不能有重复，不允许为空。一个表只能有一个主键。\n- **外键(外码)** ：外键用来和其他表建立联系用，外键是另一表的主键，外键是可以有重复的，可以是空值。一个表可以有多个外键。\n\n## 什么是 ER 图？\n\n> 我们做一个项目的时候一定要试着画 ER 图来捋清数据库设计，这个也是面试官问你项目的时候经常会被问道的。\n\n**E-R 图**也称实体-联系图(Entity Relationship Diagram)，提供了表示实体类型、属性和联系的方法，用来描述现实世界的概念模型。 它是描述现实世界关系概念模型的有效方法。 是表示概念关系模型的一种方式。\n\n下图是一个学生选课的 ER 图，每个学生可以选若干门课程，同一门课程也可以被若干人选择，所以它们之间的关系是多对多（M:N）。另外，还有其他两种关系是：1 对 1（1:1）、1 对多（1:N）。\n\n![ER图示例](数据库基础知识.assets/4717673e36966e0e4b33fccfd753f6ea.png)\n\n我们试着将上面的 ER 图转换成数据库实际的关系模型(实际设计中，我们通常会将任课教师也作为一个实体来处理)：\n\n![关系模型](数据库基础知识.assets/5897753dfb301dfa3a814ab06e718a5e.png)\n\n## 数据库范式了解吗?\n\n**1NF(第一范式)**\n\n属性（对应于表中的字段）不能再被分割，也就是这个字段只能是一个值，不能再分为多个其他的字段了。**1NF 是所有关系型数据库的最基本要求** ，也就是说关系型数据库中创建的表一定满足第一范式。\n\n**2NF(第二范式)**\n\n2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖。如下图所示，展示了第一范式到第二范式的过渡。第二范式在第一范式的基础上增加了一个列，这个列称为主键，非主属性都依赖于主键。\n\n![第二范式](数据库基础知识.assets/bd1d31be3779342427fc9e462bf7f05c.png)\n\n一些重要的概念：\n\n- **函数依赖（functional dependency）** ：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y。\n- **部分函数依赖（partial functional dependency）** ：如果 X→Y，并且存在 X 的一个真子集 X0，使得 X0→Y，则称 Y 对 X 部分函数依赖。比如学生基本信息表 R 中（学号，身份证号，姓名）当然学号属性取值是唯一的，在 R 关系中，（学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名）；所以姓名部分函数依赖与（学号，身份证号）；\n- **完全函数依赖(Full functional dependency)** ：在一个关系中，若某个非主属性数据项依赖于全部关键字称之为完全函数依赖。比如学生基本信息表 R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在 R 关系中，（学号，班级）->（姓名），但是（学号）->(姓名)不成立，（班级）->(姓名)不成立，所以姓名完全函数依赖与（学号，班级）；\n- **传递函数依赖** ： 在关系模式 R(U)中，设 X，Y，Z 是 U 的不同的属性子集，如果 X 确定 Y、Y 确定 Z，且有 X 不包含 Y，Y 不确定 X，（X∪Y）∩Z=空集合，则称 Z 传递函数依赖(transitive functional dependency) 于 X。传递函数依赖会导致数据冗余和异常。传递函数依赖的 Y 和 Z 子集往往同属于某一个事物，因此可将其合并放到一个表中。比如在关系 R(学号 ,姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。。\n\n**3NF(第三范式)**\n\n3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。符合 3NF 要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。比如在关系 R(学号 ,姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖，所以该表的设计，不符合 3NF 的要求。\n\n**总结**\n\n- 1NF：属性不可再分。\n- 2NF：1NF 的基础之上，消除了非主属性对于码的部分函数依赖。\n- 3NF：3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。\n\n## 什么是存储过程?\n\n我们可以把存储过程看成是一些 SQL 语句的集合，中间加了点逻辑控制语句。存储过程在业务比较复杂的时候是非常实用的，比如很多时候我们完成一个操作可能需要写一大串 SQL 语句，这时候我们就可以写有一个存储过程，这样也方便了我们下一次的调用。存储过程一旦调试完成通过后就能稳定运行，另外，使用存储过程比单纯 SQL 语句执行要快，因为存储过程是预编译过的。\n\n存储过程在互联网公司应用不多，因为存储过程难以调试和扩展，而且没有移植性，还会消耗数据库资源。\n\n阿里巴巴 Java 开发手册里要求禁止使用存储过程。\n\n![阿里巴巴Java开发手册:禁止存储过程](数据库基础知识.assets/0fa082bc4d4f919065767476a41b2156.png)\n\n## drop、delete 与 truncate 区别？\n\n### 用法不同\n\n- drop(丢弃数据): `drop table 表名` ，直接将表都删除掉，在删除表的时候使用。\n- truncate (清空数据) : `truncate table 表名` ，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用。\n- delete（删除数据） : `delete from 表名 where 列名=值`，删除某一列的数据，如果不加 where 子句和`truncate table 表名`作用类似。\n\ntruncate 和不带 where 子句的 delete、以及 drop 都会删除表内的数据，但是 **truncate 和 delete 只删除数据不删除表的结构(定义)，执行 drop 语句，此表的结构也会删除，也就是执行 drop 之后对应的表不复存在。**\n\n### 属于不同的数据库语言\n\ntruncate 和 drop 属于 DDL(数据定义语言)语句，操作立即生效，原数据不放到 rollback segment 中，不能回滚，操作不触发 trigger。而 delete 语句是 DML (数据库操作语言)语句，这个操作会放到 rollback segement 中，事务提交之后才生效。\n\n**DML 语句和 DDL 语句区别：**\n\n- DML 是数据库操作语言（Data Manipulation Language）的缩写，是指对数据库中表记录的操作，主要包括表记录的插入（insert）、更新（update）、删除（delete）和查询（select），是开发人员日常使用最频繁的操作。\n- DDL （Data Definition Language）是数据定义语言的缩写，简单来说，就是对数据库内部的对象进行创建、删除、修改的操作语言。它和 DML 语言的最大区别是 DML 只是对表内部数据的操作，而不涉及到表的定义、结构的修改，更不会涉及到其他对象。DDL 语句更多的被数据库管理员（DBA）所使用，一般的开发人员很少使用。\n\n### 执行速度不同\n\n一般来说:drop>truncate>delete（这个我没有设计测试过）。\n\n## 数据库设计通常分为哪几步?\n\n1. **需求分析** : 分析用户的需求，包括数据、功能和性能需求。\n2. **概念结构设计** : 主要采用 E-R 模型进行设计，包括画 E-R 图。\n3. **逻辑结构设计** : 通过将 E-R 图转换成表，实现从 E-R 模型到关系模型的转换。\n4. **物理结构设计** : 主要是为所设计的数据库选择合适的存储结构和存取路径。\n5. **数据库实施** : 包括编程、测试和试运行\n6. **数据库的运行和维护** : 系统的运行与数据库的日常维护。\n\n## 参考\n\n- <https://blog.csdn.net/rl529014/article/details/48391465>\n- <https://www.zhihu.com/question/24696366/answer/29189700>\n- <https://blog.csdn.net/bieleyang/article/details/77149954>\n"},5604:function(n,r,e){"use strict";e.r(r),r["default"]="# 阿里巴巴Java开发手册数据库部分的一些最佳实践总结\n\n## 模糊查询\n\n对于模糊查询阿里巴巴开发手册这样说到：\n\n> 【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。\n>\n> 说明:索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。\n\n## 外键和级联\n\n对于外键和级联，阿里巴巴开发手册这样说到：\n\n>【强制】不得使用外键与级联，一切外键概念必须在应用层解决。\n>\n>说明:以学生和成绩的关系为例，学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，即为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群;级联更新是强阻塞，存在数据库更新风暴的风 险;外键影响数据库的插入速度\n\n为什么不要用外键呢？大部分人可能会这样回答：\n\n> 1. **增加了复杂性：** a.每次做DELETE 或者UPDATE都必须考虑外键约束，会导致开发的时候很痛苦,测试数据极为不方便;b.外键的主从关系是定的，假如那天需求有变化，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦。\n> 2. **增加了额外工作**： 数据库需要增加维护外键的工作，比如当我们做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，保证数据的的一致性和正确性，这样会不得不消耗资源；（个人觉得这个不是不用外键的原因，因为即使你不使用外键，你在应用层面也还是要保证的。所以，我觉得这个影响可以忽略不计。）\n> 3. 外键还会因为需要请求对其他表内部加锁而容易出现死锁情况；\n> 4. **对分库分表不友好** ：因为分库分表下外键是无法生效的。\n> 5. ......\n\n我个人觉得上面这种回答不是特别的全面，只是说了外键存在的一个常见的问题。实际上，我们知道外键也是有很多好处的，比如：\n\n1. 保证了数据库数据的一致性和完整性；\n2. 级联操作方便，减轻了程序代码量；\n3. ......\n\n所以说，不要一股脑的就抛弃了外键这个概念，既然它存在就有它存在的道理，如果系统不涉及分库分表，并发量不是很高的情况还是可以考虑使用外键的。\n\n我个人是不太喜欢外键约束，比较喜欢在应用层去进行相关操作。\n\n## 关于@Transactional注解\n\n对于`@Transactional`事务注解，阿里巴巴开发手册这样说到：\n\n>【参考】@Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。\n"},"62a6":function(n,r,e){"use strict";e.r(r),r["default"]="## MySQL 基础\n\n### 关系型数据库介绍\n\n顾名思义，关系型数据库就是一种建立在关系模型的基础上的数据库。关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。\n\n关系型数据库中，我们的数据都被存放在了各种表中（比如用户表），表中的每一行就存放着一条数据（比如一个用户的信息）。\n\n![](MySQL总结.assets/5e3c1a71724a38245aa43b02_99bf70d46cc247be878de9d3a88f0c44.png)\n\n大部分关系型数据库都使用 SQL 来操作数据库中的数据。并且，大部分关系型数据库都支持事务的四大特性(ACID)。\n\n**有哪些常见的关系型数据库呢？**\n\nMySQL、PostgreSQL、Oracle、SQL Server、SQLite（微信本地的聊天记录的存储就是用的 SQLite） ......。\n\n### MySQL 介绍\n\n![](MySQL总结.assets/20210327143351823.png)\n\n**MySQL 是一种关系型数据库，主要用于持久化存储我们的系统中的一些数据比如用户信息。**\n\n由于 MySQL 是开源免费并且比较成熟的数据库，因此，MySQL 被大量使用在各种系统中。任何人都可以在 GPL(General Public License) 的许可下下载并根据个性化的需要对其进行修改。MySQL 的默认端口号是**3306**。\n\n## 存储引擎\n\n### 存储引擎相关的命令\n\n**查看 MySQL 提供的所有存储引擎**\n\n```sql\nmysql> show engines;\n```\n\n![查看MySQL提供的所有存储引擎](MySQL总结.assets/mysql-engines.png)\n\n从上图我们可以查看出 MySQL 当前默认的存储引擎是 InnoDB，并且在 5.7 版本所有的存储引擎中只有 InnoDB 是事务性存储引擎，也就是说只有 InnoDB 支持事务。\n\n**查看 MySQL 当前默认的存储引擎**\n\n我们也可以通过下面的命令查看默认的存储引擎。\n\n```sql\nmysql> show variables like '%storage_engine%';\n```\n\n**查看表的存储引擎**\n\n```sql\nshow table status like \"table_name\" ;\n```\n\n![查看表的存储引擎](MySQL总结.assets/查看表的存储引擎.png)\n\n### MyISAM 和 InnoDB 的区别\n\n![](MySQL总结.assets/20210327145248960.png)\n\nMySQL 5.5 之前，MyISAM 引擎是 MySQL 的默认存储引擎，可谓是风光一时。\n\n虽然，MyISAM 的性能还行，各种特性也还不错（比如全文索引、压缩、空间函数等）。但是，MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。\n\n5.5 版本之后，MySQL 引入了 InnoDB（事务性数据库引擎），MySQL 5.5 版本后默认的存储引擎为 InnoDB。小伙子，一定要记好这个 InnoDB ，你每次使用 MySQL 数据库都是用的这个存储引擎吧？\n\n言归正传！咱们下面还是来简单对比一下两者：\n\n**1.是否支持行级锁**\n\nMyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。\n\n也就说，MyISAM 一锁就是锁住了整张表，这在并发写的情况下是多么滴憨憨啊！这也是为什么 InnoDB 在并发写的时候，性能更牛皮了！\n\n**2.是否支持事务**\n\nMyISAM 不提供事务支持。\n\nInnoDB 提供事务支持，具有提交(commit)和回滚(rollback)事务的能力。\n\n**3.是否支持外键**\n\nMyISAM 不支持，而 InnoDB 支持。\n\n🌈 拓展一下：\n\n一般我们也是不建议在数据库层面使用外键的，应用层面可以解决。不过，这样会对数据的一致性造成威胁。具体要不要使用外键还是要根据你的项目来决定。\n\n**4.是否支持数据库异常崩溃后的安全恢复**\n\nMyISAM 不支持，而 InnoDB 支持。\n\n使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log` 。\n\n🌈 拓展一下：\n\n- MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。\n- MySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 **`REPEATABLE-READ`** ）。\n- 保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。\n\n**5.是否支持 MVCC**\n\nMyISAM 不支持，而 InnoDB 支持。\n\n讲真，这个对比有点废话，毕竟 MyISAM 连行级锁都不支持。\n\nMVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提供性能。\n\n### 关于 MyISAM 和 InnoDB 的选择问题\n\n大多数时候我们使用的都是 InnoDB 存储引擎，在某些读密集的情况下，使用 MyISAM 也是合适的。不过，前提是你的项目不介意 MyISAM 不支持事务、崩溃恢复等缺点（可是~我们一般都会介意啊！）。\n\n《MySQL 高性能》上面有一句话这样写到:\n\n> 不要轻易相信“MyISAM 比 InnoDB 快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB 的速度都可以让 MyISAM 望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。\n\n一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择 MyISAM 也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。\n\n因此，对于咱们日常开发的业务系统来说，你几乎找不到什么理由再使用 MyISAM 作为自己的 MySQL 数据库的存储引擎。\n\n## 锁机制与 InnoDB 锁算法\n\n**MyISAM 和 InnoDB 存储引擎使用的锁：**\n\n- MyISAM 采用表级锁(table-level locking)。\n- InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁\n\n**表级锁和行级锁对比：**\n\n- **表级锁：** MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。\n- **行级锁：** MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。\n\n**InnoDB 存储引擎的锁的算法有三种：**\n\n- Record lock：记录锁，单个行记录上的锁\n- Gap lock：间隙锁，锁定一个范围，不包括记录本身\n- Next-key lock：record+gap 临键锁，锁定一个范围，包含记录本身\n\n## 查询缓存\n\n执行查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实用\n\n`my.cnf` 加入以下配置，重启 MySQL 开启查询缓存\n\n```properties\nquery_cache_type=1\nquery_cache_size=600000\n```\n\nMySQL 执行以下命令也可以开启查询缓存\n\n```properties\nset global  query_cache_type=1;\nset global  query_cache_size=600000;\n```\n\n如上，**开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果**。这里的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息。（**查询缓存不命中的情况：（1）**）因此任何两个查询在任何字符上的不同都会导致缓存不命中。此外，（**查询缓存不命中的情况：（2）**）如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL 库中的系统表，其查询结果也不会被缓存。\n\n（**查询缓存不命中的情况：（3）**）**缓存建立之后**，MySQL 的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。\n\n**缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。** 因此，开启查询缓存要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十 MB 比较合适。此外，**还可以通过 sql_cache 和 sql_no_cache 来控制某个查询语句是否需要缓存：**\n\n```sql\nselect sql_no_cache count(*) from usr;\n```\n\n## 事务\n\n### 何为事务？\n\n一言蔽之，**事务是逻辑上的一组操作，要么都执行，要么都不执行。**\n\n**可以简单举一个例子不？**\n\n事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账 1000 元，这个转账会涉及到两个关键操作就是：\n\n1. 将小明的余额减少 1000 元\n2. 将小红的余额增加 1000 元。\n\n事务会把这两个操作就可以看成逻辑上的一个整体，这个整体包含的操作要么都成功，要么都要失败。\n\n这样就不会出现小明余额减少而小红的余额却并没有增加的情况。\n\n### 何为数据库事务？\n\n数据库事务在我们日常开发中接触的最多了。如果你的项目属于单体架构的话，你接触到的往往就是数据库事务了。\n\n平时，我们在谈论事务的时候，如果没有特指**分布式事务**，往往指的就是**数据库事务**。\n\n**那数据库事务有什么作用呢？**\n\n简单来说：数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：**要么全部执行成功,要么全部不执行** 。\n\n```sql\n# 开启一个事务\nSTART TRANSACTION;\n# 多条 SQL 语句\nSQL1,SQL2...\n## 提交事务\nCOMMIT;\n```\n\n![](MySQL总结.assets/640-20201207160554677.png)\n\n另外，关系型数据库（例如：`MySQL`、`SQL Server`、`Oracle` 等）事务都有 **ACID** 特性：\n\n![事务的特性](MySQL总结.assets/事务特性.png)\n\n### 何为 ACID 特性呢？\n\n1. **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；\n2. **一致性**（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；\n3. **隔离性**（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；\n4. **持久性**（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。\n\n**数据事务的实现原理呢？**\n\n我们这里以 MySQL 的 InnoDB 引擎为例来简单说一下。\n\nMySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。\n\nMySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 **`REPEATABLE-READ`** ）。\n\n保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。\n\n### 并发事务带来哪些问题?\n\n在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。\n\n- **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。\n- **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。\n- **不可重复读（Unrepeatable read）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。\n- **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。\n\n**不可重复读和幻读区别：**\n\n不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。\n\n### 事务隔离级别有哪些?\n\nSQL 标准定义了四个隔离级别：\n\n- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。\n- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。\n- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。\n- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。\n\n---\n\n|     隔离级别     | 脏读 | 不可重复读 | 幻读 |\n| :--------------: | :--: | :--------: | :--: |\n| READ-UNCOMMITTED |  √   |     √      |  √   |\n|  READ-COMMITTED  |  ×   |     √      |  √   |\n| REPEATABLE-READ  |  ×   |     ×      |  √   |\n|   SERIALIZABLE   |  ×   |     ×      |  ×   |\n\n### MySQL 的默认隔离级别是什么?\n\nMySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。我们可以通过`SELECT @@tx_isolation;`命令来查看，MySQL 8.0 该命令改为`SELECT @@transaction_isolation;`\n\n```sql\nmysql> SELECT @@tx_isolation;\n+-----------------+\n| @@tx_isolation  |\n+-----------------+\n| REPEATABLE-READ |\n+-----------------+\n```\n\n~~这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是 Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以说 InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** 已经可以完全保证事务的隔离性要求，即达到了 SQL 标准的 **SERIALIZABLE(可串行化)** 隔离级别。~~\n\n🐛 问题更正：**MySQL InnoDB 的 REPEATABLE-READ（可重读）并不保证避免幻读，需要应用使用加锁读来保证。而这个加锁度使用到的机制就是 Next-Key Locks。**\n\n因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 **READ-COMMITTED(读取提交内容)** ，但是你要知道的是 InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）** 并不会有任何性能损失。\n\nInnoDB 存储引擎在 **分布式事务** 的情况下一般会用到 **SERIALIZABLE(可串行化)** 隔离级别。\n\n🌈 拓展一下(以下内容摘自《MySQL 技术内幕：InnoDB 存储引擎(第 2 版)》7.7 章)：\n\n> InnoDB 存储引擎提供了对 XA 事务的支持，并通过 XA 事务来支持分布式事务的实现。分布式事务指的是允许多个独立的事务资源（transactional resources）参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求在其中的所有参与的事务要么都提交，要么都回滚，这对于事务原有的 ACID 要求又有了提高。另外，在使用分布式事务时，InnoDB 存储引擎的事务隔离级别必须设置为 SERIALIZABLE。\n\n## 参考\n\n- 《高性能 MySQL》\n- https://www.omnisci.com/technical-glossary/relational-database\n"},6701:function(n,r,e){"use strict";e.r(r),r["default"]="# mysql随手记-常见知识点总结\r\n\r\n## ***\\*使用覆盖索引减少IO\\****\r\n\r\nmysql的索引类型主要分为聚集索引和非聚集索引，通过聚集索引可以获取到整行数据，而通过非聚集索引只能获得主键id和当前字段。当我们要查询的字段就是非聚集索引叶子含有的字段（***\\*primary key\\**** + ***\\*field\\****），那么就不需要回表查询更多的字段，这就是覆盖索引。\r\n\r\n\\# name是索引字段\r\n\\1. ***\\*SELECT\\**** ***\\*id\\****,***\\*name\\**** ***\\*from\\**** ***\\*user\\**** ***\\*WHERE\\**** ***\\*name\\****='假装懂编程'#不需要回表\r\n\\2. ***\\*SELECT\\**** ***\\*id\\****,***\\*name\\****,age ***\\*from\\**** ***\\*user\\**** ***\\*WHERE\\**** ***\\*name\\****='假装懂编程' #需要回表\r\n\r\n**「1」**：因为name索引包含id和name数据，所以通过name索引就能得到所需数据。\r\n**「2」**：因为name索引不包含age数据，所以仅通过name索引是得不到age数据的，此时还会去主键索引里获取数据（**「回表」**）。\r\n\r\n## ***\\*不要用select \\*\\****\r\n\r\n自己用什么字段就查询什么字段，不要使用***\\*select \\*\\****，当我们用了***\\*select \\*\\****：\r\n\r\no 肯定用不了覆盖索引。\r\n\r\no 多余的字段会造成mysql解析负担。\r\n\r\no 多余的字段会造成更多的网络开销。\r\n\r\n## ***\\*复杂的sql要explain\\****\r\n\r\n当我们写下一条复杂的sql时，如果我们通过肉眼已经无法辨别mysql会使用什么索引或者mysql会不会使用到索引，这时候通过explain来查看我们的sql执行计划是个不错的选择。\r\n\r\nmysql> ***\\*explain\\**** ***\\*select\\**** ***\\*id\\****,***\\*name\\**** ***\\*from\\**** user3 ***\\*where\\**** ***\\*name\\****=\"假装懂编程\";\r\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------------+\r\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref  | rows | filtered | Extra    |\r\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------------+\r\n| 1 | SIMPLE   | user3 | NULL    | ref | name     | name | 403   | const |  1 |  100.00 | Using index |\r\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------------+\r\n1 row in ***\\*set\\****, 1 ***\\*warning\\**** (0.00 sec)\r\n\r\nref是个比较重要的指标（以下按顺序越靠后说明效率越低）：\r\n\r\nsystem->const->eq_ref->ref->fulltext->ref_or_null->index_merge->unique_subquery->index_subquery->range->index->all。 \r\n\r\n特别当我们explain出***\\*ref=all\\****的时候要注意，这时你的sql是要进行全表扫描的。\r\n\r\n## ***\\*varchar和char的区别\\****\r\n\r\n### ***\\*char\\****\r\n\r\n固定长度（字符数），如果长度小于定义的长度会用空格补充，会浪费空间。但是因为长度固定所以char的存取速度要比varchar快，char最多能存放255个字符，和编码无关。\r\n\r\n### ***\\*varchar\\****\r\n\r\n变长（字符数），如果长度小于定义的长度会按照实际的长度来存储，相比char会节约空间，但是因为是变长的，所以存取速度相比char要慢。在存储方面，若列的长度小于等于255字节，那么额外要1个字节记录长度，如果列的长度大于255字节，那么额外要2个字节记录长度。\r\n\r\n## ***\\*分页时小心limit陷阱\\****\r\n\r\n### ***\\*未用到索引的limit\\****\r\n\r\n我们在分页的业务中经常用到limit，比如后台查看用户的留言，由于留言太多，我们不得不分页。假设我们每页展示100条数据，那么每页的查询可能这样。\r\n\r\n***\\*select\\**** * ***\\*from\\**** message ***\\*limit\\**** 0,100 # 第一页\r\n***\\*select\\**** * ***\\*from\\**** message ***\\*limit\\**** 100,100 #第二页\r\n...\r\n***\\*select\\**** * ***\\*from\\**** message ***\\*limit\\**** 1000000,100 #第10000页\r\n\r\n当我们查到第10000页时，此时要过滤1000000的数据，然后再取100条数据，这个耗时肯定是巨大的。这个问题的本质还是没用到索引，那么我们让分页用到索引就好了，我们可以这样解决：\r\n因为主键id是自增且连续的，这样我们每次通过id来定位到我们的第一条数据，然后向后取100条。这个id就是你上一次获取的分页数据中，最大的那个id。\r\n\r\n***\\*select\\**** * ***\\*from\\**** message ***\\*where\\**** ***\\*id\\****>=[***\\*id\\****] ***\\*limit\\**** 100\r\n\r\n此场景适用主键是自增连续的，且不能有where条件的，有where条件的话会过滤数据。\r\n\r\n### ***\\*需要回表的limit\\****\r\n\r\n现在有这样一张表，除了主键索引外还有个***\\*user_id\\****的普通索引\r\n\r\n***\\*CREATE\\**** ***\\*TABLE\\**** `message` (\r\n `id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** AUTO_INCREMENT,\r\n `user_id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** ***\\*DEFAULT\\**** '0',\r\n `name` varchar(255) ***\\*NOT\\**** ***\\*NULL\\**** ***\\*DEFAULT\\**** '',\r\n PRIMARY ***\\*KEY\\**** (`id`),\r\n ***\\*KEY\\**** `user_id` (`user_id`)\r\n) ***\\*ENGINE\\****=***\\*InnoDB\\****;\r\n\r\n表的数据量有将近150w：\r\n\r\nmysql> ***\\*select\\**** ***\\*count\\****(*) ***\\*from\\**** message;\r\n+----------+\r\n| count(*) |\r\n+----------+\r\n| 1496067 |\r\n+----------+\r\n\r\n这时候我要统计***\\*user_id=99999\\****的用户数据，并且在所有的数据中只取第70w开始的后面5条，于是我这样执行了：\r\n\r\nmysql> ***\\*select\\**** * ***\\*from\\**** message ***\\*where\\**** user_id=99999 ***\\*limit\\**** 700000,5;\r\n+---------+---------+---------+\r\n| id   | user_id | name  |\r\n+---------+---------+---------+\r\n| 1282606 |  99999 | t154458 |\r\n| 1282607 |  99999 | t154459 |\r\n| 1282608 |  99999 | t154460 |\r\n| 1282609 |  99999 | t154461 |\r\n| 1282610 |  99999 | t154462 |\r\n+---------+---------+---------+\r\n5 rows in ***\\*set\\**** (1.17 sec)\r\n\r\n发现竟然需要**「1.17s」**的时间，user_id不是有索引吗，而且我只获取5条数据，我通过explain也看到用了***\\*user_id\\****索引。\r\n\r\nmysql> ***\\*explain\\**** ***\\*select\\**** * ***\\*from\\**** message ***\\*where\\**** user_id=99999 ***\\*limit\\**** 700000,5;\r\n+----+-------------+---------+------------+------+---------------+---------+---------+-------+--------+----------+-------+\r\n| id | select_type | table  | partitions | type | possible_keys | key   | key_len | ref  | rows  | filtered | Extra |\r\n+----+-------------+---------+------------+------+---------------+---------+---------+-------+--------+----------+-------+\r\n| 1 | SIMPLE   | message | NULL    | ref | user_id    | user_id | 4    | const | 745650 |  100.00 | NULL |\r\n+----+-------------+---------+------------+------+---------------+---------+---------+-------+--------+----------+-------+\r\n\r\n经过分析发现了一些端倪，于是我又这样执行了一下：\r\n\r\nmysql> ***\\*select\\**** a.* ***\\*from\\**** message a ***\\*join\\**** (***\\*select\\**** ***\\*id\\**** ***\\*from\\**** message ***\\*where\\**** user_id=99999 ***\\*limit\\**** 700000,5) b ***\\*on\\**** a.id=b.id;\r\n+---------+---------+---------+\r\n| id   | user_id | name  |\r\n+---------+---------+---------+\r\n| 1282606 |  99999 | t154458 |\r\n| 1282607 |  99999 | t154459 |\r\n| 1282608 |  99999 | t154460 |\r\n| 1282609 |  99999 | t154461 |\r\n| 1282610 |  99999 | t154462 |\r\n+---------+---------+---------+\r\n5 rows in ***\\*set\\**** (0.14 sec)\r\n\r\n发现只需要**「0.14s」**，比第一种节约了将近**「1s」**的时间。\r\n\r\n#### ***\\*结论：\\****\r\n\r\n首先因为你查询的是*，这意味着你要获取所有字段，那么就算你用的是user_id索引，最终也要回表去查。所以对一条数据来说，总的消耗就是**「user_id索引的查询时间+主键id索引的查询时间」**，其次因为你用了***\\*limit 70000,5\\****，因为user_id=99999的数据非常多，通过limit的话，就要过滤70w的数据，所以(**「user_id索引的查询时间+主键id索引的查询时间」**)乘以**「70w」**这整个消耗就是浪费的。对于第二条sql来说，它先是用子查询来获取主键id：\r\n\r\n***\\*select\\**** ***\\*id\\**** ***\\*from\\**** message ***\\*where\\**** user_id=99999 ***\\*limit\\**** 700000,5\r\n\r\n我们知道普通索引除了含有自身的key之外还包含主键id，那么对于这条sql就不用回表，它的总体浪费的消耗就是**「user_id索引的查询时间」**乘以**「70w」**，最终通过子查询获取到的5个id，只需要消耗**「5」**乘以**「主键id索引的查询时间」**就可以得到所需数据。整体看下来，第二条sql比第一条sql节约了**「主键id索引的查询时间」**乘以**「70w」**的消耗，所以第一条要慢很多。\r\n\r\n## ***\\*联合索引\\****\r\n\r\n多个字段在一起建立个索引叫联合索引，一般联合索引的目的就是通过多个字段可以确定一条数据。比如一个姓名不能定位到一个人，因为重名的有很多，但是**「姓名」**+**「家庭地址」**就可以定位一个人。这时姓名和家庭地址可以在一起建立一个唯一索引。注意unique key(姓名，家庭地址) 和unique key(家庭地址，姓名)是不一样的。常见的问题就是假设现在有（a,b,c）联合索引，以下查询是否能用到索引：\r\n\r\no **「问题1」**：\r\n\r\n***\\*select\\**** * ***\\*from\\**** xx ***\\*where\\**** a=1 ***\\*and\\**** b=2 ***\\*and\\**** c=3\r\n\r\n这是最典型的联合索引的最左原则，这个是能用到索引的。\r\n\r\no **「问题2」**：\r\n\r\n***\\*select\\**** * ***\\*from\\**** xx ***\\*where\\**** ***\\*and\\**** b=2 ***\\*and\\**** c=3\r\n\r\n这个不符合最左原则，所以用不到索引。\r\n\r\no **「问题3」**：\r\n\r\n***\\*select\\**** * ***\\*from\\**** xx ***\\*where\\**** ***\\*and\\**** b=2 ***\\*and\\**** a=1\r\n\r\n这个是可以用到索引的，联合索引和查询字段的顺序没关系，和建立索引的字段的顺序有关系。\r\n\r\no **「问题4」**：\r\n\r\n***\\*select\\**** * ***\\*from\\**** xx ***\\*where\\**** ***\\*and\\**** a=1 ***\\*and\\**** c=3\r\n\r\n这个a是可以用到索引的，c用不到索引。\r\n\r\n## ***\\*数字隐式转换问题\\****\r\n\r\n假设现在有这样一张表：\r\n\r\n***\\*CREATE\\**** ***\\*TABLE\\**** `user` (\r\n `id` int(1) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** AUTO_INCREMENT,\r\n `user_id` varchar(255) ***\\*DEFAULT\\**** ***\\*NULL\\****,\r\n PRIMARY ***\\*KEY\\**** (`id`),\r\n ***\\*KEY\\**** `user_id` (`user_id`)\r\n) ***\\*ENGINE\\****=***\\*InnoDB\\****;\r\n\r\n其中***\\*user_id\\****这个字段是个***\\*字符串\\****类型且还有***\\*索引\\****。这时候要查下user_id是100000的那条数据信息。于是我们写出了以下的sql：\r\n\r\n***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** user_id=100000;\r\n\r\n如果不出意外的话，在你的表已经非常大的情况下，你的sql会很慢。\r\n\r\n***\\*explain\\**** ***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** user_id=100000;\r\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+--------+----------+--------------------------+\r\n| id | select_type | table | partitions | type | possible_keys | key   | key_len | ref | rows  | filtered | Extra          |\r\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+--------+----------+--------------------------+\r\n| 1 | SIMPLE   | user3 | NULL    | index | user_id    | user_id | 1023  | NULL | 315384 |  10.00 | Using where; Using index |\r\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+--------+----------+--------------------------+\r\n\r\n**「重点」**：发现***\\*rows\\****展示的数据竟然是要全表扫描。明明user_id是有索引的，为什么还会全表扫？造成这个问题的原因是user_id是字符串，而你给的值是整型（user_id没加单引号），在mysql中，字符串和数字做比较的话，是将字符串转换成数字再进行比较的，也就是我们的sql相当于：\r\n\r\n***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** ***\\*CAST\\****(user_id ***\\*AS\\**** signed int)=100000; \r\n\r\n**「当mysql的索引字段做了函数操作时，优化器会放弃走索引。因为通过函数的话，索引值的有序性大概率会被破坏，这时候没必须要走索引了」**。知道原因后，我们把user_id加上单引号再试试：\r\n\r\n***\\*explain\\**** ***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*where\\**** user_id='100000';\r\n+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+\r\n| id | select_type | table | partitions | type | possible_keys | key   | key_len | ref  | rows | filtered | Extra    |\r\n+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+\r\n| 1 | SIMPLE   | user3 | NULL    | ref | user_id    | user_id | 1023  | const |  1 |  100.00 | Using index |\r\n+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+\r\n\r\n这时候会发现***\\*rows\\****的值是1。\r\n\r\n## ***\\*cpu暴涨如何排查\\****\r\n\r\no 通过**「top」**命令确认cpu占用情况。\r\n\r\no 通过**「show processlist」**来查看mysql线程运行情况。\r\n\r\no 通过**「show OPEN TABLES where In_use > 0」**来查看表锁情况。\r\n\r\no 通过mysql的**「error log」**来查看是否有错误。\r\n\r\no 通过**「show engine innodb status\\G」**;来查看是否有死锁。\r\n\r\no 通过**「慢查询日志」**检查是否有慢查询。\r\n\r\no 通过**「iostat」**来查看磁盘io情况。\r\n\r\n## ***\\*datetime和timestamp区别\\****\r\n\r\no **「空间」**：\r\n\r\n§ datetime占用8个字节。\r\n\r\n§ timestamp占用4个字节。\r\n\r\no **「表示范围」**：\r\n\r\n§ datetime：**「1000-01-01 00:00:00.000000」** ~ **「9999-12-31 23:59:59.999999」**\r\n\r\n§ timestamp：**「1970-01-01 00:00:01.000000」** ~ **「2038-01-19 03:14:07.999999」**\r\n\r\n#### ***\\*总结：\\****\r\n\r\ndatetime占用更大的空间，但是可以表示更久远的时间，timestamp占用更小的空间，最大只能支持到2038年。\r\n\r\n## ***\\*通过limit 1来优化查询\\****\r\n\r\n当我们要统计一下学校里是否有来自上海的学生，于是我们这样查询：\r\n\r\n***\\*select\\**** * ***\\*from\\**** student ***\\*where\\**** ***\\*from\\****=\"shanghai\";\r\n\r\n这条sql会检索出所有来自上海的学生数据，而我们只需要知道有没有来自上海的学生，所以可以通过limit 1优化：\r\n\r\n***\\*select\\**** * ***\\*from\\**** student ***\\*where\\**** ***\\*from\\****=\"shanghai\" ***\\*limit\\**** 1;\r\n\r\n这样的话，在检索出一条数据后就立马停止检索，大大降低开销。**「需要注意的是，如果from是唯一索引的话，加不加limit 1是一样的。」**\r\n\r\n## ***\\*分表后的ID怎么保证唯一性？\\****\r\n\r\n因为我们主键一般都是自增的，分表后不同表的主键肯定存在相同的，就冲突了，如何解决？\r\n\r\no 设定步长，比如10张表我们分别设定1-10的基础步长，这样不同的表就不会存在相同的主键id了。\r\n\r\n***\\*SET\\**** auto_increment_offset=1; # 从1开始\r\n***\\*SET\\**** auto_increment_increment=10; # 每次以10增长\r\n1 11 21 ... # 第一张表\r\n2 12 22 ... # 第二张表\r\n...\r\n10 20 30 ... # 第十张表\r\n\r\n这种方式适合M-M架构。\r\n\r\no 分布式ID，现在有很多开源的分布式ID算法，如雪花算法。\r\n\r\no 分表后不依赖主键ID去查询某些数据，而是根据自己生成的唯一条件去查询，比如订单号。\r\n\r\n## ***\\*为什么要用NOT NULL\\****\r\n\r\n对于一个字段来说，你可以指定默认值***\\*NULL\\****，也可以指定默认值为***\\*NOT NULL\\****，而我的建议是最好设置***\\*NOT NULL\\****，理由主要是以下：\r\n\r\no NULL值在mysql中是占用空间的，而空值是不占用空间的。\r\n\r\nNULL columns require additional space in the row to record whether their values are NULL.\r\n\r\nmysql> ***\\*select\\**** ***\\*length\\****(***\\*NULL\\****), ***\\*length\\****(''), ***\\*length\\****('1');\r\n+--------------+------------+-------------+\r\n| length(NULL) | length('') | length('1') |\r\n+--------------+------------+-------------+\r\n|     NULL |     0 |      1 |\r\n+--------------+------------+-------------+\r\n\r\no 对于字段允许null时要注意判断条件：\r\n\r\n\\1. null值过滤应该是：\r\n\r\n***\\*select\\**** * ***\\*from\\**** xx ***\\*where\\**** ***\\*name\\**** ***\\*is\\**** ***\\*not\\**** ***\\*null\\****\r\n\r\n  \\2. 空值的过滤：\r\n\r\n***\\*select\\**** * ***\\*from\\**** xx ***\\*where\\**** ***\\*name\\****!=\"\"\r\n\r\no count是不会统计null值的列的：\r\n\r\nmysql> ***\\*select\\**** * ***\\*from\\**** ***\\*user\\****;\r\n+----+------+\r\n| id | name |\r\n+----+------+\r\n| 2 | NULL |\r\n| 1 | tom |\r\n+----+------+\r\n2 rows in ***\\*set\\**** (0.00 sec)\r\n\r\nmysql> ***\\*select\\**** ***\\*count\\****(***\\*name\\****) ***\\*from\\**** ***\\*user\\****;\r\n+-------------+\r\n| count(name) |\r\n+-------------+\r\n|      1 |\r\n+-------------+\r\n1 row in ***\\*set\\**** (0.00 sec)\r\n\r\no 排序的时候（从小到大）null值会排在最前面：\r\n\r\nmysql> ***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*order\\**** ***\\*by\\**** ***\\*sort\\**** ***\\*asc\\****;\r\n+----+------+\r\n| id | sort |\r\n+----+------+\r\n| 3 | NULL |\r\n| 4 | NULL |\r\n| 1 |  1 |\r\n| 2 |  2 |\r\n+----+------+\r\n\r\nmysql认为null小于任何值。\r\n\r\n## ***\\*唯一索引字段能为NULL吗\\****\r\n\r\n是可以的。虽然唯一索引限制了每个值的唯一性，但是对null的话就束手无策，null在mysql中是一个特殊的存在，一般还是推荐NOT NULL。\r\n\r\n***\\*CREATE\\**** ***\\*TABLE\\**** `user` (\r\n `id` int(1) ***\\*NOT\\**** ***\\*NULL\\**** AUTO_INCREMENT,\r\n `user_id` varchar(255) ***\\*DEFAULT\\**** ***\\*NULL\\****,\r\n PRIMARY ***\\*KEY\\**** (`id`),\r\n ***\\*UNIQUE\\**** ***\\*KEY\\**** `user_id` (`user_id`)\r\n) ***\\*ENGINE\\****=***\\*InnoDB\\**** AUTO_INCREMENT=1;\r\n\r\n***\\*insert\\**** ***\\*into\\**** ***\\*user\\**** (user_id) ***\\*values\\**** (1),(***\\*null\\****),(***\\*null\\****);\r\nmysql> ***\\*select\\**** * ***\\*from\\**** ***\\*user\\**** ***\\*order\\**** ***\\*by\\**** user_id;\r\n+----+---------+\r\n| id | user_id |\r\n+----+---------+\r\n| 2 | NULL  |\r\n| 3 | NULL  |\r\n| 1 | 1    |\r\n+----+---------+\r\n\r\n可以发现两个null值是插入成功了。\r\n\r\n## ***\\*线上1亿数据的表加字段怎么处理\\****\r\n\r\no 尽量选择低峰期处理\r\n\r\no mysql5.7支持在线DDL，主要的算法有：\r\n\r\n§ **「ALGORITHM=INPLACE」**：需要rebuild表（注意：添加列需要rebuild，重命名列、添加索引不需要rebuild），期间仍可以DML，且保持良好的并发性能。\r\n\r\n§ **「ALGORITHM=COPY」**：需要rebuild表，不允许并发DML写操作，可读。\r\n\r\n**「rebuild」**:涉及表的重建，前提得保证有足够的磁盘空间。rebuild会在原表路径下创建新的.frm和.ibd文件，IO的消耗会较多。并且rebuild期间会申请row log空间记录DDL执行期间的DML操作，这部分操作会在DDL完成后同步到新的表空间中。\r\n**「no-rebuild」**:不涉及表的重建，除添加索引，会产生部分二级索引的写入操作外，其余操作均只修改元数据项，即只在原表路径下产生.frm文件，不会申请row log，不会消耗过多的IO，通常来说速度很快。\r\n**「复制延迟」**:在主从架构下，主一边执行DDL，一边执行DML，如果slave是单个sql线程按顺序从relay log中取命令执行，这个期间的DML，在slave上必须等待slave的DDL也执行完毕之后，才能同步。所以在IO压力比较的时候，可能会造成复制延迟。\r\n\r\no 生产环境推荐使用pt-osc/gh-ost等第三方工具进行在线加列。\r\n\r\no mysql8.0可以通过instant方式完成快速加列，只需要修改metadata信息，代价小，秒级完成。但是得满足**「不是压缩表」**、**「不是data dictionary tablespace」**、**「不是全文索引」**、**「不是临时表」**、**「新增列在最后位置」**。\r\n\r\n## ***\\*count(1)、count(\\*)、count(column)的区别\\****\r\n\r\n业务中经常要统计某些信息，这离不开mysql的count函数，count(x)中的x可以是多种多样的，其实他们在某些情况下是没区别的，某些情况下又是有区别的。\r\n\r\no myisam引擎的count(*)最快，因为它不需要实时统计，它是保存起来的，但是前提是不能加where条件。\r\n\r\no count(1)和count(*)其实没什么区别,count(*)中的***\\**\\****也并不是所想象的那样统计所有的数据，看个例子：\r\n\r\n***\\*CREATE\\**** ***\\*TABLE\\**** `user_info` (\r\n `id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** AUTO_INCREMENT,\r\n `user_id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** ***\\*DEFAULT\\**** '0',\r\n  PRIMARY ***\\*KEY\\**** (`id`)\r\n) ***\\*ENGINE\\****=***\\*InnoDB\\****;\r\n\r\n创建一个只有主键索引的表。\r\n\r\n\\#count(*)\r\nmysql> ***\\*explain\\**** ***\\*select\\**** ***\\*count\\****(*) ***\\*from\\**** user_info;\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| id | select_type | table   | partitions | type | possible_keys | key   | key_len | ref | rows | filtered | Extra    |\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| 1 | SIMPLE   | user_info | NULL    | index | NULL     | PRIMARY | 4    | NULL |  1 |  100.00 | Using index |\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n\\#count(1)\r\nmysql> ***\\*explain\\**** ***\\*select\\**** ***\\*count\\****(1) ***\\*from\\**** user_info1;\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| id | select_type | table   | partitions | type | possible_keys | key   | key_len | ref | rows | filtered | Extra    |\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| 1 | SIMPLE   | user_info | NULL    | index | NULL     | PRIMARY | 4    | NULL |  1 |  100.00 | Using index |\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n\r\n通过explain发现两者都是用的主键索引，没有任何区别。所以count(1)和coun(*)都是通过主键索引来统计的？\r\n\r\no count(*)和count(1)的覆盖索引优化：\r\n\r\n***\\*CREATE\\**** ***\\*TABLE\\**** `user_info` (\r\n `id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** AUTO_INCREMENT,\r\n `user_id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** ***\\*DEFAULT\\**** '0',\r\n PRIMARY ***\\*KEY\\**** (`id`),\r\n ***\\*KEY\\**** (`user_id`)\r\n) ***\\*ENGINE\\****=***\\*InnoDB\\****;\r\n\r\n我们加了个user_id索引：\r\n\r\n\\#count(*)\r\n***\\*explain\\**** ***\\*select\\**** ***\\*count\\****(*) ***\\*from\\**** user_info;\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| id | select_type | table   | partitions | type | possible_keys | key   | key_len | ref | rows | filtered | Extra    |\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| 1 | SIMPLE   | user_info | NULL    | index | NULL     | user_id | 4    | NULL |  1 |  100.00 | Using index |\r\n\r\n\\#count(1)\r\n***\\*explain\\**** ***\\*select\\**** ***\\*count\\****(1) ***\\*from\\**** user_info;\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| id | select_type | table   | partitions | type | possible_keys | key   | key_len | ref | rows | filtered | Extra    |\r\n+----+-------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\r\n| 1 | SIMPLE   | user_info | NULL    | index | NULL     | user_id | 4    | NULL |  1 |  100.00 | Using index |\r\n\r\n发现竟然用了user_id索引，用了覆盖索引。这其实是因为主键索引是聚集索引（除了KEY之外还有如事务ID、回滚指针等其他信息），单个索引页能存的数量行数肯定是小于user_id这种普通索引，所以同样大小的索引页，user_id可以存下更多的行数，总体来说检索的更快。\r\n\r\no count(column)：如果列的值允许为NULL，那么是不会统计NULL值的，上面介绍过。\r\n\r\nmysql> ***\\*select\\**** * ***\\*from\\**** ***\\*user\\****;\r\n+----+------+---------------------+\r\n| id | name | ctime        |\r\n+----+------+---------------------+\r\n| 1 | tom | 2021-08-27 08:45:50 |\r\n| 2 | NULL | 2021-08-27 08:45:50 |\r\n| 3 | NULL | 2021-08-27 08:46:18 |\r\n+----+------+---------------------+\r\n3 rows in ***\\*set\\**** (0.00 sec)\r\n\r\nmysql> ***\\*select\\**** ***\\*count\\****(***\\*name\\****) ***\\*from\\**** ***\\*user\\****;\r\n+-------------+\r\n| count(name) |\r\n+-------------+\r\n|      1 |\r\n+-------------+\r\n1 row in ***\\*set\\**** (0.00 sec)\r\n\r\no count(1)、count(2)...count(10086)没什么区别。\r\n\r\n## ***\\*左连接、右连接、内连接区别\\****\r\n\r\no 左连接：以左边为主，右边的没数据的补null。\r\n\r\no 右连接：以右边为主，左边没数据的补null。\r\n\r\no 内连接：两张表的交集。\r\n\r\n**「注意」**：使用小表驱动大表。\r\n\r\n## ***\\*小心 or 不使用索引\\****\r\n\r\n***\\*CREATE\\**** ***\\*TABLE\\**** `user_info` (\r\n `id` int(11) ***\\*unsigned\\**** ***\\*NOT\\**** ***\\*NULL\\**** AUTO_INCREMENT,\r\n `user_id` int(11),\r\n `name` varchar(10),\r\n PRIMARY ***\\*KEY\\**** (`id`)\r\n) ***\\*ENGINE\\****=***\\*InnoDB\\**** ***\\*DEFAULT\\**** ***\\*CHARSET\\****=utf8mb4 ***\\*COLLATE\\****=utf8mb4_unicode_ci;\r\n\r\n假设user_info表只有一个主键索引，这时我们要查***\\*id=1\\**** 或者 ***\\*user_id=2\\****的数据：\r\n\r\nmysql> ***\\*explain\\**** ***\\*select\\**** * ***\\*from\\**** user_info ***\\*where\\**** ***\\*id\\****=1 ***\\*or\\**** user_id=2;\r\n+----+-------------+------------+------------+------+---------------+------+---------+------+------+----------+-------------+\r\n| id | select_type | table   | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra    |\r\n+----+-------------+------------+------------+------+---------------+------+---------+------+------+----------+-------------+\r\n| 1 | SIMPLE   | user_info5 | NULL    | ALL | PRIMARY    | NULL | NULL  | NULL |  3 |  66.67 | Using where |\r\n+----+-------------+------------+------------+------+---------------+------+---------+------+------+----------+-------------+\r\n\r\ntype竟然是***\\*all\\****（全表扫描），解决方式就是给user_id也加个索引：\r\n\r\n***\\*alter\\**** ***\\*table\\**** user_info ***\\*add\\**** ***\\*index\\**** user_id(`user_id`)\r\nmysql> ***\\*explain\\**** ***\\*select\\**** * ***\\*from\\**** user_info ***\\*where\\**** ***\\*id\\****=1 ***\\*or\\**** user_id=2;\r\n+----+-------------+------------+------------+-------------+-----------------+-----------------+---------+------+------+----------+-------------------------------------------+\r\n| id | select_type | table   | partitions | type    | possible_keys  | key       | key_len | ref | rows | filtered | Extra                   |\r\n+----+-------------+------------+------------+-------------+-----------------+-----------------+---------+------+------+----------+-------------------------------------------+\r\n| 1 | SIMPLE   | user_info6 | NULL    | index_merge | PRIMARY,user_id | PRIMARY,user_id | 4,5   | NULL |  2 |  100.00 | Using union(PRIMARY,user_id); Using where |\r\n+----+-------------+------------+------------+-------------+-----------------+-----------------+---------+------+------+----------+-------------------------------------------+\r\n\r\n## ***\\*为什么像性别这种字段不适合加索引\\****\r\n\r\n一般一个字段需不需要建立索引除了看是不是经常在where中使用，还要看它的重复度，重复度越高的字段不适合建立索引，比如性别（只有男女）。我们知道索引分为聚集索引和非聚集索引，一整条行记录是和聚集索引绑定的，非聚集索引除了自身的值外还保存个主键id，这样当我们通过非聚集索引需要获取额外的信息的时候，那就得通过主键id去聚集索引再查一遍，俗称回表。\r\n\r\n![img](mysql随手记-常见知识点总结.assets/wpsCF48.tmp.png)假设现在表里有100w的数据，男女各一半，现在要获取所有男的姓名，如果走了sex索引，那么首先通过sex就要过滤50w的数据，然后这50w的数据还得回到主键索引里面去找，那么整个IO次数大概等于 **「（sex树的高度+id树的高度）\\* 50w」**，关键是这还不一定有全表扫的效率高，所以不推荐sex字段加索引。\r\n\r\n#### ***\\*总结：\\****\r\n\r\no 重复度大的字段就算加了索引，效率也不一定高。\r\n\r\no 索引还占空间，每次数据变更的时候还得维护索引。\r\n\r\n## ***\\*复制那些事\\****\r\n\r\n### ***\\*传统的复制（file+pos）\\****\r\n\r\n\\1. master开启二进制日志记录所有的变更。\r\n\r\n\\2. slave开启一个IO线程，通过mysql协议，对master发起请求。\r\n\r\n\\3. master开启一个线程（dump binlog，有几个slave就有几个dump binlog线程），检查自己的binlog，通过slave请求传的位置把对应的位置后的变更发给slave，如果没有带位置，那么就从头开始一个一个发给slave。\r\n\r\n\\4. slave把收到master传过来的变更记录到自己的中继日志relay log中，并记录对应的binlog的位置。\r\n\r\n\\5. slave启动另一个线程从relay log中重放变更。\r\n\r\n### ***\\*基于GTID的复制\\****\r\n\r\n传统的复制缺点：基于file（binlog）+pos（复制偏移量）来进行复制的的模式主要存在主发生故障切换一个从为主的时候，别的从无法通过file+pos来复制新的主。于是GTID模式的复制出现了：\r\n\r\n#### ***\\*概念：\\****\r\n\r\nGTID (Global Transaction ID) 是对于一个已提交事务的编号，MySQL5.6开始支持，它是一个全局唯一的编号。GTID 实际上是由UUID+TID 组成的。其中 UUID是MySQL实例的唯一标识。TID代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。 下面是一个GTID的具体形式：***\\*3E11FA47-71CA-11E1-9E33-C80AA9429562:23\\****，冒号分割前边为uuid，后边为TID。\r\n\r\n##### ***\\*工作原理：\\****\r\n\r\n\\1. 当一个事务在master执行并提交时，产生GTID，并记录到binlog中。\r\n\r\n\\2. slave收到变更后，读取到GTID后，把它设置到gtid_next变量，即下一个要执行的GTID值。\r\n\r\n\\3. sql线程从relay log中获取GTID，然后对比slave端的binlog是否有该GTID，如果有记录，说明该GTID的事务已经执行，slave会忽略。如果没有记录，slave就会执行该GTID事务，并记录该GTID到自身的binlog。\r\n\r\n### ***\\*复制方式\\****\r\n\r\n复制是基于binlog来完成的，binlog的完整性直接关系到数据的完整性。如果你的binlog没有写入到文件系统，且此时数据库正好挂了，那么这块数据是丢失的。如果你每次事务提交的时候立马把binglog刷入到文件系统，IO的压力又很大。于是mysql给出个选项，让binlog的同步策略交给我们自己，根据业务场景决定选择什么样的同步方式。\r\n\r\nmysql> ***\\*show\\**** ***\\*variables\\**** ***\\*like\\**** 'sync_binlog';\r\n+---------------+-------+\r\n| Variable_name | Value |\r\n+---------------+-------+\r\n| sync_binlog  | 1   |\r\n+---------------+-------+\r\n\r\no **「sync_binlog=0」**：表示MySQL不控制binlog的刷新，由文件系统自己根据情况刷入。这时候的性能是最好的，但是风险也是最大的。因为一旦发生故障，在binlog_cache中的所有binlog信息都会被丢失。\r\n\r\no **「sync_binlog=1」**：表示每次事务提交，MySQL都会把binlog刷入文件系统，是最安全但是性能损耗最大的设置，做多丢失一个事务的数据。\r\n\r\no **「sync_binlog=N」**：如果N不等于0或者1，刷新方式同sync_binlog=1类似，只不过此时会延长刷新频率至N次后。\r\n\r\n#### ***\\*异步复制：\\****\r\n\r\nmysql默认的复制模式就是异步方式，即master同步binlog给slave后，不会关心slave是不是收到。\r\n\r\n#### ***\\*全同步复制：\\****\r\n\r\n由于普通异步模式会导致出现slave丢失数据而master不知道的情况，进而引发主从不一致。为了解决这个问题，master得知道slave同步数据的情况，全同步复制就是master收到所有slave的ack，才执行接下来的同步。\r\n\r\n#### ***\\*半同步复制：\\****\r\n\r\n全同步复制的缺点就是慢，万一某台slave的实例因为网络问题延迟回复了ack，那么所有的slave都要等他。为了解决这个问题，于是可以做个折中，只要master至少收到一个slave的ack，那么就认为是成功的。\r\n\r\n#### ***\\*多线程复制：\\****\r\n\r\nslave上的relay log回放处理，之前是在一个线程上处理的，然而master是可以并发的，并发情况下，slave还通过一个IO线程来回放是不是显得力不从心？\r\n\r\no 在MYSQL5.6版本中，多线程复制是数据库级别的，将多个数据库下的事务按照数据库拆分到多个线程上执行，保证数据库级别的事务一致性。但是实际应用不多，大多数还是一库多表的场景。\r\n\r\no 在MYSQL5.7版本后，出现了基于逻辑时钟的方式，可以在一个数据库上并发执行relay log的回放（比如update x表和update y表，它们俩没什么事务冲突的情况下就可以并发执行）。\r\n\r\n## ***\\*聚集索引与非聚集索引的区别\\****\r\n\r\no 聚集索引一张表只能有一个，它的叶子节点存储整行数据（叶子节点即为数据页），在很多情况下，优化器倾向于使用聚集索引，因为它的叶子节点存储整行数据，并且是逻辑有序，这对一些排序、范围查找很友好。\r\n\r\no 非聚集索引也叫辅助索引，一张表可以有多个非聚集索引。辅助索引的叶子节点包含了列的值和主键的值。一般一页的大小为16k，相比聚集索引，同样一页非聚集索引的叶子节点可以存储更多的行。\r\n\r\n## ***\\*为什么使用b+树而不使用b树\\****\r\n\r\no 因为B树不管是叶子节点还是非叶子节点，都会保存数据，那么对于非叶子节点来说，能保存的数量就更少，这样对于同样的数据量，B树高度可能更高，增大磁盘的IO次数，进而影响查询效率，但是b树的优点是关键字的查询也不用每次深入到叶子节点。\r\n\r\no 因为B+树的所有数据都存储在叶子节点上，所以每次关键字的查询都要深入到叶子节点上，每一个数据的查询效率差不多，查询更稳定。B+树叶子节点是双向链表，所以排序、范围查找更优秀。\r\n\r\n \r\n\r\n "},"6b79":function(n,r,e){var s={"./3种常用的缓存读写策略.md":"de66","./Redis 基础.md":"78e1","./Redis基础.md":"1377","./Redis持久化.md":"28a6","./Redis经典面试题.md":"7399","./Redis高级.md":"ef82","./Redlock分布式锁.md":"0087","./redis-all.md":"c4a8","./redis集群以及应用场景.md":"a03c","./《面试八股文》之 Redis 16卷.md":"2787","./如何做可靠的分布式锁，Redlock真的可行么.md":"0f6a"};function t(n){var r=i(n);return e(r)}function i(n){if(!e.o(s,n)){var r=new Error("Cannot find module '"+n+"'");throw r.code="MODULE_NOT_FOUND",r}return s[n]}t.keys=function(){return Object.keys(s)},t.resolve=i,n.exports=t,t.id="6b79"},7399:function(n,r,e){"use strict";e.r(r),r["default"]='# ***\\*2W字！详解20道Redis经典面试题！（珍藏版）\\****\r\n\r\n## ***\\*前言\\****\r\n\r\n大家好，我是捡田螺的小男孩。金九银十即将到来，整理了20道经典Redis面试题，希望对大家有帮助。\r\n\r\n![img](Redis经典面试题.assets/wps5898.tmp.png) \r\n\r\n· 公众号：***\\*捡田螺的小男孩\\****\r\n\r\n· [github地址](https://link.juejin.cn/?target=https://github.com/whx123/JavaHome)\r\n\r\n## ***\\*1. 什么是Redis？它主要用来什么的？\\****\r\n\r\nRedis，英文全称是***\\*Remote Dictionary Server\\****（远程字典服务），是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。\r\n\r\n与MySQL数据库不同的是，Redis的数据是存在内存中的。它的读写速度非常快，每秒可以处理超过10万次读写操作。因此redis被***\\*广泛应用于缓存\\****，另外，Redis也经常用来做分布式锁。除此之外，Redis支持事务、持久化、LUA 脚本、LRU 驱动事件、多种集群方案。\r\n\r\n## ***\\*2.说说Redis的基本数据结构类型\\****\r\n\r\n大多数小伙伴都知道，Redis有以下这五种基本类型：\r\n\r\n· String（字符串）\r\n\r\n· Hash（哈希）\r\n\r\n· List（列表）\r\n\r\n· Set（集合）\r\n\r\n· zset（有序集合）\r\n\r\n它还有三种特殊的数据结构类型\r\n\r\n· Geospatial\r\n\r\n· Hyperloglog\r\n\r\n· Bitmap\r\n\r\n### ***\\*2.1 Redis 的五种基本数据类型\\****\r\n\r\n![img](Redis经典面试题.assets/wps5899.tmp.png) \r\n\r\n#### ***\\*String（字符串）\\****\r\n\r\n· 简介:String是Redis最基础的数据结构类型，它是二进制安全的，可以存储图片或者序列化的对象，值最大存储为512M\r\n\r\n· 简单使用举例: set key value、get key等\r\n\r\n· 应用场景：共享session、分布式锁，计数器、限流。\r\n\r\n· 内部编码有3种，int（8字节长整型）/embstr（小于等于39字节字符串）/raw（大于39个字节字符串）\r\n\r\nC语言的字符串是char[]实现的，而Redis使用***\\*SDS（simple dynamic string）\\**** 封装，sds源码如下：\r\n\r\nstruct sdshdr{\r\n\r\n unsigned int len; // 标记buf的长度\r\n\r\n unsigned int free; //标记buf中未使用的元素个数\r\n\r\n char buf[]; // 存放元素的坑\r\n\r\n}复制代码\r\n\r\nSDS 结构图如下： ![img](Redis经典面试题.assets/wps58AA.tmp.png)\r\n\r\nRedis为什么选择***\\*SDS\\****结构，而C语言原生的 char[]不香吗？\r\n\r\n举例其中一点，SDS中，O(1)时间复杂度，就可以获取字符串长度；而C 字符串，需要遍历整个字符串，时间复杂度为O(n)\r\n\r\n#### ***\\*Hash（哈希）\\****\r\n\r\n· 简介：在Redis中，哈希类型是指v（值）本身又是一个键值对（k-v）结构\r\n\r\n· 简单使用举例：hset key field value 、hget key field\r\n\r\n· 内部编码：ziplist（压缩列表） 、hashtable（哈希表）\r\n\r\n· 应用场景：缓存用户信息等。\r\n\r\n**·** ***\\*注意点\\****：如果开发使用hgetall，哈希元素比较多的话，可能导致Redis阻塞，可以使用hscan。而如果只是获取部分field，建议使用hmget。\r\n\r\n字符串和哈希类型对比如下图： ![img](Redis经典面试题.assets/wps58AB.tmp.png)\r\n\r\n#### ***\\*List（列表）\\****\r\n\r\n· 简介：列表（list）类型是用来存储多个有序的字符串，一个列表最多可以存储2^32-1个元素。\r\n\r\n· 简单实用举例： lpush key value [value ...] 、lrange key start end\r\n\r\n· 内部编码：ziplist（压缩列表）、linkedlist（链表）\r\n\r\n· 应用场景： 消息队列，文章列表,\r\n\r\n一图看懂list类型的插入与弹出： ![img](Redis经典面试题.assets/wps58AC.tmp.png)\r\n\r\nlist应用场景参考以下：\r\n\r\n· lpush+lpop=Stack（栈）\r\n\r\n· lpush+rpop=Queue（队列）\r\n\r\n· lpsh+ltrim=Capped Collection（有限集合）\r\n\r\n· lpush+brpop=Message Queue（消息队列）\r\n\r\n#### ***\\*Set（集合）\\****\r\n\r\n![img](Redis经典面试题.assets/wps58AD.tmp.png) \r\n\r\n· 简介：集合（set）类型也是用来保存多个的字符串元素，但是不允许重复元素\r\n\r\n· 简单使用举例：sadd key element [element ...]、smembers key\r\n\r\n· 内部编码：intset（整数集合）、hashtable（哈希表）\r\n\r\n**·** ***\\*注意点\\****：smembers和lrange、hgetall都属于比较重的命令，如果元素过多存在阻塞Redis的可能性，可以使用sscan来完成。\r\n\r\n· 应用场景： 用户标签,生成随机数抽奖、社交需求。\r\n\r\n#### ***\\*有序集合（zset）\\****\r\n\r\n· 简介：已排序的字符串集合，同时元素不能重复\r\n\r\n· 简单格式举例：zadd key score member [score member ...]，zrank key member\r\n\r\n· 底层内部编码：ziplist（压缩列表）、skiplist（跳跃表）\r\n\r\n· 应用场景：排行榜，社交需求（如用户点赞）。\r\n\r\n### ***\\*2.2 Redis 的三种特殊数据类型\\****\r\n\r\n· Geo：Redis3.2推出的，地理位置定位，用于存储地理位置信息，并对存储的信息进行操作。\r\n\r\n· HyperLogLog：用来做基数统计算法的数据结构，如统计网站的UV。\r\n\r\n· Bitmaps ：用一个比特位来映射某个元素的状态，在Redis中，它的底层是基于字符串类型实现的，可以把bitmaps成作一个以比特位为单位的数组\r\n\r\n## ***\\*3. Redis为什么这么快？\\****\r\n\r\n![img](Redis经典面试题.assets/wps58AE.tmp.png) \r\n\r\n### ***\\*3.1 基于内存存储实现\\****\r\n\r\n我们都知道内存读写是比在磁盘快很多的，Redis基于内存存储实现的数据库，相对于数据存在磁盘的MySQL数据库，省去磁盘I/O的消耗。\r\n\r\n### ***\\*3.2 高效的数据结构\\****\r\n\r\n我们知道，Mysql索引为了提高效率，选择了B+树的数据结构。其实合理的数据结构，就是可以让你的应用/程序更快。先看下Redis的数据结构&内部编码图：\r\n\r\n![img](Redis经典面试题.assets/wps58AF.tmp.png) \r\n\r\n#### ***\\*SDS简单动态字符串\\****\r\n\r\n![img](Redis经典面试题.assets/wps58B0.tmp.png) \r\n\r\n· 字符串长度处理：Redis获取字符串长度，时间复杂度为O(1)，而C语言中，需要从头开始遍历，复杂度为O（n）;\r\n\r\n· 空间预分配：字符串修改越频繁的话，内存分配越频繁，就会消耗性能，而SDS修改和空间扩充，会额外分配未使用的空间，减少性能损耗。\r\n\r\n· 惰性空间释放：SDS 缩短时，不是回收多余的内存空间，而是free记录下多余的空间，后续有变更，直接使用free中记录的空间，减少分配。\r\n\r\n· 二进制安全：Redis可以存储一些二进制数据，在C语言中字符串遇到\'\\0\'会结束，而 SDS中标志字符串结束的是len属性。\r\n\r\n#### ***\\*字典\\****\r\n\r\nRedis 作为 K-V 型内存数据库，所有的键值就是用字典来存储。字典就是哈希表，比如HashMap，通过key就可以直接获取到对应的value。而哈希表的特性，在O（1）时间复杂度就可以获得对应的值。\r\n\r\n#### ***\\*跳跃表\\****\r\n\r\n![img](Redis经典面试题.assets/wps58C0.tmp.png) \r\n\r\n· 跳跃表是Redis特有的数据结构，就是在链表的基础上，增加多级索引提升查找效率。\r\n\r\n· 跳跃表支持平均 O（logN）,最坏 O（N）复杂度的节点查找，还可以通过顺序性操作批量处理节点。\r\n\r\n### ***\\*3.3 合理的数据编码\\****\r\n\r\nRedis 支持多种数据数据类型，每种基本类型，可能对多种数据结构。什么时候,使用什么样数据结构，使用什么样编码，是redis设计者总结优化的结果。\r\n\r\n· String：如果存储数字的话，是用int类型的编码;如果存储非数字，小于等于39字节的字符串，是embstr；大于39个字节，则是raw编码。\r\n\r\n· List：如果列表的元素个数小于512个，列表每个元素的值都小于64字节（默认），使用ziplist编码，否则使用linkedlist编码\r\n\r\n· Hash：哈希类型元素个数小于512个，所有值小于64字节的话，使用ziplist编码,否则使用hashtable编码。\r\n\r\n· Set：如果集合中的元素都是整数且元素个数小于512个，使用intset编码，否则使用hashtable编码。\r\n\r\n· Zset：当有序集合的元素个数小于128个，每个元素的值小于64字节时，使用ziplist编码，否则使用skiplist（跳跃表）编码\r\n\r\n### ***\\*3.4 合理的线程模型\\****\r\n\r\n***\\*I/O 多路复用\\****\r\n\r\n![img](Redis经典面试题.assets/wps58C1.tmp.png) \r\n\r\n多路I/O复用技术可以让单个线程高效的处理多个连接请求，而Redis使用用epoll作为I/O多路复用技术的实现。并且，Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。\r\n\r\n什么是I/O多路复用？\r\n\r\n· I/O ：网络 I/O\r\n\r\n· 多路 ：多个网络连接\r\n\r\n· 复用：复用同一个线程。\r\n\r\n· IO多路复用其实就是一种同步IO模型，它实现了一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；而没有文件句柄就绪时,就会阻塞应用程序，交出cpu。\r\n\r\n***\\*单线程模型\\****\r\n\r\n· Redis是单线程模型的，而单线程避免了CPU不必要的上下文切换和竞争锁的消耗。也正因为是单线程，如果某个命令执行过长（如hgetall命令），会造成阻塞。Redis是面向快速执行场景的数据库。，所以要慎用如smembers和lrange、hgetall等命令。\r\n\r\n· Redis 6.0 引入了多线程提速，它的执行命令操作内存的仍然是个单线程。\r\n\r\n### ***\\*3.5 虚拟内存机制\\****\r\n\r\nRedis直接自己构建了VM机制 ，不会像一般的系统会调用系统函数处理，会浪费一定的时间去移动和请求。\r\n\r\n***\\*Redis的虚拟内存机制是啥呢？\\****\r\n\r\n虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。\r\n\r\n## ***\\*4. 什么是缓存击穿、缓存穿透、缓存雪崩？\\****\r\n\r\n### ***\\*4.1 缓存穿透问题\\****\r\n\r\n先来看一个常见的缓存使用方式：读请求来了，先查下缓存，缓存有值命中，就直接返回；缓存没命中，就去查数据库，然后把数据库的值更新到缓存，再返回。\r\n\r\n![img](Redis经典面试题.assets/wps58C2.tmp.png) \r\n\r\n***\\*缓存穿透\\****：指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。\r\n\r\n通俗点说，读请求访问时，缓存和数据库都没有某个值，这样就会导致每次对这个值的查询请求都会穿透到数据库，这就是缓存穿透。\r\n\r\n缓存穿透一般都是这几种情况产生的：\r\n\r\n**·** ***\\*业务不合理的设计\\****，比如大多数用户都没开守护，但是你的每个请求都去缓存，查询某个userid查询有没有守护。\r\n\r\n**·** ***\\*业务/运维/开发失误的操作\\****，比如缓存和数据库的数据都被误删除了。\r\n\r\n**·** ***\\*黑客非法请求攻击\\****，比如黑客故意捏造大量非法请求，以读取不存在的业务数据。\r\n\r\n***\\*如何避免缓存穿透呢？\\**** 一般有三种方法。\r\n\r\n· 1.如果是非法请求，我们在API入口，对参数进行校验，过滤非法值。\r\n\r\n· 2.如果查询数据库为空，我们可以给缓存设置个空值，或者默认值。但是如有有写请求进来的话，需要更新缓存哈，以保证缓存一致性，同时，最后给缓存设置适当的过期时间。（业务上比较常用，简单有效）\r\n\r\n· 3.使用布隆过滤器快速判断数据是否存在。即一个查询请求过来时，先通过布隆过滤器判断值是否存在，存在才继续往下查。\r\n\r\n布隆过滤器原理：它由初始值为0的位图数组和N个哈希函数组成。一个对一个key进行N个hash算法获取N个值，在比特数组中将这N个值散列后设定为1，然后查的时候如果特定的这几个位置都为1，那么布隆过滤器判断该key存在。\r\n\r\n### ***\\*4.2 缓存雪奔问题\\****\r\n\r\n***\\*缓存雪奔：\\**** 指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至down机。\r\n\r\n· 缓存雪奔一般是由于大量数据同时过期造成的，对于这个原因，可通过均匀设置过期时间解决，即让过期时间相对离散一点。如采用一个较大固定值+一个较小的随机值，5小时+0到1800秒酱紫。\r\n\r\n· Redis 故障宕机也可能引起缓存雪奔。这就需要构造Redis高可用集群啦。\r\n\r\n### ***\\*4.3 缓存击穿问题\\****\r\n\r\n***\\*缓存击穿：\\**** 指热点key在某个时间点过期的时候，而恰好在这个时间点对这个Key有大量的并发请求过来，从而大量的请求打到db。\r\n\r\n缓存击穿看着有点像，其实它两区别是，缓存雪奔是指数据库压力过大甚至down机，缓存击穿只是大量并发请求到了DB数据库层面。可以认为击穿是缓存雪奔的一个子集吧。有些文章认为它俩区别，是区别在于击穿针对某一热点key缓存，雪奔则是很多key。\r\n\r\n解决方案就有两种：\r\n\r\n**·** ***\\*1.使用互斥锁方案\\****。缓存失效时，不是立即去加载db数据，而是先使用某些带成功返回的原子操作命令，如(Redis的setnx）去操作，成功的时候，再去加载db数据库数据和设置缓存。否则就去重试获取缓存。\r\n\r\n**·** ***\\*2. “永不过期”\\****，是指没有设置过期时间，但是热点数据快要过期时，异步线程去更新和设置过期时间。\r\n\r\n## ***\\*5. 什么是热Key问题，如何解决热key问题\\****\r\n\r\n***\\*什么是热Key呢\\****？在Redis中，我们把访问频率高的key，称为热点key。\r\n\r\n如果某一热点key的请求到服务器主机时，由于请求量特别大，可能会导致主机资源不足，甚至宕机，从而影响正常的服务。\r\n\r\n![img](Redis经典面试题.assets/wps58C3.tmp.png) \r\n\r\n而热点Key是怎么产生的呢？主要原因有两个：\r\n\r\n· 用户消费的数据远大于生产的数据，如秒杀、热点新闻等读多写少的场景。\r\n\r\n· 请求分片集中，超过单Redi服务器的性能，比如固定名称key，Hash落入同一台服务器，瞬间访问量极大，超过机器瓶颈，产生热点Key问题。\r\n\r\n那么在日常开发中，如何识别到热点key呢？\r\n\r\n· 凭经验判断哪些是热Key；\r\n\r\n· 客户端统计上报；\r\n\r\n· 服务代理层上报\r\n\r\n如何解决热key问题？\r\n\r\n· Redis集群扩容：增加分片副本，均衡读流量；\r\n\r\n· 将热key分散到不同的服务器中；\r\n\r\n· 使用二级缓存，即JVM本地缓存,减少Redis的读请求。\r\n\r\n## ***\\*6. Redis 过期策略和内存淘汰策略\\****\r\n\r\n![img](Redis经典面试题.assets/wps58C4.tmp.png) \r\n\r\n### ***\\*6.1 Redis的过期策略\\****\r\n\r\n我们在set key的时候，可以给它设置一个过期时间，比如expire key 60。指定这key60s后过期，60s后，redis是如何处理的嘛？我们先来介绍几种过期策略：\r\n\r\n#### ***\\*定时过期\\****\r\n\r\n每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即对key进行清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。\r\n\r\n#### ***\\*惰性过期\\****\r\n\r\n只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。\r\n\r\n#### ***\\*定期过期\\****\r\n\r\n每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。\r\n\r\nexpires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。\r\n\r\nRedis中同时使用了***\\*惰性过期和定期过期\\****两种过期策略。\r\n\r\n· 假设Redis当前存放30万个key，并且都设置了过期时间，如果你每隔100ms就去检查这全部的key，CPU负载会特别高，最后可能会挂掉。\r\n\r\n· 因此，redis采取的是定期过期，每隔100ms就随机抽取一定数量的key来检查和删除的。\r\n\r\n· 但是呢，最后可能会有很多已经过期的key没被删除。这时候，redis采用惰性删除。在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除。\r\n\r\n但是呀，如果定期删除漏掉了很多过期的key，然后也没走惰性删除。就会有很多过期key积在内存内存，直接会导致内存爆的。或者有些时候，业务量大起来了，redis的key被大量使用，内存直接不够了，运维小哥哥也忘记加大内存了。难道redis直接这样挂掉？不会的！Redis用8种内存淘汰策略保护自己~\r\n\r\n### ***\\*6.2 Redis 内存淘汰策略\\****\r\n\r\n· volatile-lru：当内存不足以容纳新写入数据时，从设置了过期时间的key中使用LRU（最近最少使用）算法进行淘汰；\r\n\r\n· allkeys-lru：当内存不足以容纳新写入数据时，从所有key中使用LRU（最近最少使用）算法进行淘汰。\r\n\r\n· volatile-lfu：4.0版本新增，当内存不足以容纳新写入数据时，在过期的key中，使用LFU算法进行删除key。\r\n\r\n· allkeys-lfu：4.0版本新增，当内存不足以容纳新写入数据时，从所有key中使用LFU算法进行淘汰；\r\n\r\n· volatile-random：当内存不足以容纳新写入数据时，从设置了过期时间的key中，随机淘汰数据；。\r\n\r\n· allkeys-random：当内存不足以容纳新写入数据时，从所有key中随机淘汰数据。\r\n\r\n· volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，根据过期时间进行淘汰，越早过期的优先被淘汰；\r\n\r\n· noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。\r\n\r\n## ***\\*7.说说Redis的常用应用场景\\****\r\n\r\n· 缓存\r\n\r\n· 排行榜\r\n\r\n· 计数器应用\r\n\r\n· 共享Session\r\n\r\n· 分布式锁\r\n\r\n· 社交网络\r\n\r\n· 消息队列\r\n\r\n· 位操作\r\n\r\n### ***\\*7.1 缓存\\****\r\n\r\n我们一提到redis，自然而然就想到缓存，国内外中大型的网站都离不开缓存。合理的利用缓存，比如缓存热点数据，不仅可以提升网站的访问速度，还可以降低数据库DB的压力。并且，Redis相比于memcached，还提供了丰富的数据结构，并且提供RDB和AOF等持久化机制，强的一批。\r\n\r\n### ***\\*7.2 排行榜\\****\r\n\r\n当今互联网应用，有各种各样的排行榜，如电商网站的月度销量排行榜、社交APP的礼物排行榜、小程序的投票排行榜等等。Redis提供的zset数据类型能够实现这些复杂的排行榜。\r\n\r\n比如，用户每天上传视频，获得点赞的排行榜可以这样设计：\r\n\r\n· 1.用户Jay上传一个视频，获得6个赞，可以酱紫：\r\n\r\nzadd user:ranking:2021-03-03 Jay 3复制代码\r\n\r\n· \r\n\r\n\\1. 过了一段时间，再获得一个赞，可以这样：\r\n\r\nzincrby user:ranking:2021-03-03 Jay 1复制代码\r\n\r\n· \r\n\r\n\\1. 如果某个用户John作弊，需要删除该用户：\r\n\r\nzrem user:ranking:2021-03-03 John复制代码\r\n\r\n· \r\n\r\n\\1. 展示获取赞数最多的3个用户\r\n\r\nzrevrangebyrank user:ranking:2021-03-03 0 2复制代码\r\n\r\n### ***\\*7.3 计数器应用\\****\r\n\r\n各大网站、APP应用经常需要计数器的功能，如短视频的播放数、电商网站的浏览数。这些播放数、浏览数一般要求实时的，每一次播放和浏览都要做加1的操作，如果并发量很大对于传统关系型数据的性能是一种挑战。Redis天然支持计数功能而且计数的性能也非常好，可以说是计数器系统的重要选择。\r\n\r\n### ***\\*7.4 共享Session\\****\r\n\r\n如果一个分布式Web服务将用户的Session信息保存在各自服务器，用户刷新一次可能就需要重新登录了，这样显然有问题。实际上，可以使用Redis将用户的Session进行集中管理，每次用户更新或者查询登录信息都直接从Redis中集中获取。\r\n\r\n### ***\\*7.5 分布式锁\\****\r\n\r\n几乎每个互联网公司中都使用了分布式部署，分布式服务下，就会遇到对同一个资源的并发访问的技术难题，如秒杀、下单减库存等场景。\r\n\r\n· 用synchronize或者reentrantlock本地锁肯定是不行的。\r\n\r\n· 如果是并发量不大话，使用数据库的悲观锁、乐观锁来实现没啥问题。\r\n\r\n· 但是在并发量高的场合中，利用数据库锁来控制资源的并发访问，会影响数据库的性能。\r\n\r\n· 实际上，可以用Redis的setnx来实现分布式的锁。\r\n\r\n### ***\\*7.6 社交网络\\****\r\n\r\n赞/踩、粉丝、共同好友/喜好、推送、下拉刷新等是社交网站的必备功能，由于社交网站访问量通常比较大，而且传统的关系型数据不太适保存 这种类型的数据，Redis提供的数据结构可以相对比较容易地实现这些功能。\r\n\r\n### ***\\*7.7 消息队列\\****\r\n\r\n消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个不能和专业的消息中间件相比。\r\n\r\n### ***\\*7.8 位操作\\****\r\n\r\n用于数据量上亿的场景下，例如几亿用户系统的签到，去重登录次数统计，某用户是否在线状态等等。腾讯10亿用户，要几个毫秒内查询到某个用户是否在线，能怎么做？千万别说给每个用户建立一个key，然后挨个记（你可以算一下需要的内存会很恐怖，而且这种类似的需求很多。这里要用到位操作——使用setbit、getbit、bitcount命令。原理是：redis内构建一个足够长的数组，每个数组元素只能是0和1两个值，然后这个数组的下标index用来表示用户id（必须是数字哈），那么很显然，这个几亿长的大数组就能通过下标和元素值（0和1）来构建一个记忆系统。\r\n\r\n## ***\\*8. Redis 的持久化机制有哪些？优缺点说说\\****\r\n\r\nRedis是基于内存的非关系型K-V数据库，既然它是基于内存的，如果Redis服务器挂了，数据就会丢失。为了避免数据丢失了，Redis提供了***\\*持久化\\****，即把数据保存到磁盘。\r\n\r\nRedis提供了***\\*RDB和AOF\\****两种持久化机制，它持久化文件加载流程如下：\r\n\r\n![img](Redis经典面试题.assets/wps58C5.tmp.png) \r\n\r\n### ***\\*8.1 RDB\\****\r\n\r\n***\\*RDB\\****，就是把内存数据以快照的形式保存到磁盘上。\r\n\r\n什么是快照?可以这样理解，给当前时刻的数据，拍一张照片，然后保存下来。\r\n\r\nRDB持久化，是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个dump.rdb文件，Redis 重启的时候，通过加载dump.rdb文件来恢复数据。RDB触发机制主要有以下几种：\r\n\r\n![img](Redis经典面试题.assets/wps58D6.tmp.png) \r\n\r\n***\\*RDB 的优点\\****\r\n\r\n· 适合大规模的数据恢复场景，如备份，全量复制等\r\n\r\n***\\*RDB缺点\\****\r\n\r\n· 没办法做到实时持久化/秒级持久化。\r\n\r\n· 新老版本存在RDB格式兼容问题\r\n\r\n### ***\\*AOF\\****\r\n\r\n***\\*AOF（append only file）\\**** 持久化，采用日志的形式来记录每个写操作，追加到文件中，重启时再重新执行AOF文件中的命令来恢复数据。它主要解决数据持久化的实时性问题。默认是不开启的。\r\n\r\nAOF的工作流程如下：\r\n\r\n![img](Redis经典面试题.assets/wps58D7.tmp.png) \r\n\r\n***\\*AOF的优点\\****\r\n\r\n· 数据的一致性和完整性更高\r\n\r\n***\\*AOF的缺点\\****\r\n\r\n· AOF记录的内容越多，文件越大，数据恢复变慢。\r\n\r\n## ***\\*9.怎么实现Redis的高可用？\\****\r\n\r\n我们在项目中使用Redis，肯定不会是单点部署Redis服务的。因为，单点部署一旦宕机，就不可用了。为了实现高可用，通常的做法是，将数据库复制多个副本以部署在不同的服务器上，其中一台挂了也可以继续提供服务。 Redis 实现高可用有三种部署模式：***\\*主从模式，哨兵模式，集群模式\\****。\r\n\r\n### ***\\*9.1 主从模式\\****\r\n\r\n主从模式中，Redis部署了多台机器，有主节点，负责读写操作，有从节点，只负责读操作。从节点的数据来自主节点，实现原理就是***\\*主从复制机制\\****\r\n\r\n主从复制包括全量复制，增量复制两种。一般当slave第一次启动连接master，或者认为是第一次连接，就采用***\\*全量复制\\****，全量复制流程如下：\r\n\r\n![img](Redis经典面试题.assets/wps58D8.tmp.png) \r\n\r\n· 1.slave发送sync命令到master。\r\n\r\n· 2.master接收到SYNC命令后，执行bgsave命令，生成RDB全量文件。\r\n\r\n· 3.master使用缓冲区，记录RDB快照生成期间的所有写命令。\r\n\r\n· 4.master执行完bgsave后，向所有slave发送RDB快照文件。\r\n\r\n· 5.slave收到RDB快照文件后，载入、解析收到的快照。\r\n\r\n· 6.master使用缓冲区，记录RDB同步期间生成的所有写的命令。\r\n\r\n· 7.master快照发送完毕后，开始向slave发送缓冲区中的写命令;\r\n\r\n· 8.salve接受命令请求，并执行来自master缓冲区的写命令\r\n\r\nredis2.8版本之后，已经使用***\\*psync来替代sync\\****，因为sync命令非常消耗系统资源，psync的效率更高。\r\n\r\nslave与master全量同步之后，master上的数据，如果再次发生更新，就会触发***\\*增量复制\\****。\r\n\r\n当master节点发生数据增减时，就会触发replicationFeedSalves()函数，接下来在 Master节点上调用的每一个命令会使用replicationFeedSlaves()来同步到Slave节点。执行此函数之前呢，master节点会判断用户执行的命令是否有数据更新，如果有数据更新的话，并且slave节点不为空，就会执行此函数。这个函数作用就是：***\\*把用户执行的命令发送到所有的slave节点\\****，让slave节点执行。流程如下：\r\n\r\n![img](Redis经典面试题.assets/wps58D9.tmp.png) \r\n\r\n### ***\\*9.2 哨兵模式\\****\r\n\r\n主从模式中，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址。显然，多数业务场景都不能接受这种故障处理方式。Redis从2.8开始正式提供了Redis Sentinel（哨兵）架构来解决这个问题。\r\n\r\n***\\*哨兵模式\\****，由一个或多个Sentinel实例组成的Sentinel系统，它可以监视所有的Redis主节点和从节点，并在被监视的主节点进入下线状态时，***\\*自动将下线主服务器属下的某个从节点升级为新的主节点\\****。但是呢，一个哨兵进程对Redis节点进行监控，就可能会出现问题（***\\*单点问题\\****），因此，可以使用多个哨兵来进行监控Redis节点，并且各个哨兵之间还会进行监控。\r\n\r\n![img](Redis经典面试题.assets/wps58DA.tmp.png) \r\n\r\n简单来说，哨兵模式就三个作用：\r\n\r\n· 发送命令，等待Redis服务器（包括主服务器和从服务器）返回监控其运行状态；\r\n\r\n· 哨兵监测到主节点宕机，会自动将从节点切换成主节点，然后通过发布订阅模式通知其他的从节点，修改配置文件，让它们切换主机；\r\n\r\n· 哨兵之间还会相互监控，从而达到高可用。\r\n\r\n***\\*故障切换的过程是怎样的呢\\****\r\n\r\n假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。\r\n\r\n哨兵的工作模式如下：\r\n\r\n\\1. 每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他Sentinel实例发送一个 PING命令。\r\n\r\n\\2. 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel标记为主观下线。\r\n\r\n\\3. 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。\r\n\r\n\\4. 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线。\r\n\r\n\\5. 在一般情况下， 每个 Sentinel 会以每10秒一次的频率向它已知的所有Master，Slave发送 INFO 命令。\r\n\r\n\\6. 当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次\r\n\r\n\\7. 若没有足够数量的 Sentinel同意Master已经下线， Master的客观下线状态就会被移除；若Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。\r\n\r\n### ***\\*9.3 Cluster集群模式\\****\r\n\r\n哨兵模式基于主从模式，实现读写分离，它还可以自动切换，系统可用性更高。但是它每个节点存储的数据是一样的，浪费内存，并且不好在线扩容。 因此，Cluster集群应运而生，它在Redis3.0加入的，实现了Redis的***\\*分布式存储\\****。对数据进行分片，也就是说***\\*每台Redis节点上存储不同的内容\\****，来解决在线扩容的问题。并且，它也提供复制和故障转移的功能。\r\n\r\n#### ***\\*Cluster集群节点的通讯\\****\r\n\r\n一个Redis集群由多个节点组成，***\\*各个节点之间是怎么通信的呢\\****？通过***\\*Gossip协议\\****！\r\n\r\nRedis Cluster集群通过Gossip协议进行通信，节点之前不断交换信息，交换的信息内容包括节点出现故障、新节点加入、主从节点变更信息、slot信息等等。常用的Gossip消息分为4种，分别是：ping、pong、meet、fail。\r\n\r\n![img](Redis经典面试题.assets/wps58DB.tmp.png) \r\n\r\n· meet消息：通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。\r\n\r\n· ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。\r\n\r\n· pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。\r\n\r\n· fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。\r\n\r\n特别的，每个节点是通过***\\*集群总线(cluster bus)\\**** 与其他的节点进行通信的。通讯时，使用特殊的端口号，即对外服务端口号加10000。例如如果某个node的端口号是6379，那么它与其它nodes通信的端口号是 16379。nodes 之间的通信采用特殊的二进制协议。\r\n\r\n#### ***\\*Hash Slot插槽算法\\****\r\n\r\n既然是分布式存储，Cluster集群使用的分布式算法是***\\*一致性Hash\\****嘛？并不是，而是***\\*Hash Slot插槽算法\\****。\r\n\r\n***\\*插槽算法\\****把整个数据库被分为16384个slot（槽），每个进入Redis的键值对，根据key进行散列，分配到这16384插槽中的一个。使用的哈希映射也比较简单，用CRC16算法计算出一个16 位的值，再对16384取模。数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点都可以处理这16384个槽。\r\n\r\n集群中的每个节点负责一部分的hash槽，比如当前集群有A、B、C个节点，每个节点上的哈希槽数 =16384/3，那么就有：\r\n\r\n· 节点A负责0~5460号哈希槽\r\n\r\n· 节点B负责5461~10922号哈希槽\r\n\r\n· 节点C负责10923~16383号哈希槽\r\n\r\n#### ***\\*Redis Cluster集群\\****\r\n\r\nRedis Cluster集群中，需要确保16384个槽对应的node都正常工作，如果某个node出现故障，它负责的slot也会失效，整个集群将不能工作。\r\n\r\n因此为了保证高可用，Cluster集群引入了主从复制，一个主节点对应一个或者多个从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点宕机时，就会启用从节点。\r\n\r\n在Redis的每一个节点上，都有两个玩意，一个是插槽（slot），它的取值范围是0~~16383。另外一个是cluster，可以理解为一个集群管理的插件。当我们存取的key到达时，Redis 会根据CRC16算法得出一个16 bit的值，然后把结果对16384取模。酱紫每个key都会对应一个编号在 0~~16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。\r\n\r\n虽然数据是分开存储在不同节点上的，但是对客户端来说，整个集群Cluster，被看做一个整体。客户端端连接任意一个node，看起来跟操作单实例的Redis一样。当客户端操作的key没有被分配到正确的node节点时，Redis会返回转向指令，最后指向正确的node，这就有点像浏览器页面的302 重定向跳转。\r\n\r\n![img](Redis经典面试题.assets/wps58EB.tmp.png) \r\n\r\n#### ***\\*故障转移\\****\r\n\r\nRedis集群实现了高可用，当集群内节点出现故障时，通过***\\*故障转移\\****，以保证集群正常对外提供服务。\r\n\r\nredis集群通过ping/pong消息，实现故障发现。这个环境包括***\\*主观下线和客观下线\\****。\r\n\r\n***\\*主观下线：\\**** 某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。\r\n\r\n![img](Redis经典面试题.assets/wps58EC.tmp.png) \r\n\r\n***\\*客观下线：\\**** 指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。\r\n\r\n· 假如节点A标记节点B为主观下线，一段时间后，节点A通过消息把节点B的状态发到其它节点，当节点C接受到消息并解析出消息体时，如果发现节点B的pfail状态时，会触发客观下线流程；\r\n\r\n· 当下线为主节点时，此时Redis Cluster集群为统计持有槽的主节点投票，看投票数是否达到一半，当下线报告统计数大于一半时，被标记为***\\*客观下线\\****状态。\r\n\r\n流程如下：\r\n\r\n![img](Redis经典面试题.assets/wps58ED.tmp.png) \r\n\r\n***\\*故障恢复\\****：故障发现后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，以保证集群的高可用。流程如下：\r\n\r\n![img](Redis经典面试题.assets/wps58EE.tmp.png) \r\n\r\n· 资格检查：检查从节点是否具备替换故障主节点的条件。\r\n\r\n· 准备选举时间：资格检查通过后，更新触发故障选举时间。\r\n\r\n· 发起选举：到了故障选举时间，进行选举。\r\n\r\n· 选举投票：只有持有槽的***\\*主节点\\****才有票，从节点收集到足够的选票（大于一半），触发***\\*替换主节点操作\\****\r\n\r\n## ***\\*10. 使用过Redis分布式锁嘛？有哪些注意点呢？\\****\r\n\r\n***\\*分布式锁\\****，是控制分布式系统不同进程共同访问共享资源的一种锁的实现。秒杀下单、抢红包等等业务场景，都需要用到分布式锁，我们项目中经常使用Redis作为分布式锁。\r\n\r\n选了Redis分布式锁的几种实现方法，大家来讨论下，看有没有啥问题哈。\r\n\r\n· 命令setnx + expire分开写\r\n\r\n· setnx + value值是过期时间\r\n\r\n· set的扩展命令（set ex px nx）\r\n\r\n· set ex px nx + 校验唯一随机值,再删除\r\n\r\n### ***\\*10.1 命令setnx + expire分开写\\****\r\n\r\nif（jedis.setnx(key,lock_value) == 1）{ //加锁\r\n\r\n  expire（key，100）; //设置过期时间\r\n\r\n  try {\r\n\r\n​    do something  //业务请求\r\n\r\n  }catch(){\r\n\r\n　　}\r\n\r\n　　finally {\r\n\r\n​    jedis.del(key); //释放锁\r\n\r\n  }\r\n\r\n}复制代码\r\n\r\n如果执行完setnx加锁，正要执行expire设置过期时间时，进程crash掉或者要重启维护了，那这个锁就“长生不老”了，***\\*别的线程永远获取不到锁\\****啦，所以分布式锁***\\*不能\\****这么实现。\r\n\r\n### ***\\*10.2 setnx + value值是过期时间\\****\r\n\r\nlong expires = System.currentTimeMillis() + expireTime; //系统时间+设置的过期时间\r\n\r\nString expiresStr = String.valueOf(expires);\r\n\r\n \r\n\r\n// 如果当前锁不存在，返回加锁成功\r\n\r\nif (jedis.setnx(key, expiresStr) == 1) {\r\n\r\n​    return true;\r\n\r\n} \r\n\r\n// 如果锁已经存在，获取锁的过期时间\r\n\r\nString currentValueStr = jedis.get(key);\r\n\r\n \r\n\r\n// 如果获取到的过期时间，小于系统当前时间，表示已经过期\r\n\r\nif (currentValueStr != null && Long.parseLong(currentValueStr) < System.currentTimeMillis()) {\r\n\r\n \r\n\r\n   // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间（不了解redis的getSet命令的小伙伴，可以去官网看下哈）\r\n\r\n  String oldValueStr = jedis.getSet(key_resource_id, expiresStr);\r\n\r\n  \r\n\r\n  if (oldValueStr != null && oldValueStr.equals(currentValueStr)) {\r\n\r\n​     // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁\r\n\r\n​     return true;\r\n\r\n  }\r\n\r\n}\r\n\r\n​    \r\n\r\n//其他情况，均返回加锁失败\r\n\r\nreturn false;\r\n\r\n}复制代码\r\n\r\n笔者看过有开发小伙伴是这么实现分布式锁的，但是这种方案也有这些***\\*缺点\\****：\r\n\r\n· 过期时间是客户端自己生成的，分布式环境下，每个客户端的时间必须同步。\r\n\r\n· 没有保存持有者的唯一标识，可能被别的客户端释放/解锁。\r\n\r\n· 锁过期的时候，并发多个客户端同时请求过来，都执行了jedis.getSet()，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖。\r\n\r\n#### ***\\*10.3： set的扩展命令（set ex px nx）（注意可能存在的问题）\\****\r\n\r\nif（jedis.set(key, lock_value, "NX", "EX", 100s) == 1）{ //加锁\r\n\r\n  try {\r\n\r\n​    do something  //业务处理\r\n\r\n  }catch(){\r\n\r\n　　}\r\n\r\n　　finally {\r\n\r\n​    jedis.del(key); //释放锁\r\n\r\n  }\r\n\r\n}复制代码\r\n\r\n这个方案可能存在这样的问题：\r\n\r\n· 锁过期释放了，业务还没执行完。\r\n\r\n· 锁被别的线程误删。\r\n\r\n### ***\\*10.4 set ex px nx + 校验唯一随机值,再删除\\****\r\n\r\nif（jedis.set(key, uni_request_id, "NX", "EX", 100s) == 1）{ //加锁\r\n\r\n  try {\r\n\r\n​    do something  //业务处理\r\n\r\n  }catch(){\r\n\r\n　　}\r\n\r\n　　finally {\r\n\r\n​    //判断是不是当前线程加的锁,是才释放\r\n\r\n​    if (uni_request_id.equals(jedis.get(key))) {\r\n\r\n​    jedis.del(key); //释放锁\r\n\r\n​    }\r\n\r\n  }\r\n\r\n}复制代码\r\n\r\n在这里，判断当前线程加的锁和释放锁是不是一个原子操作。如果调用jedis.del()释放锁的时候，可能这把锁已经不属于当前客户端，***\\*会解除他人加的锁\\****。\r\n\r\n![img](Redis经典面试题.assets/wps58EF.tmp.png) \r\n\r\n一般也是用***\\*lua脚本\\****代替。lua脚本如下：\r\n\r\nif redis.call(\'get\',KEYS[1]) == ARGV[1] then \r\n\r\n  return redis.call(\'del\',KEYS[1]) \r\n\r\nelse\r\n\r\n  return 0\r\n\r\nend;复制代码\r\n\r\n这种方式比较不错了，一般情况下，已经可以使用这种实现方式。但是存在***\\*锁过期释放了，业务还没执行完的问题\\****（实际上，估算个业务处理的时间，一般没啥问题了）。\r\n\r\n## ***\\*11. 使用过Redisson嘛？说说它的原理\\****\r\n\r\n***\\*分布式锁\\****可能存在***\\*锁过期释放，业务没执行完的问题\\****。有些小伙伴认为，稍微把锁过期时间设置长一些就可以啦。其实我们设想一下，是否可以给获得锁的线程，开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁的过期时间延长，防止锁过期提前释放。\r\n\r\n当前***\\*开源框架Redisson\\****就解决了这个分布式锁问题。我们一起来看下Redisson底层原理是怎样的吧：\r\n\r\n![img](Redis经典面试题.assets/wps58F0.tmp.png) \r\n\r\n只要线程一加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用Redisson解决了***\\*锁过期释放，业务没执行完\\****问题。\r\n\r\n## ***\\*12. 什么是Redlock算法\\****\r\n\r\nRedis一般都是集群部署的，假设数据在主从同步过程，主节点挂了，Redis分布式锁可能会有***\\*哪些问题\\****呢？一起来看些这个流程图：\r\n\r\n![img](Redis经典面试题.assets/wps5901.tmp.png) \r\n\r\n如果线程一在Redis的master节点上拿到了锁，但是加锁的key还没同步到slave节点。恰好这时，master节点发生故障，一个slave节点就会升级为master节点。线程二就可以获取同个key的锁啦，但线程一也已经拿到锁了，锁的安全性就没了。\r\n\r\n为了解决这个问题，Redis作者 antirez提出一种高级的分布式锁算法：***\\*Redlock\\****。Redlock核心思想是这样的：\r\n\r\n搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。\r\n\r\n我们假设当前有5个Redis master节点，在5台服务器上面运行这些Redis实例。\r\n\r\n![img](Redis经典面试题.assets/wps5902.tmp.png) \r\n\r\nRedLock的实现步骤:如下\r\n\r\n· 1.获取当前时间，以毫秒为单位。\r\n\r\n· 2.按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。\r\n\r\n· 3.客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s> 30ms+40ms+50ms+4m0s+50ms）\r\n\r\n· 如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。\r\n\r\n· 如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。\r\n\r\n简化下步骤就是：\r\n\r\n· 按顺序向5个master节点请求加锁\r\n\r\n· 根据设置的超时时间来判断，是不是要跳过该master节点。\r\n\r\n· 如果大于等于三个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。\r\n\r\n· 如果获取锁失败，解锁！\r\n\r\n## ***\\*13. Redis的跳跃表\\****\r\n\r\n![img](Redis经典面试题.assets/wps5903.tmp.png) \r\n\r\n· 跳跃表是有序集合zset的底层实现之一\r\n\r\n· 跳跃表支持平均***\\*O（logN）\\****,最坏 O（N）复杂度的节点查找，还可以通过顺序性操作批量处理节点。\r\n\r\n· 跳跃表实现由***\\*zskiplist和zskiplistNode\\****两个结构组成，其中zskiplist用于保存跳跃表信息（如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点。\r\n\r\n· 跳跃表就是在链表的基础上，增加多级索引提升查找效率。\r\n\r\n## ***\\*14. MySQL与Redis 如何保证双写一致性\\****\r\n\r\n· 缓存延时双删\r\n\r\n· 删除缓存重试机制\r\n\r\n· 读取biglog异步删除缓存\r\n\r\n### ***\\*14.1 延时双删？\\****\r\n\r\n什么是延时双删呢？流程图如下：\r\n\r\n![img](Redis经典面试题.assets/wps5904.tmp.png) \r\n\r\n\\1. 先删除缓存\r\n\r\n\\2. 再更新数据库\r\n\r\n\\3. 休眠一会（比如1秒），再次删除缓存。\r\n\r\n这个休眠一会，一般多久呢？都是1秒？\r\n\r\n这个休眠时间 = 读业务逻辑数据的耗时 + 几百毫秒。为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。\r\n\r\n这种方案还算可以，只有休眠那一会（比如就那1秒），可能有脏数据，一般业务也会接受的。但是如果***\\*第二次删除缓存失败\\****呢？缓存和数据库的数据还是可能不一致，对吧？给Key设置一个自然的expire过期时间，让它自动过期怎样？那业务要接受过期时间内，数据的不一致咯？还是有其他更佳方案呢？\r\n\r\n### ***\\*14.2 删除缓存重试机制\\****\r\n\r\n因为延时双删可能会存在第二步的删除缓存失败，导致的数据不一致问题。可以使用这个方案优化：删除失败就多删除几次呀,保证删除缓存成功就可以了呀~ 所以可以引入删除缓存重试机制\r\n\r\n![img](Redis经典面试题.assets/wps5905.tmp.png) \r\n\r\n\\1. 写请求更新数据库\r\n\r\n\\2. 缓存因为某些原因，删除失败\r\n\r\n\\3. 把删除失败的key放到消息队列\r\n\r\n\\4. 消费消息队列的消息，获取要删除的key\r\n\r\n\\5. 重试删除缓存操作\r\n\r\n### ***\\*14.3 读取biglog异步删除缓存\\****\r\n\r\n重试删除缓存机制还可以吧，就是会造成好多***\\*业务代码入侵\\****。其实，还可以这样优化：通过数据库的binlog来异步淘汰key。\r\n\r\n![img](Redis经典面试题.assets/wps5906.tmp.png) \r\n\r\n以mysql为例吧\r\n\r\n· 可以使用阿里的canal将binlog日志采集发送到MQ队列里面\r\n\r\n· 然后通过ACK机制确认处理这条更新消息，删除缓存，保证数据缓存一致性\r\n\r\n## ***\\*15. 为什么Redis 6.0 之后改多线程呢？\\****\r\n\r\n· Redis6.0之前，Redis在处理客户端的请求时，包括读socket、解析、执行、写socket等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。\r\n\r\n· Redis6.0之前为什么一直不使用多线程？使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。\r\n\r\nredis使用多线程并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。\r\n\r\n这样做的目的是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。\r\n\r\n## ***\\*16. 聊聊Redis 事务机制\\****\r\n\r\nRedis通过***\\*MULTI、EXEC、WATCH\\****等一组命令集合，来实现事务机制。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。\r\n\r\n简言之，Redis事务就是***\\*顺序性、一次性、排他性\\****的执行一个队列中的一系列命令。\r\n\r\nRedis执行事务的流程如下：\r\n\r\n· 开始事务（MULTI）\r\n\r\n· 命令入队\r\n\r\n· 执行事务（EXEC）、撤销事务（DISCARD ）\r\n\r\n| ***\\*命令\\**** | ***\\*描述\\****                                               |\r\n| -------------- | ------------------------------------------------------------ |\r\n| EXEC           | 执行所有事务块内的命令                                       |\r\n| DISCARD        | 取消事务，放弃执行事务块内的所有命令                         |\r\n| MULTI          | 标记一个事务块的开始                                         |\r\n| UNWATCH        | 取消 WATCH 命令对所有 key 的监视。                           |\r\n| WATCH          | 监视key ，如果在事务执行之前，该key 被其他命令所改动，那么事务将被打断。 |\r\n\r\n## ***\\*17. Redis的Hash 冲突怎么办\\****\r\n\r\nRedis 作为一个K-V的内存数据库，它使用用一张全局的哈希来保存所有的键值对。这张哈希表，有多个哈希桶组成，哈希桶中的entry元素保存了key和value指针，其中*key指向了实际的键，*value指向了实际的值。 ![img](Redis经典面试题.assets/wps5917.tmp.png)\r\n\r\n哈希表查找速率很快的，有点类似于Java中的HashMap，它让我们在O(1) 的时间复杂度快速找到键值对。首先通过key计算哈希值，找到对应的哈希桶位置，然后定位到entry，在entry找到对应的数据。\r\n\r\n***\\*什么是哈希冲突？\\****\r\n\r\n哈希冲突： 通过不同的key，计算出一样的哈希值，导致落在同一个哈希桶中。\r\n\r\nRedis为了解决哈希冲突，采用了***\\*链式哈希\\****。链式哈希是指同一个哈希桶中，多个元素用一个链表来保存，它们之间依次用指针连接。\r\n\r\n![img](Redis经典面试题.assets/wps5918.tmp.png) \r\n\r\n有些读者可能还会有疑问：哈希冲突链上的元素只能通过指针逐一查找再操作。当往哈希表插入数据很多，冲突也会越多，冲突链表就会越长，那查询效率就会降低了。\r\n\r\n为了保持高效，Redis 会对***\\*哈希表做rehash\\****操作，也就是增加哈希桶，减少冲突。为了rehash更高效，Redis还默认使用了两个全局哈希表，一个用于当前使用，称为主哈希表，***\\*一个用于扩容，称为备用哈希表\\****。\r\n\r\n## ***\\*18. 在生成 RDB期间，Redis 可以同时处理写请求么？\\****\r\n\r\n***\\*可以的\\****，Redis提供两个指令生成RDB，分别是***\\*save和bgsave\\****。\r\n\r\n· 如果是save指令，会阻塞，因为是主线程执行的。\r\n\r\n· 如果是bgsave指令，是fork一个子进程来写入RDB文件的，快照持久化完全交给子进程来处理，父进程则可以继续处理客户端的请求。\r\n\r\n## ***\\*19. Redis底层，使用的什么协议?\\****\r\n\r\nRESP，英文全称是Redis Serialization Protocol,它是专门为redis设计的一套序列化协议. 这个协议其实在redis的1.2版本时就已经出现了,但是到了redis2.0才最终成为redis通讯协议的标准。\r\n\r\nRESP主要有***\\*实现简单、解析速度快、可读性好\\****等优点。\r\n\r\n## ***\\*20. 布隆过滤器\\****\r\n\r\n应对***\\*缓存穿透\\****问题，我们可以使用***\\*布隆过滤器\\****。布隆过滤器是什么呢？\r\n\r\n布隆过滤器是一种占用空间很小的数据结构，它由一个很长的二进制向量和一组Hash映射函数组成，它用于检索一个元素是否在一个集合中，空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。\r\n\r\n***\\*布隆过滤器原理是？\\**** 假设我们有个集合A，A中有n个元素。利用***\\*k个哈希散列\\****函数，将A中的每个元素***\\*映射\\****到一个长度为a位的数组B中的不同位置上，这些位置上的二进制数均设置为1。如果待检查的元素，经过这k个哈希散列函数的映射后，发现其k个位置上的二进制数***\\*全部为1\\****，这个元素很可能属于集合A，反之，***\\*一定不属于集合A\\****。\r\n\r\n来看个简单例子吧，假设集合A有3个元素，分别为{***\\*d1,d2,d3\\****}。有1个哈希函数，为***\\*Hash1\\****。现在将A的每个元素映射到长度为16位数组B。\r\n\r\n![img](Redis经典面试题.assets/wps5919.tmp.png) \r\n\r\n我们现在把d1映射过来，假设Hash1（d1）= 2，我们就把数组B中，下标为2的格子改成1，如下：\r\n\r\n![img](Redis经典面试题.assets/wps591A.tmp.png) \r\n\r\n我们现在把***\\*d2\\****也映射过来，假设Hash1（d2）= 5，我们把数组B中，下标为5的格子也改成1，如下：\r\n\r\n![img](Redis经典面试题.assets/wps591B.tmp.png) \r\n\r\n接着我们把***\\*d3\\****也映射过来，假设Hash1（d3）也等于 2，它也是把下标为2的格子标1：\r\n\r\n![img](Redis经典面试题.assets/wps591C.tmp.png) \r\n\r\n因此，我们要确认一个元素dn是否在集合A里，我们只要算出Hash1（dn）得到的索引下标，只要是0，那就表示这个元素***\\*不在集合A\\****，如果索引下标是1呢？那该元素***\\*可能\\****是A中的某一个元素。因为你看，d1和d3得到的下标值，都可能是1，还可能是其他别的数映射的，布隆过滤器是存在这个***\\*缺点\\****的：会存在***\\*hash碰撞\\****导致的假阳性，判断存在误差。\r\n\r\n如何***\\*减少这种误差\\****呢？\r\n\r\n· 搞多几个哈希函数映射，降低哈希碰撞的概率\r\n\r\n· 同时增加B数组的bit长度，可以增大hash函数生成的数据的范围，也可以降低哈希碰撞的概率\r\n\r\n我们又增加一个Hash2***\\*哈希映射\\****函数，假设Hash2（d1）=6,Hash2（d3）=8,它俩不就不冲突了嘛，如下：\r\n\r\n![img](Redis经典面试题.assets/wps592C.tmp.png) \r\n\r\n即使存在误差，我们可以发现，布隆过滤器并***\\*没有存放完整的数据\\****，它只是运用一系列哈希映射函数计算出位置，然后填充二进制向量。如果***\\*数量很大的话\\****，布隆过滤器通过极少的错误率，换取了存储空间的极大节省，还是挺划算的。\r\n\r\n目前布隆过滤器已经有相应实现的开源类库啦，如***\\*Google的Guava类库\\****，Twitter的 Algebird 类库，信手拈来即可，或者基于Redis自带的Bitmaps自行实现设计也是可以的。\r\n\r\n '},"78e1":function(n,r,e){"use strict";e.r(r),r["default"]='# ***\\*万字长文，38 图爆肝 Redis 基础！\\****\r\n\r\n# ***\\*00 前言\\****\r\n\r\nRedis 在互联网技术存储方面的使用可以说是非常广泛了，只要是接触过 Java 开发的朋友就算你没用过，都会听过它。在面试也是非常高频的一个知识点。\r\n\r\n最近，我的的小弟***\\*小胖和老王\\****就对 Redis 非常感兴趣；我推荐它一本书《Redis设计与实现》。谁知这货说看不下去，非要我来总结一波。所以本文算是给***\\*小胖和老王\\****的学习资料，也是我自己的学习笔记。希望对你有帮助。\r\n\r\n还是老规矩，先上张脑图。全文 13274 字，从下午 2 点爆肝到晚上 9 点，先上张思维导图镇楼：\r\n\r\n![img](Redis 基础.assets/wpsCB7A.tmp.png) \r\n\r\n## ***\\*0.1 往期精彩\\****\r\n\r\n[1、小胖问我：select 语句是怎么执行的？](https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/lRY7b9iS_xDDuyKNQKUWSg)\r\n\r\n[2、女朋友问我：MySQL 索引的原理是怎样的？](https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/ZDM_ttWCstw0mUwGtUEciw)\r\n\r\n[3、小胖问我：MySQL 日志到底有啥用？](https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/yG2pQW7qkTPF4TLBk8qgwQ)\r\n\r\n[4、老王问我：MySQL 事务与 MVCC 原理是怎样的？](https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/l62CAZ55ZU9f9fsLOQR71A)\r\n\r\n[5、女朋友问我：MySQL 的锁机制是怎样的？](https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/cuD8QiadO64VcSncpY18KQ)\r\n\r\n# ***\\*01 什么是 Redis？\\****\r\n\r\n官方是这么描述的：\r\n\r\nRedis （用 C 语言实现的）是一个开源的，基于内存的数据结构存储，可用作于数据库、缓存、消息中间件。\r\n\r\n信息简洁明了，一下就知道了三个点：***\\*基于内存、用作缓存、多种数据结构\\****。\r\n\r\n的了，那就从这三个方面开始研究呗。\r\n\r\n## ***\\*1.0 为什么要用 Redis 做缓存？\\****\r\n\r\n上面说了，用作缓存。有些小伙伴可能会问：有 MySQL 数据库就得了呗？干嘛还要缓存？而且为啥要用 Redis 做？Map 不行嘛？\r\n\r\n· 第一、二个问题，都知道 MySQL 数据是存在磁盘的，而 CPU 访问磁盘是非常慢的。如果遇到并发高的时候，所有线程每次都要访问磁盘，估计得挂。\r\n\r\n到底有多慢？请看链接：zhuanlan.zhihu.com/p/24726196\r\n\r\nRedis 和 Map 做下对比，就知道为啥不合适了。\r\n\r\n· Map 是本地缓存，如果在多台机器部署，必须每个机器都要复制一份，否则造成缓存不一致；Redis 是分布式缓存，部署在多台机器，也是用的同一份缓存，保持了一致性，问题不大。\r\n\r\n· Map 做缓存，数据量大的话会导致 JVM 内存飙升，进而拖垮程序，并且 JVM 挂了，还会导致数据丢失；Redis 可以用更大容量的内存（看你的配置，即几十G都没问题）做缓存，并且还可以持久化到磁盘。\r\n\r\n# ***\\*02 Redis 的数据结构\\****\r\n\r\n你可能第一反应不就 "String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）么？"，太简单了，我都会。\r\n\r\n老铁你错了，你说的是 Redis 的数据类型只有 5 种，也就是他的表现形式。而我说的数据结构是底层的，***\\*有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组\\****，它们的对应关系如下：\r\n\r\n![img](Redis 基础.assets/wpsCB8B.tmp.png) \r\n\r\n由上图可知 String 类型的底层实现只有一种数据结构，而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构都是集合。\r\n\r\n看到这里，你可能又有疑问了。这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？\r\n\r\n## ***\\*2.0 键和值用什么结构组织？\\****\r\n\r\n实际上，***\\*Redis 使用了一个哈希表来保存所有键值对。它的存储是以 key-value 的形式的。 key 一定是字符串，value 可以是 string、list、hash、set、sortset 中的随便一种\\****。\r\n\r\n***\\*一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。每个哈希桶中保存了键值对数据，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针\\****。这点从下图可以看出：\r\n\r\n![img](Redis 基础.assets/wpsCB9B.tmp.png) \r\n\r\n**哈希桶中的 entry 元素中保存了 *key 和 value 指针，分别指向了实际的键和值，这样一来，即使值是一个集合，也可以通过 value 指针被查找到。\r\n\r\nredis 的键值都是 redisObject 对象，即在创建时会生成一个用于键名的 redisObject 对象和一个用于键值的 redisObject 对象。这点从源码也可以看出来：\r\n\r\n***\\*typedef\\**** ***\\*struct\\**** ***\\*redisObject\\**** {\r\n\r\n  **// 类型**\r\n\r\n  ***\\*unsigned\\**** type:4;\r\n\r\n  \r\n\r\n  **// 编码**\r\n\r\n  ***\\*unsigned\\**** encoding:4;\r\n\r\n  \r\n\r\n  **// 指向数据的指针**\r\n\r\n  ***\\*void\\**** *ptr;\r\n\r\n \r\n\r\n  **// 记录对象最后一次被程序访问时间，用于计算空转时长(当前时间-lru)**\r\n\r\n  ***\\*unsigned\\**** lru:22; **/\\* lru time (relative to server.lruclock) \\*/**\r\n\r\n  \r\n\r\n  **// 引用计数，用于内存回收**\r\n\r\n  ***\\*int\\**** refcount;\r\n\r\n} robj;复制代码\r\n\r\n也就是说上图 entry 中的健值指针就分别指向这样一个 redisObject。***\\*其中 type、 encoding 和 ptr 是最重要的三个属性\\****。type 记录了对象所保存的值的类型，它的值可能是以下常量的其中一个。\r\n\r\n**/***\r\n\r\n *** 对象类型**\r\n\r\n ***/*****\\*#define REDIS_STRING 0\\****  ***\\**// 字符串\\**\\******\\*#define REDIS_LIST 1\\****   ***\\**// 列表\\**\\******\\*#define REDIS_SET 2\\****   ***\\**// 集合\\**\\******\\*#define REDIS_ZSET 3\\****   ***\\**// 有序集\\**\\******\\*#define REDIS_HASH 4\\****   ***\\**// 哈希表\\**\\***复制代码\r\n\r\nencoding 记录了 对象所保存的值的编码，它的值可能是以下常量的其中一个.\r\n\r\n**/***\r\n\r\n *** 对象编码**\r\n\r\n ***/*****\\*#define REDIS_ENCODING_RAW 0\\****       ***\\**// 编码为字符串\\**\\******\\*#define REDIS_ENCODING_INT 1\\****       ***\\**// 编码为整数\\**\\******\\*#define REDIS_ENCODING_HT 2\\****       ***\\**// 编码为哈希表\\**\\******\\*#define REDIS_ENCODING_ZIPMAP 3\\****     ***\\**// 编码为 zipmap\\**\\******\\*#define REDIS_ENCODING_LINKEDLIST 4\\****   ***\\**// 编码为双端链表\\**\\******\\*#define REDIS_ENCODING_ZIPLIST 5\\****     ***\\**// 编码为压缩列表\\**\\******\\*#define REDIS_ENCODING_INTSET 6\\****     ***\\**// 编码为整数集合\\**\\******\\*#define REDIS_ENCODING_SKIPLIST 7\\****    ***\\**// 编码为跳跃表\\**\\***复制代码\r\n\r\n比如，我们在 redis 里面 put ("狗哥",666)，在 redisObject 实际上是这样存放的：\r\n\r\n![img](Redis 基础.assets/wpsCB9C.tmp.png) \r\n\r\n## ***\\*2.1 SDS 简单动态字符串\\****\r\n\r\n简单动态字符串 (Simple dynamic string,SDS)\r\n\r\n跟传统的 C 语言字符串不一样，Redis 使用了 SDS 来构建自己的字符串对象，源码如下：\r\n\r\n***\\*struct\\**** ***\\*sdshdr\\****{\r\n\r\n \r\n\r\n  **// 字节数组，用于保存字符串**\r\n\r\n  ***\\*char\\**** buf[];\r\n\r\n \r\n\r\n  **// 记录buf数组中已使用的字节数量，也是字符串的长度**\r\n\r\n  ***\\*int\\**** len;\r\n\r\n \r\n\r\n  **// 记录buf数组未使用的字节数量**\r\n\r\n  ***\\*int\\**** free;\r\n\r\n}复制代码\r\n\r\n图示：\r\n\r\n![img](Redis 基础.assets/wpsCB9D.tmp.png) \r\n\r\nbuf属性是一个char类型的数组，最后一个字节保存了空字符\'\\0\'，不算入 len 长度。\r\n\r\n### ***\\*2.1.0 为什么使用 SDS？\\****\r\n\r\nSDS 比 C 字符串好在哪？\r\n\r\n**·** ***\\*常数复杂度获取字符串长度\\****：C 字符串不记录长度，统计长度只能逐个遍历字符，复杂度是 O(N)；而 SDS 在 len 属性中记录了自身长度，复杂度仅为 O(1)。\r\n\r\n**·** ***\\*不会发生缓冲区溢出\\****：SDS 不会发生溢出的问题，如果修改 SDS 时，空间不足。先会扩展空间，再修改！(***\\*内部实现了动态扩展机制\\****)。\r\n\r\n· SDS 可以***\\*减少内存分配的次数 (空间预分配 & 惰性空间释放)\\****。在扩展空间时，除了分配修改时所必要的空间，还会分配额外的空闲空间 (free 属性)。\r\n\r\n· SDS 是***\\*二进制安全的\\****，所有 SDS API 都会以处理二进制的方式来处理 SDS 存放在 buf 数组里的数据。\r\n\r\n## ***\\*2.2 链表\\****\r\n\r\n链表，大家都很熟悉了吧？在 Java 中 LinkedList 的底层数据结构就是链表 + 数组实现的。那 Redis 中的链表是怎样的呢？\r\n\r\n按照惯例，上源码。它使用 listNode 结构（源码位于 adlist.h）表示链表的每个节点：\r\n\r\n***\\*typedef\\**** strcut listNode{\r\n\r\n  **//前置节点**\r\n\r\n  strcut listNode  *pre;\r\n\r\n \r\n\r\n  **//后置节点**\r\n\r\n  strcut listNode  *pre;\r\n\r\n \r\n\r\n  **//节点的值**\r\n\r\n  ***\\*void\\**** *value;\r\n\r\n}listNode复制代码\r\n\r\n多个 listNode 可以通过 prev 和 next 指针组成一个双向链表，像这样：\r\n\r\n![img](Redis 基础.assets/wpsCB9E.tmp.png) \r\n\r\n节点表示出来了，整个链表又该怎么表示呢？Redis 使用 list 结构（源码位于 adlist.h）来构建链表，上源码：\r\n\r\n***\\*typedef\\**** ***\\*struct\\**** ***\\*list\\****{\r\n\r\n \r\n\r\n  **//表头结点**\r\n\r\n  listNode  *head;\r\n\r\n \r\n\r\n  **//表尾节点**\r\n\r\n  listNode  *tail;\r\n\r\n \r\n\r\n  **//链表长度**\r\n\r\n  ***\\*unsigned\\**** ***\\*long\\**** len;\r\n\r\n \r\n\r\n  **//节点值复制函数**\r\n\r\n  ***\\*void\\**** *(*dup) (viod *ptr);\r\n\r\n \r\n\r\n  **//节点值释放函数**\r\n\r\n  ***\\*void\\**** (*free) (viod *ptr);\r\n\r\n \r\n\r\n  **//节点值对比函数**\r\n\r\n  ***\\*int\\**** (*match) (***\\*void\\**** *ptr,***\\*void\\**** *key);\r\n\r\n \r\n\r\n}list复制代码\r\n\r\n![img](Redis 基础.assets/wpsCB9F.tmp.png) \r\n\r\n### ***\\*2.2.0 Redis 链表的特性\\****\r\n\r\n· 双端：有 prev 和 next 两个指针；可以前后移动。\r\n\r\n· 无环：链表不闭环，prev 和 next 都指向 null，链表访问以 null 为终点。\r\n\r\n· 获取带表头指针、表尾指针、节点数量的时间复杂度均为 O (1)。\r\n\r\n· 链表使用 void * 指针来保存节点值，可以保存各种不同类型的值。\r\n\r\n## ***\\*2.3 哈希表\\****\r\n\r\n哈希表，大家也都不陌生吧？在 Java 中哈希表的底层数据结构就是数组 + 链表实现的。那 Redis 中的哈希表是怎样实现的呢？\r\n\r\n按照惯例，上源码。哈希表使用 dictht 结构（源码位于 dict.h）表示哈希表，源码如下：\r\n\r\n***\\*typedef\\**** ***\\*struct\\**** ***\\*dictht\\****{\r\n\r\n​\t**// 哈希表数组**\r\n\r\n​\tdictEntry **table;  \r\n\r\n \r\n\r\n​\t**// 哈希表大小，也即 table 大小**\r\n\r\n​\t***\\*unsigned\\**** ***\\*long\\**** size;   \r\n\r\n \r\n\r\n​\t**// 哈希表大小掩码，用于计算索引值**\r\n\r\n​\t**// 总是等于size-1**\r\n\r\n​\t***\\*unsigned\\**** ***\\*long\\**** sizemark;   \r\n\r\n \r\n\r\n  **// 哈希表已有节点数量**\r\n\r\n​\t***\\*unsigned\\**** ***\\*long\\**** used;\r\n\r\n}dictht复制代码\r\n\r\nsizemark 和哈希值决定一个键应该被放到 table 数组的那个索引上。PS：就是 Java 中计算哈希值决定位置的方法。\r\n\r\n图示一个大小为 4 的空哈希表（不包含任何键值）\r\n\r\n![img](Redis 基础.assets/wpsCBA0.tmp.png) \r\n\r\n哈希表节点使用 dictEntry 结构表示，每个 dictEntry 都保存着一个键值对。源码如下：\r\n\r\n ***\\*typedef\\**** ***\\*struct\\**** ***\\*dictEntry\\**** {\r\n\r\n​\t**// 键**\r\n\r\n​\t***\\*void\\**** *key;\r\n\r\n \r\n\r\n​\t**// 值**\r\n\r\n​\t***\\*union\\**** {\r\n\r\n​\t\t***\\*void\\**** *val;\r\n\r\n​\t\tuint64_tu64;\r\n\r\n​\t\tint64_ts64;\r\n\r\n​\t}v; \r\n\r\n \r\n\r\n​\t**// 指向下个哈希节点，组成链表**\r\n\r\n​\t***\\*struct\\**** ***\\*dictEntry\\**** ****\\*next\\****;\r\n\r\n}dictEntry;复制代码\r\n\r\nkey 解释得很清楚了；说说 v 属性，它 保存着键值对中的值，可以是一个指针，或者是一个 uint64_t 整数，又或者是一个 int64_t 整数。\r\n\r\n***\\*next 则是执行下一个哈希表节点的指针，可以将多个哈希值相同的键值对连接在一起作为一个链表，以此来解决键冲突（collision）的问题\\****。PS：参考 Java 中 HashMap 是怎么解决冲突的。旧文：[《HashMap 源码解读》](https://juejin.cn/post/6953499916027035684/)有提过。\r\n\r\n图示通过 next 指针把相同索引值的键 k1 和 k0 连接在一起。\r\n\r\n![img](Redis 基础.assets/wpsCBB1.tmp.png) \r\n\r\n为了更好实现 rehash（扩容）；Redis 又在哈希表之上封装了一层，称之为字典。由 dict 结构表示，源码如下：\r\n\r\n***\\*typedef\\**** ***\\*struct\\**** ***\\*dict\\**** {\r\n\r\n  **// 类型特定函数**\r\n\r\n  dictType *type;\r\n\r\n  **// 私有数据**\r\n\r\n  ***\\*void\\**** * privdata; \r\n\r\n  **// 哈希表，代表两个哈希表**\r\n\r\n  dictht ht[2];\r\n\r\n  **// rehash索引**\r\n\r\n  **// 当rehash不在进行时， 值为 - 1** \r\n\r\n  in trehashidx; **/\\*rehashing not in pro gress if rehashidx==-1\\*/**\r\n\r\n}dict;\r\n\r\n \r\n\r\n\\-------------------------------------------------------\r\n\r\n***\\*typedef\\**** ***\\*struct\\**** ***\\*dictType\\****{\r\n\r\n  **//计算哈希值的函数**\r\n\r\n  ***\\*unsigned\\**** ***\\*int\\**** (*hashFunction)(***\\*const\\**** ***\\*void\\**** * key);\r\n\r\n \r\n\r\n  **// 复制键的函数**\r\n\r\n  ***\\*void\\**** *(*keyDup)(***\\*void\\**** ****\\*private\\****, ***\\*const\\**** ***\\*void\\**** *key);\r\n\r\n \r\n\r\n  **// 复制值的函数**\r\n\r\n  ***\\*void\\**** *(*valDup)(***\\*void\\**** ****\\*private\\****, ***\\*const\\**** ***\\*void\\**** *obj);  \r\n\r\n \r\n\r\n  **// 对比键的函数**\r\n\r\n  ***\\*int\\**** (*keyCompare)(***\\*void\\**** *privdata , ***\\*const\\**** ***\\*void\\**** *key1, ***\\*const\\**** ***\\*void\\**** *key2)\r\n\r\n \r\n\r\n  **// 销毁键的函数**\r\n\r\n  ***\\*void\\**** (*keyDestructor)(***\\*void\\**** ****\\*private\\****, ***\\*void\\**** *key);\r\n\r\n \r\n\r\n  **// 销毁值的函数**\r\n\r\n  ***\\*void\\**** (*valDestructor)(***\\*void\\**** ****\\*private\\****, ***\\*void\\**** *obj);  \r\n\r\n}dictType复制代码\r\n\r\ntype 属性和 privdata 属性是针对不同类型的键值对，为创建多态字典而设置的。\r\n\r\n· type 是一个指向 dictType 的指针，每个 dictType 保存了一簇用于操作特定类型键值对的函数，Redis 为用途不同的字典设置不同的类型特定函数\r\n\r\n· 而 privdata 则保存了传给类型特定函数的可选参数\r\n\r\n**·** ***\\*ht 是包含了两个哈希表的数组； ht[0] 存放真实数据，ht[1] 在对 ht[0] 进行 rehash（扩容）时使用\\****。\r\n\r\n最终，***\\*你会发现其实所谓的字典就是两个哈希表组成的\\****。图式结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCBB2.tmp.png) \r\n\r\n### ***\\*2.3.0 哈希冲突\\****\r\n\r\n当往哈希表写入大量数据时，不可避免的就出现多个 key 计算出来的哈希值相同。也就是多个不同的 key 需要放到同一个哈希桶，这就是所谓的***\\*哈希冲突\\****。\r\n\r\n而 Redis 解决哈希冲突的手段很 Java 一样，都是链式哈希：***\\*同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接\\****。\r\n\r\n![img](Redis 基础.assets/wpsCBB3.tmp.png) \r\n\r\n如图，假设 entry1、entry2、entry3 的哈希值都是 3 ；那么他们将存放在下标为 3 的哈希桶里面，并转换成链表。\r\n\r\nPS：没懂哈希冲突的看旧文。旧文：[《HashMap 源码解读》](https://juejin.cn/post/6953499916027035684/)有详细例子解析。\r\n\r\n当不断发生哈希冲突，链表越来越长，影响查询性能时，Redis 就需要 rehash。\r\n\r\n### ***\\*2.3.1 rehash（扩容）\\****\r\n\r\nRedis 开始执行 rehash，这个过程分为三步：\r\n\r\n· 1、给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；\r\n\r\n· 2、把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；\r\n\r\n· 3、释放哈希表 1 的空间。\r\n\r\n如此，就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。\r\n\r\n你肯定以为这样就完美了？但还有坑，***\\*当哈希表 1 数据量很大，如果一次性复制就会造成线程阻塞，无法服务其他请求\\****。Redis 不允许这种事发生，因此使用了***\\*渐进式 rehash\\****。\r\n\r\nPS：没懂 rehash 的看旧文。旧文：《HashMap 源码解读》有详细例子解析。\r\n\r\n### ***\\*2.3.2 渐进式 rehash\\****\r\n\r\n啥是渐进式 rehash ？\r\n\r\n在第二步拷贝数据时，Redis 仍然正常处理客户端请求，***\\*每处理一个请求，顺带从哈希表 1 中的第一个索引位置开始，把这个位置上所有的 entry 复制到哈希表 2 中，下个请求就复制位置 2\\****；直至全部复制完成。\r\n\r\n过程如下图所示：\r\n\r\n![img](Redis 基础.assets/wpsCBB4.tmp.png) \r\n\r\n具体到代码，它的过程是这样的：\r\n\r\n· 1、在字典中维持一个索引计数器变量 rehashidx，并将设置为 0，表示 rehash 开始。\r\n\r\n· 2、在 rehash 期间，客户端每次对字典进行 CRUD 操作时，会将 ht [0] 中 rehashidx 索引上的值 rehash 到 ht [1]，操作完成后 rehashidx+1。\r\n\r\n· 3、字典操作不断执行，最终在某个时间点，所有的键值对完成 rehash，这时将 rehashidx 设置为 - 1，表示 rehash 完成\r\n\r\n说到这，你可能还有以下几点疑问？\r\n\r\n***\\*只有在操作字典的时候才进行复制数据吗？如果客户端只操作一次字段是不是就完不成 rehash 了？\\****\r\n\r\n渐进式 rehash 执行时，除了根据针对字典的 CRUD 操作来进行数据迁移，***\\*Redis 本身还会有一个定时任务在执行 rehash\\****，如果没有针对字典的请求时，这个定时任务会周期性地（例如每 100ms 一次）搬移一些数据到新的哈希表。\r\n\r\n***\\*渐进式 rehash，CRUD 究竟在哪个哈希表操作呢？\\****\r\n\r\n在渐进式 rehash 过程中，字典会同时使用两个哈希表 ht [0] 和 ht [1]，所有的 CRUD 操作也会在两个哈希表进行。\r\n\r\n比如要查找一个键时，服务器会优先查找 ht [0]，如果不存在，再查找 ht [1]。当执行***\\*新增操作\\****时，新的键值对一律保存到 ht [1]，不再对 ht [0] 进行任何操作，以保证 ht [0] 的键值对数量只减不增，最后变为空表。\r\n\r\n## ***\\*2.4 跳跃表\\****\r\n\r\n跳跃表在 Java 中很少接触到，大家对这个知识点也是挺陌生的。之前在学习数据结构是看到过小灰的一篇文章，写得通俗易懂，大家可以看下，建议看完再往下看。\r\n\r\n[mp.weixin.qq.com/s/COBdoHWDh…](https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/COBdoHWDhlw4rmG_fGFhSA)\r\n\r\n跳跃表 (shiplist) 是实现 sortset (有序集合) 的底层数据结构之一；除此以外，在集群节点中也有用到它。\r\n\r\nRedis 的跳跃表由 zskiplistNode 和 zskiplist 两个结构定义，源码位于 redis.h 文件中。***\\*其中前者是跳跃表的结构；后者的作用是保存跳跃表的节点数量与头、尾节点的指针等信息\\****。\r\n\r\ntypeof ***\\*struct\\**** ***\\*zskiplistNode\\**** {\r\n\r\n  **// 后退指针**\r\n\r\n  ***\\*struct\\**** ***\\*zskiplistNode\\**** ****\\*backward\\****;\r\n\r\n  **// 分值**\r\n\r\n  ***\\*double\\**** score;\r\n\r\n  **// 成员对象**\r\n\r\n  robj *obj;\r\n\r\n  **// 层**\r\n\r\n​\t***\\*struct\\**** ***\\*zskiplistLevel\\**** {\r\n\r\n​    **// 前进指针**\r\n\r\n​    ***\\*struct\\**** ***\\*zskiplistNode\\**** ****\\*forward\\****;\r\n\r\n​\t\t**// 跨度**\r\n\r\n​\t\t***\\*unsigned\\**** ***\\*int\\**** span;\r\n\r\n​\t} level[];\r\n\r\n} zskiplistNode;复制代码\r\n\r\n如下图所示，展示了不同层高的跳跃表节点\r\n\r\n![img](Redis 基础.assets/wpsCBC5.tmp.png) \r\n\r\ntypeof ***\\*struct\\**** ***\\*zskiplist\\**** {\r\n\r\n  **// 表头节点，表尾节点**\r\n\r\n  ***\\*struct\\**** ***\\*skiplistNode\\**** ****\\*header\\****,****\\*tail\\****;\r\n\r\n  **// 表中节点数量**\r\n\r\n  ***\\*unsigned\\**** ***\\*long\\**** length;\r\n\r\n  **// 表中最大层数**\r\n\r\n  ***\\*int\\**** level;\r\n\r\n} zskiplist;复制代码\r\n\r\n下图展示了一个跳跃表示例：\r\n\r\n![img](Redis 基础.assets/wpsCBC6.tmp.png) \r\n\r\n图片最左边的是 zskiplist 结构，包含：\r\n\r\n· header：指向跳跃表的表头节点。\r\n\r\n· tail：指向跳跃表的表尾节点。\r\n\r\n· level：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。\r\n\r\n· length：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。\r\n\r\nzskiplist结构右方的是四个zskiplistNode结构， 包含：\r\n\r\n· 层：比如节点中的 L1、L2、L3 等，包括前进指针和跨度\r\n\r\n· 前进指针：用于访问位于表尾方向的其他节点\r\n\r\n· 跨度：记录了前进指针所指向节点和当前节点的距离\r\n\r\n· 后退指针：指向当前节点的前一个节点，从表尾向表头遍历\r\n\r\n· 分值：节点按各自分值从小到大排列\r\n\r\n· 成员对象：节点所保存的成员对象\r\n\r\n***\\*PS：跳跃表这块的内容比较多，比较难说清楚实现细节。具体的看上面的链接，以及《Redis 设计与实现》这本书（说得很好，微信读书网页版就有）\\****\r\n\r\n## ***\\*2.5 整数集合\\****\r\n\r\n整数集合是 Set（集合）的底层数据结构之一。 当 Set 只包含整数值元素，并且这个 Set 的元素数量不多时，Redis 就会使用整数集合作为 Set 的底层实现。\r\n\r\nRedis 使用了 intset 用于保存整数值集合，它保证了有序以及不重复。源码如下：\r\n\r\ntypeof ***\\*struct\\**** ***\\*intset\\**** {\r\n\r\n  **// 编码方式**\r\n\r\n  ***\\*unit32_t\\**** encoding;\r\n\r\n  **// 集合包含的元素数量**\r\n\r\n  ***\\*unit32_t\\**** lenght;\r\n\r\n  **// 保存元素的数组**\r\n\r\n  ***\\*int8_t\\**** contents[];\r\n\r\n} intset;复制代码\r\n\r\n一个保存了 5 个整数的集合如下所示：\r\n\r\n![img](Redis 基础.assets/wpsCBC7.tmp.png) \r\n\r\nlength 就不说了，主要说下 contents 和 encoding 的关系； contents 的真正类型取决于encoding 的值：\r\n\r\n· INTSET_ENC_INT16\r\n\r\n· INTSET_ENC_INT32\r\n\r\n· INTSET_ENC_INT64\r\n\r\n这三个值分别对应 16、32、64 编码对应能存放的数字范围是不一样的。16 最小（-32768~~32767），32 在中间（-2147483648~~2147483647）64 最大（-9223372036854775808~9223372036854775807）。\r\n\r\n如下图所示为 INTSET_ENC_INT16 类型集合存放 5 位整数占用的空间：16 * 5\r\n\r\n![img](Redis 基础.assets/wpsCBC8.tmp.png) \r\n\r\n### ***\\*2.5.0 升级操作\\****\r\n\r\n如果 contents 本来保存 1、3、5 三个整数值，后面加一个 2147483647456。\r\n\r\n那么只有 2147483647456 是真正需要 int64_t 类型来保存的，而其他的 1、3、5 都可以用 int16_t 类型来保存；***\\*这时是整体升级，所有元素都会被升级为 int64_t 类型\\****。\r\n\r\n也就是说本来是 int16_t 类型的集合，要放入大于本身的整数。就需要升级，步骤如下：\r\n\r\n· 1、根据新元素类型拓展整数集合底层数组的空间并为新元素分配空间。\r\n\r\n· 2、将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放到正确的位上，需要维持底层数组的有序性质不变。\r\n\r\n· 3、将新元素添加到底层数组。\r\n\r\n举个栗子：\r\n\r\n1、原来是数组是 INTSET_ENC_INT16 类型 3 位，占用 48 位空间；\r\n\r\n![img](Redis 基础.assets/wpsCBC9.tmp.png) \r\n\r\n2、插入整数 65535，超出 INTSET_ENC_INT16 范围；升级为 INTSET_ENC_INT32 。需要的空间也从 48 加到 128 位。如下所示：新分配空间 = 128 - 48 = 80\r\n\r\n![img](Redis 基础.assets/wpsCBCA.tmp.png) \r\n\r\n3、元素 3 排名第三，移动到 contents 索引 2 位置；其他类似，元素 2 移动到索引 1 位置；元素 1 移动到索引 0 位置\r\n\r\n![img](Redis 基础.assets/wpsCBCB.tmp.png) \r\n\r\n4、最后添加新元素 65535 即可完成升级。\r\n\r\n注意点：***\\*整数集合只支持升级、不支持降级\\****。\r\n\r\n## ***\\*2.6 压缩列表\\****\r\n\r\n压缩列表是 list 和 hash 的底层实现之一，当 list 只包含少量元素，并且每个元素都是小整数值，或者是比较短的字符串，压缩列表会作为 list 的底层实现。\r\n\r\n压缩列表（ziplist）是 Redis 为***\\*节约内存\\****而开发，它的理念是***\\*多大元素用多大内存\\****。\r\n\r\n如下图，根据每个节点的实际存储的内容决定内存的大小，第一个节点占用 5 字节，第二个节点占用 5 字节，第三个节点占用 1 字节，第四个节点占用 4 字节，第五个节点占用 3 字节。\r\n\r\n![img](Redis 基础.assets/wpsCBCC.tmp.png) \r\n\r\n图示为 ziplist 的结构：它类似于一个数组，不同的是它在表头有三个字段 zlbytes、zltail 和 zllen；分别表示列表长度、列表尾的偏移量和元素的个数；表尾有 zlend，列表结束的标识。\r\n\r\n![img](Redis 基础.assets/wpsCBDC.tmp.png) \r\n\r\n### ***\\*2.6.0 节点构成\\****\r\n\r\n图示一个压缩列表中一个节点的构成：\r\n\r\n![img](Redis 基础.assets/wpsCBDD.tmp.png) \r\n\r\n· previous_entry_length：记录前一个节点的长度\r\n\r\n· encoding：编码，控制 content 的类型和长度；分为字节数组编码和整数编码\r\n\r\n· content：保存节点值，可以是一个字节数组或整数\r\n\r\n### ***\\*2.6.1 压缩列表的查找\\****\r\n\r\n![img](Redis 基础.assets/wpsCBDE.tmp.png) \r\n\r\n如果查找的是第一个元素或最后一个元素，可通过表头三个字段的长度直接定位，复杂度是 O (1)。而查找其他元素时，只能逐个查找，复杂度是 O (N) 。\r\n\r\n倒序遍历：首先指针通过 zltail 偏移量指向表尾节点，然后通过指向***\\*节点记录的前一个节点的长度依次向前遍历访问整个压缩列表\\****。\r\n\r\n# ***\\*03 数据类型与数据结构\\****\r\n\r\n还记得文章开头那张数据类型与底层数据结构的对应关系图吗？长这样：\r\n\r\n![img](Redis 基础.assets/wpsCBDF.tmp.png) \r\n\r\nRedis 这种对应关系实际上是由 redisObject 的 type（类型）和 encoding （编码）共同决定的，详细对应关系如下：\r\n\r\n![img](Redis 基础.assets/wpsCBF0.tmp.png) \r\n\r\n下面来具体介绍下，什么条件下使用那种类型实现对应的对象。比如：String 什么情况下用 int 编码实现？什么情况下用 embstr 编码实现？什么情况下用 raw 编码实现呢？\r\n\r\n## ***\\*3.0 字符串（String）对象\\****\r\n\r\n从上图得知，String 有 int、raw、embst 三种编码格式：\r\n\r\n· int：整数值，可以用 long 类型表示，使用整数值保存对象\r\n\r\n· raw：字符串值且长度 > 32字节，使用 SDS 保存对象\r\n\r\n· embstr：字符串值且长度 < 32字节，使用 embstr 编码的 SDS 保存对象\r\n\r\nPS：对于浮点数（long double 类型表示的），Redis 会将浮点数转换成字符串值；最终视长度决定用那种编码（embstr 或 raw）保存。取出时，再将其转成浮点值。\r\n\r\n![img](Redis 基础.assets/wpsCBF1.tmp.png) \r\n\r\n### ***\\*3.0.0 embstr 和 raw 有啥区别？\\****\r\n\r\n· raw 分配内存和释放内存的次数是***\\*两次\\****，embstr 是一次\r\n\r\n· embstr 编码的数据保存在一块***\\*连续的内存\\****里面\r\n\r\n### ***\\*3.0.1 编码的转换\\****\r\n\r\n· int 类型的字符串，当保存的不再是***\\*整数值\\****，将转换成 raw 类型\r\n\r\n· embstr 类型的字符串是***\\*只读的\\****，修改时会转换成 raw 类型。原因：Redis 没有为 embstr 提供修改程序，所以它是只读的；要修改只能先转成 raw。\r\n\r\n## ***\\*3.1 列表（list）对象\\****\r\n\r\n还是从上图得知，列表的编码可以是 ziplist 或 linkedlist：\r\n\r\n· ziplist：所有元素长度都小于 64 字节且元素数量少于 512 个\r\n\r\no 以上两个条件的上限值可以通过配置文件的 list-max-ziplist-value和list-max-ziplist-entries修改\r\n\r\n· linkedlist：不满足上述条件时，将从 ziplist 转换成 linkedlist\r\n\r\n### ***\\*3.1.0 区别\\****\r\n\r\n执行 RPUSH 命令将创建一个列表对象，比如：\r\n\r\nredis> RPUSH numbers 1 "three" 5\r\n\r\n(***\\*integer\\****) 3复制代码\r\n\r\n如果 numbers 使用 ziplist 编码，对象结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCBF2.tmp.png) \r\n\r\n否则使用 linkedlist，就是双端链表作为底层实现。结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCBF3.tmp.png) \r\n\r\n## ***\\*3.2 哈希（hash）对象\\****\r\n\r\n又是从上图得知，哈希的编码可以是 ziplist 或 hashtable：\r\n\r\n· ziplist：哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节且键值对数量小于 512\r\n\r\no 以上两个条件的上限值可以通过配置文件的 hash-max-ziplist-value和hash-max-ziplist-entries修改\r\n\r\n· hashtable：不能满足上述条件，将从 ziplist 转成 hashtable\r\n\r\n### ***\\*3.2.0 区别\\****\r\n\r\n执行 HSET 命令，可以创建一个 hash 对象并保存数据：\r\n\r\nredis> HSET profile name "Tom"\r\n\r\n(***\\*integer\\****) 1\r\n\r\nredis> HSET profile age 25\r\n\r\n(***\\*integer\\****) 1\r\n\r\nredis> HSET profile career "Programmer"\r\n\r\n(***\\*integer\\****) 1复制代码\r\n\r\nziplist 保存的 hash 对象：\r\n\r\n![img](Redis 基础.assets/wpsCBF4.tmp.png) \r\n\r\n![img](Redis 基础.assets/wpsCBF5.tmp.png) \r\n\r\nhashtable 保存的 hash 对象：\r\n\r\n· 字典中每个键都是一个字符串对像，对象中保存键值对的键\r\n\r\n· 字典中每个值都是一个字符串对像，对象中保存键值对的值\r\n\r\n架构如下：\r\n\r\n![img](Redis 基础.assets/wpsCBF6.tmp.png) \r\n\r\n## ***\\*3.3 集合（set）对象\\****\r\n\r\n又又是从上图得知，哈希的编码可以是 intset 或 hashtable：\r\n\r\n· intset：集合对象保存的所有元素都是整数值且元素数量小于 512 个\r\n\r\no 以上两个条件的上限值可以通过配置文件的 set-max-intset-entries修改\r\n\r\n· hashtable：不能满足上述条件，将从 intset 转成 hashtable\r\n\r\n### ***\\*3.3.0 区别\\****\r\n\r\n使用 ***\\*SADD 命令\\****可构建一个 intset 编码的 set 对象并保存数据：\r\n\r\nredis> SADD numbers 1 3 5\r\n\r\n(***\\*integer\\****) 3复制代码\r\n\r\nintset 编码的集合对象结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCBF7.tmp.png) \r\n\r\n使用 ***\\*SADD 命令\\****可构建一个 hashtable 编码的 set 对象并保存数据：\r\n\r\nredis> SADD fruits "apple" "banana" "cherry"\r\n\r\n(***\\*integer\\****) 3复制代码\r\n\r\nhashtable 编码的 set 使用字典作为底层实现，每个键都是字符串对象，每个对象包含一个集合元素，***\\*字典值全部置为 null\\**** 。\r\n\r\nhashtable 编码的集合对象结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCBF8.tmp.png) \r\n\r\n## ***\\*3.4 有序集合（Sorted Set）对象\\****\r\n\r\n又又又是从上图得知，有序集合的编码可以是 ziplist 或 skiplist：\r\n\r\n· ziplist：保存的元素数量小于 128 个且所有元素长度都小于 64 字节\r\n\r\no 以上两个条件的上限值可以通过配置文件的 zset-max-ziplist-entries和zset-max-ziplist-value修改\r\n\r\n· skiplist：不能同时满足上述条件，将从 ziplist 转成 skiplist\r\n\r\n### ***\\*3.4.0 区别\\****\r\n\r\n使用 ***\\*ZADD\\**** 命令可以构建一个 Sorted Set 对象并保存数据：\r\n\r\nredis> ZADD price 8.5 apple 5.0 banana 6.0 cherry\r\n\r\n(***\\*integer\\****) 3复制代码\r\n\r\n![img](Redis 基础.assets/wpsCC09.tmp.png) \r\n\r\nziplist 编码实现的 Sorted Set 对象，每个集合元素使用两个相邻的节点保存，第一个节点是***\\*元素成员\\****，第二个节点是***\\*元素分值\\****。按分值***\\*从小到大\\****进行排序，结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCC0A.tmp.png) \r\n\r\nskiplist 编码实现的 Sorted Set 使用 ***\\*zset\\**** 作为底层实现，它包含***\\*跳跃表\\****和***\\*字典\\****，源码如下：\r\n\r\n***\\*typedef\\**** ***\\*struct\\**** ***\\*zset\\**** {\r\n\r\n  zskpilist *zsl;\r\n\r\n  dict *dict;\r\n\r\n}zset;复制代码\r\n\r\n大体结构如下：\r\n\r\n![img](Redis 基础.assets/wpsCC0B.tmp.png) \r\n\r\n· \r\n\r\n跳跃表 zsl 按分值从小到大保存所有集合元素；每个节点保存一个集合元素；object 属性保存元素成员、score 属性保存元素分值。目的：***\\*实现快速的范围查询操作\\****。\r\n\r\n· \r\n\r\n· \r\n\r\n字典 dict 创建一个从成员到分值的 key-value；字典中每个键值对都保存一个集合元素；键保存元素成员、值保存元素分值。目的：***\\*用 O(1) 复杂度 get 元素分值\\****。\r\n\r\n· \r\n\r\n最后，详细的结构如下所示：\r\n\r\n![img](Redis 基础.assets/wpsCC0C.tmp.png) \r\n\r\n听到这里有人可能有疑问：zset 结构同时使用***\\*跳跃表和字典\\****来保存有序集合元素，不会重复吗？\r\n\r\n不会，因为二者会通过***\\*指针\\****来共享同一个元素，并不会产生重复。\r\n\r\n为什么 skiplist 编码实现的有序集合要同时用跳跃表和字典实现？***\\*随便用一个行吗\\****？\r\n\r\n答案是：不好。我们来看看两种情况：\r\n\r\n· \r\n\r\n只用 dict ，可以保留以 O(1) 复杂度 get 成员分值；但***\\*字典是无序的\\****，所以***\\*每次进行范围操作都要对所有元素排序\\****；显然这是性能更低的。\r\n\r\n· \r\n\r\n· \r\n\r\n只用跳跃表，快速范围操作得以保留；但是没了字典，get 成员分值的复杂度将提高至 O(logN)，这也影响性能。\r\n\r\n· \r\n\r\n所以，Redis 为了把两者有点结合起来，采用了通过***\\*指针共享\\****的方式，使用两种数据结构实现。\r\n\r\n# ***\\*04 一些注意的点\\****\r\n\r\n## ***\\*4.0 Redis 如何执行命令\\****\r\n\r\nRedis 执行命令前，会先检查***\\*值对象类型\\****，判断***\\*键是否能执行该命令\\****；再检查***\\*值对象的编码方式\\****选择合适的命令执行。\r\n\r\n举个例子：列表对象有 ziplist 和 linkedlist 两种编码格式可用；前者通过 ziplist 的 API 执行命令、后者通过 linkedlist 的 API 执行命令。\r\n\r\n如果我们执行 LLEN 命令，Redis ***\\*第一步判断执行的命令是不是针对列表的\\****？是的话，第二步判断***\\*值的编码格式\\****，如果是 ziplist，使用 ***\\*ziplistLen 函数\\****操作；如果是 linkedlist 则使用 ***\\*listLength 函数\\****操作。\r\n\r\n## ***\\*4.1 Redis 内存回收机制与共享对象\\****\r\n\r\nRedis 为每个对象构建一个***\\*引用计数\\****属性，通过它可实现***\\*内存回收机制\\****（当一个对象的引用计数为 0 时，将会释放所占用内存）。\r\n\r\nRedis 会共享值为 ***\\*0 到 9999 的字符串对象\\****（这个值可能通过修改 redis.h 文件的 REDIS_SHARDED_INTEGER 常量修改）\r\n\r\nRedis 只共享字符串对象本身，***\\*为什么不共享包含字符串的对象\\****？\r\n\r\n能共享的前提是***\\*目标对象和共享对象完全相同\\****。要共享就需要验证两者是否相同？因为***\\*包含字符串的对象复杂度更高，验证消耗的 CPU 时间也更多\\****，而性能将会下降。\r\n\r\n## ***\\*4.2 lru 属性的作用\\****\r\n\r\nredisObject 的 lru 属性***\\*记录对象最后一次被访问的时间\\****，这个时间可以用于计算对象的空转时间（***\\*公式：当前时间 - lru 时间\\****）。\r\n\r\n# ***\\*05 巨人的肩膀\\****\r\n\r\n· 《Redis 设计与实现》\r\n\r\n· redis 源码：github.com/antirez/redis\r\n\r\n· redis 源码中文注释版：github.com/huangz1990/redis-3.0-annotated\r\n\r\n· cnblogs.com/Java3y/p/9870829.html\r\n\r\n· time.geekbang.org/column/article/268253\r\n\r\n· [www.fidding.me/article/108](https://link.juejin.cn/?target=http://www.fidding.me/article/108)\r\n\r\n· segmentfault.com/a/1190000019980165\r\n\r\n· cnblogs.com/chenchen0618/p/13260202.html\r\n\r\n# ***\\*06 总结\\****\r\n\r\n本文从常用的缓存技术讲起，深入 Redis 的数据类型与底层数据结构。第一小节从 Redis 和缓存聊起；第二节站在源码角度跟你分析 Redis 的 6 种数据结构：SDS、链表、哈希表、跳跃表、整数集合以及压缩列表的特性；第三节着重和你分享 5 种数据类型和 6 中底层结构的对应关系；第四节则是画龙点睛地和你分享了 Redis 是怎么执行命令的？怎么释放内存等问题。\r\n\r\n '},"7a2e":function(n,r,e){"use strict";e.r(r),r["default"]='# redis事务和mysql事务的区别\r\n\r\n**事务的四大特性**\r\n\r\n \r\n\r\n\r\n\r\nACID，指数据库事务正确执行的四个基本要素的缩写。包含：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。\r\n\r\n\r\n\r\n##  \r\n\r\n## ***\\*原子性(Atomicity)\\****\r\n\r\n \r\n\r\n\r\n\r\n说的是一个事物内所有操作就是最小的一个操作单元，要么全部成功，要么全部失败。这是最基本的特性，保证了因为一些其他因素导致数据库异常，或者宕机。\r\n\r\n\r\n\r\n## ***\\*一致性(Consistency)\\****\r\n\r\n \r\n\r\n\r\n\r\n一个事务可以封装状态改变（除非它是一个只读的）。事务必须始终保持系统处于一致的状态，不管在任何给定的时间并发事务有多少。\r\n\r\n \r\n\r\n一致性有下面特点：\r\n\r\n \r\n\r\n· \r\n\r\n如果一个操作触发辅助操作（级联，触发器），这些也必须成功，否则交易失败。\r\n\r\n· \r\n\r\n· \r\n\r\n如果系统是由多个节点组成，一致性规定所有的变化必须传播到所有节点（多主复制）。如果从站节点是异步更新，那么我们打破一致性规则，系统成为“最终一致性”。\r\n\r\n· \r\n\r\n· \r\n\r\n一个事务是数据状态的切换，因此，如果事务是并发多个，系统也必须如同串行事务一样操作。\r\n\r\n· \r\n\r\n \r\n\r\n在现实中，事务系统遭遇并发请求时，这种串行化是有成本的， Amdahl法则描述如下：它是描述序列串行执行和并发之间的关系。\r\n\r\n“一个程序在并行计算情况下使用多个处理器所能提升的速度是由这个程序中串行执行部分的时间决定的。”\r\n\r\n大多数数据库管理系统选择（默认情况下）是放宽一致性，以达到更好的并发性。\r\n\r\n\r\n\r\n## ***\\*隔离性\\****\r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n\r\n事物的隔离性，基于原子性和一致性，因为事物是原子化，量子化的，所以，事物可以有多个原子包的形式并发执行，但是，每个事物互不干扰。\r\n\r\n \r\n\r\n但是，由于多个事物可能操作同一个资源，不同的事物为了保证隔离性，会有很多锁方案，当然这是数据库的实现，他们怎么实现的，我们不必深究。\r\n\r\n\r\n\r\n \r\n\r\n## ***\\*持久性\\****\r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n持久性，当一个事物提交之后，数据库状态永远的发生了改变，即这个事物只要提交了，哪怕提交后宕机，他也确确实实的提交了，不会出现因为刚刚宕机了而让提交不生效，是要事物提交，他就像洗不掉的纹身，永远的固化了，除非你毁了硬盘。\r\n\r\n\r\n\r\n \r\n\r\n**事务命令**\r\n\r\n \r\n\r\n***\\*mysql：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEDE.tmp.png) \r\n\r\n \r\n\r\nBegin：显式的开启一个事务\r\n\r\nCommit：提交事务，将对数据库进行的所有的修改变成永久性\r\n\r\nRollback：结束用户的事务，并撤销现在正在进行的未提交的修改\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEDF.tmp.png) \r\n\r\n \r\n\r\n***\\*redis：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE0.tmp.png) \r\n\r\n \r\n\r\nMulti：标记事务的开始\r\n\r\nExec：执行事务的commands队列\r\n\r\nDiscard：结束事务，并清除commands队列\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE1.tmp.png) \r\n\r\n \r\n\r\n**默认状态**\r\n\r\n***\\*mysql：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE2.tmp.png) \r\n\r\nmysql会默认开启一个事务，且缺省设置是自动提交，即每成功执行sql，一个事务就会马上commit，所以不能rollback，\r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE3.tmp.png) \r\n\r\n \r\n\r\n***\\*redis：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE4.tmp.png) \r\n\r\nredis默认不会开启事务，即command会立即执行，而不会排队，并不支持rollback\r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE5.tmp.png) \r\n\r\n \r\n\r\n**使用方式**\r\n\r\n***\\*mysql（包含两种方式）：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE6.tmp.png) \r\n\r\n \r\n\r\n用Begin、Rollback、commit显式开启并控制一个 ***\\*新的\\**** Transaction\r\n\r\n执行命令 set autocommit=0，用来禁止当前会话自动commit，控制 ***\\*默认开启的事务\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE7.tmp.png) \r\n\r\n \r\n\r\n***\\*redis：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE8.tmp.png) \r\n\r\n \r\n\r\n用multi、exec、discard，显式开启并控制一个Transaction。\r\n\r\n（注意：这里没有强调 ***\\*“新的”\\**** ，因为默认是不会开启事务的）。\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEE9.tmp.png) \r\n\r\n \r\n\r\n**实现原理**\r\n\r\n***\\*mysql：\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEEA.tmp.png) \r\n\r\n \r\n\r\nmysql实现事务，是基于undo/redo日志\r\n\r\nundo记录修改前状态，rollback基于undo日志实现\r\n\r\nredo记录修改后的状态，commit基于redo日志实现\r\n\r\n \r\n\r\n既然是基于redo日志实现记录修改后的状态，那么大家应该也知道，**redo日志是innodb专有的**，所以innodb会支持事务\r\n\r\n \r\n\r\n在mysql中无论是否开启事务，sql都会被立即执行并返回执行结果，只是事务开启后执行后的状态只是记录在redo日志，执行commit之后，数据才会被写入磁盘\r\n\r\n \r\n\r\n（以上内容后面我会详细在mysql篇给大家讲到，大家可以先简单了解下）\r\n\r\n \r\n\r\n· \r\n\r\nint insertSelective = serviceOrderMapper.insertSelective(s);\r\n\r\n所以，上述代码，insertSelective 将会被立即赋值（无论是否开启事务，只是结果或未被写入磁盘）：\r\n\r\n· \r\n\r\ninsertSelective = 受影响的行数;\r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEEB.tmp.png) \r\n\r\n \r\n\r\n***\\*redis:\\****\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEEC.tmp.png) \r\n\r\n \r\n\r\nredis实现事务，是基于commands队列\r\n\r\n \r\n\r\n如果没有开启事务，command将会被立即执行并返回执行结果，并且直接写入磁盘\r\n\r\n \r\n\r\n如果事务开启，command不会被立即执行，而是排入队列，并返回排队状态（具体依赖于客户端（例如：spring-data-redis）自身实现）。\r\n\r\n调用exec才会执行commands队列\r\n\r\n· \r\n\r\nboolean a = redisTemplate.opsForZSet().add("generalService",orderId,System.currentTimeMillis())boolean a = redisTemplate.opsForZSet().add("generalService",orderId,System.currentTimeMillis())\r\n\r\n以上代码如果没有开启事务，操作被立即执行，a将会被立即赋值（true/false）\r\n\r\n \r\n\r\n如果开启事务，操作不会被立即执行，将会返回null值，而a的类型是boolean，所以将会抛出异常：\r\n\r\n· \r\n\r\njava.lang.NullPointerException  空指针异常\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEED.tmp.png) \r\n\r\n \r\n\r\n**Redis事务不支持Rollback（重点）**\r\n\r\n \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEEE.tmp.png) \r\n\r\n事实上Redis命令在事务执行时可能会失败，但仍会继续执行剩余命令而不是Rollback（事务回滚）。如果你使用过关系数据库，这种情况可能会让你感到很奇怪。然而针对这种情况具备很好的解释：\r\n\r\n \r\n\r\n· \r\n\r\nRedis命令可能会执行失败，仅仅是由于错误的语法被调用（命令排队时检测不出来的错误），或者使用错误的数据类 型操作某个Key：\r\n\r\n· \r\n\r\n 这意味着，实际上失败的命令都是编程错误造成的，都是开发中能够被检测出来的，生产环境中不应该存在。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n· \r\n\r\n由于不必支持Rollback,Redis内部简洁并且更加高效。\r\n\r\n· \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsEFF.tmp.png) \r\n\r\n \r\n\r\n**redis 事务中的错误**\r\n\r\n##  \r\n\r\n![img](redis事务和mysql事务的区别.assets/wpsF00.tmp.jpg) \r\n\r\n \r\n\r\n \r\n\r\n事务期间，可能会遇到两种命令错误：\r\n\r\n \r\n\r\n· \r\n\r\n在调用EXEC命令之前出现错误（COMMAND排队失败）。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n例如，命令可能存在语法错误（参数数量错误，错误的命令名称...）；\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n或者可能存在某些关键条件，如内存不足的情况（如果服务器使用maxmemory指令做了内存限制）。\r\n\r\n· \r\n\r\n \r\n\r\n**客户端会在****EXEC****调用之前检测第一种错误**。 通过检查排队命令的状态回复（***注意：这里是指排队的状态回复，而不是执行结果***），如果命令使用QUEUED进行响应，则它已正确排队，否则Redis将返回错误。如果排队命令时发生错误，大多数客户端将中止该事务并清除命令队列。然而：\r\n\r\n \r\n\r\n· \r\n\r\n在Redis 2.6.5之前，这种情况下，在EXEC命令调用后，客户端会执行命令的子集（成功排队的命令）而忽略之前的错误。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n从Redis 2.6.5开始，服务端会记住在累积命令期间发生的错误，当EXEC命令调用时，将拒绝执行事务，并返回这些错误，同时自动清除命令队列。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n示例如下：\r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n\\>MULTI+OK>INCR a b c-ERR wrong number of arguments for \'incr\' command\r\n\r\n \r\n\r\n这是由于INCR命令的语法错误，将在调用EXEC之前被检测出来，并终止事务（version2.6.5+）。\r\n\r\n \r\n\r\n· \r\n\r\n在调用EXEC命令之后出现错误。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n例如，使用错误的值对某个key执行操作（如针对String值调用List操作）\r\n\r\n· \r\n\r\n \r\n\r\n**EXEC****命令执行之后发生的错误并不会被特殊对待**：即使事务中的某些命令执行失败，其他命令仍会被正常执行。\r\n\r\n \r\n\r\n· \r\n\r\n示例如下：\r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n· \r\n\r\n\\>MULTI+OK>SET a 3+QUEUED>LPOP a+QUEUED>EXEC*2+OK-ERR Operation against a key holding the wrong kind of value>\r\n\r\n· \r\n\r\nEXEC返回一个包含两个元素的字符串数组，一个元素是OK，另一个是-ERR……。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n能否将错误合理的反馈给用户这取决于客户端library(如：Spring-data-redis.redisTemplate)的自身实现。\r\n\r\n· \r\n\r\n \r\n\r\n· \r\n\r\n需要注意的是，即使命令失败，队列中的所有其他命令也会被处理----Redis不会停止命令的处理。\r\n\r\n· \r\n\r\n 3\r\n\r\n​     结语        \r\n\r\n \r\n\r\n \r\n\r\n  redis和mysql 的事务在默认状态，使用方式，实现原理等方面都是有很大区别的\r\n\r\n \r\n\r\n  mysql的事务完美的支持了事务的四大特性，而redis事务只保证了其中的一致性和隔离性，不满足原子性和持久性\r\n\r\n \r\n\r\n '},"7c80":function(n,r,e){"use strict";e.r(r),r["default"]="# MySQL常见语句汇总\r\n\r\n# MySQL常见语句汇总\r\n\r\n## 数据库操作\r\n\r\n### 连接数据库\r\n\r\n```\r\nC:\\Users\\21952>mysql -u root -p\r\nEnter password: ******\r\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\r\nYour MySQL connection id is 16\r\nServer version: 8.0.19 MySQL Community Server - GPL\r\n\r\nCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\r\n\r\nOracle is a registered trademark of Oracle Corporation and/or its\r\naffiliates. Other names may be trademarks of their respective\r\nowners.\r\n\r\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\r\n\r\n```\r\n\r\n### 创建数据库\r\n\r\n```\r\nCREATE DATABASE 数据库名;\r\n\r\n```\r\n\r\n### 删除数据库\r\n\r\n```\r\nDROP DATABASE 数据库名;\r\n\r\n```\r\n\r\n### 选择数据库\r\n\r\n```\r\nuse 数据库名;\r\n\r\n```\r\n\r\n### 查看所有数据库\r\n\r\n```\r\nmysql> SHOW DATABASES;\r\n+--------------------+\r\n| Database           |\r\n+--------------------+\r\n| blog               |\r\n| information_schema |\r\n| mydb               |\r\n| mysql              |\r\n| notes              |\r\n| notesblog          |\r\n| performance_schema |\r\n| sys                |\r\n| test               |\r\n+--------------------+\r\n9 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n## 数据表操作\r\n\r\n### 创建数据表\r\n\r\n```\r\nCREATE TABLE table_name(\r\n    column_name column_type,\r\n    ...\r\n);\r\n\r\n```\r\n\r\n以下例子中将创建user表\r\n\r\n```\r\nCREATE TABLE IF NOT EXISTS `user`(\r\n    `uid` INT UNSIGNED AUTO_INCREMENT,\r\n    `uname` VARCHAR(20) NOT NULL,\r\n    `age` INT,\r\n    `sex` VARCHAR(2),\r\n    PRIMARY KEY(`uid`)\r\n)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\r\n\r\n```\r\n\r\n解析：\r\n\r\n- IF NOT EXISTS表示只有当user表不存在时才创建\r\n- UNSIGNED存储的时无符号数\r\n- NOT NULL表示该字段不能为空，否则会报错\r\n- AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。\r\n- PRIMARY KEY关键字用于定义列为主键。 您可以使用多列来定义主键，列间以逗号分隔。\r\n- ENGINE 设置存储引擎，CHARSET 设置编码。\r\n\r\n### 删除数据表\r\n\r\n```\r\nDROP TABLE [IF EXISTS] table_name;\r\n\r\n```\r\n\r\n### 修改表结构\r\n\r\n#### 修改表名\r\n\r\n修改表名有两种方式：\r\n\r\n```\r\nALTER TABLE old_table_name RENAME new_table_name;\r\n\r\nRENAME TABLE old_table_name TO new_table_name;\r\n\r\n```\r\n\r\n示例如下：\r\n\r\n```\r\nmysql> ALTER TABLE user RENAME user1;\r\nQuery OK, 0 rows affected (0.28 sec)\r\n\r\nmysql> RENAME TABLE user1 TO user;\r\nQuery OK, 0 rows affected (0.51 sec)\r\n\r\n```\r\n\r\n#### 修改表中某一列的列名和列结构\r\n\r\n```\r\nALTER TABLE table_name CHANGE old_column_name new_column_name new_ype;\r\n\r\n```\r\n\r\n将user表的uname更改为name，且将VARCHAR(20)修改为VARCHAR(21)\r\n\r\n```\r\nALTER TABLE user CHANGE uname name VARCHAR(21) NOT NULL;\r\n\r\n```\r\n\r\n#### 修改列结构\r\n\r\n```\r\nALTER TABLE table_name MODIFY column_name new_type;\r\n\r\n```\r\n\r\n实例：\r\n\r\n```\r\nmysql> ALTER TABLE user MODIFY uname VARCHAR(20);\r\nQuery OK, 3 rows affected (1.28 sec)\r\nRecords: 3  Duplicates: 0  Warnings: 0\r\n\r\n```\r\n\r\n#### 增加列\r\n\r\n```\r\nmysql> ALTER TABLE user ADD address VARCHAR(20);\r\nQuery OK, 0 rows affected (0.63 sec)\r\nRecords: 0  Duplicates: 0  Warnings: 0\r\n\r\n```\r\n\r\n#### 删除列\r\n\r\n```\r\nmysql> ALTER TABLE user DROP address;\r\nQuery OK, 0 rows affected (0.93 sec)\r\nRecords: 0  Duplicates: 0  Warnings: 0\r\n\r\n```\r\n\r\n### 查看表结构\r\n\r\n```\r\nDESC table_name;\r\n\r\nmysql> DESC user;\r\n+-------+--------------+------+-----+---------+----------------+\r\n| Field | Type         | Null | Key | Default | Extra          |\r\n+-------+--------------+------+-----+---------+----------------+\r\n| uid   | int unsigned | NO   | PRI | NULL    | auto_increment |\r\n| uname | varchar(21)  | NO   |     | NULL    |                |\r\n| age   | int          | YES  |     | NULL    |                |\r\n| sex   | varchar(2)   | YES  |     | NULL    |                |\r\n+-------+--------------+------+-----+---------+----------------+\r\n4 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n### 查看当前数据库的所有表\r\n\r\n```\r\nmysql> SHOW TABLES;\r\n+----------------+\r\n| Tables_in_test |\r\n+----------------+\r\n| stu            |\r\n| user           |\r\n+----------------+\r\n2 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n## 数据操作\r\n\r\n### 插入数据\r\n\r\n```\r\nINSERT INTO table_name (field1, field2,...fieldN) VALUES (value1, value2,...valueN);\r\n\r\n```\r\n\r\n我们可以在VALUES前面指定部分要插入的字段\r\n\r\n当我们要插入全部字段可以省略`(field1, field2,...fieldN)`\r\n\r\n插入全部字段：(要指定主键)\r\n\r\n```\r\nmysql> INSERT INTO user VALUES (1, 'xgc', 21, '男');\r\nQuery OK, 1 row affected (0.08 sec)\r\n\r\n```\r\n\r\n插入部分字段(当主键设置了AUTO_INCREMENT，主键可以省略，主键会自动加1)\r\n\r\n```\r\nmysql> INSERT INTO user (uname, age) VALUES ('zhangsan', 22);\r\nQuery OK, 1 row affected (0.08 sec)\r\n\r\n```\r\n\r\n### 查询数据\r\n\r\n```\r\nSELECT column_name [AS result_name],column_name FROM table_name [WHRER Clause] [LIMIT N] [OFFSET M]\r\n\r\n```\r\n\r\n`[]`内的为可选项\r\n\r\n- `AS result_name`表示为查询结果对应的列名取个别名\r\n- WHERE子句后面跟着选择条件\r\n- LIMIT来设置返回的记录数\r\n- OFFSET指定查询数据的偏移量，默认为0\r\n\r\n当我们要查询全部字段的时候，可以用`*`来代替列名\r\n\r\n```\r\nmysql> SELECT * FROM user;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   1 | xgc      |   21 | 男   |\r\n|   6 | zhangsan |   22 | NULL |\r\n+-----+----------+------+------+\r\n2 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n查询部分字段\r\n\r\n```\r\nmysql> SELECT uname AS name,age FROM user;\r\n+----------+------+\r\n| name     | age  |\r\n+----------+------+\r\n| xgc      |   21 |\r\n| zhangsan |   22 |\r\n+----------+------+\r\n2 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n#### WHERE子句\r\n\r\n```\r\nmysql> SELECT * FROM user WHERE uid=6;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   6 | zhangsan |   22 | NULL |\r\n+-----+----------+------+------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n#### LIMIT子句\r\n\r\nLIMIT后面可以加一个或两个参数\r\n\r\n只有一个参数，则表示要查询的记录数\r\n\r\n```\r\nmysql> SELECT * FROM  user LIMIT 1;\r\n+-----+-------+------+------+\r\n| uid | uname | age  | sex  |\r\n+-----+-------+------+------+\r\n|   1 | xgc   |   21 | 男   |\r\n+-----+-------+------+------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n有两个参数，第一个表示要跳过的数量，第二个表示要查询的记录数\r\n\r\n```\r\nmysql> SELECT * FROM  user LIMIT 1,2;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   6 | zhangsan |   22 | NULL |\r\n+-----+----------+------+------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n##### OFFSET子句\r\n\r\nOFFSET子句不能单独使用，只有在LIMIT子句存在的时候才能使用\r\n\r\n为了方便测试，再增加一条数据\r\n\r\n```\r\nmysql> INSERT INTO user (uname, age, sex) VALUES ('xiaoli', 22, '男');\r\nQuery OK, 1 row affected (0.35 sec)\r\n\r\n```\r\n\r\n此时全部数据如下：\r\n\r\n```\r\nmysql> SELECT * FROM user;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   1 | xgc      |   21 | 男   |\r\n|   6 | zhangsan |   22 | NULL |\r\n|   7 | xiaoli   |   22 | 男   |\r\n+-----+----------+------+------+\r\n3 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n测试OFFSET子句\r\n\r\n```\r\nmysql> SELECT * FROM user WHERE age=22 LIMIT 1 OFFSET 1;\r\n+-----+--------+------+------+\r\n| uid | uname  | age  | sex  |\r\n+-----+--------+------+------+\r\n|   7 | xiaoli |   22 | 男   |\r\n+-----+--------+------+------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n#### UNION操作符\r\n\r\nMySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。\r\n\r\n```\r\nSELECT column_name, column_name FROM table_name [WHERE Clause]\r\nUNION [ALL | DISTINCT]\r\nSELECT column_name, column_name FROM table_name [WHERE Clause];\r\n\r\n```\r\n\r\n参数：\r\n\r\n- **DISTINCT:** 可选，删除结果集中重复的数据。默认。\r\n- **ALL:** 可选，返回所有结果集，包含重复数据。\r\n\r\n**注：**\r\n\r\n- 查询结果的列数要相同，不同会报错。\r\n- UNION操作符不会检查列名是否相同，直接将第二个SELECT语句的组合到第一个SELECT语句的结果集中。即结果集的列名为第一个SELECT语句的列名。\r\n\r\n实例：\r\n\r\n```\r\nSELECT * FROM user WHERE uname = 'xgc'\r\nUNION\r\nSELECT * FROM user WHERE age = 22;\r\n\r\n```\r\n\r\n#### ORDER BY 排序\r\n\r\n我们可以使用ORDER BY子句来对数据集排序，再返回结果\r\n\r\n```\r\nSELECT column_name, column_name FROM table_name ORDER BY column_name [ASC | DESC], [column_name [ASC | DESC]]\r\n\r\n```\r\n\r\n- ORDER BY后面的列名表示要根据这个列名来排序\r\n- ASC表示升序排序，DESC表示降序排序。默认按升序排序\r\n- 我们可以使用多个列名排序，先按照靠前的列名排序，当列名相同时就按照下一个列名来排序。\r\n\r\n示例：\r\n\r\n```\r\nmysql> SELECT * FROM user ORDER BY age DESC;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   6 | zhangsan |   22 | NULL |\r\n|   7 | xiaoli   |   22 | 男   |\r\n|   1 | xgc      |   21 | 男   |\r\n+-----+----------+------+------+\r\n3 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n#### GROUP BY 分组\r\n\r\nGROUP BY 语句根据一个或多个列对结果集进行分组。将列值相同的分为一组。\r\n\r\n在分组的列上我们可以使用 COUNT, SUM, AVG等函数。\r\n\r\n```\r\nSELECT column_name function(column_name) FROM table_name [WITH ROLLUP]\r\nGROUP BY column_name;\r\n\r\n```\r\n\r\n- WITH ROLLUP 可以实现在分组统计数据基础上再进行相同的统计\r\n\r\n示例：将统计user表中年龄为22的分为一组，并统计对应人数\r\n\r\n```\r\nmysql> select age, count(age) AS num from user group by age;\r\n+------+------------+\r\n| age  | num        |\r\n+------+------------+\r\n|   21 |          1 |\r\n|   22 |          2 |\r\n+------+------------+\r\n2 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n这里，我们可以使用`WITH ROLLUP`再统计查询出的总人数\r\n\r\n```\r\nmysql> select age, count(age) AS num from user group by age WITH ROLLUP;\r\n+------+-----+\r\n| age  | num |\r\n+------+-----+\r\n|   21 |   1 |\r\n|   22 |   2 |\r\n| NULL |   3 |\r\n+------+-----+\r\n3 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n我们看到使用`WITH ROLLUP`统计出的数据对应age列的值为NULL。我们可以使用coalesce来设置取代NULL的值。\r\n\r\n我们来看看语法\r\n\r\n```\r\ncoalesce(a,b,c)\r\n\r\n```\r\n\r\n说明：如果a==null,则选择b；如果b==null,则选择c；如果a!=null,则选择a；如果a b c 都为null ，则返回为null。\r\n\r\n我们将其设置为`总数`\r\n\r\n```\r\nmysql> select coalesce(age, '总数') AS age, count(age) AS num from user group by age WITH ROLLUP;\r\n+--------+-----+\r\n| age    | num |\r\n+--------+-----+\r\n| 21     |   1 |\r\n| 22     |   2 |\r\n| 总数   |   3 |\r\n+--------+-----+\r\n3 rows in set, 1 warning (0.00 sec)\r\n\r\n```\r\n\r\n### 修改数据\r\n\r\n```\r\nUPDATE table_name SET column_name = new_value, column_name = new_value [WHERE Clause]\r\n\r\n```\r\n\r\n### 删除数据\r\n\r\n```\r\nDELETE FROM table_name [WHERE Clause]\r\n\r\n```\r\n\r\n### WHERE子句\r\n\r\n```\r\nSELECT column_name, column_name FROM table_name [WHERE condition1 [AND|OR] condition2 ..]\r\n\r\n```\r\n\r\n- WHERE后面跟的是查询条件\r\n\r\n- 可以使用AND和OR连接多个查询条件\r\n\r\n- WHERE 子句可以运用于 SQL 的 SELECT、DELETE 或者 UPDATE 命令。\r\n\r\n- MySQL 的 WHERE 子句的字符串比较是不区分大小写的。 可以使用 BINARY 关键字来设定 WHERE 子句的字符串比较是区分大小写的。\r\n\r\n  ```\r\n  SELECT * FROM user WHERE BINARY name=`xgc`;\r\n  \r\n  ```\r\n\r\n操作符如下表：\r\n\r\n| 操作符 | 描述                                                         | 实例               |\r\n| ------ | ------------------------------------------------------------ | ------------------ |\r\n| =      | 等号，检测两个值是否相等，如果相等返回true                   | (A = B) 返回false  |\r\n| <>, != | 不等于，检测两个值是否相等，如果不相等返回true               | (A != B) 返回 true |\r\n| >      | 大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true | (A > B) 返回false  |\r\n| <      | 小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true | (A < B) 返回 true  |\r\n| >=     | 大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true | (A >= B) 返回false |\r\n| <=     | 小于等于号，检测左边的值是否小于或等于右边的值, 如果左边的值小于或等于右边的值返回true | (A <= B) 返回 true |\r\n\r\n#### LIKE子句\r\n\r\n我们可以在WHERE子句中使用LIKE子句\r\n\r\nLIKE子句可以代替等号`=`，区别在于LIKE子句支持模糊匹配。\r\n\r\nMySQL提供了两种匹配方式\r\n\r\n- `%`：匹配任意0个或多个字符。\r\n- `_`：匹配单个任意字符\r\n\r\n```\r\nmysql> SELECT * FROM user WHERE uname LIKE 'zh%';\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   6 | zhangsan |   22 | NULL |\r\n+-----+----------+------+------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n#### REGEXP\r\n\r\n我们知道MySQL可以通过`LIKE`进行模糊匹配。\r\n\r\nMySQL中使用 REGEXP 操作符来进行正则表达式匹配。\r\n\r\n```\r\nSELECT * FROM user WHERE uname REGEXP '^xiao'\r\n\r\n```\r\n\r\n上面就表示查询列uname的值以xiao开头的数据。\r\n\r\n| 模式       | 描述                                                         |\r\n| ---------- | ------------------------------------------------------------ |\r\n| ^          | 匹配输入字符串的开始位置。                                   |\r\n| $          | 匹配输入字符串的结束位置。                                   |\r\n| .          | 匹配除 `\\n` 之外的任何单个字符。要匹配包括 `\\n` 在内的任何字符，使用 `[.\\n]` |\r\n| [...]      | 字符集合。匹配所包含的任意一个字符。例如， `[abc]` 可以匹配 `plain` 中的 `a`。 |\r\n| [^...]     | 负值字符集合。匹配未包含的任意字符。例如， `[^abc]`可以匹配 `plain` 中的`p`。 |\r\n| p1\\|p2\\|p3 | 匹配 p1 或 p2 或 p3。例如，`z|flood`能匹配 `z` 或 `food`。`(z|f)ood`则匹配 `zood` 或 `food`。 |\r\n| *          | 匹配前面的子表达式零次或多次。例如，`zo*` 能匹配 `z` 以及 `zoo`。`*` 等价于`{0,}`。 |\r\n| +          | 匹配前面的子表达式一次或多次。例如，`zo+` 能匹配 `zo` 以及 `zoo`，但不能匹配 `z`。`+` 等价于 `{1,}`。 |\r\n| {n}        | `n` 是一个非负整数。匹配确定的 `n` 次。例如，`o{2}` 不能匹配 `Bob` 中的 `o`，但是能匹配 \"food\" 中的两个 o。 |\r\n| {n,m}      | m 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。 |\r\n\r\n#### NULL值处理\r\n\r\n当我们需要查询列值为空或不为空是，`=`和`!=`是不起作用的。\r\n\r\n我们应该使用的应该是`IS NULL`和`IS NOT NULL`\r\n\r\n```\r\nSELECT * FROM user WHERE sex IS NULL;\r\n\r\nSELECT * FROM user WHERE sex IS NOT NULL;\r\n\r\n```\r\n\r\n### JOIN 连接\r\n\r\n在真正的应用中经常需要从多个数据表中读取数据。\r\n\r\n我们可以使用MySQL 的 JOIN 在两个或多个表中查询数据。\r\n\r\n我们可以在 SELECT, UPDATE 和 DELETE 语句中使用 Mysql 的 JOIN 来进行联合多表查询。\r\n\r\nJOIN 按照功能大致分为如下三类：\r\n\r\n- **INNER JOIN（内连接,或等值连接）**：获取两个表中字段匹配关系的记录。\r\n- **LEFT JOIN（左连接）：**获取左表所有记录，即使右表没有对应匹配的记录。\r\n- **RIGHT JOIN（右连接）：** 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。\r\n\r\n在学习JOIN前，我们先了解什么叫做笛卡尔积：\r\n\r\n> 在我们进行多表联合查询的时候会出现的一种情况——**笛卡尔积现象**\r\n\r\n现在，我们有两个集合A和B\r\n\r\nA = {0,1} B = {2,3,4}\r\n\r\n集合 A×B 和 B×A的结果集就可以分别表示为以下这种形式：\r\n\r\nA×B = {（0，2），（1，2），（0，3），（1，3），（0，4），（1，4）}；\r\n\r\nB×A = {（2，0），（2，1），（3，0），（3，1），（4，0），（4，1）}\r\n\r\n以上A×B和B×A的结果就可以叫做两个集合相乘的**笛卡尔积**。\r\n\r\n从上面我们得出两个结论：\r\n\r\n- 两个集合相乘，不满足交换率，既 A×B ≠ B×A\r\n- A集合和B集合相乘，包含了集合A中元素和集合B中元素相结合的所有的可能性。即两个集合相乘得到的新集合的元素个数是 A集合的元素个数 × B集合的元素个数\r\n\r\n数据库表连接数据行匹配时所遵循的算法就是以上提到的**笛卡尔积**\r\n\r\n在使用前，我们先看看联合多表查询的两个表\r\n\r\n```\r\nmysql> SELECT * FROM stu;\r\n+-----+----------+------+------+---------+\r\n| sid | sname    | age  | sex  | address |\r\n+-----+----------+------+------+---------+\r\n|   1 | zhangsan |   21 | 男   | NULL    |\r\n|   2 | lisi     |   21 | NULL | NULL    |\r\n+-----+----------+------+------+---------+\r\n2 rows in set (0.00 sec)\r\n\r\nmysql> SELECT * FROM user;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   1 | xgc      |   21 | 男   |\r\n|   6 | zhangsan |   22 | NULL |\r\n|   7 | xiaoli   |   22 | 男   |\r\n+-----+----------+------+------+\r\n3 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n**INNER JOIN：**\r\n\r\n我们把stu表和user表中age相等的记录查询出来(当然，查询出来的数据是没应用意义的，但只是为了查看一下效果)\r\n\r\n```\r\nmysql> SELECT * FROM user u INNER JOIN stu s ON u.age = s.age;\r\n+-----+-------+------+------+-----+----------+------+------+---------+\r\n| uid | uname | age  | sex  | sid | sname    | age  | sex  | address |\r\n+-----+-------+------+------+-----+----------+------+------+---------+\r\n|   1 | xgc   |   21 | 男   |   1 | zhangsan |   21 | 男   | NULL    |\r\n|   1 | xgc   |   21 | 男   |   2 | lisi     |   21 | NULL | NULL    |\r\n+-----+-------+------+------+-----+----------+------+------+---------+\r\n2 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n我来先解释一下上面SQL语句的意义\r\n\r\n- INNER JOIN，就是内连接\r\n- 表名user、stu后面的u、s分别是它们的别名，从`u.age = s.age`可以看到，它有区分两个表相同列名的作用\r\n- ON的作用类似于WHERE，表示的是查询后符合条件的记录\r\n\r\n我们看到内连接的匹配就是：\r\n\r\n- 先用笛卡尔积来进行组合成 `A表记录数 x B表记录数` 个记录\r\n- 然后使用ON后面条件筛选出符合的记录\r\n\r\n**LEFT JOIN：**\r\n\r\n```\r\nmysql> SELECT * FROM user u LEFT JOIN stu s ON u.age = s.age;\r\n+-----+----------+------+------+------+----------+------+------+---------+\r\n| uid | uname    | age  | sex  | sid  | sname    | age  | sex  | address |\r\n+-----+----------+------+------+------+----------+------+------+---------+\r\n|   1 | xgc      |   21 | 男   |    1 | zhangsan |   21 | 男   | NULL    |\r\n|   1 | xgc      |   21 | 男   |    2 | lisi     |   21 | NULL | NULL    |\r\n|   6 | zhangsan |   22 | NULL | NULL | NULL     | NULL | NULL | NULL    |\r\n|   7 | xiaoli   |   22 | 男   | NULL | NULL     | NULL | NULL | NULL    |\r\n+-----+----------+------+------+------+----------+------+------+---------+\r\n4 rows in set (0.00 sec)\r\n\r\n```\r\n\r\nRIGHT JOIN:\r\n\r\n```\r\nmysql> SELECT * FROM user u RIGHT JOIN stu s ON u.age = s.age;\r\n+------+-------+------+------+-----+----------+------+------+---------+\r\n| uid  | uname | age  | sex  | sid | sname    | age  | sex  | address |\r\n+------+-------+------+------+-----+----------+------+------+---------+\r\n|    1 | xgc   |   21 | 男   |   1 | zhangsan |   21 | 男   | NULL    |\r\n|    1 | xgc   |   21 | 男   |   2 | lisi     |   21 | NULL | NULL    |\r\n+------+-------+------+------+-----+----------+------+------+---------+\r\n2 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n## MySQL事务\r\n\r\n事务指的是一组SQL语句，要么全部执行，要么全部执行。\r\n\r\n- 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。\r\n- 事务用来管理 insert,update,delete 语句\r\n\r\n> 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。\r\n>\r\n> 因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。\r\n\r\n### 修改MySQL自动提交模式\r\n\r\nMySQL中事务默认是自动提交的，我们可以手动设置关闭或开启自动提交事务的模式\r\n\r\n- **SET AUTOCOMMIT=0** 禁止自动提交\r\n- **SET AUTOCOMMIT=1** 开启自动提交\r\n\r\n### 开启事务\r\n\r\n我们可以手动开启一个事务，从而使对数据库的操作在提交后才永久生效\r\n\r\n- BEGIN 或 START TRANSACTION 显式地开启一个事务；\r\n\r\n### 事务回滚\r\n\r\n当我们在执行事务的时候，发现其中一条语句出现错误，并且希望撤销正在进行的所有未提交的修改。那么我们可以使用事务回滚。\r\n\r\n- ROLLBACK 或 ROLLBACK WORK 进行事务的回滚\r\n\r\n### 事务提交\r\n\r\n当事务执行之后，而且没有一条语句出现错误。我们打算提交所有的修改，从而让对数据库的修改持久化。我们就要进行事务的提交\r\n\r\n- COMMIT 或 COMMIT WORK 会提交事务，并使已对数据库进行的所有修改成为永久性的；\r\n\r\n### 事务处理示例(开启、回滚、提交)\r\n\r\n```\r\nmysql> SELECT * FROM user;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   1 | xgc      |   21 | 男   |\r\n|   6 | zhangsan |   22 | NULL |\r\n|   7 | xiaoli   |   22 | 男   |\r\n+-----+----------+------+------+\r\n3 rows in set (0.00 sec)\r\n\r\n# 开启事务\r\nmysql> BEGIN;\r\nQuery OK, 0 rows affected (0.00 sec)\r\n\r\nmysql> INSERT INTO user (uname, age) VALUES('lisi', 18);\r\nQuery OK, 1 row affected (0.00 sec)\r\n\r\n# 提交事务\r\nmysql> COMMIT;\r\nQuery OK, 0 rows affected (0.06 sec)\r\n\r\n# 开启事务\r\nmysql> BEGIN;\r\nQuery OK, 0 rows affected (0.00 sec)\r\n\r\nmysql> INSERT INTO user (uname, age) VALUES('xiaohong', 18);\r\nQuery OK, 1 row affected (0.00 sec)\r\n\r\n# 事务回滚\r\nmysql> ROLLBACK;\r\nQuery OK, 0 rows affected (0.04 sec)\r\n\r\n# 查看回滚后的数据\r\nmysql> SELECT * FROM user;\r\n+-----+----------+------+------+\r\n| uid | uname    | age  | sex  |\r\n+-----+----------+------+------+\r\n|   1 | xgc      |   21 | 男   |\r\n|   6 | zhangsan |   22 | NULL |\r\n|   7 | xiaoli   |   22 | 男   |\r\n|   8 | lisi     |   18 | NULL |\r\n+-----+----------+------+------+\r\n4 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n### 保存点\r\n\r\nSAVEPOINT是在数据库事务处理中实现子事务（subtransaction），也称为嵌套事务的方法。事务可以回滚到SAVEPOINT 而不影响到SAVEPOINT创建前的变化，不需要放弃整个事务。\r\n\r\n允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT\r\n\r\n- 声明一个保存点\r\n\r\n  ```\r\n  SAVEPOINT savapoint_name;\r\n  \r\n  ```\r\n\r\n- 回滚到保存点\r\n\r\n  ```\r\n  ROLLBACK TO savepoint_name;\r\n  \r\n  ```\r\n\r\n- 删除保存点，一般在事务处理完成后（执行一条 ROLLBACK 或 COMMIT）自动释放\r\n\r\n  MySQL5以来，可以用：\r\n\r\n  ```\r\n  RELEASE SAVEPOINT savepoint_name; #删除指定保存点\r\n  \r\n  ```\r\n\r\n### 设置事务隔离级别\r\n\r\n事务的隔离级别是用来解决并发时的问题，如：脏读、幻读、不可重复读\r\n\r\nInnoDB 存储引擎提供事务的隔离级别有\r\n\r\n- READ UNCOMMITTED\r\n- READ COMMITTED\r\n- REPEATABLE READ\r\n- SERIALIZABLE\r\n\r\n设置事务隔离级别\r\n\r\n```\r\nSET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL \r\nREAD COMMITTED | READ UNCOMMITTED | REPEATABLE READ | SERIALIZABLE\r\n\r\n```\r\n\r\n### 查看事务隔离级别\r\n\r\n查看全局和当前会话事务隔离级别：\r\n\r\n```\r\nmysql> select @@global.transaction_isolation, @@transaction_isolation;\r\n+--------------------------------+-------------------------+\r\n| @@global.transaction_isolation | @@transaction_isolation |\r\n+--------------------------------+-------------------------+\r\n| REPEATABLE-READ                | REPEATABLE-READ         |\r\n+--------------------------------+-------------------------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n## MySQL 索引\r\n\r\nMySQL索引的建立对于MySQL的高效运行是很重要的，索引能够大大提高MySQL的检索速度。\r\n\r\n创建索引，你需要确保该索引是应用在SQL查询条件的条件(一般是作为WHERE子句的条件)\r\n\r\n实际上，索引也是一张表。该表保存了主键与索引字段，并指向实体表的记录。\r\n\r\n虽然索引能够加快查询速度，但我们不应该滥用索引。因此更新(UPDATE、DELETE、INSERT)表的时候，MySQL不仅会保存数据，还要保存一下索引文件，这会降低更新表的速度。\r\n\r\n### 索引分类\r\n\r\n在MySQL中，索引分为普通索引，唯一索引，主键索引和全文索引。其中每种索引根据包含列的不同又可以分为单列索引和组合索引。\r\n\r\n因此，我们又可以说索引分为单列索引和组合索引。\r\n\r\n- 单列索引，即一个索引只包含单个列。一个表中可以有多个单列索引。\r\n\r\n- 组合索引，即一个索引包含多个列。\r\n\r\n  组合索引指的是在多个字段上创建的索引。只有在查询条件中使用了创建索引的第一个字段，索引才用被使用。使用组合索引时遵循最左前缀匹配原则。\r\n\r\n  **最左前缀匹配原则：**\r\n\r\n  mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配。\r\n\r\n  比如a = 1 and b = 2 and c > 3 and d = 4，如果建立(a,b,c,d)顺序的索引，d是用不到索引的，\r\n\r\n  如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。\r\n\r\n这里，我们来看看普通索引，唯一索引，主键索引和全文索引的不同\r\n\r\n- 普通索引：这是最基本的索引，它没有任何限制。\r\n\r\n- 唯一索引：它与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。\r\n\r\n  如果是组合索引，则列值的组合必须唯一。\r\n\r\n- 主键索引：一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表时同时创建主键索引。\r\n\r\n- 全文索引：主要用来查找文本中的关键字，而不是直接与索引中的值相比较。\r\n\r\n  FULLTEXT索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。\r\n\r\n  FULLTEXT索引配合match against操作使用，而不是一般的where语句加like。\r\n\r\n### 创建索引\r\n\r\n下面这三种方法是创建普通索引、唯一索引和全文索引的方法：\r\n\r\n#### 建表后，直接创建\r\n\r\n```\r\nCREATE [UNIQUE | FULLTEXT] INDEX index_name ON table_name(column_name[, column_name]);\r\n\r\n```\r\n\r\n#### 修改表结构(添加索引)\r\n\r\n```\r\nALTER TABLE table_name ADD [UNIQUE | FULLTEXT] INDEX index_name(column_name[, column_name]);\r\n\r\n```\r\n\r\n#### 创建表时同时指定\r\n\r\n```\r\nCREATA TABLE table_name(\r\n\tcolumn_name column_type,\r\n    column_name column_type,\r\n    [INDEX | FULLTEXT | UNIQUE] [index_name] (column_name[, column_name])\r\n);\r\n\r\n```\r\n\r\n创建主键索引的两种方式如下：\r\n\r\n#### 修改表结构(主键索引)\r\n\r\n```\r\nALTER TABLE table_name ADD CONSTRAINT pk_name PRIMARY KEY(column_name[, column_name]);\r\n\r\n```\r\n\r\n#### 建表时同时创建\r\n\r\n```\r\nCREATE TABLE table_name(\r\n\tcolumn_name column_type,\r\n    column_name column_type,\r\n    PRIMARY KEY(column_name[, column_name])\r\n);\r\n\r\n```\r\n\r\n### 删除索引\r\n\r\n上面所有的索引都可以使用下面语句删除\r\n\r\n```\r\nDROP INDEX index_name ON table_name;\r\n\r\nALTER TABLE table_name DROP INDEX index_name;\r\n\r\n```\r\n\r\n如果是主键，我们还可以不用指定索引名\r\n\r\n```\r\nALTER TABLE table_name DROP PRIMARY KEY;\r\n\r\n```\r\n\r\n### 显示索引信息\r\n\r\n```\r\nSHOW INDEX FROM table_name;\r\n\r\n```\r\n\r\n示例：\r\n\r\n```\r\nmysql> SHOW INDEX FROM user;\r\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\r\n| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |\r\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\r\n| user  |          0 | PRIMARY  |            1 | uid         | A         |           0 |     NULL |   NULL |      | BTREE      |         |               | YES     | NULL       |\r\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n## 临时表\r\n\r\nMySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。\r\n\r\n临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。\r\n\r\n### 创建临时表\r\n\r\n```\r\nCREATE TEMPORARY TABLE table_name(\r\n\tcolumn_name column_type,\r\n    column_name column_type\r\n);\r\n\r\n```\r\n\r\n使用**SHOW TABLES**命令显示数据表列表时，我们是无法看到临时表。\r\n\r\n### 删除临时表\r\n\r\n默认情况下，当你断开与数据库的连接后，临时表就会自动被销毁。\r\n\r\n当然我们也可以在当前MySQL会话使用 **DROP TABLE** 命令来手动删除临时表。\r\n\r\n```\r\nDROP TABLE table_name;\r\n\r\n```\r\n\r\n## 复制表\r\n\r\n有时候，我们需要完成的复制MySQL的数据表，包括表结构、索引等。如果仅仅使用`CREATE TABLE new_table_name SELECT`命令是无法实现的。\r\n\r\n可能我们也会需要复制MySQL表的数据到另一个表。\r\n\r\n### 复制表结构\r\n\r\n1. 使用 **SHOW CREATE TABLE** 命令获取创建数据表语句，该语句包含了原数据表的结构，索引等。\r\n\r\n   ```\r\n   SHOW CREATE TABLE table_name;\r\n   \r\n   ```\r\n\r\n2. 复制该数据库表语句修改表名并执行\r\n\r\n示例：\r\n\r\n```\r\nmysql> SHOW CREATE TABLE user;\r\n+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| Table | Create Table                                                                                                                                                                                                                                                                  |\r\n+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| user  | CREATE TABLE `user` (\r\n  `uid` int unsigned NOT NULL AUTO_INCREMENT,\r\n  `uname` varchar(20) DEFAULT NULL,\r\n  `age` int DEFAULT NULL,\r\n  `sex` varchar(2) DEFAULT NULL,\r\n  PRIMARY KEY (`uid`)\r\n) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci |\r\n+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n1 row in set (0.00 sec)\r\n\r\n```\r\n\r\n### 复制表数据\r\n\r\n```\r\nINSERT INTO table_name SELECT column_name FROM table_name;\r\n\r\n```\r\n\r\n## 元数据\r\n\r\n| 命令              | 描述                      |\r\n| ----------------- | ------------------------- |\r\n| SELECT VERSION()  | 服务器版本信息            |\r\n| SELECT DATABASE() | 当前数据库名 (或者返回空) |\r\n| SELECT USER()     | 当前用户名                |\r\n| SHOW STATUS       | 服务器状态                |\r\n| SHOW VARIABLES    | 服务器配置变量            |\r\n\r\n## MySQL 序列\r\n\r\n一张数据表只能有一个字段是自增主键。如果我们想实现其他字段也自动增加，可以使用MySQL序列。\r\n\r\n### 使用AUTO_INCREMENT\r\n\r\nMySQL 中最简单使用序列的方法就是使用 AUTO_INCREMENT 来定义列。\r\n\r\n```\r\nmysql> CREATE TABLE insect\r\n    -> (\r\n    -> id INT UNSIGNED NOT NULL AUTO_INCREMENT,\r\n    -> PRIMARY KEY (id),\r\n    -> name VARCHAR(30) NOT NULL, # type of insect\r\n    -> date DATE NOT NULL, # date collected\r\n    -> origin VARCHAR(30) NOT NULL # where collected\r\n);\r\nQuery OK, 0 rows affected (0.02 sec)\r\n\r\nmysql> INSERT INTO insect (id,name,date,origin) VALUES\r\n    -> (NULL,'housefly','2001-09-10','kitchen'),\r\n    -> (NULL,'millipede','2001-09-10','driveway'),\r\n    -> (NULL,'grasshopper','2001-09-10','front yard');\r\nQuery OK, 3 rows affected (0.02 sec)\r\nRecords: 3  Duplicates: 0  Warnings: 0\r\nmysql> SELECT * FROM insect ORDER BY id;\r\n+----+-------------+------------+------------+\r\n| id | name        | date       | origin     |\r\n+----+-------------+------------+------------+\r\n|  1 | housefly    | 2001-09-10 | kitchen    |\r\n|  2 | millipede   | 2001-09-10 | driveway   |\r\n|  3 | grasshopper | 2001-09-10 | front yard |\r\n+----+-------------+------------+------------+\r\n3 rows in set (0.00 sec)\r\n\r\n```\r\n\r\n### 获取AUTO_INCREMENT值\r\n\r\n在MySQL的客户端中我们可以使用 SQL中的1686434 函数来获取最后的插入表中的自增列的值。\r\n\r\n```\r\nSELECT LAST_INSERT_ID();\r\n\r\n```\r\n\r\n### 重置序列\r\n\r\n如果我们删除了数据表中的多条记录，并希望对剩下数据的AUTO_INCREMENT列进行重新排列。那么我们可以通过删除自增的列，然后重新添加来实现。\r\n\r\n不过该操作要非常小心，如果在删除的同时又有新记录添加，有可能会出现数据混乱。\r\n\r\n```\r\nmysql> ALTER TABLE insect DROP id;\r\nmysql> ALTER TABLE insect\r\n    -> ADD id INT UNSIGNED NOT NULL AUTO_INCREMENT FIRST,\r\n    -> ADD PRIMARY KEY (id);\r\n\r\n```\r\n\r\n### 设置序列的开始值\r\n\r\n一般情况下序列的开始值为1，但如果你需要指定一个开始值100，那我们可以通过以下语句来实现：\r\n\r\n```\r\nmysql> CREATE TABLE insect\r\n    -> (\r\n    -> id INT UNSIGNED NOT NULL AUTO_INCREMENT,\r\n    -> PRIMARY KEY (id),\r\n    -> name VARCHAR(30) NOT NULL, \r\n    -> date DATE NOT NULL,\r\n    -> origin VARCHAR(30) NOT NULL\r\n)engine=innodb auto_increment=100 charset=utf8;\r\n\r\n```\r\n\r\n或者你也可以在表创建成功后，通过以下语句来实现：\r\n\r\n```\r\nmysql> ALTER TABLE t AUTO_INCREMENT = 100;\r\n\r\n```\r\n\r\n## 处理重复数据\r\n\r\n有些 MySQL 数据表中可能存在重复的记录，有些情况我们允许重复数据的存在，但有时候我们也需要删除这些重复的数据。\r\n\r\n### 防止表中出现重复数据\r\n\r\n你可以在 MySQL 数据表中设置指定的字段为 **PRIMARY KEY（主键）** 或者 **UNIQUE（唯一）** 索引来保证数据的唯一性。\r\n\r\n让我们尝试一个实例：下表中无索引及主键，所以该表允许出现多条重复记录。\r\n\r\n```\r\nCREATE TABLE person_tbl\r\n(\r\n    first_name CHAR(20),\r\n    last_name CHAR(20),\r\n    sex CHAR(10)\r\n);\r\n\r\n```\r\n\r\n如果你想设置表中字段 first_name，last_name 数据不能重复，你可以设置双**主键**模式来设置数据的唯一性， 如果你设置了双主键，那么那个键的默认值不能为 NULL，可设置为 NOT NULL。如下所示：\r\n\r\n```\r\nCREATE TABLE person_tbl\r\n(\r\n   first_name CHAR(20) NOT NULL,\r\n   last_name CHAR(20) NOT NULL,\r\n   sex CHAR(10),\r\n   PRIMARY KEY (last_name, first_name)\r\n);\r\n\r\n```\r\n\r\n另一种设置数据的唯一性方法是添加一个 **UNIQUE 索引**，如下所示：\r\n\r\n```\r\nCREATE TABLE person_tbl\r\n(\r\n   first_name CHAR(20) NOT NULL,\r\n   last_name CHAR(20) NOT NULL,\r\n   sex CHAR(10),\r\n   UNIQUE (last_name, first_name)\r\n);\r\n\r\n```\r\n\r\n**INSERT IGNORE INTO** 与 **INSERT INTO** 的区别就是 INSERT IGNORE 会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的。\r\n\r\n以下实例使用了 INSERT IGNORE INTO，执行后不会出错，也不会向数据表中插入重复数据：\r\n\r\n```\r\nmysql> INSERT IGNORE INTO person_tbl (last_name, first_name)\r\n    -> VALUES( 'Jay', 'Thomas');\r\nQuery OK, 1 row affected (0.00 sec)\r\nmysql> INSERT IGNORE INTO person_tbl (last_name, first_name)\r\n    -> VALUES( 'Jay', 'Thomas');\r\nQuery OK, 0 rows affected (0.00 sec)\r\n\r\n```\r\n\r\n如果我们设置了**唯一索引**，那么在使用`INSERT INTO`插入重复数据时，SQL 语句将无法执行成功,并抛出错。假设我们使用INSERT IGNORE INTO，如果插入重复数据，将不返回错误，只以警告形式返回。\r\n\r\n### 统计重复数据\r\n\r\n以下我们将统计表中 first_name 和 last_name的重复记录数：\r\n\r\n```\r\nmysql> SELECT COUNT(*) as repetitions, last_name, first_name\r\n    -> FROM person_tbl\r\n    -> GROUP BY last_name, first_name\r\n    -> HAVING repetitions > 1;\r\n\r\n```\r\n\r\n### 过滤重复数据\r\n\r\n如果你需要读取不重复的数据可以在 SELECT 语句中使用 DISTINCT 关键字来过滤重复数据。\r\n\r\n```\r\nmysql> SELECT DISTINCT last_name, first_name\r\n    -> FROM person_tbl;\r\n\r\n```\r\n\r\n你也可以使用 GROUP BY 来读取数据表中不重复的数据：\r\n\r\n```\r\nmysql> SELECT last_name, first_name\r\n    -> FROM person_tbl\r\n    -> GROUP BY (last_name, first_name);\r\n\r\n```\r\n\r\n### 删除重复数据\r\n\r\n如果你想删除数据表中的重复数据，你可以使用以下的SQL语句：\r\n\r\n```\r\nmysql> CREATE TABLE tmp SELECT last_name, first_name, sex FROM person_tbl  GROUP BY (last_name, first_name, sex);\r\nmysql> DROP TABLE person_tbl;\r\nmysql> ALTER TABLE tmp RENAME TO person_tbl;\r\n\r\n```\r\n\r\n当然你也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。方法如下：\r\n\r\n```\r\nmysql> ALTER IGNORE TABLE person_tbl\r\n    -> ADD PRIMARY KEY (last_name, first_name);\r\n\r\n```\r\n\r\n## 导出数据\r\n\r\nMySQL中你可以使用**SELECT...INTO OUTFILE**语句来简单的导出数据到文本文件上。\r\n\r\n### 使用 SELECT ... INTO OUTFILE 语句导出数据\r\n\r\n以下实例中我们将数据表 runoob_tbl 数据导出到 /tmp/runoob.txt 文件中:\r\n\r\n```\r\nmysql> SELECT * FROM runoob_tbl \r\n    -> INTO OUTFILE '/tmp/runoob.txt';\r\n\r\n```\r\n\r\n### 导出表\r\n\r\n**mysqldump** 是 mysql 用于转存储数据库的实用程序。它主要产生一个 SQL 脚本，其中包含从头重新创建数据库所必需的命令 CREATE TABLE INSERT 等。\r\n\r\n使用 **mysqldump** 导出数据需要使用 **--tab** 选项来指定导出文件指定的目录，该目标必须是可写的。\r\n\r\n以下实例将数据表 runoob_tbl 导出到 /tmp 目录中：\r\n\r\n```\r\n$ mysqldump -u root -p --no-create-info \\\r\n            --tab=/tmp RUNOOB runoob_tbl\r\npassword ******\r\n\r\n```\r\n\r\n### 导出SQL格式数据\r\n\r\n导出 SQL 格式的数据到指定文件，如下所示：\r\n\r\n```\r\n$ mysqldump -u root -p RUNOOB runoob_tbl > dump.txt\r\npassword ******\r\n\r\n```\r\n\r\n以上命令创建的文件内容如下：\r\n\r\n```\r\n-- MySQL dump 8.23\r\n--\r\n-- Host: localhost    Database: RUNOOB\r\n---------------------------------------------------------\r\n-- Server version       3.23.58\r\n\r\n--\r\n-- Table structure for table `runoob_tbl`\r\n--\r\n\r\nCREATE TABLE runoob_tbl (\r\n  runoob_id int(11) NOT NULL auto_increment,\r\n  runoob_title varchar(100) NOT NULL default '',\r\n  runoob_author varchar(40) NOT NULL default '',\r\n  submission_date date default NULL,\r\n  PRIMARY KEY  (runoob_id),\r\n  UNIQUE KEY AUTHOR_INDEX (runoob_author)\r\n) TYPE=MyISAM;\r\n\r\n--\r\n-- Dumping data for table `runoob_tbl`\r\n--\r\n\r\nINSERT INTO runoob_tbl \r\n       VALUES (1,'Learn PHP','John Poul','2007-05-24');\r\nINSERT INTO runoob_tbl \r\n       VALUES (2,'Learn MySQL','Abdul S','2007-05-24');\r\nINSERT INTO runoob_tbl \r\n       VALUES (3,'JAVA Tutorial','Sanjay','2007-05-06');\r\n\r\n```\r\n\r\n如果你需要导出整个数据库的数据，可以使用以下命令：\r\n\r\n```\r\n$ mysqldump -u root -p RUNOOB > database_dump.txt\r\npassword ******\r\n\r\n```\r\n\r\n如果需要备份所有数据库，可以使用以下命令：\r\n\r\n```\r\n$ mysqldump -u root -p --all-databases > database_dump.txt\r\npassword ******\r\n\r\n```\r\n\r\n--all-databases 选项在 MySQL 3.23.12 及以后版本加入。\r\n\r\n该方法可用于实现数据库的备份策略。\r\n\r\n### 将数据表及数据库拷贝至其他主机\r\n\r\n如果你需要将数据拷贝至其他的 MySQL 服务器上, 你可以在 mysqldump 命令中指定数据库名及数据表。\r\n\r\n在**源主机**上执行以下命令，将数据备份至 dump.txt 文件中:\r\n\r\n```\r\n$ mysqldump -u root -p database_name table_name > dump.txt\r\npassword *****\r\n\r\n```\r\n\r\n如果完整备份数据库，则无需使用特定的表名称。\r\n\r\n如果你需要将备份的数据库**导入到MySQL服务器**中，可以使用以下命令，使用以下命令你需要确认数据库已经创建：\r\n\r\n```\r\n$ mysql -u root -p database_name < dump.txt\r\npassword *****\r\n\r\n```\r\n\r\n你也可以使用以下命令将导出的数据直接导入到远程的服务器上，但请确保两台服务器是相通的，是可以相互访问的：\r\n\r\n```\r\n$ mysqldump -u root -p database_name \\\r\n       | mysql -h other-host.com database_name\r\n\r\n```\r\n\r\n以上命令中使用了管道来将导出的数据导入到指定的远程主机上。\r\n\r\n## 导入数据\r\n\r\n### mysql 命令导入\r\n\r\n```\r\nmysql -u user_name -p < 要导入的数据库数据(runoob.sql)\r\n\r\n```\r\n\r\n### source命令导入\r\n\r\n```\r\nsource sql文件\r\n\r\n```\r\n\r\n### LOAD DATA 导入数据\r\n\r\n```\r\nLOAD DATA LOCAL INFILE 'dump.txt' INTO TABLE table_name;\r\n\r\n```\r\n\r\n如果指定LOCAL关键词，则表明从客户主机上按路径读取文件。如果没有指定，则文件在服务器上按路径读取文件。\r\n\r\n### 使用mysqlimport导入数据\r\n\r\nmysqlimport 客户端提供了 LOAD DATA INFILEQL 语句的一个命令行接口。mysqlimport 的大多数选项直接对应 LOAD DATA INFILE 子句。\r\n\r\n从文件 dump.txt 中将数据导入到 mytbl 数据表中, 可以使用以下命令：\r\n\r\n```\r\n$ mysqlimport -u root -p --local mytbl dump.txt\r\npassword *****\r\n\r\n```\r\n\r\n \r\n\r\n# MySQL指南之SQL语句基础\r\n\r\n#### 零、结构化查询语言：SQL(Structured Query Language)\r\n\r\n```\r\nDDL 数据定义语言 管理库，表\r\nDML 数据操作语言 增删改查 \r\nDCL 数据控制语言 数据控制，权限访问等\r\n\r\n```\r\n\r\n------\r\n\r\n##### 准备活动：创建库和表\r\n\r\n```\r\nCREATE DATABASE datatype;\r\nUSE datatype;\r\n\r\nCREATE TABLE type_number(\r\ntype CHAR(12), \r\nbyte TINYINT UNSIGNED,\r\nrange_singed VARCHAR(20),\r\nrange_unsinged VARCHAR(20),\r\ninfo VARCHAR(40)\r\n);\r\n\r\n```\r\n\r\n------\r\n\r\n> 目前状态：\r\n\r\n```\r\nmysql> SHOW DATABASES;                                                      \r\n+--------------------+                                                      \r\n| Database           |                                                      \r\n+--------------------+                                                      \r\n| datatype           |                                                      \r\n| information_schema |                                                      \r\n| mycode             |                                                      \r\n| mysql              |                                                      \r\n| performance_schema |                                                      \r\n| seckill            |                                                      \r\n+--------------------+                   \r\n\r\nmysql> USE datatype;\r\nDatabase changed\r\n\r\nmysql> SHOW TABLES;\r\n+--------------------+\r\n| Tables_in_datatype |\r\n+--------------------+\r\n| type_number        |\r\n+--------------------+\r\n\r\nmysql> DESC type_number;\r\n+----------------+---------------------+------+-----+---------+-------+\r\n| Field          | Type                | Null | Key | Default | Extra |\r\n+----------------+---------------------+------+-----+---------+-------+\r\n| type           | char(12)            | YES  |     | NULL    |       |\r\n| byte           | tinyint(3) unsigned | YES  |     | NULL    |       |\r\n| range_singed   | varchar(20)         | YES  |     | NULL    |       |\r\n| range_unsinged | varchar(20)         | YES  |     | NULL    |       |\r\n| info           | varchar(40)         | YES  |     | NULL    |       |\r\n+----------------+---------------------+------+-----+---------+-------+\r\n\r\n```\r\n\r\n------\r\n\r\n#### 一、DML 数据库记录操作 `LEVEL 1`\r\n\r\n> LEVEL 1先简单掌握一下下面的用法\r\n\r\n![image-20211111135015007](0.MySQL常见语句汇总.assets/image-20211111135015007.png)\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n##### 1、记录的插入操作\r\n\r\n> ```\r\n> INSERT INTO <表名> (属性,...) VALUES (值,...),...;\r\n> ```\r\n\r\n```\r\n|-- 插入一条数据 INSERT INTO <表名> (属性,...) VALUES (值,...);\r\nINSERT INTO \r\ntype_number(type,byte,range_singed,range_unsinged,info) \r\nVALUES\r\n('TINYINT',1,'-2⁷ ~ 2⁷-1','0 ~ 2⁸-1','很小整数');\r\n\r\n|-- 查询所有 SELECT * FROM <表名>;\r\nmysql> SELECT * FROM type_number;\r\n+---------+------+----------------+----------------+--------------+\r\n| type    | byte | range_singed   | range_unsinged | info         |\r\n+---------+------+----------------+----------------+--------------+\r\n| TINYINT |    1 | -2⁷ ~ 2⁷-1     | 0 ~ 2⁸-1       | 很小整数     |\r\n+---------+------+----------------+----------------+--------------+\r\n\r\n|-- 你也可以一次，插入多条数据\r\nINSERT INTO \r\ntype_number(type,byte,range_singed,range_unsinged,info) \r\nVALUES\r\n('TINYINT',1,'-2⁷ ~ 2⁷-1','0 ~ 2⁸-1','很小整数'),\r\n('SMALLINT',2,'-2¹⁶ ~ 2¹⁶-1','0 ~ 2¹⁶-1','小整数'),\r\n('MEDIUMINT',3,'-2²⁴ ~ 2²⁴-1','0 ~ 2²⁴-1','中等整数'),\r\n('INT',4,'-2³² ~ 2³²-1','0 ~ 2³²-1','标准整数'),\r\n('BIGINT',8,'-2⁶⁴ ~ 2⁶⁴-1','0 ~ 2⁶⁴-1','大整数');\r\n\r\nmysql> SELECT * FROM type_number;\r\n+-----------+------+----------------------+----------------+--------------+\r\n| type      | byte | range_singed         | range_unsinged | info         |\r\n+-----------+------+----------------------+----------------+--------------+\r\n| TINYINT   |    1 | -2⁷ ~ 2⁷-1           | 0 ~ 2⁸-1       | 很小整数     |\r\n| TINYINT   |    1 | -2⁷ ~ 2⁷-1           | 0 ~ 2⁸-1       | 很小整数     |\r\n| SMALLINT  |    2 | -2¹⁶ ~ 2¹⁶-1         | 0 ~ 2¹⁶-1      | 小整数       |\r\n| MEDIUMINT |    3 | -2²⁴ ~ 2²⁴-1         | 0 ~ 2²⁴-1      | 中等整数     |\r\n| INT       |    4 | -2³² ~ 2³²-1         | 0 ~ 2³²-1      | 标准整数     |\r\n| BIGINT    |    8 | -2⁶⁴ ~ 2⁶⁴-1         | 0 ~ 2⁶⁴-1      | 大整数       |\r\n+-----------+------+----------------------+----------------+--------------+\r\n\r\n```\r\n\r\n##### 2、记录的更新操作\r\n\r\n> ```\r\n> UPDATE <表名> SET 属性 = 值,... WHERE 条件;\r\n> ```\r\n\r\n```\r\nUPDATE type_number \r\nSET \r\ninfo='微型整数'\r\nWHERE type = 'TINYINT';\r\n\r\nmysql> SELECT * FROM type_number;\r\n+-----------+------+----------------------+----------------+--------------+\r\n| type      | byte | range_singed         | range_unsinged | info         |\r\n+-----------+------+----------------------+----------------+--------------+\r\n| TINYINT   |    1 | -2⁷ ~ 2⁷-1           | 0 ~ 2⁸-1       | 微型整数     |\r\n| TINYINT   |    1 | -2⁷ ~ 2⁷-1           | 0 ~ 2⁸-1       | 微型整数     |\r\n| SMALLINT  |    2 | -2¹⁶ ~ 2¹⁶-1         | 0 ~ 2¹⁶-1      | 小整数       |\r\n| MEDIUMINT |    3 | -2²⁴ ~ 2²⁴-1         | 0 ~ 2²⁴-1      | 中等整数     |\r\n| INT       |    4 | -2³² ~ 2³²-1         | 0 ~ 2³²-1      | 标准整数     |\r\n| BIGINT    |    8 | -2⁶⁴ ~ 2⁶⁴-1         | 0 ~ 2⁶⁴-1      | 大整数       |\r\n+-----------+------+----------------------+----------------+--------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 3.记录的删除操作\r\n\r\n> ```\r\n> DELETE FROM <表名> WHERE 条件;\r\n> ```\r\n\r\n```\r\n|--- 删除操作\r\nDELETE FROM type_number \r\nWHERE type = 'TINYINT';\r\n\r\nmysql> SELECT * FROM type_number;\r\n+-----------+------+----------------------+----------------+--------------+\r\n| type      | byte | range_singed         | range_unsinged | info         |\r\n+-----------+------+----------------------+----------------+--------------+\r\n| SMALLINT  |    2 | -2¹⁶ ~ 2¹⁶-1         | 0 ~ 2¹⁶-1      | 小整数       |\r\n| MEDIUMINT |    3 | -2²⁴ ~ 2²⁴-1         | 0 ~ 2²⁴-1      | 中等整数     |\r\n| INT       |    4 | -2³² ~ 2³²-1         | 0 ~ 2³²-1      | 标准整数     |\r\n| BIGINT    |    8 | -2⁶⁴ ~ 2⁶⁴-1         | 0 ~ 2⁶⁴-1      | 大整数       |\r\n+-----------+------+----------------------+----------------+--------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 4.记录的查询操作\r\n\r\n> ```\r\n> SELECT 属性,... FROM <表名> WHERE 条件;\r\n> ```\r\n\r\n```\r\nmysql> \r\nSELECT \r\ntype,range_unsinged \r\nFROM type_number \r\nWHERE byte>=4;\r\n+--------+----------------+\r\n| type   | range_unsinged |\r\n+--------+----------------+\r\n| INT    | 0 ~ 2³²-1      |\r\n| BIGINT | 0 ~ 2⁶⁴-1      |\r\n+--------+----------------+\r\n\r\n```\r\n\r\n------\r\n\r\n#### 二、图片表pic `(LEVER 2)`\r\n\r\n> 这个是用来记录图片信息的表，数据准备过程详见番外篇：\r\n>  [[番外\\]-练习MySQL没素材？来一波字符串操作](https://juejin.cn/post/6844903798335520781)\r\n\r\n![image-20211111134950922](0.MySQL常见语句汇总.assets/image-20211111134950922.png)\r\n\r\n\r\n\r\n\r\n\r\n##### 1.建表语句\r\n\r\n```\r\nCREATE TABLE pic(\r\n   id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,\r\n   pic_path  VARCHAR(120)   NOT NULL,\r\n   pic_length  INT UNSIGNED  DEFAULT 0,\r\n   pic_mime TINYINT UNSIGNED,\r\n   pic_width SMALLINT UNSIGNED,\r\n   pic_height SMALLINT UNSIGNED\r\n );\r\n\r\n|--- id 为主键 自增长\r\n|--- pic_path表示名字，不定长度 ，给个VARCHAR 120 吧，差不多够用吧\r\n|--- 图片文件大小不会非常大，给个INT足够了 ， 给个默认值 0 \r\n|--- pic_mime 0 表示 image/png  1表示 image/jpeg 给个最小的\r\n|--- pic_width和pic_height也不会非常大，无符号SMALLINT足够\r\n\r\n```\r\n\r\n------\r\n\r\n##### 2.查询操作 `AS` 的作用\r\n\r\n```\r\n|-- 查询高大于1200像素的记录，使用AS 来 临时更改查询输出的属性名(不会改变实际记录)\r\nmysql> \r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height>1200;\r\n\r\n+----------------------+--------+--------+\r\n| 路径                 | 宽/px  | 高/px  |\r\n+----------------------+--------+--------+\r\n| 30000X20000.jpg      |  30000 |  20000 |\r\n| 3000X2000.jpg        |   3000 |   2000 |\r\n| ecNKedygCmSjTWWF.jpg |    700 |   1352 |\r\n| gtQiXnRfkvvTLinw.jpg |   2880 |   2025 |\r\n| HXqqASHJETSlvpnc.jpg |   3600 |   2400 |\r\n| ndbMXlwKuCpiiVqC.jpg |   1701 |   2268 |\r\n| screen.png           |   1080 |   1920 |\r\n| XQWGrglfjGVuJfzJ.jpg |   1200 |   1696 |\r\n+----------------------+--------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 3.查询是属性可参与运算\r\n\r\n```\r\n|-- CONCAT函数用于连接字符串  注意：\\需要转义 \r\nmysql> \r\nSELECT \r\nCONCAT('E:\\\\SpringBootFiles\\\\imgs\\\\',pic_path) AS 绝对路径,\r\npic_width * pic_height AS '像素点个数' \r\nFROM pic \r\nWHERE pic_height>1200;\r\n\r\n+----------------------------------------------+-----------------+\r\n| 绝对路径                                     | 像素点个数      |\r\n+----------------------------------------------+-----------------+\r\n| E:\\SpringBootFiles\\imgs\\30000X20000.jpg      |       600000000 |\r\n| E:\\SpringBootFiles\\imgs\\3000X2000.jpg        |         6000000 |\r\n| E:\\SpringBootFiles\\imgs\\ecNKedygCmSjTWWF.jpg |          946400 |\r\n| E:\\SpringBootFiles\\imgs\\gtQiXnRfkvvTLinw.jpg |         5832000 |\r\n| E:\\SpringBootFiles\\imgs\\HXqqASHJETSlvpnc.jpg |         8640000 |\r\n| E:\\SpringBootFiles\\imgs\\ndbMXlwKuCpiiVqC.jpg |         3857868 |\r\n| E:\\SpringBootFiles\\imgs\\screen.png           |         2073600 |\r\n| E:\\SpringBootFiles\\imgs\\XQWGrglfjGVuJfzJ.jpg |         2035200 |\r\n+----------------------------------------------+-----------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 4.`WHERE`条件的千变万化\r\n\r\n![image-20211111135122869](0.MySQL常见语句汇总.assets/image-20211111135122869.png)\r\n\r\n\r\n\r\n\r\n\r\n###### 4.1: 条件`与` -- `AND` 和 `&&`\r\n\r\n> 条件必须全部满足\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height>1200 AND \r\npic_width > 1500;\r\n\r\n+----------------------+--------+--------+\r\n| 路径                 | 宽/px  | 高/px  |\r\n+----------------------+--------+--------+\r\n| 30000X20000.jpg      |  30000 |  20000 |\r\n| 3000X2000.jpg        |   3000 |   2000 |\r\n| gtQiXnRfkvvTLinw.jpg |   2880 |   2025 |\r\n| HXqqASHJETSlvpnc.jpg |   3600 |   2400 |\r\n| ndbMXlwKuCpiiVqC.jpg |   1701 |   2268 |\r\n+----------------------+--------+--------+\r\n\r\n|--- AND 效果等于 &&\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height>1200 && \r\npic_width > 1500;\r\n\r\n```\r\n\r\n------\r\n\r\n###### 4.2: 条件`或` -- `OR` 和 `||`\r\n\r\n> 条件满足一个即可\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height>1200 OR \r\npic_width > 1500;\r\n\r\n+----------------------+--------+--------+\r\n| 路径                 | 宽/px  | 高/px  |\r\n+----------------------+--------+--------+\r\n| 30000X20000.jpg      |  30000 |  20000 |\r\n| 3000X2000.jpg        |   3000 |   2000 |\r\n| ecNKedygCmSjTWWF.jpg |    700 |   1352 |\r\n| gtQiXnRfkvvTLinw.jpg |   2880 |   2025 |\r\n| HXqqASHJETSlvpnc.jpg |   3600 |   2400 |\r\n| ndbMXlwKuCpiiVqC.jpg |   1701 |   2268 |\r\n| screen.png           |   1080 |   1920 |\r\n| XQWGrglfjGVuJfzJ.jpg |   1200 |   1696 |\r\n+----------------------+--------+--------+\r\n\r\n|--- OR 效果等于 || \r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height>1200 ||\r\npic_width > 1500;\r\n\r\n```\r\n\r\n------\r\n\r\n###### 4.3: 条件`非` -- `NOT` 和 `!`\r\n\r\n> 对条件取反\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE NOT pic_height < 1200;  \r\n\r\n+----------------------+--------+--------+\r\n| 路径                 | 宽/px  | 高/px  |\r\n+----------------------+--------+--------+\r\n| 30000X20000.jpg      |  30000 |  20000 |\r\n| 3000X2000.jpg        |   3000 |   2000 |\r\n| ecNKedygCmSjTWWF.jpg |    700 |   1352 |\r\n| gtQiXnRfkvvTLinw.jpg |   2880 |   2025 |\r\n| HXqqASHJETSlvpnc.jpg |   3600 |   2400 |\r\n| ndbMXlwKuCpiiVqC.jpg |   1701 |   2268 |\r\n| screen.png           |   1080 |   1920 |\r\n| XQWGrglfjGVuJfzJ.jpg |   1200 |   1696 |\r\n+----------------------+--------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n###### 4.4: 散点匹配`IN(v1,v2,v3,...)`\r\n\r\n> 符合v1,v2,v3,...之一可匹配\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height IN (1696,2268); \r\n\r\n+----------------------+--------+--------+\r\n| 路径                 | 宽/px  | 高/px  |\r\n+----------------------+--------+--------+\r\n| ndbMXlwKuCpiiVqC.jpg |   1701 |   2268 |\r\n| XQWGrglfjGVuJfzJ.jpg |   1200 |   1696 |\r\n+----------------------+--------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n###### 4.5: 区间匹配`BETWEEN v1 AND v2`\r\n\r\n> v1,v2之间可匹配\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_height BETWEEN 1696 AND 2268; \r\n\r\n+----------------------+--------+--------+\r\n| 路径                 | 宽/px  | 高/px  |\r\n+----------------------+--------+--------+\r\n| 3000X2000.jpg        |   3000 |   2000 |\r\n| gtQiXnRfkvvTLinw.jpg |   2880 |   2025 |\r\n| ndbMXlwKuCpiiVqC.jpg |   1701 |   2268 |\r\n| screen.png           |   1080 |   1920 |\r\n| XQWGrglfjGVuJfzJ.jpg |   1200 |   1696 |\r\n+----------------------+--------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n###### 4.6：模糊查询：`LIKE`\r\n\r\n> ```\r\n> '%'匹配任意多个字符,'_'匹配任意单个字符\r\n> ```\r\n\r\n```\r\nmysql>\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_path LIKE 'androi%'; \r\n\r\n+----------------------------------------------+--------+--------+\r\n| 路径                                         | 宽/px  | 高/px  |\r\n+----------------------------------------------+--------+--------+\r\n| android\\008525ebc2b7d434070e74c00841a30f.png |    544 |    544 |\r\n| android\\054d98e2d96dc42d9b2b036126fccf49.png |    544 |    544 |\r\n| android\\05baf2d03651d1110d7a403f14aee877.png |    544 |    544 |\r\n| android\\0655e07d6717847489cd222c9c9e0b1d.png |    500 |    500 |\r\n| android\\079c4cb46c95b2365b5bc5150e7d5213.png |    544 |    544 |\r\n| android\\07a4dc9b4b207cb420a71cbf941ad45a.png |    544 |    544 |\r\n| android\\07abb7972a5638b53afa3b5eb98b19c1.png |    500 |    500 |\r\n    ......\r\n \r\nmysql>\r\nSELECT \r\npic_path AS 路径 , \r\npic_width AS '宽/px', \r\npic_height AS '高/px' \r\nFROM pic \r\nWHERE pic_path LIKE 'p_em%';\r\n\r\n+--------------------------------------------+--------+--------+\r\n| 路径                                       | 宽/px  | 高/px  |\r\n+--------------------------------------------+--------+--------+\r\n| poem\\世界·绽放.jpg                         |   1148 |    712 |\r\n| poem\\我爱你，是火山岩的缄默.jpg            |    690 |    397 |\r\n| poem\\枝·你是树的狂舞.jpg                   |    500 |    333 |\r\n| poem\\海与鹿王.jpg                          |    799 |    499 |\r\n| poem\\游梦人·诗的诞生.jpg                   |    800 |    444 |\r\n| poem\\珊瑚墓地.jpg                          |   1104 |    719 |\r\n+--------------------------------------------+--------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n###### 4.7:比较符号`= != < > <= >=`\r\n\r\n> 小学生都知道的，就不废话了，查看一下小于10Kb的图片\r\n\r\n```\r\nmysql>\r\nSELECT \r\npic_path AS 路径 ,  \r\npic_length AS '大小/byte' \r\nFROM pic \r\nWHERE pic_length < 10*1024;\r\n\r\n+----------------------------------------------+-------------+\r\n| 路径                                         | 大小/byte   |\r\n+----------------------------------------------+-------------+\r\n| 30X20.jpg                                    |       10158 |\r\n| android\\613f2b8f0eaa8f63bedce9781527c9ab.png |        4001 |\r\n| android\\94b5c41232f9761403890c09c2b1aae3.png |        4001 |\r\n| android\\d3fd676f224f0734beb48d0c0d2f4e66.png |        4001 |\r\n| udp发送与接收消息_控制台.png                 |        9184 |\r\n+----------------------------------------------+-------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 5. `GROUP BY`分组查询\r\n\r\n> 会先排序，再列出\r\n\r\n```\r\n|--- GROUP BY\r\nSELECT \r\npic_mime AS \"类型\",\r\navg(pic_length) AS '平均大小/byte' ,\r\ncount(pic_length) AS '总数量/个' ,\r\nmin(pic_length) AS '最小值/byte' ,\r\nmax(pic_length) AS '最大值/byte' ,\r\nsum(pic_length) AS '总和/byte'\r\nFROM pic \r\nGROUP BY pic_mime;\r\n\r\n+--------+-------------------+---------------+----------------+----------------+-------------+\r\n| 类型   | 平均大小/byte     | 总数量/个     | 最小值/byte    | 最大值/byte    | 总和/byte   |\r\n+--------+-------------------+---------------+----------------+----------------+-------------+\r\n|      0 |       141518.8734 |           229 |           4001 |         829338 |    32407822 |\r\n|      1 |      2133272.8000 |            60 |          10158 |      116342886 |   127996368 |\r\n+--------+-------------------+---------------+----------------+----------------+-------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 6.结果集筛选：`HAVING`\r\n\r\n> 现在查询宽高比在1.1和1.3之间的图片\r\n\r\n```\r\n|-- 如果用WHERE 来查询 感觉有点不优雅\r\nSELECT \r\npic_path AS 路径 , \r\npic_width/pic_height AS '宽高比'\r\nFROM pic \r\nWHERE pic_width/pic_height > 1.1 && pic_width/pic_height<1.3; \r\n\r\n+------------------------------------------------------------------+-----------+\r\n| 路径                                                             | 宽高比    |\r\n+------------------------------------------------------------------+-----------+\r\n| dQXbnTRjUdNxhiyl.jpg                                             |    1.2308 |\r\n| JsXHWmKqOlziKmeA.jpg                                             |    1.2600 |\r\n| logo\\android\\Android原生绘图之让你了解View的运动.png             |    1.2884 |\r\n| 洛天依.jpg                                                       |    1.1990 |\r\n+------------------------------------------------------------------+-----------+\r\n\r\n|-- AS 相当于将列取了变量，对结果集再进行筛选用HAVING,用WHERE则报错，找不到列\r\nSELECT \r\npic_path AS 路径 , \r\npic_width/pic_height AS ratio \r\nFROM pic \r\nHAVING ratio > 1.1 && ratio <1.3;\r\n\r\n+------------------------------------------------------------------+--------+\r\n| 路径                                                             | ratio  |\r\n+------------------------------------------------------------------+--------+\r\n| dQXbnTRjUdNxhiyl.jpg                                             | 1.2308 |\r\n| JsXHWmKqOlziKmeA.jpg                                             | 1.2600 |\r\n| logo\\android\\Android原生绘图之让你了解View的运动.png             | 1.2884 |\r\n| 洛天依.jpg                                                       | 1.1990 |\r\n+------------------------------------------------------------------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 7.结果排序：`ORDER BY`\r\n\r\n> 按照ratio将序排列\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_width/pic_height AS ratio \r\nFROM pic \r\nHAVING ratio > 1.1 && ratio <1.3;\r\nORDER BY ratio DESC \r\n\r\n+------------------------------------------------------------------+--------+\r\n| 路径                                                             | ratio  |\r\n+------------------------------------------------------------------+--------+\r\n| dQXbnTRjUdNxhiyl.jpg                                             | 1.2308 |\r\n| JsXHWmKqOlziKmeA.jpg                                             | 1.2600 |\r\n| logo\\android\\Android原生绘图之让你了解View的运动.png             | 1.2884 |\r\n| 洛天依.jpg                                                       | 1.1990 |\r\n+------------------------------------------------------------------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 8.控制条目数：`LIMIT`\r\n\r\n```\r\n|-- 偏移一条，取两条\r\nSELECT \r\npic_path AS 路径 , \r\npic_width/pic_height AS ratio \r\nFROM pic \r\nHAVING ratio > 1.1 && ratio <1.3\r\nORDER BY ratio DESC LIMIT 1,2;\r\n\r\n+----------------------+--------+\r\n| 路径                 | ratio  |\r\n+----------------------+--------+\r\n| JsXHWmKqOlziKmeA.jpg | 1.2600 |\r\n| dQXbnTRjUdNxhiyl.jpg | 1.2308 |\r\n+----------------------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n#### 三、子查询 `(LEVER 3)`\r\n\r\n##### 1.查询大于平均尺寸的图片 --  `WHERE`\r\n\r\n```\r\n|--- 出现在其他SQL语句内的SELECT语句\r\n|--- 子查询必须在()内\r\n|--- 增删改查都可以进行子查询,返回：标量，行，列或子查询\r\n\r\n|-- 1-1：查出图片平均大小\r\nSELECT \r\nROUND(AVG(pic_length),2) AS '平均大小' \r\nFROM pic;\r\n\r\n+--------------+\r\n| 平均大小     |\r\n+--------------+\r\n|    555031.80 |\r\n+--------------+\r\n1 row in set (0.00 sec)\r\n\r\n|-- 1-2：在用WHERE 筛选\r\nSELECT \r\npic_path AS 路径 , \r\npic_length  AS '大小/byte' \r\nFROM pic \r\nWHERE pic_length > 555031.80;\r\n\r\n+----------------------------------------------+-------------+\r\n| 路径                                         | 大小/byte   |\r\n+----------------------------------------------+-------------+\r\n| 30000X20000.jpg                              |   116342886 |\r\n| 3000X2000.jpg                                |     3404969 |\r\n| android\\12284e5f7197d8be737fa967c8b00fbe.png |      829338 |\r\n| android\\594665add495ac9da8b6bbee1c63f1b8.png |      598974 |\r\n| android\\7cc97458727e23f7d161b8a1a7c6b453.png |      559420 |\r\n| android\\cbb1524f5ab4266698f3a6fc2992ccae.png |      829338 |\r\n| android\\d52539b1b508a594d1f2865037ff50c5.png |      598974 |\r\n| android\\f07ddfe5a103e4a024e14e2569f1d70e.png |      829338 |\r\n| android\\f0d1e7713d5557a8f9c74c9904843e09.png |      559420 |\r\n| bg.png                                       |      688207 |\r\n| gtQiXnRfkvvTLinw.jpg                         |      771187 |\r\n| poem\\珊瑚墓地.jpg                            |      984472 |\r\n| XoazFNMQROveEPQn.jpg                         |      795364 |\r\n+----------------------------------------------+-------------+\r\n\r\n|--- 也就是将一个语句包在WHERE 条件里\r\nSELECT \r\npic_path AS 路径 , \r\npic_length  AS '大小/byte' \r\nFROM pic \r\nWHERE pic_length > (\r\n    SELECT \r\n    ROUND(AVG(pic_length),2) \r\n    FROM pic\r\n);\r\n\r\n```\r\n\r\n------\r\n\r\n##### 2.查出每种类型的最新插入的图片 --  `WHERE`\r\n\r\n```\r\nSELECT \r\npic_path AS 路径 , \r\npic_mime AS 类型 \r\nFROM pic \r\nWHERE id IN (\r\n    SELECT \r\n    max(id)\r\n    FROM pic \r\n    GROUP BY pic_mime\r\n);\r\n\r\n+------------------+--------+\r\n| 路径             | 类型   |\r\n+------------------+--------+\r\n| 洛天依.jpg       |      1 |\r\n| 虚拟机栈.png     |      0 |\r\n+------------------+--------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 3.FROM子查询 --  `FROM`\r\n\r\n```\r\nSELECT \r\nid, \r\npic_path AS 路径 , \r\npic_length  AS '大小/byte' \r\nFROM pic \r\nWHERE id>=10&&id<=15 \r\nORDER BY pic_length DESC;\r\n\r\n+----+----------------------------------------------+-------------+\r\n| id | 路径                                         | 大小/byte   |\r\n+----+----------------------------------------------+-------------+\r\n| 15 | android\\0f3bf63796ac370a08ee97b056b0587b.png |      178849 |\r\n| 14 | android\\0951ef0be68f0c498ca34ffcd7fc7faa.png |      175842 |\r\n| 11 | android\\079c4cb46c95b2365b5bc5150e7d5213.png |       86996 |\r\n| 10 | android\\0655e07d6717847489cd222c9c9e0b1d.png |       53764 |\r\n| 12 | android\\07a4dc9b4b207cb420a71cbf941ad45a.png |       46270 |\r\n| 13 | android\\07abb7972a5638b53afa3b5eb98b19c1.png |       43360 |\r\n+----+----------------------------------------------+-------------+\r\n\r\n|--- 将查询结果当做一张表，再查询操作\r\nSELECT \r\nid,路径 FROM (\r\n   SELECT \r\n   id, \r\n   pic_path AS 路径 , \r\n   pic_length  AS '大小/byte' \r\n   FROM pic \r\n   WHERE id>=10&&id<=15 \r\n   ORDER BY pic_length DESC\r\n) AS result \r\nWHERE `大小/byte` < 59999;\r\n\r\n+----+----------------------------------------------+\r\n| id | 路径                                         |\r\n+----+----------------------------------------------+\r\n| 10 | android\\0655e07d6717847489cd222c9c9e0b1d.png |\r\n| 12 | android\\07a4dc9b4b207cb420a71cbf941ad45a.png |\r\n| 13 | android\\07abb7972a5638b53afa3b5eb98b19c1.png |\r\n+----+----------------------------------------------+\r\n\r\n```\r\n\r\n------\r\n\r\n#### 四、连接查询\r\n\r\n##### 0.创建关联表\r\n\r\n> 首先连接查询要多张表，现在建一个`mime_type` 的表\r\n\r\n```\r\n|--- 建表\r\nCREATE TABLE mime_type(\r\n   mime_id SMALLINT UNSIGNED PRIMARY KEY,\r\n   mime_info CHAR(24)\r\n );\r\n\r\n|--- 插入数据\r\nINSERT INTO mime_type(mime_id,mime_info) VALUES\r\n(0,'image/png'),\r\n(1,'image/jpeg'),\r\n(2,'image/svg+xml'),\r\n(3,'video/mp4'),\r\n(4,'text/plain');\r\n\r\n|--- 效果\r\nmysql> select * from mime_type;\r\n+---------+---------------+\r\n| mime_id | mime_info     |\r\n+---------+---------------+\r\n|       0 | image/png     |\r\n|       1 | image/jpeg    |\r\n|       2 | image/svg+xml |\r\n|       3 | video/mp4     |\r\n|       4 | text/plain    |\r\n+---------+---------------+\r\n\r\n|-- 为了说明问题，pic表添加一条测试数据：pic_mime = 8  也就是 mime_type表找不到时\r\nINSERT INTO pic(pic_path,pic_length,pic_mime,pic_width,pic_height) VALUES('test.jpg',100,8,300,200);\r\n\r\n```\r\n\r\n------\r\n\r\n##### 1.内连接查询 `INNER JOIN`\r\n\r\n> ```\r\n> SELECT 待查属性 FROM 表1 INNER JOIN 表2 ON 条件 WHERE 条件\r\n> ```\r\n\r\n```\r\nSELECT id, pic_path AS 路径 , mime_type.mime_info AS 类型 , pic_length \r\nFROM pic INNER JOIN mime_type \r\nON pic.pic_mime = mime_type.mime_id \r\nORDER BY id DESC LIMIT 4;\r\n\r\n+-----+------------------+------------+------------+\r\n| id  | 路径             | 类型       | pic_length |\r\n+-----+------------------+------------+------------+\r\n| 289 | 虚拟机栈.png     | image/png  |      63723 |\r\n| 288 | 统一返回.png     | image/png  |      29485 |\r\n| 287 | 洛天依.jpg       | image/jpeg |      42117 |\r\n| 286 | 标记整理.png     | image/png  |      29288 |\r\n+-----+------------------+------------+------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 2.左连接查询 : `LEFT JOIN`\r\n\r\n> 保持左表的记录完整性，右表查不到就摆 NULL\r\n\r\n```\r\nSELECT id, pic_path AS 路径 , mime_type.mime_info AS 类型 , pic_length \r\nFROM pic LEFT JOIN mime_type \r\nON pic.pic_mime = mime_type.mime_id \r\nORDER BY id DESC LIMIT 4;\r\n\r\n+-----+------------------+------------+------------+\r\n| id  | 路径             | 类型       | pic_length |\r\n+-----+------------------+------------+------------+\r\n| 290 | test.jpg         | NULL       |        100 |\r\n| 289 | 虚拟机栈.png     | image/png  |      63723 |\r\n| 288 | 统一返回.png     | image/png  |      29485 |\r\n| 287 | 洛天依.jpg       | image/jpeg |      42117 |\r\n+-----+------------------+------------+------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 3. 右(外)连接查询 :`RIGHT JOIN`\r\n\r\n> 保持右表的记录完整性，左表查不到就摆 NULL\r\n\r\n```\r\nSELECT id, pic_path AS 路径 , mime_type.mime_info AS 类型 , pic_length \r\nFROM pic RIGHT JOIN mime_type \r\nON pic.pic_mime = mime_type.mime_id \r\nORDER BY id LIMIT 8;\r\n\r\n+------+--------------------------------------+---------------+------------+\r\n| id   | 路径                                 | 类型          | pic_length |\r\n+------+--------------------------------------+---------------+------------+\r\n| NULL | NULL                                 | text/plain    |       NULL |\r\n| NULL | NULL                                 | video/mp4     |       NULL |\r\n| NULL | NULL                                 | image/svg+xml |       NULL |\r\n|    1 | 30000X20000.jpg                      | image/jpeg    |  116342886 |\r\n|    2 | 3000X2000.jpg                        | image/jpeg    |    3404969 |\r\n|    3 | 300X200.jpg                          | image/jpeg    |      99097 |\r\n|    4 | 30X20.jpg                            | image/jpeg    |      10158 |\r\n|    5 | 6dc9e8455c47d964e1a8a4ef04cf9477.jpg | image/jpeg    |     236254 |\r\n+------+--------------------------------------+---------------+------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 4. 全(外)连接 (伪):`使用UNION`\r\n\r\n> MySQL不支持全外连接，所以只能采取关键字UNION来联合左、右连接的方法 UNION : 将若干条sql的查询结果集合并成一个。 `UNION ALL`不会覆盖相同结果\r\n\r\n```\r\nSELECT id, pic_path AS 路径 , mime_type.mime_info AS 类型 , pic_length \r\nFROM pic LEFT JOIN mime_type ON pic.pic_mime = mime_type.mime_id \r\nUNION(\r\nSELECT id, pic_path AS 路径 , mime_type.mime_info AS 类型 , pic_length \r\nFROM pic RIGHT JOIN mime_type ON pic.pic_mime = mime_type.mime_id \r\n) \r\nORDER BY id DESC;\r\n\r\n+------+------------------------------------------------------------------------------------+---------------+------------+\r\n| id   | 路径                                                                               | 类型          | pic_length |\r\n+------+------------------------------------------------------------------------------------+---------------+------------+\r\n|  290 | test.jpg                                                                           | NULL          |        100 |\r\n|  289 | 虚拟机栈.png                                                                       | image/png     |      63723 |\r\n|  288 | 统一返回.png                                                                       | image/png     |      29485 |\r\n|  287 | 洛天依.jpg                                                                         | image/jpeg    |      42117 |\r\n...\r\n|    3 | 300X200.jpg                                                                        | image/jpeg    |      99097 |\r\n|    2 | 3000X2000.jpg                                                                      | image/jpeg    |    3404969 |\r\n|    1 | 30000X20000.jpg                                                                    | image/jpeg    |  116342886 |\r\n| NULL | NULL                                                                               | text/plain    |       NULL |\r\n| NULL | NULL                                                                               | video/mp4     |       NULL |\r\n| NULL | NULL                                                                               | image/svg+xml |       NULL |\r\n+------+------------------------------------------------------------------------------------+---------------+------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 5. UNION小测试\r\n\r\n```\r\nCREATE TABLE a(\r\nid CHAR(4),\r\nnum INT\r\n);\r\n\r\nINSERT INTO a(id,num) VALUES\r\n('a',4),('b',6),('c',2),('d',8);\r\n\r\nCREATE TABLE b(\r\nid CHAR(4),\r\nnum INT\r\n);\r\nINSERT INTO b(id,num) VALUES\r\n('b',8),('c',7),('d',3),('e',18);\r\n\r\nmysql> SELECT * FROM a;         mysql> SELECT * FROM b;         \r\n+------+------+                 +------+------+  \r\n| id   | num  |                 | id   | num  |  \r\n+------+------+                 +------+------+  \r\n| a    |    4 |                 | b    |    8 |  \r\n| b    |    6 |                 | c    |    7 |  \r\n| c    |    2 |                 | d    |    3 |  \r\n| d    |    8 |                 | e    |   18 |  \r\n+------+------+                 +------+------+  \r\n\r\nSELECT id,sum(num) FROM \r\n(SELECT * FROM a \r\nUNION ALL \r\nSELECT * FROM b) as temp \r\nGROUP BY id;\r\n\r\n+------+----------+\r\n| id   | sum(num) |\r\n+------+----------+\r\n| a    |        4 |\r\n| b    |       14 |\r\n| c    |        9 |\r\n| d    |       11 |\r\n| e    |       18 |\r\n+------+----------+\r\n\r\n```\r\n\r\n------\r\n\r\n#### 六、DDL 建库/表\r\n\r\n##### 1、关于操作数据库\r\n\r\n```\r\nSHOW DATABASES; # 显示所有的数据库\r\nSHOW CREATE DATABASE <数据库名> # 查看数据库创建信息\r\nUSE <数据库名>; # 使用数据库\r\nCREATE DATABASE <数据库名> [CHARACTER SET <字符集>]; # 创建一个将的数据库指定字符集\r\nALTER DATABASE <数据库名> CHARACTER SET <字符集>; # 修改数据库字符集\r\nDROP DATABASE  <数据库名>; # 传说中的删库跑路\r\nSELECT DATABASE(); # 查看当前选中的数据库\r\n\r\n```\r\n\r\n------\r\n\r\n##### 2.显示数据库信息\r\n\r\n```\r\nSHOW TABLES; # 展示当前数据库中的表\r\nSHOW TABLES FROM mysql # 展示指定数据库中的表\r\nDESC <表名>; # 查看表结构\r\nSHOW COLUMNS FROM <表名>; # 查看表结构\r\n\r\n```\r\n\r\n------\r\n\r\n##### 3.创建表\r\n\r\n```\r\n|-- UNSIGNED 无符号  AUTO_INCREMENT 自增长 \r\n|-- ZEROFILL 前面自动填 0 , 默认 UNSIGNED\r\nCREATE TABLE create_test(\r\n   id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,\r\n   code TINYINT(5) ZEROFILL DEFAULT 0  \r\n );\r\n \r\n INSERT INTO create_test(code) VALUES (5);\r\n INSERT INTO create_test VALUES (); #默认值测试\r\n mysql> SELECT * FROM create_test;\r\n+----+-------+\r\n| id | code  |\r\n+----+-------+\r\n|  1 | 00005 |\r\n|  2 | 00000 |\r\n+----+-------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 4.为表增加属性\r\n\r\n> ```\r\n> ALTER TABLE <表名> ADD 属性信息 [AFTER 属性] ;\r\n> ```\r\n\r\n```\r\n|-- 看一下当前表结构\r\n\r\nmysql> DESC create_test;\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n| Field | Type                         | Null | Key | Default | Extra          |\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n| id    | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| code  | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n\r\nmysql> ALTER TABLE create_test ADD age SMALLINT UNSIGNED NOT NULL;\r\nmysql> DESC create_test;\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n| Field | Type                         | Null | Key | Default | Extra          |\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n| id    | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| code  | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age   | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n\r\n|-- AFTER可将属性排在指定属性之后(强迫症专用)\r\n|-- ALTER TABLE create_test ADD password VARCHAR(32) AFTER id;\r\nmysql> ALTER TABLE create_test ADD password VARCHAR(32) AFTER id;\r\nmysql> DESC create_test;\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| Field    | Type                         | Null | Key | Default | Extra          |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| id       | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| password | varchar(32)                  | YES  |     | NULL    |                |\r\n| code     | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age      | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n\r\n|-- 一次添加多个属性\r\nALTER TABLE create_test ADD (aaa VARCHAR(32), bbb VARCHAR(32),ccc VARCHAR(32));\r\nmysql> DESC create_test;\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| Field    | Type                         | Null | Key | Default | Extra          |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| id       | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| password | varchar(32)                  | YES  |     | NULL    |                |\r\n| code     | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age      | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n| aaa      | varchar(32)                  | YES  |     | NULL    |                |\r\n| bbb      | varchar(32)                  | YES  |     | NULL    |                |\r\n| ccc      | varchar(32)                  | YES  |     | NULL    |                |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 5.为表删除属性\r\n\r\n> ```\r\n> ALTER TABLE <表名> DROP 属性\r\n> ```\r\n\r\n```\r\nALTER TABLE create_test DROP aaa,DROP bbb,DROP ccc;\r\n\r\nmysql> DESC create_test;\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| Field    | Type                         | Null | Key | Default | Extra          |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| id       | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| password | varchar(32)                  | YES  |     | NULL    |                |\r\n| code     | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age      | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 6.修改属性的类型\r\n\r\n> ```\r\n> ALTER TABLE <表名> MODIFY 属性 属性类型 [FIRST];\r\n> ```\r\n\r\n```\r\n|-- 把password改成VARCHAR(40)\r\nALTER TABLE create_test MODIFY password VARCHAR(40);\r\nmysql> DESC create_test;\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| Field    | Type                         | Null | Key | Default | Extra          |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| id       | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| password | varchar(40)                  | YES  |     | NULL    |                |\r\n| code     | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age      | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n\r\n|-- 将某个属性移到最顶\r\nALTER TABLE create_test MODIFY password VARCHAR(40) FIRST;\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| Field    | Type                         | Null | Key | Default | Extra          |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n| password | varchar(40)                  | YES  |     | NULL    |                |\r\n| id       | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| code     | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age      | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n+----------+------------------------------+------+-----+---------+----------------+\r\n\r\n```\r\n\r\n------\r\n\r\n###### 7.修改表的属性名\r\n\r\n> ```\r\n> ALTER TABLE <表名> CHANGE 原属性 新属性 新属性类型;\r\n> ```\r\n\r\n```\r\nmysql> ALTER TABLE create_test CHANGE password pw varchar(40);\r\nmysql> DESC create_test;\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n| Field | Type                         | Null | Key | Default | Extra          |\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n| pw    | varchar(40)                  | YES  |     | NULL    |                |\r\n| id    | int(10) unsigned             | NO   | PRI | NULL    | auto_increment |\r\n| code  | tinyint(5) unsigned zerofill | YES  |     | 00000   |                |\r\n| age   | smallint(5) unsigned         | NO   |     | NULL    |                |\r\n+-------+------------------------------+------+-----+---------+----------------+\r\n\r\n```\r\n\r\n------\r\n\r\n##### 8.修改表名\r\n\r\n> 方式一：`ALTER TABLE 旧表名 RENAME 新表名;` 方式二：`RENAME TABLE 旧表名 TO 新表名;`\r\n\r\n```\r\nALTER TABLE create_test RENAME 阿姆斯特朗回旋加速喷气式阿姆斯特朗炮;\r\nmysql> SHOW TABLES;\r\n+--------------------------------------------------------+\r\n| Tables_in_datatype                                     |\r\n+--------------------------------------------------------+\r\n| 阿姆斯特朗回旋加速喷气式阿姆斯特朗炮                   |\r\n| a                                                      |\r\n| b                                                      |\r\n| mime_type                                              |\r\n| pic                                                    |\r\n| type_number                                            |\r\n+--------------------------------------------------------+\r\n\r\nRENAME TABLE 阿姆斯特朗回旋加速喷气式阿姆斯特朗炮 TO toly;\r\n\r\nmysql> SHOW TABLES;\r\n+--------------------+\r\n| Tables_in_datatype |\r\n+--------------------+\r\n| a                  |\r\n| b                  |\r\n| mime_type          |\r\n| pic                |\r\n| toly               |\r\n| type_number        |\r\n+--------------------+\r\n\r\n```\r\n\r\n  "},"97d6":function(n,r,e){"use strict";e.r(r),r["default"]="# MySQL 的全局锁、表级锁、行级锁\r\n\r\n大家好，我是小林。\r\n\r\n\r\n\r\n这次，来说说 **MySQL 的锁**，主要是 Q&A 的形式，看起来会比较轻松。\r\n\r\n\r\n\r\n在 MySQL 里，根据加锁的范围，可以分为**全局锁、表级锁和行锁**三类。\r\n\r\n不多 BB 了，**发车！**\r\n\r\n![image-20211111124843481](MySQL 的全局锁、表级锁、行级锁.assets/image-20211111124843481.png)\r\n\r\n### 全局锁\r\n\r\n> 全局锁是怎么用的？\r\n\r\n要使用全局锁，则要执行这条命：\r\n\r\n```\r\nflush tables with read lock\r\n```\r\n\r\n执行后，**整个数据库就处于只读状态了**，这时其他线程执行以下操作，都会被阻塞：\r\n\r\n- 对数据的增删查改操作，比如 select、insert、delete、update等语句；\r\n- 对表结构的更改操作，比如 alter table、drop table 等语句。\r\n\r\n如果要释放全局锁，则要执行这条命令：\r\n\r\n```\r\nunlock tables\r\n```\r\n\r\n当然，当会话断开了，全局锁会被自动释放。\r\n\r\n> 全局锁应用场景是什么？\r\n\r\n全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。\r\n\r\n举个例子大家就知道了。\r\n\r\n在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。\r\n\r\n如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据库表的更细，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。\r\n\r\n那么，有可能出现这样的顺序：\r\n\r\n1. 先备份了用户表的数据；\r\n2. 然后有用户发起了购买商品的操作；\r\n3. 接着再备份商品表的数据。\r\n\r\n也就是在备份用户表和商品表之间，有用户购买了商品。\r\n\r\n这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。\r\n\r\n所以，在全库逻辑备份期间，加上全局锁，就不会出现上面这种情况了。\r\n\r\n> 加全局锁又会带来什么缺点呢？\r\n\r\n加上全局锁，意味着整个数据库都是只读状态。\r\n\r\n那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。\r\n\r\n> 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？\r\n\r\n有的，如果数据库的引擎支持的事务支持**可重复读的隔离级别**，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。\r\n\r\n因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。\r\n\r\n备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 `–single-transaction` 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。\r\n\r\nInnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。\r\n\r\n但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。\r\n\r\n### 表级锁\r\n\r\n> MySQL 表级锁有哪些？具体怎么用的。\r\n\r\nMySQL 里面表级别的锁有这几种：\r\n\r\n- 表锁；\r\n- 元数据锁（MDL）;\r\n- 意向锁；\r\n- AUTO-INC 锁；\r\n\r\n#### 表锁\r\n\r\n先来说说***表锁\\***。\r\n\r\n如果我们想对学生表（t_student）加表锁，可以使用下面的命令：\r\n\r\n```\r\n//表级别的共享锁，也就是读锁；\r\nlock tables t_student read;\r\n\r\n//表级别的独占锁，也就是写锁；\r\nlock tables t_stuent wirte;\r\n```\r\n\r\n需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。\r\n\r\n也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。\r\n\r\n要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：\r\n\r\n```\r\nunlock tables\r\n```\r\n\r\n另外，当会话退出后，也会释放所有表锁。\r\n\r\n不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，**InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁**。\r\n\r\n#### 元数据锁\r\n\r\n再来说说***元数据锁（MDL）\\***。\r\n\r\n我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：\r\n\r\n- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；\r\n- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；\r\n\r\nMDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。\r\n\r\n当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。\r\n\r\n反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。\r\n\r\n> MDL 不需要显示调用，那它是在什么时候释放的?\r\n\r\nMDL 是在事务提交后才会释放，这意味着**事务执行期间，MDL 是一直持有的**。\r\n\r\n那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：\r\n\r\n1. 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；\r\n2. 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；\r\n3. 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，\r\n\r\n那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。\r\n\r\n> 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？\r\n\r\n这是因为申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。\r\n\r\n所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。\r\n\r\n#### 意向锁\r\n\r\n接着，说说***意向锁\\***。\r\n\r\n- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；\r\n- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；\r\n\r\n也就是，当执行插入、更新、删除操作，需要先对表加上「意向共享锁」，然后对该记录加独占锁。\r\n\r\n而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。\r\n\r\n不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下：\r\n\r\n```\r\n//先在表上加上意向共享锁，然后对读取的记录加独占锁\r\nselect ... lock in share mode;\r\n\r\n//先表上加上意向独占锁，然后对读取的记录加独占锁\r\nselect ... for update;\r\n```\r\n\r\n**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（\\*lock tables … read\\*）和独占表锁（\\*lock tables … write\\*）发生冲突。**\r\n\r\n表锁和行锁是满足读读共享、读写互斥、写写互斥的。\r\n\r\n如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。\r\n\r\n那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。\r\n\r\n所以，**意向锁的目的是为了快速判断表里是否有记录被加锁**。\r\n\r\n#### AUTO-INC 锁\r\n\r\n最后，说说 ***AUTO-INC 锁\\***。\r\n\r\n在为某个字段声明 `AUTO_INCREMENT` 属性时，之后可以在插入数据时，可以不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。\r\n\r\nAUTO-INC 锁是特殊的表锁机制，锁**不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放**。\r\n\r\n**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。\r\n\r\n那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的。\r\n\r\n但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。\r\n\r\n因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增。\r\n\r\n一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上轻量级锁，**然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**。\r\n\r\nInnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。\r\n\r\n- 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁；\r\n- 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁；\r\n- 当 innodb_autoinc_lock_mode = 1，这个是默认值，两种锁混着用，如果能够确定插入记录的数量就采用轻量级锁，不确定时就采用 AUTO-INC 锁。\r\n\r\n不过，当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，**这在有主从赋值的场景中是不安全的**。\r\n\r\n> 行级锁有哪些？\r\n\r\nInnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。\r\n\r\n行级锁的类型主要有三类：\r\n\r\n- Record Lock，记录锁，也就是仅仅把一条记录锁上；\r\n- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；\r\n- Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。\r\n\r\n前面也提到，普通的 select 语句是不会对记录加锁的，如果要在查询时对记录加行锁，可以使用下面这两个方式：\r\n\r\n```\r\n//对读取的记录加共享锁\r\nselect ... lock in share mode;\r\n\r\n//对读取的记录加独占锁\r\nselect ... for update;\r\n```\r\n\r\n上面这两条语句必须再一个事务中，当事务提交了，锁就会被释放，因此在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。\r\n\r\n"},a03c:function(n,r,e){"use strict";e.r(r),r["default"]="相关阅读：\n\n- [史上最全Redis高可用技术解决方案大全](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247484850&idx=1&sn=3238360bfa8105cf758dcf7354af2814&chksm=cea24a79f9d5c36fb2399aafa91d7fb2699b5006d8d037fe8aaf2e5577ff20ae322868b04a87&token=1082669959&lang=zh_CN&scene=21#wechat_redirect)\n- [Raft协议实战之Redis Sentinel的选举Leader源码解析](http://weizijun.cn/2015/04/30/Raft%E5%8D%8F%E8%AE%AE%E5%AE%9E%E6%88%98%E4%B9%8BRedis%20Sentinel%E7%9A%84%E9%80%89%E4%B8%BELeader%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/)\n\n目录：\n\n\x3c!-- TOC --\x3e\n\n- [Redis 集群以及应用](#redis-集群以及应用)\n    - [集群](#集群)\n        - [主从复制](#主从复制)\n            - [主从链(拓扑结构)](#主从链拓扑结构)\n            - [复制模式](#复制模式)\n            - [问题点](#问题点)\n        - [哨兵机制](#哨兵机制)\n            - [拓扑图](#拓扑图)\n            - [节点下线](#节点下线)\n            - [Leader选举](#Leader选举)\n            - [故障转移](#故障转移)\n            - [读写分离](#读写分离)\n            - [定时任务](#定时任务)\n        - [分布式集群(Cluster)](#分布式集群cluster)\n            - [拓扑图](#拓扑图)\n            - [通讯](#通讯)\n                - [集中式](#集中式)\n                - [Gossip](#gossip)\n            - [寻址分片](#寻址分片)\n                - [hash取模](#hash取模)\n                - [一致性hash](#一致性hash)\n                - [hash槽](#hash槽)\n    - [使用场景](#使用场景)\n        - [热点数据](#热点数据)\n        - [会话维持 Session](#会话维持-session)\n        - [分布式锁 SETNX](#分布式锁-setnx)\n        - [表缓存](#表缓存)\n        - [消息队列 list](#消息队列-list)\n        - [计数器 string](#计数器-string)\n    - [缓存设计](#缓存设计)\n        - [更新策略](#更新策略)\n        - [更新一致性](#更新一致性)\n        - [缓存粒度](#缓存粒度)\n        - [缓存穿透](#缓存穿透)\n            - [解决方案](#解决方案)\n        - [缓存雪崩](#缓存雪崩)\n            - [出现后应对](#出现后应对)\n            - [请求过程](#请求过程)\n\n\x3c!-- /MarkdownTOC --\x3e\n\n# Redis 集群以及应用\n\n## 集群\n\n### 主从复制\n\n#### 主从链(拓扑结构)\n\n\n\n![主从](redis集群以及应用场景.assets/67539461-d1a26c00-f714-11e9-81ae-61fa89faf156.png)\n\n![主从](redis集群以及应用场景.assets/67539485-e0891e80-f714-11e9-8980-d253239fcd8b.png)\n\n#### 复制模式\n- 全量复制：Master 全部同步到 Slave\n- 部分复制：Slave 数据丢失进行备份\n\n#### 问题点\n- 同步故障\n    - 复制数据延迟(不一致)\n    - 读取过期数据(Slave 不能删除数据)\n    - 从节点故障\n    - 主节点故障\n- 配置不一致\n    - maxmemory 不一致:丢失数据\n    - 优化参数不一致:内存不一致.\n- 避免全量复制\n    - 选择小主节点(分片)、低峰期间操作.\n    - 如果节点运行 id 不匹配(如主节点重启、运行 id 发生变化)，此时要执行全量复制，应该配合哨兵和集群解决.\n    - 主从复制挤压缓冲区不足产生的问题(网络中断，部分复制无法满足)，可增大复制缓冲区( rel_backlog_size 参数).\n- 复制风暴\n\n### 哨兵机制\n\n#### 拓扑图\n\n![哨兵机制-拓扑图](redis集群以及应用场景.assets/哨兵机制-拓扑图.png)\n\n#### 节点下线\n\n- 主观下线\n    - 即 Sentinel 节点对 Redis 节点失败的偏见，超出超时时间认为 Master 已经宕机。\n    - Sentinel 集群的每一个 Sentinel 节点会定时对 Redis 集群的所有节点发心跳包检测节点是否正常。如果一个节点在 `down-after-milliseconds` 时间内没有回复 Sentinel 节点的心跳包，则该 Redis 节点被该 Sentinel 节点主观下线。\n- 客观下线\n    - 所有 Sentinel 节点对 Redis 节点失败要达成共识，即超过 quorum 个统一。\n    - 当节点被一个 Sentinel 节点记为主观下线时，并不意味着该节点肯定故障了，还需要 Sentinel 集群的其他 Sentinel 节点共同判断为主观下线才行。\n    - 该 Sentinel 节点会询问其它 Sentinel 节点，如果 Sentinel 集群中超过 quorum 数量的 Sentinel 节点认为该 Redis 节点主观下线，则该 Redis 客观下线。\n\n#### Leader选举\n\n- 选举出一个 Sentinel 作为 Leader：集群中至少有三个 Sentinel 节点，但只有其中一个节点可完成故障转移.通过以下命令可以进行失败判定或领导者选举。\n- 选举流程\n    1. 每个主观下线的 Sentinel 节点向其他 Sentinel 节点发送命令，要求设置它为领导者.\n    2. 收到命令的 Sentinel 节点如果没有同意通过其他 Sentinel 节点发送的命令，则同意该请求，否则拒绝。\n    3. 如果该 Sentinel 节点发现自己的票数已经超过 Sentinel 集合半数且超过 quorum，则它成为领导者。\n    4. 如果此过程有多个 Sentinel 节点成为领导者，则等待一段时间再重新进行选举。\n\n#### 故障转移\n\n- 转移流程\n    1. Sentinel 选出一个合适的 Slave 作为新的 Master(slaveof no one 命令)。\n    2. 向其余 Slave 发出通知，让它们成为新 Master 的 Slave( parallel-syncs 参数)。\n    3. 等待旧 Master 复活，并使之成为新 Master 的 Slave。\n    4. 向客户端通知 Master 变化。\n- 从 Slave 中选择新 Master 节点的规则(slave 升级成 master 之后)\n    1. 选择 slave-priority 最高的节点。\n    2. 选择复制偏移量最大的节点(同步数据最多)。\n    3. 选择 runId 最小的节点。\n\n>Sentinel 集群运行过程中故障转移完成，所有 Sentinel 又会恢复平等。Leader 仅仅是故障转移操作出现的角色。\n\n#### 读写分离\n\n#### 定时任务\n\n- 每 1s 每个 Sentinel 对其他 Sentinel 和 Redis 执行 ping，进行心跳检测。\n- 每 2s 每个 Sentinel 通过 Master 的 Channel 交换信息(pub - sub)。\n- 每 10s 每个 Sentinel 对 Master 和 Slave 执行 info，目的是发现 Slave 节点、确定主从关系。\n\n### 分布式集群(Cluster)\n\n#### 拓扑图\n\n![image](redis集群以及应用场景.assets/67539510-f8f93900-f714-11e9-9d8d-08afdecff95a.png)\n\n#### 通讯\n\n##### 集中式\n\n> 将集群元数据(节点信息、故障等等)集中存储在某个节点上。\n- 优势\n    1. 元数据的更新读取具有很强的时效性，元数据修改立即更新\n- 劣势\n    1. 数据集中存储\n\n##### Gossip\n\n![image](redis集群以及应用场景.assets/67539546-16c69e00-f715-11e9-9891-1e81b6af624c.png)\n\n- [Gossip 协议](https://www.jianshu.com/p/8279d6fd65bb)\n\n#### 寻址分片\n\n##### hash取模\n\n- hash(key)%机器数量\n- 问题\n    1. 机器宕机，造成数据丢失，数据读取失败\n    1. 伸缩性\n\n##### 一致性hash\n\n- ![image](redis集群以及应用场景.assets/67539595-352c9980-f715-11e9-8e4a-9d9c04027785.png)\n\n- 问题\n    1. 一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。\n        - 解决方案\n            - 可以通过引入虚拟节点机制解决：即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。\n\n##### hash槽\n\n- CRC16(key)%16384\n- \n![image](redis集群以及应用场景.assets/67539610-3fe72e80-f715-11e9-8e0d-ea58bc965795.png)\n\n## 使用场景\n\n### 热点数据\n\n存取数据优先从 Redis 操作，如果不存在再从文件（例如 MySQL）中操作，从文件操作完后将数据存储到 Redis 中并返回。同时有个定时任务后台定时扫描 Redis 的 key，根据业务规则进行淘汰，防止某些只访问一两次的数据一直存在 Redis 中。\n>例如使用 Zset 数据结构，存储 Key 的访问次数/最后访问时间作为 Score，最后做排序，来淘汰那些最少访问的 Key。  \n\n如果企业级应用，可以参考：[阿里云的 Redis 混合存储版][1]\n\n### 会话维持 Session\n\n会话维持 Session 场景，即使用 Redis 作为分布式场景下的登录中心存储应用。每次不同的服务在登录的时候，都会去统一的 Redis 去验证 Session 是否正确。但是在微服务场景，一般会考虑 Redis + JWT 做 Oauth2 模块。\n>其中 Redis 存储 JWT 的相关信息主要是留出口子，方便以后做统一的防刷接口，或者做登录设备限制等。\n\n### 分布式锁 SETNX\n\n命令格式：`SETNX key value`：当且仅当 key 不存在，将 key 的值设为 value。若给定的 key 已经存在，则 SETNX 不做任何动作。\n\n1. 超时时间设置：获取锁的同时，启动守护线程，使用 expire 进行定时更新超时时间。如果该业务机器宕机，守护线程也挂掉，这样也会自动过期。如果该业务不是宕机，而是真的需要这么久的操作时间，那么增加超时时间在业务上也是可以接受的，但是肯定有个最大的阈值。\n2. 但是为了增加高可用，需要使用多台 Redis，就增加了复杂性，就可以参考 Redlock：[Redlock分布式锁](Redlock分布式锁.md#怎么在单节点上实现分布式锁)\n\n### 表缓存\n\nRedis 缓存表的场景有黑名单、禁言表等。访问频率较高，即读高。根据业务需求，可以使用后台定时任务定时刷新 Redis 的缓存表数据。\n\n### 消息队列 list\n\n主要使用了 List 数据结构。  \nList 支持在头部和尾部操作，因此可以实现简单的消息队列。\n1. 发消息：在 List 尾部塞入数据。\n2. 消费消息：在 List 头部拿出数据。\n\n同时可以使用多个 List，来实现多个队列，根据不同的业务消息，塞入不同的 List，来增加吞吐量。\n\n### 计数器 string\n\n主要使用了 INCR、DECR、INCRBY、DECRBY 方法。\n\nINCR key：给 key 的 value 值增加一 \nDECR key：给 key 的 value 值减去一\n\n## 缓存设计\n\n### 更新策略\n\n- LRU、LFU、FIFO 算法自动清除：一致性最差，维护成本低。\n- 超时自动清除(key expire)：一致性较差，维护成本低。\n- 主动更新：代码层面控制生命周期，一致性最好，维护成本高。\n\n在 Redis 根据在 redis.conf 的参数 `maxmemory` 来做更新淘汰策略：\n1. noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。大多数写命令都会导致占用更多的内存(有极少数会例外, 如 DEL 命令)。\n2. allkeys-lru: 所有 key 通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。\n3. volatile-lru: 只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。\n4. allkeys-random: 所有key通用; 随机删除一部分 key。\n5. volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。\n6. volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。\n\n### 更新一致性\n\n- 读请求：先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。\n- 写请求：先删除缓存，然后再更新数据库(避免大量地写、却又不经常读的数据导致缓存频繁更新)。\n\n### 缓存粒度\n\n- 通用性：全量属性更好。\n- 占用空间：部分属性更好。\n- 代码维护成本。\n\n### 缓存穿透\n\n> 当大量的请求无命中缓存、直接请求到后端数据库(业务代码的 bug、或恶意攻击)，同时后端数据库也没有查询到相应的记录、无法添加缓存。  \n> 这种状态会一直维持，流量一直打到存储层上，无法利用缓存、还会给存储层带来巨大压力。\n\n#### 解决方案\n\n1. 请求无法命中缓存、同时数据库记录为空时在缓存添加该 key 的空对象(设置过期时间)，缺点是可能会在缓存中添加大量的空值键(比如遭到恶意攻击或爬虫)，而且缓存层和存储层数据短期内不一致；\n2. 使用布隆过滤器在缓存层前拦截非法请求、自动为空值添加黑名单(同时可能要为误判的记录添加白名单).但需要考虑布隆过滤器的维护(离线生成/ 实时生成)。\n\n### 缓存雪崩\n\n> 缓存崩溃时请求会直接落到数据库上，很可能由于无法承受大量的并发请求而崩溃，此时如果只重启数据库，或因为缓存重启后没有数据，新的流量进来很快又会把数据库击倒。\n\n#### 出现后应对\n\n- 事前：Redis 高可用，主从 + 哨兵，Redis Cluster，避免全盘崩溃。\n- 事中：本地 ehcache 缓存 + hystrix 限流 & 降级，避免数据库承受太多压力。\n- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。\n\n#### 请求过程\n\n1. 用户请求先访问本地缓存，无命中后再访问 Redis，如果本地缓存和 Redis 都没有再查数据库，并把数据添加到本地缓存和 Redis；\n2. 由于设置了限流，一段时间范围内超出的请求走降级处理(返回默认值，或给出友情提示)。\n\n"},a669:function(n,r,e){"use strict";e.r(r),r["default"]="本文来自[木木匠](https://github.com/kinglaw1204)投稿。\n\n\x3c!-- TOC --\x3e\n\n- [一 MySQL 基础架构分析](#一-mysql-基础架构分析)\n    - [1.1 MySQL 基本架构概览](#11-mysql-基本架构概览)\n    - [1.2 Server 层基本组件介绍](#12-server-层基本组件介绍)\n        - [1) 连接器](#1-连接器)\n        - [2) 查询缓存(MySQL 8.0 版本后移除)](#2-查询缓存mysql-80-版本后移除)\n        - [3) 分析器](#3-分析器)\n        - [4) 优化器](#4-优化器)\n        - [5) 执行器](#5-执行器)\n- [二 语句分析](#二-语句分析)\n    - [2.1 查询语句](#21-查询语句)\n    - [2.2 更新语句](#22-更新语句)\n- [三 总结](#三-总结)\n- [四 参考](#四-参考)\n\n\x3c!-- /TOC --\x3e\n\n本篇文章会分析下一个 sql 语句在 MySQL 中的执行流程，包括 sql 的查询在 MySQL 内部会怎么流转，sql 语句的更新是怎么完成的。\n\n在分析之前我会先带着你看看 MySQL 的基础架构，知道了 MySQL 由那些组件组成以及这些组件的作用是什么，可以帮助我们理解和解决这些问题。\n\n## 一 MySQL 基础架构分析\n\n### 1.1 MySQL 基本架构概览\n\n下图是 MySQL  的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。\n\n先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在 1.2 节中会详细介绍到这些组件的作用。\n\n- **连接器：**身份认证和权限相关(登录 MySQL 的时候)。\n- **查询缓存：**执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。\n- **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。\n- **优化器：**按照 MySQL 认为最优的方案去执行。\n- **执行器：**执行语句，然后从存储引擎返回数据。\n\n \n\n简单来说 MySQL  主要分为 Server 层和存储引擎层：\n\n- **Server 层**：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。\n- **存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。**\n\n### 1.2 Server 层基本组件介绍\n\n#### 1) 连接器\n\n连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。\n\n主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。\n\n#### 2) 查询缓存(MySQL 8.0 版本后移除)\n\n查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。\n\n连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。\n\nMySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。\n\n所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。\n\nMySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。\n\n#### 3) 分析器\n\nMySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：\n\n**第一步，词法分析**，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。\n\n**第二步，语法分析**，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。\n\n完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。\n\n#### 4) 优化器 \n\n优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。\n\n可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。\n\n#### 5) 执行器\n\n当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。\n\n## 二 语句分析 \n\n### 2.1 查询语句\n\n说了以上这么多，那么究竟一条 sql 语句是如何执行的呢？其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下：\n\n```sql\nselect * from tb_student  A where A.age='18' and A.name=' 张三 ';\n```\n\n结合上面的说明，我们分析下这个语句的执行流程：\n\n* 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。\n* 通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。\n* 接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案：\n  \n        a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。\n        b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。\n    那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。\n\n* 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。\n\n### 2.2 更新语句\n\n以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下：\n\n```\nupdate tb_student A set A.age='19' where A.name=' 张三 ';\n```\n我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实这条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块是 **binlog（归档日志）** ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 **redo log（重做日志）**，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：\n\n* 先查询到张三这一条数据，如果有缓存，也是会用到缓存。\n* 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。\n* 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。\n* 更新完成。\n\n**这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗?**\n\n这是因为最开始 MySQL 并没有 InnoDB 引擎（InnoDB 引擎是其他公司以插件形式插入 MySQL 的），MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。\n\n并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？\n\n* **先写 redo log 直接提交，然后写 binlog**，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 bingog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。\n* **先写 binlog，然后写 redo log**，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。\n\n如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？\n这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：\n\n* 判断 redo log 是否完整，如果判断是完整的，就立即提交。\n* 如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。\n\n这样就解决了数据一致性的问题。\n\n## 三 总结\n\n* MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用，redolog 只有 InnoDB 有。\n* 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。\n* 查询语句的执行流程如下：权限校验（如果命中缓存）---\x3e查询缓存---\x3e分析器---\x3e优化器---\x3e权限校验---\x3e执行器---\x3e引擎\n* 更新语句执行流程如下：分析器----\x3e权限校验----\x3e执行器---\x3e引擎---redo log(prepare 状态)---\x3ebinlog---\x3eredo log(commit状态)\n\n## 四 参考\n\n* 《MySQL 实战45讲》\n* MySQL 5.6参考手册:<https://dev.MySQL.com/doc/refman/5.6/en/>\n"},b2b7:function(n,r,e){"use strict";e.r(r),r["default"]="> 本文来自公号程序猿阿星投稿，JavaGuide 对其做了补充完善。\n\n## 前言\n\n`MySQL` 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 `binlog`（归档日志）和事务日志 `redo log`（重做日志）和 `undo log`（回滚日志）。\n\n![](MySQL三大日志.assets/01.png)\n\n今天就来聊聊 `redo log`（重做日志）、`binlog`（归档日志）、两阶段提交、`undo log` （回滚日志）。\n\n## redo log\n\n`redo log`（重做日志）是`InnoDB`存储引擎独有的，它让`MySQL`拥有了崩溃恢复能力。\n\n比如 `MySQL` 实例挂了或宕机了，重启时，`InnoDB`存储引擎会使用`redo log`恢复数据，保证数据的持久性与完整性。\n\n![](MySQL三大日志.assets/02.png)\n\n`MySQL` 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 `Buffer Pool` 中。\n\n后续的查询都是先从 `Buffer Pool` 中找，没有命中再去硬盘加载，减少硬盘 `IO` 开销，提升性能。\n\n更新表数据的时候，也是如此，发现 `Buffer Pool` 里存在要更新的数据，就直接在 `Buffer Pool` 里更新。\n\n然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（`redo log buffer`）里，接着刷盘到 `redo log` 文件里。\n\n![](MySQL三大日志.assets/03.png)\n\n理想情况，事务一提交就会进行刷盘操作，但实际上，刷盘的时机是根据策略来进行的。\n\n> 小贴士：每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成\n\n### 刷盘时机\n\n`InnoDB` 存储引擎为 `redo log` 的刷盘策略提供了 `innodb_flush_log_at_trx_commit` 参数，它支持三种策略：\n\n- **0** ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作\n- **1** ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）\n- **2** ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache\n\n`innodb_flush_log_at_trx_commit` 参数默认为 1 ，也就是说当事务提交时会调用 `fsync` 对 redo log 进行刷盘\n\n另外，`InnoDB` 存储引擎有一个后台线程，每隔`1` 秒，就会把 `redo log buffer` 中的内容写到文件系统缓存（`page cache`），然后调用 `fsync` 刷盘。\n\n![](MySQL三大日志.assets/04.png)\n\n也就是说，一个没有提交事务的 `redo log` 记录，也可能会刷盘。\n\n**为什么呢？**\n\n因为在事务执行过程 `redo log` 记录是会写入`redo log buffer` 中，这些 `redo log` 记录会被后台线程刷盘。\n\n![](MySQL三大日志.assets/05.png)\n\n除了后台线程每秒`1`次的轮询操作，还有一种情况，当 `redo log buffer` 占用的空间即将达到 `innodb_log_buffer_size` 一半的时候，后台线程会主动刷盘。\n\n下面是不同刷盘策略的流程图。\n\n#### innodb_flush_log_at_trx_commit=0\n\n![](MySQL三大日志.assets/06.png)\n\n为`0`时，如果`MySQL`挂了或宕机可能会有`1`秒数据的丢失。\n\n#### innodb_flush_log_at_trx_commit=1\n\n![](MySQL三大日志.assets/07.png)\n\n为`1`时， 只要事务提交成功，`redo log`记录就一定在硬盘里，不会有任何数据丢失。\n\n如果事务执行期间`MySQL`挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失。\n\n#### innodb_flush_log_at_trx_commit=2\n\n![](MySQL三大日志.assets/09.png)\n\n为`2`时， 只要事务提交成功，`redo log buffer`中的内容只写入文件系统缓存（`page cache`）。\n\n如果仅仅只是`MySQL`挂了不会有任何数据丢失，但是宕机可能会有`1`秒数据的丢失。\n\n### 日志文件组\n\n硬盘上存储的 `redo log` 日志文件不只一个，而是以一个**日志文件组**的形式出现的，每个的`redo`日志文件大小都是一样的。\n\n比如可以配置为一组`4`个文件，每个文件的大小是 `1GB`，整个 `redo log` 日志文件组可以记录`4G`的内容。\n\n它采用的是环形数组形式，从头开始写，写到末尾又回到头循环写，如下图所示。\n\n![](MySQL三大日志.assets/10.png)\n\n在个**日志文件组**中还有两个重要的属性，分别是 `write pos、checkpoint`\n\n- **write pos** 是当前记录的位置，一边写一边后移\n- **checkpoint** 是当前要擦除的位置，也是往后推移\n\n每次刷盘 `redo log` 记录到**日志文件组**中，`write pos` 位置就会后移更新。\n\n每次 `MySQL` 加载**日志文件组**恢复数据时，会清空加载过的 `redo log` 记录，并把 `checkpoint` 后移更新。\n\n`write pos` 和 `checkpoint` 之间的还空着的部分可以用来写入新的 `redo log` 记录。\n\n![](MySQL三大日志.assets/11.png)\n\n如果 `write pos` 追上 `checkpoint` ，表示**日志文件组**满了，这时候不能再写入新的 `redo log` 记录，`MySQL` 得停下来，清空一些记录，把 `checkpoint` 推进一下。\n\n![](MySQL三大日志.assets/12.png)\n\n### redo log 小结\n\n相信大家都知道 `redo log` 的作用和它的刷盘时机、存储形式。\n\n现在我们来思考一个问题： **只要每次把修改后的数据页直接刷盘不就好了，还有 `redo log` 什么事？**\n\n它们不都是刷盘么？差别在哪里？\n\n```java\n1 Byte = 8bit\n1 KB = 1024 Byte\n1 MB = 1024 KB\n1 GB = 1024 MB\n1 TB = 1024 GB\n```\n\n实际上，数据页大小是`16KB`，刷盘比较耗时，可能就修改了数据页里的几 `Byte` 数据，有必要把完整的数据页刷盘吗？\n\n而且数据页刷盘是随机写，因为一个数据页对应的位置可能在硬盘文件的随机位置，所以性能是很差。\n\n如果是写 `redo log`，一行记录可能就占几十 `Byte`，只包含表空间号、数据页号、磁盘文件偏移\n量、更新值，再加上是顺序写，所以刷盘速度很快。\n\n所以用 `redo log` 形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强。\n\n> 其实内存的数据页在一定时机也会刷盘，我们把这称为页合并，讲 `Buffer Pool`的时候会对这块细说\n\n## binlog\n\n`redo log` 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 `InnoDB` 存储引擎。\n\n而 `binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。\n\n不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。\n\n那 `binlog` 到底是用来干嘛的？\n\n可以说`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。\n\n![](MySQL三大日志.assets/01.png)\n\n`binlog`会记录所有涉及更新数据的逻辑操作，并且是顺序写。\n\n### 记录格式\n\n`binlog` 日志有三种格式，可以通过`binlog_format`参数指定。\n\n- **statement**\n- **row**\n- **mixed**\n\n指定`statement`，记录的内容是`SQL`语句原文，比如执行一条`update T set update_time=now() where id=1`，记录的内容如下。\n\n![](MySQL三大日志.assets/02.png)\n\n同步数据时，会执行记录的`SQL`语句，但是有个问题，`update_time=now()`这里会获取当前系统时间，直接执行会导致与原库的数据不一致。\n\n为了解决这种问题，我们需要指定为`row`，记录的内容不再是简单的`SQL`语句了，还包含操作的具体数据，记录内容如下。\n\n![](MySQL三大日志.assets/03.png)\n\n`row`格式记录的内容看不到详细信息，要通过`mysqlbinlog`工具解析出来。\n\n`update_time=now()`变成了具体的时间`update_time=1627112756247`，条件后面的@1、@2、@3 都是该行数据第 1 个~3 个字段的原始值（**假设这张表只有 3 个字段**）。\n\n这样就能保证同步数据的一致性，通常情况下都是指定为`row`，这样可以为数据库的恢复与同步带来更好的可靠性。\n\n但是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗`IO`资源，影响执行速度。\n\n所以就有了一种折中的方案，指定为`mixed`，记录的内容是前两者的混合。\n\n`MySQL`会判断这条`SQL`语句是否可能引起数据不一致，如果是，就用`row`格式，否则就用`statement`格式。\n\n### 写入机制\n\n`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。\n\n因为一个事务的`binlog`不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为`binlog cache`。\n\n我们可以通过`binlog_cache_size`参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（`Swap`）。\n\n`binlog`日志刷盘流程如下\n\n![](MySQL三大日志.assets/04.png)\n\n- **上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快**\n- **上图的 fsync，才是将数据持久化到磁盘的操作**\n\n`write`和`fsync`的时机，可以由参数`sync_binlog`控制，默认是`0`。\n\n为`0`的时候，表示每次提交事务都只`write`，由系统自行判断什么时候执行`fsync`。\n\n![](MySQL三大日志.assets/05.png)\n\n虽然性能得到提升，但是机器宕机，`page cache`里面的 binglog 会丢失。\n\n为了安全起见，可以设置为`1`，表示每次提交事务都会执行`fsync`，就如同**binlog 日志刷盘流程**一样。\n\n最后还有一种折中方式，可以设置为`N(N>1)`，表示每次提交事务都`write`，但累积`N`个事务后才`fsync`。\n\n![](MySQL三大日志.assets/06.png)\n\n在出现`IO`瓶颈的场景里，将`sync_binlog`设置成一个比较大的值，可以提升性能。\n\n同样的，如果机器宕机，会丢失最近`N`个事务的`binlog`日志。\n\n## 两阶段提交\n\n`redo log`（重做日志）让`InnoDB`存储引擎拥有了崩溃恢复能力。\n\n`binlog`（归档日志）保证了`MySQL`集群架构的数据一致性。\n\n虽然它们都属于持久化的保证，但是侧重点不同。\n\n在执行更新语句过程，会记录`redo log`与`binlog`两块日志，以基本的事务为单位，`redo log`在事务执行过程中可以不断写入，而`binlog`只有在提交事务时才写入，所以`redo log`与`binlog`的写入时机不一样。\n\n![](MySQL三大日志.assets/01.png)\n\n回到正题，`redo log`与`binlog`两份日志之间的逻辑不一致，会出现什么问题？\n\n我们以`update`语句为例，假设`id=2`的记录，字段`c`值是`0`，把字段`c`值更新成`1`，`SQL`语句为`update T set c=1 where id=2`。\n\n假设执行过程中写完`redo log`日志后，`binlog`日志写期间发生了异常，会出现什么情况呢？\n\n![](MySQL三大日志.assets/02.png)\n\n由于`binlog`没写完就异常，这时候`binlog`里面没有对应的修改记录。因此，之后用`binlog`日志恢复数据时，就会少这一次更新，恢复出来的这一行`c`值是`0`，而原库因为`redo log`日志恢复，这一行`c`值是`1`，最终数据不一致。\n\n![](MySQL三大日志.assets/03.png)\n\n为了解决两份日志之间的逻辑一致问题，`InnoDB`存储引擎使用**两阶段提交**方案。\n\n原理很简单，将`redo log`的写入拆成了两个步骤`prepare`和`commit`，这就是**两阶段提交**。\n\n![](MySQL三大日志.assets/04.png)\n\n使用**两阶段提交**后，写入`binlog`时发生异常也不会有影响，因为`MySQL`根据`redo log`日志恢复数据时，发现`redo log`还处于`prepare`阶段，并且没有对应`binlog`日志，就会回滚该事务。\n\n![](MySQL三大日志.assets/05.png)\n\n再看一个场景，`redo log`设置`commit`阶段发生异常，那会不会回滚事务呢？\n\n![](MySQL三大日志.assets/06.png)\n\n并不会回滚事务，它会执行上图框住的逻辑，虽然`redo log`是处于`prepare`阶段，但是能通过事务`id`找到对应的`binlog`日志，所以`MySQL`认为是完整的，就会提交事务恢复数据。\n\n## undo log\n\n> 这部分内容为 JavaGuide 的补充：\n\n我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 **回滚日志** 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。\n\n另外，`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改\n\n## 总结\n\n> 这部分内容为 JavaGuide 的补充：\n\nMySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。\n\n`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。\n\n## 站在巨人的肩膀上\n\n- 《MySQL 实战 45 讲》\n- 《从零开始带你成为 MySQL 实战优化高手》\n- 《MySQL 是怎样运行的：从根儿上理解 MySQL》\n- 《MySQL 技术 Innodb 存储引擎》\n\n## MySQL 好文推荐\n\n- [CURD 这么多年，你有了解过 MySQL 的架构设计吗？](https://mp.weixin.qq.com/s/R-1km7r0z3oWfwYQV8iiqA)\n- [浅谈 MySQL InnoDB 的内存组件](https://mp.weixin.qq.com/s/7Kab4IQsNcU_bZdbv_MuOg)\n"},b603:function(n,r,e){"use strict";e.r(r),r["default"]="**文章目录：**\r\n\r\n- 什么是MySQL？　＊\r\n\r\n- MySQL常用的存储引擎有什么？它们有什么区别？　＊＊＊\r\n\r\n- 数据库的三大范式　＊＊\r\n\r\n- MySQL的数据类型有哪些　＊＊\r\n\r\n- 索引　＊＊＊\r\n\r\n- - 什么是索引？\r\n  - 索引的优缺点？\r\n  - 索引的数据结构？\r\n  - Hash索引和B+树的区别？\r\n  - 索引的类型有哪些?\r\n  - 索引的种类有哪些？\r\n  - B树和B+树的区别？\r\n  - 数据库为什么使用B+树而不是B树？\r\n  - 什么是聚簇索引，什么是非聚簇索引？\r\n  - 非聚簇索引一定会进行回表查询吗？\r\n  - 索引的使用场景有哪些？\r\n  - 索引的设计原则？\r\n  - 如何对索引进行优化？\r\n  - 如何创建/删除索引？\r\n  - 使用索引查询时性能一定会提升吗？\r\n  - 什么是前缀索引？\r\n  - 什么是最左匹配原则？\r\n  - 索引在什么情况下会失效？\r\n\r\n- 数据库的事务　＊＊＊\r\n\r\n- - 什么是数据库的事务？\r\n  - 事务的四大特性是什么？\r\n  - 数据库的并发一致性问题\r\n  - 数据库的隔离级别有哪些？\r\n  - 隔离级别是如何实现的？\r\n  - 什么是MVCC？\r\n\r\n- 数据库的锁　＊＊＊\r\n\r\n- - 什么是数据库的锁？\r\n  - 数据库的锁与隔离级别的关系？\r\n  - 数据库锁的类型有哪些？\r\n  - MySQL中InnoDB引擎的行锁模式及其是如何实现的？\r\n  - 什么是数据库的乐观锁和悲观锁，如何实现？\r\n  - 什么是死锁？如何避免？\r\n\r\n- SQL语句基础知识\r\n\r\n- - SQL语句主要分为哪几类　＊\r\n  - SQL约束有哪些？　＊＊\r\n  - 什么是子查询？　＊＊\r\n  - 了解MySQL的几种连接查询吗？　＊＊＊\r\n  - mysql中in和exists的区别？　＊＊\r\n  - varchar和char的区别？　＊＊＊\r\n  - MySQL中int(10)和char(10)和varchar(10)的区别？　＊＊＊\r\n  - drop、delete和truncate的区别？　＊＊\r\n  - UNION和UNION ALL的区别？　＊＊\r\n  - 什么是临时表，什么时候会使用到临时表，什么时候删除临时表？　＊\r\n  - 大表数据查询如何进行优化？　＊＊＊\r\n  - 了解慢日志查询吗？统计过慢查询吗？对慢查询如何优化？　＊＊＊\r\n  - 为什么要设置主键？　＊＊\r\n  - 主键一般用自增ID还是UUID？　＊＊\r\n  - 字段为什么要设置成not null?　＊＊\r\n  - 如何优化查询过程中的数据访问？　＊＊＊\r\n  - 如何优化长难的查询语句？　＊＊\r\n  - 如何优化LIMIT分页？　＊＊\r\n  - 如何优化UNION查询　＊＊\r\n  - 如何优化WHERE子句　＊＊＊\r\n  - SQL语句执行的很慢原因是什么？　＊＊＊\r\n  - SQL语句的执行顺序?　＊\r\n\r\n- 数据库优化\r\n\r\n- - 大表如何优化？　＊＊＊\r\n  - 什么是垂直分表、垂直分库、水平分表、水平分库？　＊＊＊\r\n  - 分库分表后，ID键如何处理？　＊＊＊\r\n  - MySQL的复制原理及流程？如何实现主从复制？　＊＊＊\r\n  - 了解读写分离吗？　＊＊＊\r\n\r\n\r\n\r\n## 什么是MySQL？　＊\r\n\r\n百度百科上的解释：MySQL是一种开放源代码的关系型数据库管理系统（RDBMS），使用最常用的数据库管理语言--结构化查询语言（SQL）进行数据库管理。MySQL是开放源代码的，因此任何人都可以在General Public License的许可下下载并根据个性化的需要对其进行修改。\r\n\r\n## MySQL常用的存储引擎有什么？它们有什么区别？　＊＊＊\r\n\r\n- InnoDB\r\n\r\n  InnoDB是MySQL的默认存储引擎，支持事务、行锁和外键等操作。\r\n\r\n- MyISAM\r\n\r\n  MyISAM是MySQL5.1版本前的默认存储引擎，MyISAM的并发性比较差，不支持事务和外键等操作，默认的锁的粒度为表级锁。\r\n\r\n|          |               InnoDB               |                     MyISAM                     |\r\n| :------: | :--------------------------------: | :--------------------------------------------: |\r\n|   外键   |                支持                |                     不支持                     |\r\n|   事务   |                支持                |                     不支持                     |\r\n|    锁    |           支持表锁和行锁           |                    支持表锁                    |\r\n| 可恢复性 |        根据事务日志进行恢复        |                   无事务日志                   |\r\n|  表结构  | 数据和索引是集中存储的，.ibd和.frm | 数据和索引是分开存储的，数据`.MYD`，索引`.MYI` |\r\n| 查询性能 |      一般情况相比于MyISAM较差      |            一般情况相比于InnoDB较差            |\r\n|   索引   |              聚簇索引              |                   非聚簇索引                   |\r\n\r\n## 数据库的三大范式　＊＊\r\n\r\n- 第一范式：确保每列保持原子性，数据表中的所有字段值都是不可分解的原子值。\r\n- 第二范式：确保表中的每列都和主键相关\r\n- 第三范式：确保每列都和主键列直接相关而不是间接相关\r\n\r\n## MySQL的数据类型有哪些　＊＊\r\n\r\n- 整数\r\n\r\n  TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT分别占用8、16、24、32、64位存储空间。值得注意的是，INT(10)中的10只是表示显示字符的个数，并无实际意义。一般和UNSIGNED ZEROFILL配合使用才有实际意义，例如，数据类型INT(3)，属性为UNSIGNED ZEROFILL，如果插入的数据为3的话，实际存储的数据为003。\r\n\r\n- 浮点数\r\n\r\n  FLOAT、DOUBLE及DECIMAL为浮点数类型，DECIMAL是利用字符串进行处理的，能存储精确的小数。相比于FLOAT和DOUBLE，DECIMAL的效率更低些。FLOAT、DOUBLE及DECIMAL都可以指定列宽，例如FLOAT(5,2)表示一共5位，两位存储小数部分，三位存储整数部分。\r\n\r\n- 字符串\r\n\r\n  字符串常用的主要有CHAR和VARCHAR，VARCHAR主要用于存储可变长字符串，相比于定长的CHAR更节省空间。CHAR是定长的，根据定义的字符串长度分配空间。\r\n\r\n  应用场景：对于经常变更的数据使用CHAR更好，CHAR不容易产生碎片。对于非常短的列也是使用CHAR更好些，CHAR相比于VARCHAR在效率上更高些。一般避免使用TEXT/BLOB等类型，因为查询时会使用临时表，造成严重的性能开销。\r\n\r\n- 日期\r\n\r\n  比较常用的有year、time、date、datetime、timestamp等，datetime保存从1000年到9999年的时间，精度到秒，使用8字节的存储空间，与时区无关。timestamp和UNIX的时间戳相同，保存从1970年1月1日午夜到2038年的时间，精度到秒，使用四个字节的存储空间，并且与时区相关。\r\n\r\n  应用场景：尽量使用timestamp，相比于datetime它有着更高的空间效率。\r\n\r\n## 索引　＊＊＊\r\n\r\n### 什么是索引？\r\n\r\n百度百科的解释：索引是对数据库表的一列或者多列的值进行排序一种结构，使用索引可以快速访问数据表中的特定信息。\r\n\r\n### 索引的优缺点？\r\n\r\n优点：\r\n\r\n- 大大加快数据检索的速度。\r\n- 将随机I/O变成顺序I/O(因为B+树的叶子节点是连接在一起的)\r\n- 加速表与表之间的连接\r\n\r\n缺点：\r\n\r\n- 从空间角度考虑，建立索引需要占用物理空间\r\n- 从时间角度 考虑，创建和维护索引都需要花费时间，例如对数据进行增删改的时候都需要维护索引。\r\n\r\n### 索引的数据结构？\r\n\r\n索引的数据结构主要有B+树和哈希表，对应的索引分别为B+树索引和哈希索引。InnoDB引擎的索引类型有B+树索引和哈希索引，默认的索引类型为B+树索引。\r\n\r\n- B+树索引\r\n\r\n  熟悉数据结构的同学都知道，B+树、平衡二叉树、红黑树都是经典的数据结构。在B+树中，所有的记录节点都是按照键值大小的顺序放在叶子节点上，如下图。\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\1.png)\r\n\r\n从上图可以看出 ，因为B+树具有有序性，并且所有的数据都存放在叶子节点，所以查找的效率非常高，并且支持排序和范围查找。\r\n\r\nB+树的索引又可以分为主索引和辅助索引。其中主索引为聚簇索引，辅助索引为非聚簇索引。聚簇索引是以主键作为B+ 树索引的键值所构成的B+树索引，聚簇索引的叶子节点存储着完整的数据记录；非聚簇索引是以非主键的列作为B+树索引的键值所构成的B+树索引，非聚簇索引的叶子节点存储着主键值。所以使用非聚簇索引进行查询时，会先找到主键值，然后到根据聚簇索引找到主键对应的数据域。上图中叶子节点存储的是数据记录，为聚簇索引的结构图，非聚簇索引的结构图如下：\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\2.png)\r\n\r\n上图中的字母为数据的非主键的列值，假设要查询该列值为B的信息，则需先找到主键7，在到聚簇索引中查询主键7所对应的数据域。\r\n\r\n- 哈希索引\r\n\r\n  哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列通过哈希算法进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的key值，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是o(1)，一般多用于精确查找。\r\n\r\n### Hash索引和B+树的区别？\r\n\r\n因为两者数据结构上的差异导致它们的使用场景也不同，哈希索引一般多用于精确的等值查找，B+索引则多用于除了精确的等值查找外的其他查找。在大多数情况下，会选择使用B+树索引。\r\n\r\n- 哈希索引不支持排序，因为哈希表是无序的。\r\n- 哈希索引不支持范围查找。\r\n- 哈希索引不支持模糊查询及多列索引的最左前缀匹配。\r\n- 因为哈希表中会存在哈希冲突，所以哈希索引的性能是不稳定的，而B+树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点\r\n\r\n### 索引的类型有哪些?\r\n\r\nMySQL主要的索引类型主要有FULLTEXT，HASH，BTREE，RTREE。\r\n\r\n- FULLTEXT\r\n\r\n  FULLTEXT即全文索引，MyISAM存储引擎和InnoDB存储引擎在MySQL5.6.4以上版本支持全文索引，一般用于查找文本中的关键字，而不是直接比较是否相等，多在CHAR，VARCHAR，TAXT等数据类型上创建全文索引。全文索引主要是用来解决WHERE name LIKE \"%zhang%\"等针对文本的模糊查询效率低的问题。\r\n\r\n- HASH\r\n\r\n  HASH即哈希索引，哈希索引多用于等值查询，时间复杂夫为o(1)，效率非常高，但不支持排序、范围查询及模糊查询等。\r\n\r\n- BTREE\r\n\r\n  BTREE即B+树索引，INnoDB存储引擎默认的索引，支持排序、分组、范围查询、模糊查询等，并且性能稳定。\r\n\r\n- RTREE\r\n\r\n  RTREE即空间数据索引，多用于地理数据的存储，相比于其他索引，空间数据索引的优势在于范围查找\r\n\r\n### 索引的种类有哪些？\r\n\r\n- 主键索引：数据列不允许重复，不能为NULL，一个表只能有一个主键索引\r\n- 组合索引：由多个列值组成的索引。\r\n- 唯一索引：数据列不允许重复，可以为NULL，索引列的值必须唯一的，如果是组合索引，则列值的组合必须唯一。\r\n- 全文索引：对文本的内容进行搜索。\r\n- 普通索引：基本的索引类型，可以为NULL\r\n\r\n### B树和B+树的区别？\r\n\r\nB树和B+树最主要的区别主要有两点：\r\n\r\n- B树中的内部节点和叶子节点均存放键和值，而B+树的内部节点只有键没有值，叶子节点存放所有的键和值。\r\n\r\n- B＋树的叶子节点是通过相连在一起的，方便顺序检索。\r\n\r\n  两者的结构图如下。\r\n\r\n  \r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\3.png)\r\n\r\n### 数据库为什么使用B+树而不是B树？\r\n\r\n- B树适用于随机检索，而B+树适用于随机检索和顺序检索\r\n- B+树的空间利用率更高，因为B树每个节点要存储键和值，而B+树的内部节点只存储键，这样B+树的一个节点就可以存储更多的索引，从而使树的高度变低，减少了I/O次数，使得数据检索速度更快。\r\n- B+树的叶子节点都是连接在一起的，所以范围查找，顺序查找更加方便\r\n- B+树的性能更加稳定，因为在B+树中，每次查询都是从根节点到叶子节点，而在B树中，要查询的值可能不在叶子节点，在内部节点就已经找到。\r\n\r\n那在什么情况适合使用B树呢，因为B树的内部节点也可以存储值，所以可以把一些频繁访问的值放在距离根节点比较近的地方，这样就可以提高查询效率。综上所述，B+树的性能更加适合作为数据库的索引。\r\n\r\n### 什么是聚簇索引，什么是非聚簇索引？\r\n\r\n聚簇索引和非聚簇索引最主要的区别是**数据和索引是否分开存储**。\r\n\r\n- 聚簇索引：将数据和索引放到一起存储，索引结构的叶子节点保留了数据行。\r\n- 非聚簇索引：将数据进和索引分开存储，索引叶子节点存储的是指向数据行的地址。\r\n\r\n在InnoDB存储引擎中，默认的索引为B+树索引，利用主键创建的索引为主索引，也是聚簇索引，在主索引之上创建的索引为辅助索引，也是非聚簇索引。为什么说辅助索引是在主索引之上创建的呢，因为辅助索引中的叶子节点存储的是主键。\r\n\r\n在MyISAM存储引擎中，默认的索引也是B+树索引，但主索引和辅助索引都是非聚簇索引，也就是说索引结构的叶子节点存储的都是一个指向数据行的地址。并且使用辅助索引检索无需访问主键的索引。\r\n\r\n可以从非常经典的两张图看看它们的区别(图片来源于网络)：\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\4.png)\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\5.png)\r\n\r\n### 非聚簇索引一定会进行回表查询吗？\r\n\r\n上面是说了非聚簇索引的叶子节点存储的是主键，也就是说要先通过非聚簇索引找到主键，再通过聚簇索引找到主键所对应的数据，后面这个再通过聚簇索引找到主键对应的数据的过程就是回表查询，那么非聚簇索引就一定会进行回表查询吗？\r\n\r\n答案是不一定的，这里涉及到一个索引覆盖的问题，如果查询的数据在辅助索引上完全能获取到便不需要回表查询。例如有一张表存储着个人信息包括id、name、age等字段。假设聚簇索引是以ID为键值构建的索引，非聚簇索引是以name为键值构建的索引，`select id,name from user where name = 'zhangsan';`这个查询便不需要进行回表查询因为，通过非聚簇索引已经能全部检索出数据，这就是索引覆盖的情况。如果查询语句是这样，`select id,name,age from user where name = 'zhangsan';`则需要进行回表查询，因为通过非聚簇索引不能检索出age的值。那应该如何解决那呢？只需要将索引覆盖即可，建立age和name的联合索引再使用`select id,name,age from user where name = 'zhangsan';`进行查询即可。\r\n\r\n所以通过索引覆盖能解决非聚簇索引回表查询的问题。\r\n\r\n### 索引的使用场景有哪些？\r\n\r\n- 对于中大型表建立索引非常有效，对于非常小的表，一般全部表扫描速度更快些。\r\n- 对于超大型的表，建立和维护索引的代价也会变高，这时可以考虑分区技术。\r\n- 如何表的增删改非常多，而查询需求非常少的话，那就没有必要建立索引了，因为维护索引也是需要代价的。\r\n- 一般不会出现在where条件中的字段就没有必要建立索引了。\r\n- 多个字段经常被查询的话可以考虑联合索引。\r\n- 字段多且字段值没有重复的时候考虑唯一索引。\r\n- 字段多且有重复的时候考虑普通索引。\r\n\r\n### 索引的设计原则？\r\n\r\n- 最适合索引的列是在where后面出现的列或者连接句子中指定的列，而不是出现在SELECT关键字后面的选择列表中的列。\r\n- 索引列的基数越大，索引的效果越好，换句话说就是索引列的区分度越高，索引的效果越好。比如使用性别这种区分度很低的列作为索引，效果就会很差，因为列的基数最多也就是三种，大多不是男性就是女性。\r\n- 尽量使用短索引，对于较长的字符串进行索引时应该指定一个较短的前缀长度，因为较小的索引涉及到的磁盘I/O较少，并且索引高速缓存中的块可以容纳更多的键值，会使得查询速度更快。\r\n- 尽量利用最左前缀。\r\n- 不要过度索引，每个索引都需要额外的物理空间，维护也需要花费时间，所以索引不是越多越好。\r\n\r\n### 如何对索引进行优化？\r\n\r\n对索引的优化其实最关键的就是要符合索引的设计原则和应用场景，将不符合要求的索引优化成符合索引设计原则和应用场景的索引。\r\n\r\n除了索引的设计原则和应用场景那几点外，还可以从以下两方面考虑。\r\n\r\n- 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，因为这样无法使用索引。例如`select * from table_name where a + 1 = 2`\r\n- 将区分度最高的索引放在前面\r\n- 尽量少使用select*\r\n\r\n索引的使用场景、索引的设计原则和如何对索引进行优化可以看成一个问题。\r\n\r\n### 如何创建/删除索引？\r\n\r\n创建索引：\r\n\r\n- 使用CREATE INDEX 语句\r\n\r\n  `CREATE INDEX index_name ON table_name (column_list);`\r\n\r\n- 在CREATE TABLE时创建\r\n\r\n  ```\r\n  \tCREATE TABLE user(\r\n  \tid INT PRIMARY KEY,\r\n  \tinformation text,\r\n  \tFULLTEXT KEY (information)\r\n  );\r\n  ```\r\n\r\n- 使用ALTER TABLE创建索引\r\n\r\n  `ALTER TABLE table_name ADD INDEX index_name (column_list);`\r\n\r\n删除索引：\r\n\r\n- 删除主键索引\r\n\r\n  `alter table 表名 drop primary key`\r\n\r\n- 删除其他索引\r\n\r\n  `alter table 表名 drop key 索引名`\r\n\r\n### 使用索引查询时性能一定会提升吗？\r\n\r\n不一定，前面在索引的使用场景和索引的设计原则中已经提到了如何合理地使用索引，因为创建和维护索引需要花费空间和时间上的代价，如果不合理地使用索引反而会使查询性能下降。\r\n\r\n### 什么是前缀索引？\r\n\r\n前缀索引是指对文本或者字符串的前几个字符建立索引，这样索引的长度更短，查询速度更快。\r\n\r\n使用场景：前缀的区分度比较高的情况下。\r\n\r\n建立前缀索引的方式\r\n\r\n```\r\nALTER TABLE table_name ADD KEY(column_name(prefix_length));\r\n```\r\n\r\n这里面有个prefix_length参数很难确定，这个参数就是前缀长度的意思。通常可以使用以下方法进行确定，先计算全列的区分度\r\n\r\n```\r\nSELECT COUNT(DISTINCT column_name) / COUNT(*) FROM table_name;\r\n```\r\n\r\n然后在计算前缀长度为多少时和全列的区分度最相似。\r\n\r\n```\r\nSELECT COUNT(DISTINCT LEFT(column_name, prefix_length)) / COUNT(*) FROM table_name;\r\n```\r\n\r\n不断地调整prefix_length的值，直到和全列计算出区分度相近。\r\n\r\n### 什么是最左匹配原则？\r\n\r\n最左匹配原则：从最左边为起点开始连续匹配，遇到范围查询（<、>、between、like）会停止匹配。\r\n\r\n例如建立索引(a,b,c)，大家可以猜测以下几种情况是否用到了索引。\r\n\r\n- 第一种\r\n\r\n  ```\r\n  select * from table_name where a = 1 and b = 2 and c = 3 \r\n  select * from table_name where b = 2 and a = 1 and c = 3\r\n  ```\r\n\r\n  上面两次查询过程中所有值都用到了索引，where后面字段调换不会影响查询结果，因为MySQL中的优化器会自动优化查询顺序。\r\n\r\n- 第二种\r\n\r\n  ```\r\n  select * from table_name where a = 1\r\n  select * from table_name where a = 1 and b = 2  \r\n  select * from table_name where a = 1 and b = 2 and c = 3\r\n  ```\r\n\r\n  答案是三个查询语句都用到了索引，因为三个语句都是从最左开始匹配的。\r\n\r\n- 第三种\r\n\r\n  ```\r\n  select * from table_name where  b = 1 \r\n  select * from table_name where  b = 1 and c = 2 \r\n  ```\r\n\r\n  答案是这两个查询语句都没有用到索引，因为不是从最左边开始匹配的\r\n\r\n- 第四种\r\n\r\n  ```\r\n  select * from table_name where a = 1 and c = 2 \r\n  ```\r\n\r\n  这个查询语句只有a列用到了索引，c列没有用到索引，因为中间跳过了b列，不是从最左开始连续匹配的。\r\n\r\n- 第五种\r\n\r\n  ```\r\n  select * from table_name where  a = 1 and b < 3 and c < 1\r\n  ```\r\n\r\n  这个查询中只有a列和b列使用到了索引，而c列没有使用索引，因为根据最左匹配查询原则，遇到范围查询会停止。\r\n\r\n- 第六种\r\n\r\n  ```\r\n  select * from table_name where a like 'ab%'; \r\n  select * from table_name where  a like '%ab'\r\n  select * from table_name where  a like '%ab%'\r\n  ```\r\n\r\n  对于列为字符串的情况，只有前缀匹配可以使用索引，中缀匹配和后缀匹配只能进行全表扫描。\r\n\r\n### 索引在什么情况下会失效？\r\n\r\n在上面介绍了几种不符合最左匹配原则的情况会导致索引失效，除此之外，以下这几种情况也会导致索引失效。\r\n\r\n- 条件中有or，例如`select * from table_name where a = 1 or b = 3`\r\n- 在索引上进行计算会导致索引失效，例如`select * from table_name where a + 1 = 2`\r\n- 在索引的类型上进行数据类型的隐形转换，会导致索引失效，例如字符串一定要加引号，假设 `select * from table_name where a = '1'`会使用到索引，如果写成`select * from table_name where a = 1`则会导致索引失效。\r\n- 在索引中使用函数会导致索引失效，例如`select * from table_name where abs(a) = 1`\r\n- 在使用like查询时以%开头会导致索引失效\r\n- 索引上使用！、=、<>进行判断时会导致索引失效，例如`select * from table_name where a != 1`\r\n- 索引字段上使用 is null/is not null判断时会导致索引失效，例如`select * from table_name where a is null`\r\n\r\n## 数据库的事务　＊＊＊\r\n\r\n### 什么是数据库的事务？\r\n\r\n百度百科的解释：数据库事务( transaction)是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成。\r\n\r\n### 事务的四大特性是什么？\r\n\r\n- 原子性：原子性是指包含事务的操作要么全部执行成功，要么全部失败回滚。\r\n- 一致性：一致性指事务在执行前后状态是一致的。\r\n- 隔离性：一个事务所进行的修改在最终提交之前，对其他事务是不可见的。\r\n- 持久性：数据一旦提交，其所作的修改将永久地保存到数据库中。\r\n\r\n### 数据库的并发一致性问题\r\n\r\n当多个事务并发执行时，可能会出现以下问题：\r\n\r\n- 脏读：事务A更新了数据，但还没有提交，这时事务B读取到事务A更新后的数据，然后事务A回滚了，事务B读取到的数据就成为脏数据了。\r\n- 不可重复读：事务A对数据进行多次读取，事务B在事务A多次读取的过程中执行了更新操作并提交了，导致事务A多次读取到的数据并不一致。\r\n- 幻读：事务A在读取数据后，事务B向事务A读取的数据中插入了几条数据，事务A再次读取数据时发现多了几条数据，和之前读取的数据不一致。\r\n- 丢失修改：事务A和事务B都对同一个数据进行修改，事务A先修改，事务B随后修改，事务B的修改覆盖了事务A的修改。\r\n\r\n不可重复度和幻读看起来比较像，它们主要的区别是：在不可重复读中，发现数据不一致主要是数据被更新了。在幻读中，发现数据不一致主要是数据增多或者减少了。\r\n\r\n### 数据库的隔离级别有哪些？\r\n\r\n- 未提交读：一个事务在提交前，它的修改对其他事务也是可见的。\r\n- 提交读：一个事务提交之后，它的修改才能被其他事务看到。\r\n- 可重复读：在同一个事务中多次读取到的数据是一致的。\r\n- 串行化：需要加锁实现，会强制事务串行执行。\r\n\r\n数据库的隔离级别分别可以解决数据库的脏读、不可重复读、幻读等问题。\r\n\r\n| 隔离级别 |  脏读  | 不可重复读 |  幻读  |\r\n| :------: | :----: | :--------: | :----: |\r\n| 未提交读 |  允许  |    允许    |  允许  |\r\n|  提交读  | 不允许 |    允许    |  允许  |\r\n| 可重复读 | 不允许 |   不允许   |  允许  |\r\n|  串行化  | 不允许 |   不允许   | 不允许 |\r\n\r\n**MySQL的默认隔离级别是可重复读。**\r\n\r\n### 隔离级别是如何实现的？\r\n\r\n事务的隔离机制主要是依靠锁机制和MVCC(多版本并发控制)实现的，提交读和可重复读可以通过MVCC实现，串行化可以通过锁机制实现。\r\n\r\n### 什么是MVCC？\r\n\r\nMVCC(multiple version concurrent control)是一种控制并发的方法，主要用来提高数据库的并发性能。\r\n\r\n在了解MVCC时应该先了解当前读和快照读。\r\n\r\n- 当前读：读取的是数据库的最新版本，并且在读取时要保证其他事务不会修改当前记录，所以会对读取的记录加锁。\r\n- 快照读：不加锁读取操作即为快照读，使用MVCC来读取快照中的数据，避免加锁带来的性能损耗。\r\n\r\n可以看到MVCC的作用就是在不加锁的情况下，解决数据库读写冲突问题，并且解决脏读、幻读、不可重复读等问题，但是不能解决丢失修改问题。\r\n\r\nMVCC的实现原理：\r\n\r\n- 版本号\r\n\r\n  系统版本号：是一个自增的ID，每开启一个事务，系统版本号都会递增。\r\n\r\n  事务版本号：事务版本号就是事务开始时的系统版本号，可以通过事务版本号的大小判断事务的时间顺序。\r\n\r\n- 行记录隐藏的列\r\n\r\n  DB_ROW_ID：所需空间6byte，隐含的自增ID，用来生成聚簇索引，如果数据表没有指定聚簇索引，InnoDB会利用这个隐藏ID创建聚簇索引。\r\n\r\n  DB_TRX_ID：所需空间6byte，最近修改的事务ID，记录创建这条记录或最后一次修改这条记录的事务ID。\r\n\r\n  DB_ROLL_PTR：所需空间7byte，回滚指针，指向这条记录的上一个版本。\r\n\r\n  它们大致长这样，省略了具体字段的值。·\r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\6.png)\r\n\r\n- undo日志\r\n\r\n  MVCC做使用到的快照会存储在Undo日志中，该日志通过回滚指针将一个一个数据行的所有快照连接起来。它们大致长这样。\r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\7.png)\r\n\r\n举一个简单的例子说明下，比如最开始的某条记录长这样![Image](\\2万字的MySQL八股文背诵版.assets\\8.png)\r\n\r\n现在来了一个事务对他的年龄字段进行了修改，变成了这样\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\9.png)\r\n\r\n现在又来了一个事务2对它的性别进行了修改，它又变成了这样\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\10.png)\r\n\r\n从上面的分析可以看出，事务对同一记录的修改，记录的各个会在Undo日志中连接成一个线性表，在表头的就是最新的旧纪录。\r\n\r\n在重复读的隔离级别下，InnoDB的工作流程：\r\n\r\n- SELECT\r\n\r\n  作为查询的结果要满足两个条件：\r\n\r\n- 1. 当前事务所要查询的数据行快照的创建版本号必须小于当前事务的版本号，这样做的目的是保证当前事务读取的数据行的快照要么是在当前事务开始前就已经存在的，要么就是当前事务自身插入或者修改过的。\r\n  2. 当前事务所要读取的数据行快照的删除版本号必须是大于当前事务的版本号，如果是小于等于的话，表示该数据行快照已经被删除，不能读取。\r\n\r\n- INSERT\r\n\r\n  将当前系统版本号作为数据行快照的创建版本号。\r\n\r\n- DELETE\r\n\r\n  将当前系统版本号作为数据行快照的删除版本号。\r\n\r\n- UPDATE\r\n\r\n  保存当前系统版本号为更新前的数据行快照创建行版本号，并保存当前系统版本号为更新后的数据行快照的删除版本号，其实就是，先删除在插入即为更新。\r\n\r\n总结一下，MVCC的作用就是在避免加锁的情况下最大限度解决读写并发冲突的问题，它可以实现提交读和可重复度两个隔离级。\r\n\r\n## 数据库的锁　＊＊＊\r\n\r\n### 什么是数据库的锁？\r\n\r\n当数据库有并发事务的时候，保证数据访问顺序的机制称为锁机制。\r\n\r\n### 数据库的锁与隔离级别的关系？\r\n\r\n| 隔离级别 |                 实现方式                 |\r\n| :------: | :--------------------------------------: |\r\n| 未提交读 |       总是读取最新的数据，无需加锁       |\r\n|  提交读  | 读取数据时加共享锁，读取数据后释放共享锁 |\r\n| 可重复读 | 读取数据时加共享锁，事务结束后释放共享锁 |\r\n|  串行化  | 锁定整个范围的键，一直持有锁直到事务结束 |\r\n\r\n### 数据库锁的类型有哪些？\r\n\r\n按照锁的粒度可以将MySQL锁分为三种：\r\n\r\n| MySQL锁类别 | 资源开销 | 加锁速度 | 是否会出现死锁 | 锁的粒度 | 并发度 |\r\n| :---------: | :------: | :------: | :------------: | :------: | :----: |\r\n|   表级锁    |    小    |    快    |      不会      |    大    |   低   |\r\n|   行级锁    |    大    |    慢    |       会       |    小    |   高   |\r\n|   页面锁    |   一般   |   一般   |      不会      |   一般   |  一般  |\r\n\r\nMyISAM默认采用表级锁，InnoDB默认采用行级锁。\r\n\r\n从锁的类别上区别可以分为共享锁和排他锁\r\n\r\n- 共享锁：共享锁又称读锁，简写为S锁，一个事务对一个数据对象加了S锁，可以对这个数据对象进行读取操作，但不能进行更新操作。并且在加锁期间其他事务只能对这个数据对象加S锁，不能加X锁。\r\n- 排他锁：排他锁又称为写锁，简写为X锁，一个事务对一个数据对象加了X锁，可以对这个对象进行读取和更新操作，加锁期间，其他事务不能对该数据对象进行加X锁或S锁。\r\n\r\n它们的兼容情况如下（不太会用excel，图太丑了）：\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\11.png)\r\n\r\n### MySQL中InnoDB引擎的行锁模式及其是如何实现的？\r\n\r\n**行锁模式**\r\n\r\n在存在行锁和表锁的情况下，一个事务想对某个表加X锁时，需要先检查是否有其他事务对这个表加了锁或对这个表的某一行加了锁，对表的每一行都进行检测一次这是非常低效率的，为了解决这种问题，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁，两种意向锁都是表锁。\r\n\r\n- 意向共享锁：简称IS锁，一个事务打算给数据行加共享锁前必须先获得该表的IS锁。\r\n- 意向排他锁：简称IX锁，一个事务打算给数据行加排他锁前必须先获得该表的IX锁。\r\n\r\n有了意向锁，一个事务想对某个表加X锁，只需要检查是否有其他事务对这个表加了X/IX/S/IS锁即可。\r\n\r\n锁的兼容性如下：\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\12.png)\r\n\r\n行锁实现方式：INnoDB的行锁是通过给索引上的索引项加锁实现的，如果没有索引，InnoDB将通过隐藏的聚簇索引来对记录进行加锁。\r\n\r\nInnoDB行锁主要分三种情况：\r\n\r\n- Record lock：对索引项加锁\r\n- Grap lock：对索引之间的“间隙”、第一条记录前的“间隙”或最后一条后的间隙加锁。\r\n- Next-key lock：前两种放入组合，对记录及前面的间隙加锁。\r\n\r\nInnoDB行锁的特性：如果不通过索引条件检索数据，那么InnoDB将对表中所有记录加锁，实际产生的效果和表锁是一样的。\r\n\r\nMVCC不能解决幻读问题，在可重复读隔离级别下，使用MVCC+Next-Key Locks可以解决幻读问题。\r\n\r\n### 什么是数据库的乐观锁和悲观锁，如何实现？\r\n\r\n乐观锁：系统假设数据的更新在大多数时候是不会产生冲突的，所以数据库只在更新操作提交的时候对数据检测冲突，如果存在冲突，则数据更新失败。\r\n\r\n乐观锁实现方式：一般通过版本号和CAS算法实现。\r\n\r\n悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。通俗讲就是每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。\r\n\r\n悲观锁的实现方式：通过数据库的锁机制实现，对查询语句添加for updata。\r\n\r\n### 什么是死锁？如何避免？\r\n\r\n死锁是指两个或者两个以上进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。在MySQL中，MyISAM是一次获得所需的全部锁，要么全部满足，要么等待，所以不会出现死锁。在InnoDB存储引擎中，除了单个SQL组成的事务外，锁都是逐步获得的，所以存在死锁问题。\r\n\r\n如何避免MySQL发生死锁或锁冲突：\r\n\r\n- 如果不同的程序并发存取多个表，尽量以相同的顺序访问表。\r\n- 在程序以批量方式处理数据的时候，如果已经对数据排序，尽量保证每个线程按照固定的顺序来处理记录。\r\n- 在事务中，如果需要更新记录，应直接申请足够级别的排他锁，而不应该先申请共享锁，更新时在申请排他锁，因为在当前用户申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突或者死锁。\r\n- 尽量使用较低的隔离级别\r\n- 尽量使用索引访问数据，使加锁更加准确，从而减少锁冲突的机会\r\n- 合理选择事务的大小，小事务发生锁冲突的概率更低\r\n- 尽量用相等的条件访问数据，可以避免Next-Key锁对并发插入的影响。\r\n- 不要申请超过实际需要的锁级别，查询时尽量不要显示加锁\r\n- 对于一些特定的事务，可以表锁来提高处理速度或减少死锁的概率。\r\n\r\n## SQL语句基础知识\r\n\r\n### SQL语句主要分为哪几类　＊\r\n\r\n- 数据据定义语言DDL（Data Definition Language）：主要有CREATE，DROP，ALTER等对逻辑结构有操作的，包括表结构、视图和索引。\r\n- 数据库查询语言DQL（Data Query Language）：主要以SELECT为主\r\n- 数据操纵语言DML（Data Manipulation Language）：主要包括INSERT，UPDATE，DELETE\r\n- 数据控制功能DCL（Data Control Language）：主要是权限控制能操作，包括GRANT，REVOKE，COMMIT，ROLLBACK等。\r\n\r\n### SQL约束有哪些？　＊＊\r\n\r\n- 主键约束：主键为在表中存在一列或者多列的组合，能唯一标识表中的每一行。一个表只有一个主键，并且主键约束的列不能为空。\r\n- 外键约束：外键约束是指用于在两个表之间建立关系，需要指定引用主表的哪一列。只有主表的主键可以被从表用作外键，被约束的从表的列可以不是主键，所以创建外键约束需要先定义主表的主键，然后定义从表的外键。\r\n- 唯一约束：确保表中的一列数据没有相同的值，一个表可以定义多个唯一约束。\r\n- 默认约束：在插入新数据时，如果该行没有指定数据，系统将默认值赋给该行，如果没有设置没默认值，则为NULL。\r\n- Check约束：Check会通过逻辑表达式来判断数据的有效性，用来限制输入一列或者多列的值的范围。在列更新数据时，输入的内容必须满足Check约束的条件。\r\n\r\n### 什么是子查询？　＊＊\r\n\r\n子查询：把一个查询的结果在另一个查询中使用\r\n\r\n子查询可以分为以下几类：\r\n\r\n- 标量子查询：指子查询返回的是一个值，可以使用 =,>,<,>=,<=,<>等操作符对子查询标量结果进行比较，一般子查询会放在比较式的右侧。\r\n\r\n  ```\r\n  SELECT * FROM user WHERE age = (SELECT max(age) from user)  //查询年纪最大的人\r\n  ```\r\n\r\n- 列子查询：指子查询的结果是n行一列，一般应用于对表的某个字段进行查询返回。可以使用IN、ANY、SOME和ALL等操作符，不能直接使用\r\n\r\n  ```\r\n  SELECT num1 FROM table1 WHERE num1 > ANY (SELECT num2 FROM table2)\r\n  ```\r\n\r\n- 行子查询：指子查询返回的结果一行n列\r\n\r\n  ```\r\n  SELECT * FROM user WHERE (age,sex) = (SELECT age,sex FROM user WHERE name=\"zhangsan\")\r\n  ```\r\n\r\n- 表子查询：指子查询是n行n列的一个数据表\r\n\r\n  ```\r\n  SELECT * FROM student WHERE (name,age,sex) IN (SELECT name,age,sex FROM class1) //在学生表中找到班级在1班的学生\r\n  ```\r\n\r\n### 了解MySQL的几种连接查询吗？　＊＊＊\r\n\r\nMySQl的连接查询主要可以分为外连接，内连接，交叉连接\r\n\r\n- 外连接\r\n\r\n  外连接主要分为左外连接(LEFT JOIN)、右外连接(RIGHT JOIN)、全外连接。\r\n\r\n  左外连接：显示左表中所有的数据及右表中符合条件的数据，右表中不符合条件的数据为null。\r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\13.png)\r\n\r\n  右外连接：显示左表中所有的数据及右表中符合条件的数据，右表中不符合条件的数据为null。\r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\14.png)\r\n\r\n  MySQL中不支持全外连接。\r\n\r\n- 内连接：只显示符合条件的数据\r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\15.png)\r\n\r\n- 交叉连接：使用笛卡尔积的一种连接。\r\n\r\n  笛卡尔积，百度百科的解释：两个集合*X*和*Y*的笛卡尔积表示为*X* × *Y*，第一个对象是*X*的成员而第二个对象是*Y*的所有可能有序对的其中一个成员 。例如：A={a,b}，B={0,1,2}，A × B = {(a,0)，(a,1)，(a,2)，(b,0)，(b,1)，(b,2)}\r\n\r\n举例如下：有两张表分为L表和R表。\r\n\r\nL表\r\n\r\n|  A   |  B   |\r\n| :--: | :--: |\r\n|  a1  |  b1  |\r\n|  a2  |  b2  |\r\n|  a3  |  b3  |\r\n\r\nR表\r\n\r\n|  B   |  C   |\r\n| :--: | :--: |\r\n|  b1  |  c1  |\r\n|  b2  |  c2  |\r\n|  b4  |  c3  |\r\n\r\n- 左外连接 ：`select L.`*`,R.`*` from L left join R on L.b=R.b`\r\n\r\n  |  A   |  B   |  B   |  C   |\r\n  | :--: | :--: | :--: | :--: |\r\n  |  a1  |  b1  |  b1  |  c1  |\r\n  |  a2  |  b2  |  b2  |  c2  |\r\n  |  a3  |  b3  | null | null |\r\n\r\n- 右外连接：`select L.`*`,R.`*` from L right join R on L.b=R.b`\r\n\r\n  |  B   |  C   |  A   |  B   |\r\n  | :--: | :--: | :--: | :--: |\r\n  |  b1  |  c1  |  a1  |  b1  |\r\n  |  b2  |  c2  |  a2  |  b2  |\r\n  |  b4  |  c3  | null | null |\r\n\r\n- 内连接：`select L.`*`,R.`*` from L inner join R on L.b=R.b`\r\n\r\n  |  A   |  B   |  B   |  C   |\r\n  | :--: | :--: | :--: | :--: |\r\n  |  a1  |  b1  |  b1  |  c1  |\r\n  |  a2  |  b2  |  b2  |  c2  |\r\n\r\n- 交叉连接：`select L.`*`,R.`*` from L,R`\r\n\r\n  |  A   |  B   |  B   |  C   |\r\n  | :--: | :--: | :--: | :--: |\r\n  |  a1  |  b1  |  b1  |  c1  |\r\n  |  a1  |  b1  |  b2  |  c2  |\r\n  |  a1  |  b1  |  b4  |  c3  |\r\n  |  a2  |  b2  |  b1  |  c1  |\r\n  |  a2  |  b2  |  b2  |  c2  |\r\n  |  a2  |  b2  |  b4  |  c3  |\r\n  |  a3  |  b3  |  b1  |  c1  |\r\n  |  a3  |  b3  |  b2  |  c2  |\r\n  |  a3  |  b3  |  b4  |  c3  |\r\n\r\n### mysql中in和exists的区别？　＊＊\r\n\r\nin和exists一般用于子查询。\r\n\r\n- 使用exists时会先进行外表查询，将查询到的每行数据带入到内表查询中看是否满足条件；使用in一般会先进行内表查询获取结果集，然后对外表查询匹配结果集，返回数据。\r\n- in在内表查询或者外表查询过程中都会用到索引。\r\n- exists仅在内表查询时会用到索引\r\n- 一般来说，当子查询的结果集比较大，外表较小使用exist效率更高；当子查询寻得结果集较小，外表较大时，使用in效率更高。\r\n- 对于not in和not exists，not exists效率比not in的效率高，与子查询的结果集无关，因为not in对于内外表都进行了全表扫描，没有使用到索引。not exists的子查询中可以用到表上的索引。\r\n\r\n### varchar和char的区别？　＊＊＊\r\n\r\n- varchar表示变长，char表示长度固定。当所插入的字符超过他们的长度时，在严格模式下，会拒绝插入并提示错误信息，在一般模式下，会截取后插入。如char(5)，无论插入的字符长度是多少，长度都是5，插入字符长度小于5，则用空格补充。对于varchar(5)，如果插入的字符长度小于5，则存储的字符长度就是插入字符的长度，不会填充。\r\n- 存储容量不同，对于char来说，最多能存放的字符个数为255。对于varchar，最多能存放的字符个数是65532。\r\n- 存储速度不同，char长度固定，存储速度会比varchar快一些，但在空间上会占用额外的空间，属于一种空间换时间的策略。而varchar空间利用率会高些，但存储速度慢，属于一种时间换空间的策略。\r\n\r\n### MySQL中int(10)和char(10)和varchar(10)的区别？　＊＊＊\r\n\r\nint(10)中的10表示的是显示数据的长度，而char(10)和varchar(10)表示的是存储数据的大小。\r\n\r\n### drop、delete和truncate的区别？　＊＊\r\n\r\n|          |                drop                |                delete                |           truncate           |\r\n| :------: | :--------------------------------: | :----------------------------------: | :--------------------------: |\r\n|   速度   |                 快                 |             逐行删除，慢             |             较快             |\r\n|   类型   |                DDL                 |                 DML                  |             DDL              |\r\n|   回滚   |              不可回滚              |                可回滚                |           不可回滚           |\r\n| 删除内容 | 删除整个表，数据行、索引都会被删除 | 表结构还在，删除表的一部分或全部数据 | 表结构还在，删除表的全部数据 |\r\n\r\n一般来讲，删除整个表，使用drop，删除表的部分数据使用delete，保留表结构删除表的全部数据使用truncate。\r\n\r\n### UNION和UNION ALL的区别？　＊＊\r\n\r\nunion和union all的作用都是将两个结果集合并到一起。\r\n\r\n- union会对结果去重并排序，union all直接直接返回合并后的结果，不去重也不进行排序。\r\n- union all的性能比union性能好。\r\n\r\n### 什么是临时表，什么时候会使用到临时表，什么时候删除临时表？　＊\r\n\r\nMySQL在执行SQL语句的时候会临时创建一些存储中间结果集的表，这种表被称为临时表，临时表只对当前连接可见，在连接关闭后，临时表会被删除并释放空间。\r\n\r\n临时表主要分为内存临时表和磁盘临时表两种。内存临时表使用的是MEMORY存储引擎，磁盘临时表使用的是MyISAM存储引擎。\r\n\r\n一般在以下几种情况中会使用到临时表：\r\n\r\n- FROM中的子查询\r\n- DISTINCT查询并加上ORDER BY\r\n- ORDER BY和GROUP BY的子句不一样时会产生临时表\r\n- 使用UNION查询会产生临时表\r\n\r\n### 大表数据查询如何进行优化？　＊＊＊\r\n\r\n- 索引优化\r\n- SQL语句优化\r\n- 水平拆分\r\n- 垂直拆分\r\n- 建立中间表\r\n- 使用缓存技术\r\n- 固定长度的表访问起来更快\r\n- 越小的列访问越快\r\n\r\n### 了解慢日志查询吗？统计过慢查询吗？对慢查询如何优化？　＊＊＊\r\n\r\n慢查询一般用于记录执行时间超过某个临界值的SQL语句的日志。\r\n\r\n相关参数：\r\n\r\n- slow_query_log：是否开启慢日志查询，1表示开启，0表示关闭。\r\n- slow_query_log_file：MySQL数据库慢查询日志存储路径。\r\n- long_query_time：慢查询阈值，当SQL语句查询时间大于阈值，会被记录在日志上。\r\n- log_queries_not_using_indexes：未使用索引的查询会被记录到慢查询日志中。\r\n- log_output：日志存储方式。“FILE”表示将日志存入文件。“TABLE”表示将日志存入数据库。\r\n\r\n如何对慢查询进行优化？\r\n\r\n- 分析语句的执行计划，查看SQL语句的索引是否命中\r\n- 优化数据库的结构，将字段很多的表分解成多个表，或者考虑建立中间表。\r\n- 优化LIMIT分页。\r\n\r\n### 为什么要设置主键？　＊＊\r\n\r\n主键是唯一区分表中每一行的唯一标识，如果没有主键，更新或者删除表中特定的行会很困难，因为不能唯一准确地标识某一行。\r\n\r\n### 主键一般用自增ID还是UUID？　＊＊\r\n\r\n使用自增ID的好处：\r\n\r\n- 字段长度较uuid会小很多。\r\n- 数据库自动编号，按顺序存放，利于检索\r\n- 无需担心主键重复问题\r\n\r\n使用自增ID的缺点：\r\n\r\n- 因为是自增，在某些业务场景下，容易被其他人查到业务量。\r\n- 发生数据迁移时，或者表合并时会非常麻烦\r\n- 在高并发的场景下，竞争自增锁会降低数据库的吞吐能力\r\n\r\nUUID：通用唯一标识码，UUID是基于当前时间、计数器和硬件标识等数据计算生成的。\r\n\r\n使用UUID的优点：\r\n\r\n- 唯一标识，不会考虑重复问题，在数据拆分、合并时也能达到全局的唯一性。\r\n- 可以在应用层生成，提高数据库的吞吐能力。\r\n- 无需担心业务量泄露的问题。\r\n\r\n使用UUID的缺点：\r\n\r\n- 因为UUID是随机生成的，所以会发生随机IO，影响插入速度，并且会造成硬盘的使用率较低。\r\n- UUID占用空间较大，建立的索引越多，造成的影响越大。\r\n- UUID之间比较大小较自增ID慢不少，影响查询速度。\r\n\r\n最后说下结论，一般情况MySQL推荐使用自增ID。因为在MySQL的InnoDB存储引擎中，主键索引是一种聚簇索引，主键索引的B+树的叶子节点按照顺序存储了主键值及数据，如果主键索引是自增ID，只需要按顺序往后排列即可，如果是UUID，ID是随机生成的，在数据插入时会造成大量的数据移动，产生大量的内存碎片，造成插入性能的下降。\r\n\r\n### 字段为什么要设置成not null?　＊＊\r\n\r\n首先说一点，NULL和空值是不一样的，空值是不占用空间的，而NULL是占用空间的，所以字段设为NOT NULL后仍然可以插入空值。\r\n\r\n字段设置成not null主要有以下几点原因：\r\n\r\n- NULL值会影响一些函数的统计，如count，遇到NULL值，这条记录不会统计在内。\r\n\r\n- B树不存储NULL，所以索引用不到NULL，会造成第一点中说的统计不到的问题。\r\n\r\n- NOT IN子查询在有NULL值的情况下返回的结果都是空值。\r\n\r\n  例如user表如下\r\n\r\n  |  id  | username |\r\n  | :--: | :------: |\r\n  |  0   | zhangsan |\r\n  |  1   |   lisi   |\r\n  |  2   |   null   |\r\n\r\n  `select * from `user` where username NOT IN (select username from `user` where id != 0)`，这条查询语句应该查到zhangsan这条数据，但是结果显示为null。\r\n\r\n- MySQL在进行比较的时候，NULL会参与字段的比较，因为NULL是一种比较特殊的数据类型，数据库在处理时需要进行特殊处理，增加了数据库处理记录的复杂性。\r\n\r\n### 如何优化查询过程中的数据访问？　＊＊＊\r\n\r\n从减少数据访问方面考虑：\r\n\r\n- 正确使用索引，尽量做到索引覆盖\r\n- 优化SQL执行计划\r\n\r\n从返回更少的数据方面考虑：\r\n\r\n- 数据分页处理\r\n- 只返回需要的字段\r\n\r\n从减少服务器CPU开销方面考虑：\r\n\r\n- 合理使用排序\r\n- 减少比较的操作\r\n- 复杂运算在客户端处理\r\n\r\n从增加资源方面考虑：\r\n\r\n- 客户端多进程并行访问\r\n- 数据库并行处理\r\n\r\n### 如何优化长难的查询语句？　＊＊\r\n\r\n- 将一个大的查询分解为多个小的查询\r\n- 分解关联查询，使缓存的效率更高\r\n\r\n### 如何优化LIMIT分页？　＊＊\r\n\r\n- 在LIMIT偏移量较大的时候，查询效率会变低，可以记录每次取出的最大ID，下次查询时可以利用ID进行查询\r\n- 建立复合索引\r\n\r\n### 如何优化UNION查询　＊＊\r\n\r\n如果不需要对结果集进行去重或者排序建议使用UNION ALL，会好一些。\r\n\r\n### 如何优化WHERE子句　＊＊＊\r\n\r\n- 不要在where子句中使用!=和<>进行不等于判断，这样会导致放弃索引进行全表扫描。\r\n- 不要在where子句中使用null或空值判断，尽量设置字段为not null。\r\n- 尽量使用union all代替or\r\n- 在where和order by涉及的列建立索引\r\n- 尽量减少使用in或者not in，会进行全表扫描\r\n- 在where子句中使用参数会导致全表扫描\r\n- 避免在where子句中对字段及进行表达式或者函数操作会导致存储引擎放弃索引进而全表扫描\r\n\r\n### SQL语句执行的很慢原因是什么？　＊＊＊\r\n\r\n- 如果SQL语句只是偶尔执行很慢，可能是执行的时候遇到了锁，也可能是redo log日志写满了，要将redo log中的数据同步到磁盘中去。\r\n- 如果SQL语句一直都很慢，可能是字段上没有索引或者字段有索引但是没用上索引。\r\n\r\n### SQL语句的执行顺序?　＊\r\n\r\n```\r\nSELECT DISTINCT \r\n\tselect_list \r\nFROM \r\n\tleft_table \r\nLEFT JOIN \r\n\tright_table ON join_condition \r\nWHERE \r\n\twhere_condition \r\nGROUP BY \r\n\tgroup_by_list \r\nHAVING \r\n\thaving_condition \r\nORDER BY \r\n\torder_by_condition\r\n```\r\n\r\n执行顺序如下：\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\16.png)\r\n\r\n- FROM：对SQL语句执行查询时，首先对关键字两边的表以笛卡尔积的形式执行连接，并产生一个虚表V1。虚表就是视图，数据会来自多张表的执行结果。\r\n- ON：对FROM连接的结果进行ON过滤,并创建虚表V2\r\n- JOIN：将ON过滤后的左表添加进来，并创建新的虚拟表V3\r\n- WHERE：对虚拟表V3进行WHERE筛选，创建虚拟表V4\r\n- GROUP BY：对V4中的记录进行分组操作，创建虚拟表V5\r\n- HAVING：对V5进行过滤，创建虚拟表V6\r\n- SELECT：将V6中的结果按照SELECT进行筛选，创建虚拟表V7\r\n- DISTINCT：对V7表中的结果进行去重操作，创建虚拟表V8，如果使用了GROUP BY子句则无需使用DISTINCT，因为分组的时候是将列中唯一的值分成一组，并且每组只返回一行记录，所以所有的记录都h是不同的。\r\n- ORDER BY：对V8表中的结果进行排序。\r\n\r\n## 数据库优化\r\n\r\n### 大表如何优化？　＊＊＊\r\n\r\n- 限定数据的范围：避免不带任何限制数据范围条件的查询语句。\r\n- 读写分离：主库负责写，从库负责读。\r\n- 垂直分表：将一个表按照字段分成多个表，每个表存储其中一部分字段。\r\n- 水平分表：在同一个数据库内，把一个表的数据按照一定规则拆分到多个表中。\r\n- 对单表进行优化：对表中的字段、索引、查询SQL进行优化。\r\n- 添加缓存\r\n\r\n### 什么是垂直分表、垂直分库、水平分表、水平分库？　＊＊＊\r\n\r\n垂直分表：将一个表按照字段分成多个表，每个表存储其中一部分字段。一般会将常用的字段放到一个表中，将不常用的字段放到另一个表中。\r\n\r\n垂直分表的优势：\r\n\r\n- 避免IO竞争减少锁表的概率。因为大的字段效率更低，第一数据量大，需要的读取时间长。第二，大字段占用的空间更大，单页内存储的行数变少，会使得IO操作增多。\r\n- 可以更好地提升热门数据的查询效率。\r\n\r\n垂直分库：按照业务对表进行分类，部署到不同的数据库上面，不同的数据库可以放到不同的服务器上面。\r\n\r\n垂直分库的优势：\r\n\r\n- 降低业务中的耦合，方便对不同的业务进行分级管理。\r\n- 可以提升IO、数据库连接数、解决单机硬件资源的瓶颈问题。\r\n\r\n垂直拆分（分库、分表）的缺点：\r\n\r\n- 主键出现冗余，需要管理冗余列\r\n- 事务的处理变得复杂\r\n- 仍然存在单表数据量过大的问题\r\n\r\n水平分表：在同一个数据库内，把同一个表的数据按照一定规则拆分到多个表中。\r\n\r\n水平分表的优势：\r\n\r\n- 解决了单表数据量过大的问题\r\n- 避免IO竞争并减少锁表的概率\r\n\r\n水平分库：把同一个表的数据按照一定规则拆分到不同的数据库中，不同的数据库可以放到不同的服务器上。\r\n\r\n水平分库的优势：\r\n\r\n- 解决了单库大数据量的瓶颈问题\r\n- IO冲突减少，锁的竞争减少，某个数据库出现问题不影响其他数据库（可用性），提高了系统的稳定性和可用性\r\n\r\n水平拆分（分表、分库）的缺点：\r\n\r\n- 分片事务一致性难以解决\r\n- 跨节点JOIN性能差，逻辑会变得复杂\r\n- 数据扩展难度大，不易维护\r\n\r\n在系统设计时应根据业务耦合来确定垂直分库和垂直分表的方案，在数据访问压力不是特别大时应考虑缓存、读写分离等方法，若数据量很大，或持续增长可考虑水平分库分表，水平拆分所涉及的逻辑比较复杂，常见的方案有客户端架构和代理架构。\r\n\r\n### 分库分表后，ID键如何处理？　＊＊＊\r\n\r\n分库分表后不能每个表的ID都是从1开始，所以需要一个全局ID，设置全局ID主要有以下几种方法：\r\n\r\n- UUID：优点：本地生成ID，不需要远程调用；全局唯一不重复。缺点：占用空间大，不适合作为索引。\r\n\r\n- 数据库自增ID：在分库分表表后使用数据库自增ID，需要一个专门用于生成主键的库，每次服务接收到请求，先向这个库中插入一条没有意义的数据，获取一个数据库自增的ID，利用这个ID去分库分表中写数据。优点：简单易实现。缺点：在高并发下存在瓶颈。系统结构如下图（图片来源于网络）\r\n\r\n  ![Image](\\2万字的MySQL八股文背诵版.assets\\17.png)\r\n\r\n- Redis生成ID：优点：不依赖数据库，性能比较好。缺点：引入新的组件会使得系统复杂度增加\r\n\r\n- Twitter的snowflake算法：是一个64位的long型的ID，其中有1bit是不用的，41bit作为毫秒数，10bit作为工作机器ID，12bit作为序列号。\r\n\r\n  1bit：第一个bit默认为0，因为二进制中第一个bit为1的话为负数，但是ID不能为负数.\r\n\r\n  41bit：表示的是时间戳，单位是毫秒。\r\n\r\n  10bit：记录工作机器ID，其中5个bit表示机房ID，5个bit表示机器ID。\r\n\r\n  12bit：用来记录同一毫秒内产生的不同ID。\r\n\r\n- 美团的Leaf分布式ID生成系统，美团点评分布式ID生成系统\r\n\r\n### MySQL的复制原理及流程？如何实现主从复制？　＊＊＊\r\n\r\nMySQL复制：为保证主服务器和从服务器的数据一致性，在向主服务器插入数据后，从服务器会自动将主服务器中修改的数据同步过来。\r\n\r\n主从复制的原理：\r\n\r\n主从复制主要有三个线程：binlog线程，I/O线程，SQL线程。\r\n\r\n- binlog线程：负责将主服务器上的数据更改写入到二进制日志（Binary log）中。\r\n- I/O线程：负责从主服务器上读取二进制日志（Binary log），并写入从服务器的中继日志（Relay log）中。\r\n- SQL线程：负责读取中继日志，解析出主服务器中已经执行的数据更改并在从服务器中重放\r\n\r\n复制过程如下（图片来源于网络）：\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\18.png)\r\n\r\n1. Master在每个事务更新数据完成之前，将操作记录写入到binlog中。\r\n2. Slave从库连接Master主库，并且Master有多少个Slave就会创建多少个binlog dump线程。当Master节点的binlog发生变化时，binlog dump会通知所有的Slave，并将相应的binlog发送给Slave。\r\n3. I/O线程接收到binlog内容后，将其写入到中继日志（Relay log）中。\r\n4. SQL线程读取中继日志，并在从服务器中重放。\r\n\r\n这里补充一个通俗易懂的图。\r\n\r\n![Image](\\2万字的MySQL八股文背诵版.assets\\19.png)\r\n\r\n主从复制的作用：\r\n\r\n- 高可用和故障转移\r\n- 负载均衡\r\n- 数据备份\r\n- 升级测试\r\n\r\n### 了解读写分离吗？　＊＊＊\r\n\r\n读写分离主要依赖于主从复制，主从复制为读写分离服务。\r\n\r\n读写分离的优势：\r\n\r\n- 主服务器负责写，从服务器负责读，缓解了锁的竞争\r\n- 从服务器可以使用MyISAM，提升查询性能及节约系统开销\r\n- 增加冗余，提高可用性"},bc06:function(n,r,e){"use strict";e.r(r),r["default"]="> 作者: 听风，原文地址: <https://www.cnblogs.com/huchong/p/10219318.html>。JavaGuide 已获得作者授权。\n\n\x3c!-- TOC --\x3e\n\n- [数据库命令规范](#数据库命令规范)\n- [数据库基本设计规范](#数据库基本设计规范)\n    - [1. 所有表必须使用 Innodb 存储引擎](#1-所有表必须使用-innodb-存储引擎)\n    - [2. 数据库和表的字符集统一使用 UTF8](#2-数据库和表的字符集统一使用-utf8)\n    - [3. 所有表和字段都需要添加注释](#3-所有表和字段都需要添加注释)\n    - [4. 尽量控制单表数据量的大小,建议控制在 500 万以内。](#4-尽量控制单表数据量的大小建议控制在-500-万以内)\n    - [5. 谨慎使用 MySQL 分区表](#5-谨慎使用-mysql-分区表)\n    - [6.尽量做到冷热数据分离,减小表的宽度](#6尽量做到冷热数据分离减小表的宽度)\n    - [7. 禁止在表中建立预留字段](#7-禁止在表中建立预留字段)\n    - [8. 禁止在数据库中存储图片,文件等大的二进制数据](#8-禁止在数据库中存储图片文件等大的二进制数据)\n    - [9. 禁止在线上做数据库压力测试](#9-禁止在线上做数据库压力测试)\n    - [10. 禁止从开发环境,测试环境直接连接生成环境数据库](#10-禁止从开发环境测试环境直接连接生成环境数据库)\n- [数据库字段设计规范](#数据库字段设计规范)\n    - [1. 优先选择符合存储需要的最小的数据类型](#1-优先选择符合存储需要的最小的数据类型)\n    - [2. 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据](#2-避免使用-textblob-数据类型最常见的-text-类型可以存储-64k-的数据)\n    - [3. 避免使用 ENUM 类型](#3-避免使用-enum-类型)\n    - [4. 尽可能把所有列定义为 NOT NULL](#4-尽可能把所有列定义为-not-null)\n    - [5. 使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间](#5-使用-timestamp4-个字节-或-datetime-类型-8-个字节-存储时间)\n    - [6. 同财务相关的金额类数据必须使用 decimal 类型](#6-同财务相关的金额类数据必须使用-decimal-类型)\n- [索引设计规范](#索引设计规范)\n    - [1. 限制每张表上的索引数量,建议单张表索引不超过 5 个](#1-限制每张表上的索引数量建议单张表索引不超过-5-个)\n    - [2. 禁止给表中的每一列都建立单独的索引](#2-禁止给表中的每一列都建立单独的索引)\n    - [3. 每个 Innodb 表必须有个主键](#3-每个-innodb-表必须有个主键)\n    - [4. 常见索引列建议](#4-常见索引列建议)\n    - [5.如何选择索引列的顺序](#5如何选择索引列的顺序)\n    - [6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）](#6-避免建立冗余索引和重复索引增加了查询优化器生成执行计划的时间)\n    - [7. 对于频繁的查询优先考虑使用覆盖索引](#7-对于频繁的查询优先考虑使用覆盖索引)\n    - [8.索引 SET 规范](#8索引-set-规范)\n- [数据库 SQL 开发规范](#数据库-sql-开发规范)\n    - [1. 建议使用预编译语句进行数据库操作](#1-建议使用预编译语句进行数据库操作)\n    - [2. 避免数据类型的隐式转换](#2-避免数据类型的隐式转换)\n    - [3. 充分利用表上已经存在的索引](#3-充分利用表上已经存在的索引)\n    - [4. 数据库设计时，应该要对以后扩展进行考虑](#4-数据库设计时应该要对以后扩展进行考虑)\n    - [5. 程序连接不同的数据库使用不同的账号，禁止跨库查询](#5-程序连接不同的数据库使用不同的账号禁止跨库查询)\n    - [6. 禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询](#6-禁止使用-select--必须使用-select-字段列表-查询)\n    - [7. 禁止使用不含字段列表的 INSERT 语句](#7-禁止使用不含字段列表的-insert-语句)\n    - [8. 避免使用子查询，可以把子查询优化为 join 操作](#8-避免使用子查询可以把子查询优化为-join-操作)\n    - [9. 避免使用 JOIN 关联太多的表](#9-避免使用-join-关联太多的表)\n    - [10. 减少同数据库的交互次数](#10-减少同数据库的交互次数)\n    - [11. 对应同一列进行 or 判断时，使用 in 代替 or](#11-对应同一列进行-or-判断时使用-in-代替-or)\n    - [12. 禁止使用 order by rand() 进行随机排序](#12-禁止使用-order-by-rand-进行随机排序)\n    - [13. WHERE 从句中禁止对列进行函数转换和计算](#13-where-从句中禁止对列进行函数转换和计算)\n    - [14. 在明显不会有重复值时使用 UNION ALL 而不是 UNION](#14-在明显不会有重复值时使用-union-all-而不是-union)\n    - [15. 拆分复杂的大 SQL 为多个小 SQL](#15-拆分复杂的大-sql-为多个小-sql)\n- [数据库操作行为规范](#数据库操作行为规范)\n    - [1. 超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作](#1-超-100-万行的批量写-updatedeleteinsert-操作要分批多次进行操作)\n    - [2. 对于大表使用 pt-online-schema-change 修改表结构](#2-对于大表使用-pt-online-schema-change-修改表结构)\n    - [3. 禁止为程序使用的账号赋予 super 权限](#3-禁止为程序使用的账号赋予-super-权限)\n    - [4. 对于程序连接数据库账号,遵循权限最小原则](#4-对于程序连接数据库账号遵循权限最小原则)\n\n\x3c!-- /TOC --\x3e\n\n## 数据库命令规范\n\n- 所有数据库对象名称必须使用小写字母并用下划线分割\n- 所有数据库对象名称禁止使用 MySQL 保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来）\n- 数据库对象的命名要能做到见名识意，并且最后不要超过 32 个字符\n- 临时库表必须以 tmp_为前缀并以日期为后缀，备份表必须以 bak_为前缀并以日期 (时间戳) 为后缀\n- 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低）\n\n------\n\n## 数据库基本设计规范\n\n### 1. 所有表必须使用 Innodb 存储引擎\n\n没有特殊要求（即 Innodb 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 Innodb 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 Innodb）。\n\nInnodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。\n\n### 2. 数据库和表的字符集统一使用 UTF8\n\n兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储 emoji 表情的需要，字符集需要采用 utf8mb4 字符集。\n\n参考文章：[MySQL 字符集不一致导致索引失效的一个真实案例](https://blog.csdn.net/horses/article/details/107243447)\n\n### 3. 所有表和字段都需要添加注释\n\n使用 comment 从句添加表和列的备注，从一开始就进行数据字典的维护\n\n### 4. 尽量控制单表数据量的大小,建议控制在 500 万以内。\n\n500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。\n\n可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小\n\n### 5. 谨慎使用 MySQL 分区表\n\n分区表在物理上表现为多个文件，在逻辑上表现为一个表；\n\n谨慎选择分区键，跨分区查询效率可能更低；\n\n建议采用物理分表的方式管理大数据。\n\n### 6.尽量做到冷热数据分离,减小表的宽度\n\n> MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。\n\n减少磁盘 IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO）；\n\n更有效的利用缓存，避免读入无用的冷数据；\n\n经常一起使用的列放到一个表中（避免更多的关联操作）。\n\n### 7. 禁止在表中建立预留字段\n\n预留字段的命名很难做到见名识义。\n\n预留字段无法确认存储的数据类型，所以无法选择合适的类型。\n\n对预留字段类型的修改，会对表进行锁定。\n\n### 8. 禁止在数据库中存储图片,文件等大的二进制数据\n\n通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时。\n\n通常存储于文件服务器，数据库只存储文件地址信息\n\n### 9. 禁止在线上做数据库压力测试\n\n### 10. 禁止从开发环境,测试环境直接连接生产环境数据库\n\n------\n\n## 数据库字段设计规范\n\n### 1. 优先选择符合存储需要的最小的数据类型\n\n**原因：**\n\n列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。\n\n**方法：**\n\n**a.将字符串转换成数字类型存储,如:将 IP 地址转换成整形数据**\n\nMySQL 提供了两个方法来处理 ip 地址\n\n- inet_aton 把 ip 转为无符号整型 (4-8 位)\n- inet_ntoa 把整型的 ip 转为地址\n\n插入数据前，先用 inet_aton 把 ip 地址转为整型，可以节省空间，显示数据时，使用 inet_ntoa 把整型的 ip 地址转为地址显示即可。\n\n**b.对于非负型的数据 (如自增 ID,整型 IP) 来说,要优先使用无符号整型来存储**\n\n**原因：**\n\n无符号相对于有符号可以多出一倍的存储空间\n\n```\nSIGNED INT -2147483648~2147483647\nUNSIGNED INT 0~4294967295\n```\n\nVARCHAR(N) 中的 N 代表的是字符数，而不是字节数，使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。**过大的长度会消耗更多的内存。**\n\n### 2. 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据\n\n**a. 建议把 BLOB 或是 TEXT 列分离到单独的扩展表中**\n\nMySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。\n\n如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。\n\n**2、TEXT 或 BLOB 类型只能使用前缀索引**\n\n因为[MySQL](https://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247487885&idx=1&sn=65b1bf5f7d4505502620179669a9c2df&chksm=ebd62ea1dca1a7b7bf884bcd9d538d78ba064ee03c09436ca8e57873b1d98a55afd6d7884cfc&scene=21#wechat_redirect) 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的\n\n### 3. 避免使用 ENUM 类型\n\n修改 ENUM 值需要使用 ALTER 语句\n\nENUM 类型的 ORDER BY 操作效率低，需要额外操作\n\n禁止使用数值作为 ENUM 的枚举值\n\n### 4. 尽可能把所有列定义为 NOT NULL\n\n**原因：**\n\n索引 NULL 列需要额外的空间来保存，所以要占用更多的空间\n\n进行比较和计算时要对 NULL 值做特别的处理\n\n### 5. 使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间\n\nTIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07\n\nTIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高\n\n超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储\n\n**经常会有人用字符串存储日期型的数据（不正确的做法）**\n\n- 缺点 1：无法用日期函数进行计算和比较\n- 缺点 2：用字符串存储日期要占用更多的空间\n\n### 6. 同财务相关的金额类数据必须使用 decimal 类型\n\n- 非精准浮点：float,double\n- 精准浮点：decimal\n\nDecimal 类型为精准浮点数，在计算时不会丢失精度\n\n占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节\n\n可用于存储比 bigint 更大的整型数据\n\n------\n\n## 索引设计规范\n\n### 1. 限制每张表上的索引数量,建议单张表索引不超过 5 个\n\n索引并不是越多越好！索引可以提高效率同样可以降低效率。\n\n索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。\n\n因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。\n\n### 2. 禁止给表中的每一列都建立单独的索引\n\n5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。\n\n### 3. 每个 Innodb 表必须有个主键\n\nInnodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。\n\nInnodb 是按照主键索引的顺序来组织表的\n\n- 不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）\n- 不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）\n- 主键建议使用自增 ID 值\n\n------\n\n### 4. 常见索引列建议\n\n- 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列\n- 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段\n- 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好\n- 多表 join 的关联列\n\n------\n\n### 5.如何选择索引列的顺序\n\n建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。\n\n- 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）\n- 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）\n- 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）\n\n------\n\n### 6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）\n\n- 重复索引示例：primary key(id)、index(id)、unique index(id)\n- 冗余索引示例：index(a,b,c)、index(a,b)、index(a)\n\n------\n\n### 7. 对于频繁的查询优先考虑使用覆盖索引\n\n> 覆盖索引：就是包含了所有查询字段 (where,select,order by,group by 包含的字段) 的索引\n\n**覆盖索引的好处：**\n\n- **避免 Innodb 表进行索引的二次查询:** Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。\n- **可以把随机 IO 变成顺序 IO 加快查询效率:** 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。\n\n------\n\n### 8.索引 SET 规范\n\n**尽量避免使用外键约束**\n\n- 不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引\n- 外键可用于保证数据的参照完整性，但建议在业务端实现\n- 外键会影响父表和子表的写操作从而降低性能\n\n------\n\n## 数据库 SQL 开发规范\n\n### 1. 建议使用预编译语句进行数据库操作\n\n预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题。\n\n只传参数，比传递 SQL 语句更高效。\n\n相同语句可以一次解析，多次使用，提高处理效率。\n\n### 2. 避免数据类型的隐式转换\n\n隐式转换会导致索引失效如:\n\n```\nselect name,phone from customer where id = '111';\n```\n\n### 3. 充分利用表上已经存在的索引\n\n避免使用双%号的查询条件。如：`a like '%123%'`，（如果无前置%,只有后置%，是可以用到列上的索引的）\n\n一个 SQL 只能利用到复合索引中的一列进行范围查询。如：有 a,b,c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b,c 列上的索引将不会被用到。\n\n在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧，使用 left join 或 not exists 来优化 not in 操作，因为 not in 也通常会使用索引失效。\n\n### 4. 数据库设计时，应该要对以后扩展进行考虑\n\n### 5. 程序连接不同的数据库使用不同的账号，禁止跨库查询\n\n- 为数据库迁移和分库分表留出余地\n- 降低业务耦合度\n- 避免权限过大而产生的安全风险\n\n### 6. 禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询\n\n**原因：**\n\n- 消耗更多的 CPU 和 IO 以网络带宽资源\n- 无法使用覆盖索引\n- 可减少表结构变更带来的影响\n\n### 7. 禁止使用不含字段列表的 INSERT 语句\n\n如：\n\n```\ninsert into values ('a','b','c');\n```\n\n应使用：\n\n```\ninsert into t(c1,c2,c3) values ('a','b','c');\n```\n\n### 8. 避免使用子查询，可以把子查询优化为 join 操作\n\n通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。\n\n**子查询性能差的原因：**\n\n子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。\n\n由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。\n\n### 9. 避免使用 JOIN 关联太多的表\n\n对于 MySQL 来说，是存在关联缓存的，缓存的大小可以由 join_buffer_size 参数进行设置。\n\n在 MySQL 中，对于同一个 SQL 多关联（join）一个表，就会多分配一个关联缓存，如果在一个 SQL 中关联的表越多，所占用的内存也就越大。\n\n如果程序中大量的使用了多表关联的操作，同时 join_buffer_size 设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。\n\n同时对于关联操作来说，会产生临时表操作，影响查询效率，MySQL 最多允许关联 61 个表，建议不超过 5 个。\n\n### 10. 减少同数据库的交互次数\n\n数据库更适合处理批量操作，合并多个相同的操作到一起，可以提高处理效率。\n\n### 11. 对应同一列进行 or 判断时，使用 in 代替 or\n\nin 的值不要超过 500 个，in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。\n\n### 12. 禁止使用 order by rand() 进行随机排序\n\norder by rand() 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。\n\n推荐在程序中获取一个随机值，然后从数据库中获取数据的方式。\n\n### 13. WHERE 从句中禁止对列进行函数转换和计算\n\n对列进行函数转换或计算时会导致无法使用索引\n\n**不推荐：**\n\n```\nwhere date(create_time)='20190101'\n```\n\n**推荐：**\n\n```\nwhere create_time >= '20190101' and create_time < '20190102'\n```\n\n### 14. 在明显不会有重复值时使用 UNION ALL 而不是 UNION\n\n- UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作\n- UNION ALL 不会再对结果集进行去重操作\n\n### 15. 拆分复杂的大 SQL 为多个小 SQL\n\n- 大 SQL 逻辑上比较复杂，需要占用大量 CPU 进行计算的 SQL\n- MySQL 中，一个 SQL 只能使用一个 CPU 进行计算\n- SQL 拆分后可以通过并行执行来提高处理效率\n\n------\n\n## 数据库操作行为规范\n\n### 1. 超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作\n\n**大批量操作可能会造成严重的主从延迟**\n\n主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，\n而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况\n\n**binlog 日志为 row 格式时会产生大量的日志**\n\n大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因\n\n**避免产生大事务操作**\n\n大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。\n\n特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批\n\n### 2. 对于大表使用 pt-online-schema-change 修改表结构\n\n- 避免大表修改产生的主从延迟\n- 避免在对表字段进行修改时进行锁表\n\n对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的。\n\npt-online-schema-change 它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个 DDL 操作，分解成多个小的批次进行。\n\n### 3. 禁止为程序使用的账号赋予 super 权限\n\n- 当达到最大连接数限制时，还运行 1 个有 super 权限的用户连接\n- super 权限只能留给 DBA 处理问题的账号使用\n\n### 4. 对于程序连接数据库账号,遵循权限最小原则\n\n- 程序使用数据库账号只能在一个 DB 下使用，不准跨库\n- 程序使用的账号原则上不准有 drop 权限\n"},c4a8:function(n,r,e){"use strict";e.r(r),r["default"]='\n### 简单介绍一下 Redis 呗!\n\n简单来说 **Redis 就是一个使用 C 语言开发的数据库**，不过与传统数据库不同的是 **Redis 的数据是存在内存中的** ，也就是它是内存数据库，所以读写速度非常快，因此 Redis 被广泛应用于缓存方向。\n\n另外，**Redis 除了做缓存之外，也经常用来做分布式锁，甚至是消息队列。**\n\n**Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。**\n\n### 分布式缓存常见的技术选型方案有哪些？\n\n分布式缓存的话，使用的比较多的主要是 **Memcached** 和 **Redis**。不过，现在基本没有看过还有项目使用 **Memcached** 来做缓存，都是直接用 **Redis**。\n\nMemcached 是分布式缓存最开始兴起的那会，比较常用的。后来，随着 Redis 的发展，大家慢慢都转而使用更加强大的 Redis 了。\n\n分布式缓存主要解决的是单机缓存的容量受服务器限制并且无法保存通用信息的问题。因为，本地缓存只在当前服务里有效，比如如果你部署了两个相同的服务，他们两者之间的缓存数据是无法共同的。\n\n### 说一下 Redis 和 Memcached 的区别和共同点\n\n现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！\n\n**共同点** ：\n\n1. 都是基于内存的数据库，一般都用来当做缓存使用。\n2. 都有过期策略。\n3. 两者的性能都非常高。\n\n**区别** ：\n\n1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。\n2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。**\n3. **Redis 有灾难恢复机制。** 因为可以把缓存中的数据持久化到磁盘上。\n4. **Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**\n5. **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。**\n6. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 引入了多线程 IO ）\n7. **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**\n8. **Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**\n\n相信看了上面的对比之后，我们已经没有什么理由可以选择使用 Memcached 来作为自己项目的分布式缓存了。\n\n### 缓存数据的处理流程是怎样的？\n\n作为暖男一号，我给大家画了一个草图。\n\n![正常缓存处理流程](redis-all.assets/缓存的处理流程.png)\n\n简单来说就是:\n\n1. 如果用户请求的数据在缓存中就直接返回。\n2. 缓存中不存在的话就看数据库中是否存在。\n3. 数据库中存在的话就更新缓存中的数据。\n4. 数据库中不存在的话就返回空数据。\n\n### 为什么要用 Redis/为什么要用缓存？\n\n_简单，来说使用缓存主要是为了提升用户体验以及应对更多的用户。_\n\n下面我们主要从“高性能”和“高并发”这两点来看待这个问题。\n\n![](redis-all.assets/使用缓存之后.png)\n\n**高性能** ：\n\n对照上面 👆 我画的图。我们设想这样的场景：\n\n假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。\n\n**这样有什么好处呢？** 那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。\n\n不过，要保持数据库和缓存中的数据的一致性。 如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！\n\n**高并发：**\n\n一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。\n\n> QPS（Query Per Second）：服务器每秒可以执行的查询次数；\n\n由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。\n\n### Redis 除了做缓存，还能做什么？\n\n- **分布式锁** ： 通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。相关阅读：[《分布式锁中的王者方案 - Redisson》](https://mp.weixin.qq.com/s/CbnPRfvq4m1sqo2uKI6qQw)。\n- **限流** ：一般是通过 Redis + Lua 脚本的方式来实现限流。相关阅读：[《我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了！》](https://mp.weixin.qq.com/s/kyFAWH3mVNJvurQDt4vchA)。\n- **消息队列** ：Redis 自带的 list 数据结构可以作为一个简单的队列使用。Redis5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。\n- **复杂业务场景** ：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景比如通过 bitmap 统计活跃用户、通过 sorted set 维护排行榜。\n- ......\n\n### Redis 常见数据结构以及使用场景分析\n\n你可以自己本机安装 redis 或者通过 redis 官网提供的[在线 redis 环境](https://try.redis.io/)。\n\n![try-redis](redis-all.assets/try-redis.png)\n\n#### string\n\n1. **介绍** ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 **简单动态字符串**（simple dynamic string，**SDS**）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。\n2. **常用命令：** `set,get,strlen,exists,decr,incr,setex` 等等。\n3. **应用场景：** 一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。\n\n下面我们简单看看它的使用！\n\n**普通字符串的基本操作：**\n\n```bash\n127.0.0.1:6379> set key value #设置 key-value 类型的值\nOK\n127.0.0.1:6379> get key # 根据 key 获得对应的 value\n"value"\n127.0.0.1:6379> exists key  # 判断某个 key 是否存在\n(integer) 1\n127.0.0.1:6379> strlen key # 返回 key 所储存的字符串值的长度。\n(integer) 5\n127.0.0.1:6379> del key # 删除某个 key 对应的值\n(integer) 1\n127.0.0.1:6379> get key\n(nil)\n```\n\n**批量设置** :\n\n```bash\n127.0.0.1:6379> mset key1 value1 key2 value2 # 批量设置 key-value 类型的值\nOK\n127.0.0.1:6379> mget key1 key2 # 批量获取多个 key 对应的 value\n1) "value1"\n2) "value2"\n```\n\n**计数器（字符串的内容为整数的时候可以使用）：**\n\n```bash\n127.0.0.1:6379> set number 1\nOK\n127.0.0.1:6379> incr number # 将 key 中储存的数字值增一\n(integer) 2\n127.0.0.1:6379> get number\n"2"\n127.0.0.1:6379> decr number # 将 key 中储存的数字值减一\n(integer) 1\n127.0.0.1:6379> get number\n"1"\n```\n\n**过期（默认为永不过期）**：\n\n```bash\n127.0.0.1:6379> expire key  60 # 数据在 60s 后过期\n(integer) 1\n127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)\nOK\n127.0.0.1:6379> ttl key # 查看数据还有多久过期\n(integer) 56\n```\n\n#### list\n\n1. **介绍** ：**list** 即是 **链表**。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 **LinkedList**，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。\n2. **常用命令:** `rpush,lpop,lpush,rpop,lrange,llen` 等。\n3. **应用场景:** 发布与订阅或者说消息队列、慢查询。\n\n下面我们简单看看它的使用！\n\n**通过 `rpush/lpop` 实现队列：**\n\n```bash\n127.0.0.1:6379> rpush myList value1 # 向 list 的头部（右边）添加元素\n(integer) 1\n127.0.0.1:6379> rpush myList value2 value3 # 向list的头部（最右边）添加多个元素\n(integer) 3\n127.0.0.1:6379> lpop myList # 将 list的尾部(最左边)元素取出\n"value1"\n127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end\n1) "value2"\n2) "value3"\n127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一\n1) "value2"\n2) "value3"\n```\n\n**通过 `rpush/rpop` 实现栈：**\n\n```bash\n127.0.0.1:6379> rpush myList2 value1 value2 value3\n(integer) 3\n127.0.0.1:6379> rpop myList2 # 将 list的头部(最右边)元素取出\n"value3"\n```\n\n我专门画了一个图方便小伙伴们来理解：\n\n![redis list](redis-all.assets/redis-list.png)\n\n**通过 `lrange` 查看对应下标范围的列表元素：**\n\n```bash\n127.0.0.1:6379> rpush myList value1 value2 value3\n(integer) 3\n127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end\n1) "value1"\n2) "value2"\n127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一\n1) "value1"\n2) "value2"\n3) "value3"\n```\n\n通过 `lrange` 命令，你可以基于 list 实现分页查询，性能非常高！\n\n**通过 `llen` 查看链表长度：**\n\n```bash\n127.0.0.1:6379> llen myList\n(integer) 3\n```\n\n#### hash\n\n1. **介绍** ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。\n2. **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。\n3. **应用场景:** 系统中对象数据的存储。\n\n下面我们简单看看它的使用！\n\n```bash\n127.0.0.1:6379> hmset userInfoKey name "guide" description "dev" age "24"\nOK\n127.0.0.1:6379> hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。\n(integer) 1\n127.0.0.1:6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值。\n"guide"\n127.0.0.1:6379> hget userInfoKey age\n"24"\n127.0.0.1:6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值\n1) "name"\n2) "guide"\n3) "description"\n4) "dev"\n5) "age"\n6) "24"\n127.0.0.1:6379> hkeys userInfoKey # 获取 key 列表\n1) "name"\n2) "description"\n3) "age"\n127.0.0.1:6379> hvals userInfoKey # 获取 value 列表\n1) "guide"\n2) "dev"\n3) "24"\n127.0.0.1:6379> hset userInfoKey name "GuideGeGe" # 修改某个字段对应的值\n127.0.0.1:6379> hget userInfoKey name\n"GuideGeGe"\n```\n\n#### set\n\n1. **介绍 ：** set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。\n2. **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。\n3. **应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景\n\n下面我们简单看看它的使用！\n\n```bash\n127.0.0.1:6379> sadd mySet value1 value2 # 添加元素进去\n(integer) 2\n127.0.0.1:6379> sadd mySet value1 # 不允许有重复元素\n(integer) 0\n127.0.0.1:6379> smembers mySet # 查看 set 中所有的元素\n1) "value1"\n2) "value2"\n127.0.0.1:6379> scard mySet # 查看 set 的长度\n(integer) 2\n127.0.0.1:6379> sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素\n(integer) 1\n127.0.0.1:6379> sadd mySet2 value2 value3\n(integer) 2\n127.0.0.1:6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中\n(integer) 1\n127.0.0.1:6379> smembers mySet3\n1) "value2"\n```\n\n#### sorted set\n\n1. **介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。\n2. **常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。\n3. **应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。\n\n```bash\n127.0.0.1:6379> zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重\n(integer) 1\n127.0.0.1:6379> zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素\n(integer) 2\n127.0.0.1:6379> zcard myZset # 查看 sorted set 中的元素数量\n(integer) 3\n127.0.0.1:6379> zscore myZset value1 # 查看某个 value 的权重\n"3"\n127.0.0.1:6379> zrange  myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素\n1) "value3"\n2) "value2"\n3) "value1"\n127.0.0.1:6379> zrange  myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start  1 为 stop\n1) "value3"\n2) "value2"\n127.0.0.1:6379> zrevrange  myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start  1 为 stop\n1) "value1"\n2) "value2"\n```\n\n#### bitmap\n\n1. **介绍：** bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间。\n2. **常用命令：** `setbit` 、`getbit` 、`bitcount`、`bitop`\n3. **应用场景：** 适合需要保存状态信息（比如是否签到、是否登录...）并需要进一步对这些信息进行分析的场景。比如用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。\n\n```bash\n# SETBIT 会返回之前位的值（默认是 0）这里会生成 7 个位\n127.0.0.1:6379> setbit mykey 7 1\n(integer) 0\n127.0.0.1:6379> setbit mykey 7 0\n(integer) 1\n127.0.0.1:6379> getbit mykey 7\n(integer) 0\n127.0.0.1:6379> setbit mykey 6 1\n(integer) 0\n127.0.0.1:6379> setbit mykey 8 1\n(integer) 0\n# 通过 bitcount 统计被被设置为 1 的位的数量。\n127.0.0.1:6379> bitcount mykey\n(integer) 2\n```\n\n针对上面提到的一些场景，这里进行进一步说明。\n\n**使用场景一：用户行为分析**\n很多网站为了分析你的喜好，需要研究你点赞过的内容。\n\n```bash\n# 记录你喜欢过 001 号小姐姐\n127.0.0.1:6379> setbit beauty_girl_001 uid 1\n```\n\n**使用场景二：统计活跃用户**\n\n使用时间作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1\n\n那么我该如何计算某几天/月/年的活跃用户呢(暂且约定，统计时间内只要有一天在线就称为活跃)，有请下一个 redis 的命令\n\n```bash\n# 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。\n# BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种参数\nBITOP operation destkey key [key ...]\n```\n\n初始化数据：\n\n```bash\n127.0.0.1:6379> setbit 20210308 1 1\n(integer) 0\n127.0.0.1:6379> setbit 20210308 2 1\n(integer) 0\n127.0.0.1:6379> setbit 20210309 1 1\n(integer) 0\n```\n\n统计 20210308~20210309 总活跃用户数: 1\n\n```bash\n127.0.0.1:6379> bitop and desk1 20210308 20210309\n(integer) 1\n127.0.0.1:6379> bitcount desk1\n(integer) 1\n```\n\n统计 20210308~20210309 在线活跃用户数: 2\n\n```bash\n127.0.0.1:6379> bitop or desk2 20210308 20210309\n(integer) 1\n127.0.0.1:6379> bitcount desk2\n(integer) 2\n```\n\n**使用场景三：用户在线状态**\n\n对于获取或者统计用户在线状态，使用 bitmap 是一个节约空间且效率又高的一种方法。\n\n只需要一个 key，然后用户 ID 为 offset，如果在线就设置为 1，不在线就设置为 0。\n\n### Redis 单线程模型详解\n\n**Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型** （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。\n\n**既然是单线程，那怎么监听大量的客户端连接呢？**\n\nRedis 通过**IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。\n\n这样的好处非常明显： **I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗**（和 NIO 中的 `Selector` 组件很像）。\n\n另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件：1. 文件事件; 2. 时间事件。\n\n时间事件不需要多花时间了解，我们接触最多的还是 **文件事件**（客户端进行读取写入等操作，涉及一系列网络通信）。\n\n《Redis 设计与实现》有一段话是如是介绍文件事件的，我觉得写得挺不错。\n\n> Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。\n>\n> 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。\n>\n> **虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字**，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n\n可以看出，文件事件处理器（file event handler）主要是包含 4 个部分：\n\n- 多个 socket（客户端连接）\n- IO 多路复用程序（支持多个客户端连接的关键）\n- 文件事件分派器（将 socket 关联到相应的事件处理器）\n- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）\n\n![](redis-all.assets/redis事件处理器.png)\n\n<p style="text-align:right; font-size:14px; color:gray">《Redis设计与实现：12章》</p>\n\n### Redis 没有使用多线程？为什么不使用多线程？\n\n虽然说 Redis 是单线程模型，但是，实际上，**Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。**\n\n![redis4.0 more thread](redis-all.assets/redis4.0-more-thread.png)\n\n不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。\n\n大体上来说，**Redis 6.0 之前主要还是单线程处理。**\n\n**那，Redis6.0 之前 为什么不使用多线程？**\n\n我觉得主要原因有下面 3 个：\n\n1. 单线程编程容易并且更容易维护；\n2. Redis 的性能瓶颈不在 CPU ，主要在内存和网络；\n3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。\n\n### Redis6.0 之后为何引入了多线程？\n\n**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。\n\n虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。\n\nRedis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 `redis.conf` ：\n\n```bash\nio-threads-do-reads yes\n```\n\n开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 `redis.conf` :\n\n```bash\nio-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程\n```\n\n推荐阅读：\n\n1. [Redis 6.0 新特性-多线程连环 13 问！](https://mp.weixin.qq.com/s/FZu3acwK6zrCBZQ_3HoUgw)\n2. [为什么 Redis 选择单线程模型](https://draveness.me/whys-the-design-redis-single-thread/)\n\n### Redis 给缓存数据设置过期时间有啥用？\n\n一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。为什么呢？\n\n因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接 Out of memory。\n\nRedis 自带了给缓存数据设置过期时间的功能，比如：\n\n```bash\n127.0.0.1:6379> exp key 60 # 数据在 60s 后过期\n(integer) 1\n127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)\nOK\n127.0.0.1:6379> ttl key # 查看数据还有多久过期\n(integer) 56\n```\n\n注意：**Redis 中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间。 **\n\n**过期时间除了有助于缓解内存的消耗，还有什么其他用么？**\n\n很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效。\n\n如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。\n\n### Redis 是如何判断数据是否过期的呢？\n\nRedis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。\n\n![redis过期字典](redis-all.assets/redis过期时间.png)\n\n过期字典是存储在 redisDb 这个结构里的：\n\n```c\ntypedef struct redisDb {\n    ...\n\n    dict *dict;     //数据库键空间,保存着数据库中所有键值对\n    dict *expires   // 过期字典,保存着键的过期时间\n    ...\n} redisDb;\n```\n\n### 过期的数据的删除策略了解么？\n\n如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？\n\n常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：\n\n1. **惰性删除** ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。\n2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。\n\n定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 **定期删除+惰性/懒汉式删除** 。\n\n但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了。\n\n怎么解决这个问题呢？答案就是：**Redis 内存淘汰机制。**\n\n### Redis 内存淘汰机制了解么？\n\n> 相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?\n\nRedis 提供 6 种数据淘汰策略：\n\n1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰\n2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰\n3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰\n4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）\n5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰\n6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！\n\n4.0 版本后增加以下两种：\n\n7. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰\n8. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key\n\n### Redis 持久化机制(怎么保证 Redis 挂掉之后再重启数据可以进行恢复)\n\n很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。\n\nRedis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。\n\n**快照（snapshotting）持久化（RDB）**\n\nRedis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。\n\n快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：\n\n```conf\nsave 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n\nsave 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n\nsave 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n```\n\n**AOF（append-only file）持久化**\n\n与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：\n\n```conf\nappendonly yes\n```\n\n开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到内存缓存 `server.aof_buf` 中，然后再根据 `appendfsync` 配置来决定何时将其同步到硬盘中的 AOF 文件。\n\nAOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 `appendonly.aof`。\n\n在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：\n\n```conf\nappendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度\nappendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘\nappendfsync no        #让操作系统决定何时进行同步\n```\n\n为了兼顾数据和写入性能，用户可以考虑 `appendfsync everysec` 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。\n\n**相关 issue** ：[783：Redis 的 AOF 方式](https://github.com/Snailclimb/JavaGuide/issues/783)\n\n**拓展：Redis 4.0 对于持久化机制的优化**\n\nRedis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。\n\n如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。\n\n官方文档地址：https://redis.io/topics/persistence\n\n![](redis-all.assets/image-20210807145107290.png)\n\n**补充内容：AOF 重写**\n\nAOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。\n\nAOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。\n\n在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。\n\n### Redis 事务\n\nRedis 可以通过 **`MULTI`，`EXEC`，`DISCARD` 和 `WATCH`** 等命令来实现事务(transaction)功能。\n\n```bash\n> MULTI\nOK\n> SET USER "Guide哥"\nQUEUED\n> GET USER\nQUEUED\n> EXEC\n1) OK\n2) "Guide哥"\n```\n\n使用 [`MULTI`](https://redis.io/commands/multi) 命令后可以输入多个命令。Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 [`EXEC`](https://redis.io/commands/exec) 命令将执行所有命令。\n\n这个过程是这样的：\n\n1. 开始事务（`MULTI`）。\n2. 命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)。\n3. 执行事务(`EXEC`)。\n\n你也可以通过 [`DISCARD`](https://redis.io/commands/discard) 命令取消一个事务，它会清空事务队列中保存的所有命令。\n\n```bash\n> MULTI\nOK\n> SET USER "Guide哥"\nQUEUED\n> GET USER\nQUEUED\n> DISCARD\nOK\n```\n\n[`WATCH`](https://redis.io/commands/watch) 命令用于监听指定的键，当调用 `EXEC` 命令执行事务时，如果一个被 `WATCH` 命令监视的键被修改的话，整个事务都不会执行，直接返回失败。\n\n```bash\n> WATCH USER\nOK\n> MULTI\n> SET USER "Guide哥"\nOK\n> GET USER\nGuide哥\n> EXEC\nERR EXEC without MULTI\n```\n\nRedis 官网相关介绍 [https://redis.io/topics/transactions](https://redis.io/topics/transactions) 如下：\n\n![redis事务](redis-all.assets/redis事务.png)\n\n但是，Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性： **1. 原子性**，**2. 隔离性**，**3. 持久性**，**4. 一致性**。\n\n1. **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；\n2. **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；\n3. **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。\n4. **一致性（Consistency）：** 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；\n\n**Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。**\n\nRedis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。\n\n![redis roll back](redis-all.assets/redis-rollBack.png)\n\n你可以将 Redis 中的事务就理解为 ：**Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。**\n\n**相关 issue** :\n\n- [issue452: 关于 Redis 事务不满足原子性的问题](https://github.com/Snailclimb/JavaGuide/issues/452) 。\n- [Issue491:关于 redis 没有事务回滚？](https://github.com/Snailclimb/JavaGuide/issues/491)\n\n### 缓存穿透\n\n#### 什么是缓存穿透？\n\n缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。\n\n#### 缓存穿透情况的处理流程是怎样的？\n\n如下图所示，用户的请求最终都要跑到数据库中查询一遍。\n\n![缓存穿透情况](redis-all.assets/缓存穿透情况.png)\n\n#### 有哪些解决办法？\n\n最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。\n\n**1）缓存无效 key**\n\n如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n\n另外，这里多说一嘴，一般情况下我们是这样设计 key 的： `表名:列名:主键名:主键值` 。\n\n如果用 Java 代码展示的话，差不多是下面这样的：\n\n```java\npublic Object getObjectInclNullById(Integer id) {\n    // 从缓存中获取数据\n    Object cacheValue = cache.get(id);\n    // 缓存为空\n    if (cacheValue == null) {\n        // 从数据库中获取\n        Object storageValue = storage.get(key);\n        // 缓存空对象\n        cache.set(key, storageValue);\n        // 如果存储数据为空，需要设置一个过期时间(300秒)\n        if (storageValue == null) {\n            // 必须设置过期时间，否则有被攻击的风险\n            cache.expire(key, 60 * 5);\n        }\n        return storageValue;\n    }\n    return cacheValue;\n}\n```\n\n**2）布隆过滤器**\n\n布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。\n\n具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。\n\n加入布隆过滤器之后的缓存处理流程图如下。\n\n![image](redis-all.assets/加入布隆过滤器后的缓存处理流程.png)\n\n但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： **布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**\n\n_为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！_\n\n我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**\n\n1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。\n2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。\n\n我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**\n\n1. 对给定元素再次进行相同的哈希计算；\n2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。\n\n然后，一定会出现这样一种情况：**不同的字符串可能哈希出来的位置相同。** （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）\n\n更多关于布隆过滤器的内容可以看我的这篇原创：[《不了解布隆过滤器？一文给你整的明明白白！》](https://github.com/Snailclimb/JavaGuide/blob/master/docs/cs-basics/data-structure/bloom-filter.md) ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。\n\n### 缓存雪崩\n\n#### 什么是缓存雪崩？\n\n我发现缓存雪崩这名字起的有点意思，哈哈。\n\n实际上，缓存雪崩描述的就是这样一个简单的场景：**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。\n\n举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。\n\n还有一种缓存雪崩的场景是：**有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。** 这样的情况，有下面几种解决办法：\n\n举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。\n\n#### 有哪些解决办法？\n\n**针对 Redis 服务不可用的情况：**\n\n1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。\n2. 限流，避免同时处理大量的请求。\n\n**针对热点缓存失效的情况：**\n\n1. 设置不同的失效时间比如随机设置缓存的失效时间。\n2. 缓存永不失效。\n\n### 如何保证缓存和数据库数据的一致性？\n\n细说的话可以扯很多，但是我觉得其实没太大必要（小声 BB：很多解决方案我也没太弄明白）。我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。\n\n下面单独对 **Cache Aside Pattern（旁路缓存模式）** 来聊聊。\n\nCache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。\n\n如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：\n\n1. **缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。\n2. **增加 cache 更新重试机制（常用）**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。\n\n### 参考\n\n- 《Redis 开发与运维》\n- 《Redis 设计与实现》\n- Redis 命令总结：http://Redisdoc.com/string/set.html\n- 通俗易懂的 Redis 数据结构基础教程：[https://juejin.im/post/5b53ee7e5188251aaa2d2e16](https://juejin.im/post/5b53ee7e5188251aaa2d2e16)\n- WHY Redis choose single thread (vs multi threads): [https://medium.com/@jychen7/sharing-redis-single-thread-vs-multi-threads-5870bd44d153](https://medium.com/@jychen7/sharing-redis-single-thread-vs-multi-threads-5870bd44d153)\n'},ca0c:function(n,r,e){"use strict";e.r(r),r["default"]="\x3c!-- TOC --\x3e\n\n- [一致性非锁定读和锁定读](#一致性非锁定读和锁定读)\n  - [一致性非锁定读](#一致性非锁定读)\n  - [锁定读](#锁定读)\n- [InnoDB 对 MVCC 的实现](#InnoDB对MVCC的实现)\n  - [隐藏字段](#隐藏字段])\n  - [ReadView](#ReadView)\n  - [undo-log](#undo-log)\n  - [数据可见性算法](#数据可见性算法)\n- [RC、RR 隔离级别下 MVCC 的差异](#RC、RR隔离级别下MVCC的差异)\n- [MVCC 解决不可重复读问题](#MVCC解决不可重复读问题)\n  - [在 RC 下 ReadView 生成情况](#在RC下ReadView生成情况)\n  - [在 RR 下 ReadView 生成情况](#在RR下ReadView生成情况)\n- [MVCC+Next-key-Lock 防止幻读](#MVCC➕Next-key-Lock防止幻读)\n\n\x3c!-- /TOC --\x3e\n\n## 一致性非锁定读和锁定读\n\n### 一致性非锁定读\n\n对于 [**一致性非锁定读（Consistent Nonlocking Reads）** ](https://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html)的实现，通常做法是加一个版本号或者时间戳字段，在更新数据的同时版本号 + 1 或者更新时间戳。查询时，将当前可见的版本号与对应记录的版本号进行比对，如果记录的版本小于可见版本，则表示该记录可见\n\n在 `InnoDB` 存储引擎中，[多版本控制 (multi versioning)](https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html) 就是对非锁定读的实现。如果读取的行正在执行 `DELETE` 或 `UPDATE` 操作，这时读取操作不会去等待行上锁的释放。相反地，`InnoDB` 存储引擎会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)\n\n在 `Repeatable Read` 和 `Read Committed` 两个隔离级别下，如果是执行普通的 `select` 语句（不包括 `select ... lock in share mode` ,`select ... for update`）则会使用 `一致性非锁定读（MVCC）`。并且在 `Repeatable Read` 下 `MVCC` 实现了可重复读和防止部分幻读\n\n### 锁定读\n\n如果执行的是下列语句，就是 [**锁定读（Locking Reads）**](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html)\n\n- `select ... lock in share mode`\n- `select ... for update`\n- `insert`、`update`、`delete` 操作\n\n在锁定读下，读取的是数据的最新版本，这种读也被称为 `当前读（current read）`。锁定读会对读取到的记录加锁：\n\n- `select ... lock in share mode`：对记录加 `S` 锁，其它事务也可以加`S`锁，如果加 `x` 锁则会被阻塞\n\n- `select ... for update`、`insert`、`update`、`delete`：对记录加 `X` 锁，且其它事务不能加任何锁\n\n在一致性非锁定读下，即使读取的记录已被其它事务加上 `X` 锁，这时记录也是可以被读取的，即读取的快照数据。上面说了，在 `Repeatable Read` 下 `MVCC` 防止了部分幻读，这边的 “部分” 是指在 `一致性非锁定读` 情况下，只能读取到第一次查询之前所插入的数据（根据 Read View 判断数据可见性，Read View 在第一次查询时生成）。但是！如果是 `当前读` ，每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。所以， **`InnoDB` 在实现`Repeatable Read` 时，如果执行的是当前读，则会对读取的记录使用 `Next-key Lock` ，来防止其它事务在间隙间插入数据**\n\n## InnoDB 对 MVCC 的实现\n\n`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改\n\n### 隐藏字段\n\n在内部，`InnoDB` 存储引擎为每行数据添加了三个 [隐藏字段](https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html)：\n\n- `DB_TRX_ID（6字节）`：表示最后一次插入或更新该行的事务 id。此外，`delete` 操作在内部被视为更新，只不过会在记录头 `Record header` 中的 `deleted_flag` 字段将其标记为已删除\n- `DB_ROLL_PTR（7字节）` 回滚指针，指向该行的 `undo log` 。如果该行未被更新，则为空\n- `DB_ROW_ID（6字节）`：如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该 id 来生成聚簇索引\n\n### ReadView\n\n```c\nclass ReadView {\n  /* ... */\nprivate:\n  trx_id_t m_low_limit_id;      /* 大于等于这个 ID 的事务均不可见 */\n\n  trx_id_t m_up_limit_id;       /* 小于这个 ID 的事务均可见 */\n\n  trx_id_t m_creator_trx_id;    /* 创建该 Read View 的事务ID */\n\n  trx_id_t m_low_limit_no;      /* 事务 Number, 小于该 Number 的 Undo Logs 均可以被 Purge */\n\n  ids_t m_ids;                  /* 创建 Read View 时的活跃事务列表 */\n\n  m_closed;                     /* 标记 Read View 是否 close */\n}\n```\n\n[`Read View`](https://github.com/facebook/mysql-8.0/blob/8.0/storage/innobase/include/read0types.h#L298) 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”\n\n主要有以下字段：\n\n- `m_low_limit_id`：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见\n- `m_up_limit_id`：活跃事务列表 `m_ids` 中最小的事务 ID，如果 `m_ids` 为空，则 `m_up_limit_id` 为 `m_low_limit_id`。小于这个 ID 的数据版本均可见\n- `m_ids`：`Read View` 创建时其他未提交的活跃事务 ID 列表。创建 `Read View`时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。`m_ids` 不包括当前事务自己和已提交的事务（正在内存中）\n- `m_creator_trx_id`：创建该 `Read View` 的事务 ID\n\n**事务可见性示意图**（[图源](https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/#MVCC-1)）：\n\n![trans_visible](InnoDB对MVCC的实现.assets/trans_visible.jpg)\n\n### undo-log\n\n`undo log` 主要有两个作用：\n\n- 当事务回滚时用于将数据恢复到修改前的样子\n- 另一个作用是 `MVCC` ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 `undo log` 读取之前的版本数据，以此实现非锁定读\n\n**在 `InnoDB` 存储引擎中 `undo log` 分为两种： `insert undo log` 和 `update undo log`：**\n\n1. **`insert undo log`** ：指在 `insert` 操作中产生的 `undo log`。因为 `insert` 操作的记录只对事务本身可见，对其他事务不可见，故该 `undo log` 可以在事务提交后直接删除。不需要进行 `purge` 操作\n\n**`insert` 时的数据初始状态：**\n\n![](InnoDB对MVCC的实现.assets/317e91e1-1ee1-42ad-9412-9098d5c6a9ad.png)\n\n2. **`update undo log`** ：`update` 或 `delete` 操作中产生的 `undo log`。该 `undo log`可能需要提供 `MVCC` 机制，因此不能在事务提交时就进行删除。提交时放入 `undo log` 链表，等待 `purge线程` 进行最后的删除\n\n**数据第一次被修改时：**\n\n![](InnoDB对MVCC的实现.assets/c52ff79f-10e6-46cb-b5d4-3c9cbcc1934a.png)\n\n**数据第二次被修改时：**\n\n![](InnoDB对MVCC的实现.assets/6a276e7a-b0da-4c7b-bdf7-c0c7b7b3b31c.png)\n\n不同事务或者相同事务的对同一记录行的修改，会使该记录行的 `undo log` 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。\n\n### 数据可见性算法\n\n在 `InnoDB` 存储引擎中，创建一个新事务后，执行每个 `select` 语句前，都会创建一个快照（Read View），**快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号**。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）。当用户在这个事务中要读取某个记录行的时候，`InnoDB` 会将该记录行的 `DB_TRX_ID` 与 `Read View` 中的一些变量及当前事务 ID 进行比较，判断是否满足可见性条件\n\n[具体的比较算法](https://github.com/facebook/mysql-8.0/blob/8.0/storage/innobase/include/read0types.h#L161)如下：[图源](https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/#MVCC-1)\n\n![](InnoDB对MVCC的实现.assets/8778836b-34a8-480b-b8c7-654fe207a8c2.png)\n\n1. 如果记录 DB_TRX_ID < m_up_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之前就提交了，所以该记录行的值对当前事务是可见的\n\n2. 如果 DB_TRX_ID >= m_low_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤 5\n\n3. m_ids 为空，则表明在当前事务创建快照之前，修改该行的事务就已经提交了，所以该记录行的值对当前事务是可见的\n\n4. 如果 m_up_limit_id <= DB_TRX_ID < m_low_limit_id，表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表 m_ids 进行查找（源码中是用的二分查找，因为是有序的）\n\n   - 如果在活跃事务列表 m_ids 中能找到 DB_TRX_ID，表明：① 在当前事务创建快照前，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了，但没有提交；或者 ② 在当前事务创建快照后，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了。这些情况下，这个记录行的值对当前事务都是不可见的。跳到步骤 5\n\n   - 在活跃事务列表中找不到，则表明“id 为 trx_id 的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见\n\n5. 在该记录行的 DB_ROLL_PTR 指针所指向的 `undo log` 取出快照记录，用快照记录的 DB_TRX_ID 跳到步骤 1 重新开始判断，直到找到满足的快照版本或返回空\n\n## RC 和 RR 隔离级别下 MVCC 的差异\n\n在事务隔离级别 `RC` 和 `RR` （InnoDB 存储引擎的默认事务隔离级别）下，`InnoDB` 存储引擎使用 `MVCC`（非锁定一致性读），但它们生成 `Read View` 的时机却不同\n\n- 在 RC 隔离级别下的 **`每次select`** 查询前都生成一个`Read View` (m_ids 列表)\n- 在 RR 隔离级别下只在事务开始后 **`第一次select`** 数据前生成一个`Read View`（m_ids 列表）\n\n## MVCC 解决不可重复读问题\n\n虽然 RC 和 RR 都通过 `MVCC` 来读取快照数据，但由于 **生成 Read View 时机不同**，从而在 RR 级别下实现可重复读\n\n举个例子：\n\n![](InnoDB对MVCC的实现.assets/6fb2b9a1-5f14-4dec-a797-e4cf388ed413.png)\n\n### 在 RC 下 ReadView 生成情况\n\n1. **`假设时间线来到 T4 ，那么此时数据行 id = 1 的版本链为`：**\n\n   ![](InnoDB对MVCC的实现.assets/a3fd1ec6-8f37-42fa-b090-7446d488fd04.png)\n\n由于 RC 级别下每次查询都会生成`Read View` ，并且事务 101、102 并未提交，此时 `103` 事务生成的 `Read View` 中活跃的事务 **`m_ids` 为：[101,102]** ，`m_low_limit_id`为：104，`m_up_limit_id`为：101，`m_creator_trx_id` 为：103\n\n- 此时最新记录的 `DB_TRX_ID` 为 101，m_up_limit_id <= 101 < m_low_limit_id，所以要在 `m_ids` 列表中查找，发现 `DB_TRX_ID` 存在列表中，那么这个记录不可见\n- 根据 `DB_ROLL_PTR` 找到 `undo log` 中的上一版本记录，上一条记录的 `DB_TRX_ID` 还是 101，不可见\n- 继续找上一条 `DB_TRX_ID`为 1，满足 1 < m_up_limit_id，可见，所以事务 103 查询到数据为 `name = 菜花`\n\n2. **`时间线来到 T6 ，数据的版本链为`：**\n\n   ![markdown](InnoDB对MVCC的实现.assets/528559e9-dae8-4d14-b78d-a5b657c88391.png)\n\n因为在 RC 级别下，重新生成 `Read View`，这时事务 101 已经提交，102 并未提交，所以此时 `Read View` 中活跃的事务 **`m_ids`：[102]** ，`m_low_limit_id`为：104，`m_up_limit_id`为：102，`m_creator_trx_id`为：103\n\n- 此时最新记录的 `DB_TRX_ID` 为 102，m_up_limit_id <= 102 < m_low_limit_id，所以要在 `m_ids` 列表中查找，发现 `DB_TRX_ID` 存在列表中，那么这个记录不可见\n\n- 根据 `DB_ROLL_PTR` 找到 `undo log` 中的上一版本记录，上一条记录的 `DB_TRX_ID` 为 101，满足 101 < m_up_limit_id，记录可见，所以在 `T6` 时间点查询到数据为 `name = 李四`，与时间 T4 查询到的结果不一致，不可重复读！\n\n3. **`时间线来到 T9 ，数据的版本链为`：**\n\n![markdown](InnoDB对MVCC的实现.assets/6f82703c-36a1-4458-90fe-d7f4edbac71a.png)\n\n重新生成 `Read View`， 这时事务 101 和 102 都已经提交，所以 **m_ids** 为空，则 m_up_limit_id = m_low_limit_id = 104，最新版本事务 ID 为 102，满足 102 < m_low_limit_id，可见，查询结果为 `name = 赵六`\n\n> **总结：** **在 RC 隔离级别下，事务在每次查询开始时都会生成并设置新的 Read View，所以导致不可重复读**\n\n### 在 RR 下 ReadView 生成情况\n\n**在可重复读级别下，只会在事务开始后第一次读取数据时生成一个 Read View（m_ids 列表）**\n\n1. **`在 T4 情况下的版本链为`：**\n\n![markdown](InnoDB对MVCC的实现.assets/0e906b95-c916-4f30-beda-9cb3e49746bf.png)\n\n在当前执行 `select` 语句时生成一个 `Read View`，此时 **`m_ids`：[101,102]** ，`m_low_limit_id`为：104，`m_up_limit_id`为：101，`m_creator_trx_id` 为：103\n\n此时和 RC 级别下一样：\n\n- 最新记录的 `DB_TRX_ID` 为 101，m_up_limit_id <= 101 < m_low_limit_id，所以要在 `m_ids` 列表中查找，发现 `DB_TRX_ID` 存在列表中，那么这个记录不可见\n- 根据 `DB_ROLL_PTR` 找到 `undo log` 中的上一版本记录，上一条记录的 `DB_TRX_ID` 还是 101，不可见\n- 继续找上一条 `DB_TRX_ID`为 1，满足 1 < m_up_limit_id，可见，所以事务 103 查询到数据为 `name = 菜花`\n\n2. **`时间点 T6 情况下`：**\n\n   ![markdown](InnoDB对MVCC的实现.assets/79ed6142-7664-4e0b-9023-cf546586aa39.png)\n\n   在 RR 级别下只会生成一次`Read View`，所以此时依然沿用 **`m_ids` ：[101,102]** ，`m_low_limit_id`为：104，`m_up_limit_id`为：101，`m_creator_trx_id` 为：103\n\n- 最新记录的 `DB_TRX_ID` 为 102，m_up_limit_id <= 102 < m_low_limit_id，所以要在 `m_ids` 列表中查找，发现 `DB_TRX_ID` 存在列表中，那么这个记录不可见\n\n- 根据 `DB_ROLL_PTR` 找到 `undo log` 中的上一版本记录，上一条记录的 `DB_TRX_ID` 为 101，不可见\n\n- 继续根据 `DB_ROLL_PTR` 找到 `undo log` 中的上一版本记录，上一条记录的 `DB_TRX_ID` 还是 101，不可见\n\n- 继续找上一条 `DB_TRX_ID`为 1，满足 1 < m_up_limit_id，可见，所以事务 103 查询到数据为 `name = 菜花`\n\n3. **时间点 T9 情况下：**\n\n![markdown](InnoDB对MVCC的实现.assets/cbbedbc5-0e3c-4711-aafd-7f3d68a4ed4e.png)\n\n此时情况跟 T6 完全一样，由于已经生成了 `Read View`，此时依然沿用 **`m_ids` ：[101,102]** ，所以查询结果依然是 `name = 菜花`\n\n## MVCC➕Next-key-Lock 防止幻读\n\n`InnoDB`存储引擎在 RR 级别下通过 `MVCC`和 `Next-key Lock` 来解决幻读问题：\n\n**1、执行普通 `select`，此时会以 `MVCC` 快照读的方式读取数据**\n\n在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 `Read View` ，并使用至事务提交。所以在生成 `Read View` 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”\n\n**2、执行 select...for update/lock in share mode、insert、update、delete 等当前读**\n\n在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！`InnoDB` 使用 [Next-key Lock](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-next-key-locks) 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读\n\n## 参考\n\n- **《MySQL 技术内幕 InnoDB 存储引擎第 2 版》**\n- [Innodb 中的事务隔离级别和锁的关系](https://tech.meituan.com/2014/08/20/innodb-lock.html)\n- [MySQL 事务与 MVCC 如何实现的隔离级别](https://blog.csdn.net/qq_35190492/article/details/109044141)\n- [InnoDB 事务分析-MVCC](https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/)\n"},cbc6:function(n,r,e){"use strict";e.r(r),r["default"]="MySQL 字符编码集中有两套 UTF-8 编码实现：**`utf8`** 和 **`utf8mb4`**。\n\n如果使用 **`utf8`**  的话，存储emoji 符号和一些比较复杂的汉字、繁体字就会出错。\n\n为什么会这样呢？这篇文章可以从源头给你解答。\n\n## 何为字符集？\n\n字符是各种文字和符号的统称，包括各个国家文字、标点符号、表情、数字等等。 **字符集** 就是一系列字符的集合。字符集的种类较多，每个字符集可以表示的字符范围通常不同，就比如说有些字符集是无法表示汉字的。\n\n**计算机只能存储二进制的数据，那英文、汉字、表情等字符应该如何存储呢？**\n\n我们要将这些字符和二级制的数据一一对应起来，比如说字符“a”对应“01100001”，反之，“01100001”对应 “a”。我们将字符对应二进制数据的过程称为\"**字符编码**\"，反之，二进制数据解析成字符的过程称为“**字符解码**”。\n\n## 有哪些常见的字符集？\n\n常见的字符集有 ASCII、GB2312、GBK、UTF-8......。\n\n不同的字符集的主要区别在于：\n\n- 可以表示的字符范围\n- 编码方式\n\n### ASCII\n\n**ASCII** (**A**merican **S**tandard **C**ode for **I**nformation **I**nterchange，美国信息交换标准代码) 是一套主要用于现代美国英语的字符集（这也是 ASCII 字符集的局限性所在）。\n\n**为什么 ASCII 字符集没有考虑到中文等其他字符呢？** 因为计算机是美国人发明的，当时，计算机的发展还处于比较雏形的时代，还未在其他国家大规模使用。因此，美国发布 ASCII 字符集的时候没有考虑兼容其他国家的语言。\n\nASCII 字符集至今为止共定义了 128 个字符，其中有 33 个控制字符（比如回车、删除）无法显示。\n\n一个 ASCII 码长度是一个字节也就是 8 个 bit，比如“a”对应的 ASCII 码是“01100001”。不过，最高位是 0 仅仅作为校验位，其余 7 位使用 0 和 1 进行组合，所以，ASCII 字符集可以定义 128（2^7）个字符。\n\n由于，ASCII 码可以表示的字符实在是太少了。后来，人们对其进行了扩展得到了 **ASCII 扩展字符集** 。ASCII 扩展字符集使用 8 位（bits）表示一个字符，所以，ASCII 扩展字符集可以定义 256（2^8）个字符。\n\n![ASCII字符编码](字符集.assets/c1c6375d08ca268690cef2b13591a5b4.png)\n\n### GB2312\n\n我们上面说了，ASCII 字符集是一种现代美国英语适用的字符集。因此，很多国家都捣鼓了一个适合自己国家语言的字符集。\n\nGB2312 字符集是一种对汉字比较友好的字符集，共收录 6700 多个汉字，基本涵盖了绝大部分常用汉字。不过，GB2312 字符集不支持绝大部分的生僻字和繁体字。\n\n对于英语字符，GB2312 编码和 ASCII 码是相同的，1 字节编码即可。对于非英字符，需要 2 字节编码。\n\n### GBK\n\nGBK 字符集可以看作是 GB2312 字符集的扩展，兼容 GB2312 字符集，共收录了 20000 多个汉字。\n\nGBK 中 K 是汉语拼音 Kuo Zhan（扩展）中的“Kuo”的首字母。\n\n### GB18030\n\nGB18030 完全兼容 GB2312 和 GBK 字符集，纳入中国国内少数民族的文字，且收录了日韩汉字，是目前为止最全面的汉字字符集，共收录汉字 70000 多个。\n\n### BIG5\n\nBIG5 主要针对的是繁体中文，收录了 13000 多个汉字。\n\n### Unicode & UTF-8编码\n\n为了更加适合本国语言，诞生了很多种字符集。\n\n我们上面也说了不同的字符集可以表示的字符范围以及编码规则存在差异。这就导致了一个非常严重的问题：**使用错误的编码方式查看一个包含字符的文件就会产生乱码现象。**\n\n就比如说你使用 UTF-8 编码方式打开 GB2312 编码格式的文件就会出现乱码。示例：“牛”这个汉字 GB2312 编码后的十六进制数值为 “C5A3”，而 “C5A3” 用 UTF-8 解码之后得到的却是 “ţ”。\n\n你可以通过这个网站在线进行编码和解码：https://www.haomeili.net/HanZi/ZiFuBianMaZhuanHuan\n\n![](字符集.assets/836c49b117ee4408871b0020b74c991d.png)\n\n这样我们就搞懂了乱码的本质： **编码和解码时用了不同或者不兼容的字符集** 。\n\n![](字符集.assets/a8808cbabeea49caa3af27d314fa3c02-1.jpg)\n\n为了解决这个问题，人们就想：“如果我们能够有一种字符集将世界上所有的字符都纳入其中就好了！”。\n\n然后，**Unicode** 带着这个使命诞生了。\n\nUnicode 字符集中包含了世界上几乎所有已知的字符。不过，Unicode 字符集并没有规定如何存储这些字符（也就是如何使用二进制数据表示这些字符）。\n\n然后，就有了 **UTF-8**（**8**-bit **U**nicode **T**ransformation **F**ormat）。类似的还有 UTF-16、 UTF-32。\n\nUTF-8 使用 1 到 4 个字节为每个字符编码， UTF-16 使用 2 或 4 个字节为每个字符编码，UTF-32 固定位 4 个字节为每个字符编码。\n\nUTF-8 可以根据不同的符号自动选择编码的长短，像英文字符只需要 1 个字节就够了，这一点 ASCII 字符集一样 。因此，对于英语字符，UTF-8 编码和 ASCII 码是相同的。\n\nUTF-32 的规则最简单，不过缺陷也比较明显，对于英文字母这类字符消耗的空间是 UTF-8 的 4 倍之多。\n\n**UTF-8** 是目前使用最广的一种字符编码，。\n\n![](字符集.assets/1280px-Utf8webgrowth.svg.png)\n\n## MySQL 字符集\n\nMySQL 支持很多种字符编码的方式，比如 UTF-8、GB2312、GBK、BIG5。\n\n你可以通过 `SHOW CHARSET` 命令来查看。\n\n![](字符集.assets/image-20211008164229671.png)\n\n通常情况下，我们建议使用 UTF-8 作为默认的字符编码方式。\n\n不过，这里有一个小坑。\n\nMySQL 字符编码集中有两套 UTF-8 编码实现：\n\n- **`utf8`** ： `utf8`编码只支持`1-3`个字节 。 在 `utf8` 编码中，中文是占 3 个字节，其他数字、英文、符号占一个字节。但 emoji 符号占 4 个字节，一些较复杂的文字、繁体字也是 4 个字节。\n- **`utf8mb4`** ： UTF-8 的完整实现，正版！最多支持使用 4 个字节表示字符，因此，可以用来存储 emoji 符号。\n\n**为什么有两套 UTF-8 编码实现呢？** 原因如下：\n\n![](字符集.assets/image-20211008164542347.png)\n\n因此，如果你需要存储`emoji`类型的数据或者一些比较复杂的文字、繁体字到 MySQL 数据库的话，数据库的编码一定要指定为`utf8mb4` 而不是`utf8` ，要不然存储的时候就会报错了。\n\n演示一下吧！（环境：MySQL 5.7+）\n\n建表语句如下，我们指定数据库 CHARSET 为 `utf8` 。\n\n```sql\nCREATE TABLE `user` (\n  `id` varchar(66) CHARACTER SET utf8mb4 NOT NULL,\n  `name` varchar(33) CHARACTER SET utf8mb4 NOT NULL,\n  `phone` varchar(33) CHARACTER SET utf8mb4 DEFAULT NULL,\n  `password` varchar(100) CHARACTER SET utf8mb4 DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n\n当我们执行下面的 insert 语句插入数据到数据库时，果然报错！\n\n```sql\nINSERT INTO `user` (`id`, `name`, `phone`, `password`)\nVALUES\n\t('A00003', 'guide哥😘😘😘', '181631312312', '123456');\n\n```\n\n报错信息如下：\n\n```\nIncorrect string value: '\\xF0\\x9F\\x98\\x98\\xF0\\x9F...' for column 'name' at row 1\n```\n\n## 参考\n\n- 字符集和字符编码（Charset & Encoding）： https://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html\n- 十分钟搞清字符集和字符编码：http://cenalulu.github.io/linux/character-encoding/\n- Unicode-维基百科：https://zh.wikipedia.org/wiki/Unicode\n- GB2312-维基百科：https://zh.wikipedia.org/wiki/GB_2312\n- UTF-8-维基百科：https://zh.wikipedia.org/wiki/UTF-8\n- GB18030-维基百科: https://zh.wikipedia.org/wiki/GB_18030"},cf89:function(n,r,e){"use strict";e.r(r),r["default"]="- 公众号和Github待发文章：[数据库：数据库连接池原理详解与自定义连接池实现](https://www.fangzhipeng.com/javainterview/2019/07/15/mysql-connector-pool.html)\n- [基于JDBC的数据库连接池技术研究与应用](http://blog.itpub.net/9403012/viewspace-111794/)\n- [数据库连接池技术详解](https://juejin.im/post/5b7944c6e51d4538c86cf195)\n\n数据库连接本质就是一个 socket 的连接。数据库服务端还要维护一些缓存和用户权限信息之类的 所以占用了一些内存\n\n连接池是维护的数据库连接的缓存，以便将来需要对数据库的请求时可以重用这些连接。为每个用户打开和维护数据库连接，尤其是对动态数据库驱动的网站应用程序的请求，既昂贵又浪费资源。**在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中。**连接池还减少了用户必须等待建立与数据库的连接的时间。\n\n操作过数据库的朋友应该都知道数据库连接池这个概念，它几乎每天都在和我们打交道，但是你真的了解 **数据库连接池** 吗？\n\n### 没有数据库连接池之前\n\n我相信你一定听过这样一句话：**Java语言中，JDBC（Java DataBase Connection）是应用程序与数据库沟通的桥梁**。\n\n\n\n\n\n\n\n\n"},d3ba:function(n,r,e){"use strict";e.r(r),r["default"]="\n\n## Mysql索引主要使用的两种数据结构\n\n### 哈希索引\n\n对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。\n\n### BTree索引 \n\n\n\n## 覆盖索引介绍\n\n### 什么是覆盖索引\n\n如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道InnoDB存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！\n\n### 覆盖索引使用实例 \n\n现在我创建了索引(username,age)，我们执行下面的 sql 语句\n\n```sql\nselect username , age from user where username = 'Java' and age = 22\n```\n\n在查询数据的时候：要查询出的列在叶子节点都存在！所以，就不用回表。\n\n## 选择索引和编写利用这些索引的查询的3个原则\n\n1. 单行访问是很慢的。特别是在机械硬盘存储中（SSD的随机I/O要快很多，不过这一点仍然成立）。如果服务器从存储中读取一个数据块只是为了获取其中一行，那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引，用以提升效率。\n2. 按顺序访问范围数据是很快的，这有两个原因。第一，顺序 I/O 不需要多次磁盘寻道，所以比随机I/O要快很多（特别是对机械硬盘）。第二，如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且GROUPBY查询也无须再做排序和将行按组进行聚合计算了。\n3. 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么存储引擎就不需要再回表查找行。这避免了大量的单行访问，而上面的第1点已经写明单行访问是很慢的。\n\n## 为什么索引能提高查询速度\n\n> 以下内容整理自：\n> 地址： https://juejin.im/post/5b55b842f265da0f9e589e79\n> 作者 ：Java3y\n\n### 先从 MySQL 的基本存储结构说起\n\nMySQL的基本存储结构是页(记录都存在页里边)：\n\n![MySQL的基本存储结构是页](MySQL Index.assets/28559421.jpg)\n\n![](MySQL Index.assets/82053134.jpg)\n\n - **各个数据页可以组成一个双向链表**\n - **每个数据页中的记录又可以组成一个单向链表**\n     - 每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录\n     - 以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。\n\n所以说，如果我们写select * from user where indexname = 'xxx'这样没有进行任何优化的sql语句，默认会这样做：\n\n1. **定位到记录所在的页：需要遍历双向链表，找到所在的页**\n2. **从所在的页内中查找相应的记录：由于不是根据主键查询，只能遍历所在页的单链表了**\n\n很明显，在数据量很大的情况下这样查找会很慢！这样的时间复杂度为O(n)。\n\n\n### 使用索引之后 \n\n索引做了些什么可以让我们查询加快速度呢？其实就是将无序的数据变成有序(相对)：\n\n![](MySQL Index.assets/5373082.jpg)\n\n要找到id为8的记录简要 步骤：\n\n![](MySQL Index.assets/89338047.jpg)\n\n很明显的是：没有用索引我们是需要遍历双向链表来定位对应的页，现在通过 **“目录”** 就可以很快地定位到对应的页上了！（二分查找，时间复杂度近似为O(logn)）\n\n其实底层结构就是B+树，B+树作为树的一种实现，能够让我们很快地查找出对应的记录。\n\n## 关于索引其他重要的内容补充\n\n> 以下内容整理自：《Java工程师修炼之道》\n\n\n### 最左前缀原则\n\nMySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引。如User表的name和city加联合索引就是(name,city)，而最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到。如下：        \n\n```                                                                                       \nselect * from user where name=xx and city=xx ; ／／可以命中索引\nselect * from user where name=xx ; // 可以命中索引\nselect * from user where city=xx ; // 无法命中索引            \n```\n\n这里需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 `city= xx and name ＝xx`，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。\n\n由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。\n\n### 注意避免冗余索引\n\n冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city）和（name）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者。在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。\n\nMySQL 5.7 版本后，可以通过查询 sys 库的 `schema_redundant_indexes` 表来查看冗余索引。\n\n"},de66:function(n,r,e){"use strict";e.r(r),r["default"]="看到很多小伙伴简历上写了“**熟练使用缓存**”，但是被我问到“**缓存常用的3种读写策略**”的时候却一脸懵逼。\n\n在我看来，造成这个问题的原因是我们在学习 Redis 的时候，可能只是简单了写一些 Demo，并没有去关注缓存的读写策略，或者说压根不知道这回事。\n\n但是，搞懂3种常见的缓存读写策略对于实际工作中使用缓存以及面试中被问到缓存都是非常有帮助的！\n\n下面我会简单介绍一下自己对于这 3 种缓存读写策略的理解。 \n\n另外，**这3 种缓存读写策略各有优劣，不存在最佳，需要我们根据具体的业务场景选择更适合的。**\n\n*个人能力有限。如果文章有任何需要补充/完善/修改的地方，欢迎在评论区指出，共同进步！——爱你们的 Guide 哥*\n\n### Cache Aside Pattern（旁路缓存模式）\n\n**Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**\n\nCache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是以 DB 的结果为准。\n\n下面我们来看一下这个策略模式下的缓存读写步骤。\n\n**写** ：\n\n- 先更新 DB\n- 然后直接删除 cache 。\n\n简单画了一张图帮助大家理解写的步骤。\n\n![](3种常用的缓存读写策略.assets/5687fe759a1dac9ed9554d27e3a23b6d.png)\n\n**读** :\n\n- 从 cache 中读取数据，读取到就直接返回\n- cache中读取不到的话，就从 DB 中读取数据返回\n- 再把数据放到 cache 中。\n\n简单画了一张图帮助大家理解读的步骤。\n\n![](3种常用的缓存读写策略.assets/a8c18b5f5b1aed03234bcbbd8c173a87.png)\n\n\n你仅仅了解了上面这些内容的话是远远不够的，我们还要搞懂其中的原理。\n\n比如说面试官很可能会追问：“**在写数据的过程中，可以先删除 cache ，后更新 DB 么？**”\n\n**答案：** 那肯定是不行的！因为这样可能会造成**数据库（DB）和缓存（Cache）数据不一致**的问题。为什么呢？比如说请求1 先写数据A，请求2随后读数据A的话就很有可能产生数据不一致性的问题。这个过程可以简单描述为：\n\n> 请求1先把cache中的A数据删除 -> 请求2从DB中读取数据->请求1再把DB中的A数据更新。\n\n当你这样回答之后，面试官可能会紧接着就追问：“**在写数据的过程中，先更新DB，后删除cache就没有问题了么？**”\n\n**答案：** 理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多！\n\n比如请求1先读数据 A，请求2随后写数据A，并且数据A不在缓存中的话也有可能产生数据不一致性的问题。这个过程可以简单描述为：\n\n> 请求1从DB读数据A->请求2写更新数据 A 到数据库并把删除cache中的A数据->请求1将数据A写入cache。\n\n现在我们再来分析一下 **Cache Aside Pattern 的缺陷**。\n\n**缺陷1：首次请求数据一定不在 cache 的问题** \n\n解决办法：可以将热点数据可以提前放入cache 中。\n\n**缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。**\n\n解决办法：\n\n- 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。\n- 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。\n\n### Read/Write Through Pattern（读写穿透）\n\nRead/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。\n\n这种缓存读写策略小伙伴们应该也发现了在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入DB的功能。\n\n**写（Write Through）：**\n\n- 先查 cache，cache 中不存在，直接更新 DB。\n- cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）。\n\n简单画了一张图帮助大家理解写的步骤。\n\n![](3种常用的缓存读写策略.assets/20210201100340808.png)\n\n**读(Read Through)：** \n\n- 从 cache 中读取数据，读取到就直接返回 。\n- 读取不到的话，先从 DB 加载，写入到 cache 后返回响应。\n\n简单画了一张图帮助大家理解读的步骤。\n\n![](3种常用的缓存读写策略.assets/9ada757c78614934aca11306f334638d.png)\n\nRead-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。\n\n和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。\n\n### Write Behind Pattern（异步缓存写入）\n\nWrite Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。\n\n但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。**\n\n很明显，这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没异步更新DB的话，cache服务可能就就挂掉了。\n\n这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 InnoDB Buffer Pool 机制都用到了这种策略。\n\nWrite Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。\n"},e371:function(n,r,e){"use strict";e.r(r),r["default"]="> 原文地址：https://shockerli.net/post/1000-line-mysql-note/ ，JavaGuide 对本文进行了简答排版，新增了目录。\n> 作者：格物\n\n非常不错的总结，强烈建议保存下来，需要的时候看一看。\n\n\x3c!-- TOC --\x3e\n- [基本操作](#基本操作)\n- [数据库操作](#数据库操作)\n- [表的操作](#表的操作)\n- [数据操作](#数据操作)\n- [字符集编码](#字符集编码)\n- [数据类型(列类型)](#数据类型列类型)\n- [列属性(列约束)](#列属性列约束)\n- [建表规范](#建表规范)\n- [SELECT](#select)\n- [UNION](#union)\n- [子查询](#子查询)\n- [连接查询(join)](#连接查询join)\n- [TRUNCATE](#truncate)\n- [备份与还原](#备份与还原)\n- [视图](#视图)\n- [事务(transaction)](#事务transaction)\n- [锁表](#锁表)\n- [触发器](#触发器)\n- [SQL编程](#sql编程)\n- [存储过程](#存储过程)\n- [用户和权限管理](#用户和权限管理)\n- [表维护](#表维护)\n- [杂项](#杂项)\n\n\x3c!-- /TOC --\x3e\n\n### 基本操作\n\n```mysql\n/* Windows服务 */\n-- 启动MySQL\n    net start mysql\n-- 创建Windows服务\n    sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格)\n/* 连接与断开服务器 */\nmysql -h 地址 -P 端口 -u 用户名 -p 密码\nSHOW PROCESSLIST -- 显示哪些线程正在运行\nSHOW VARIABLES -- 显示系统变量信息\n```\n\n### 数据库操作\n\n```mysql\n/* 数据库操作 */ ------------------\n-- 查看当前数据库\n    SELECT DATABASE();\n-- 显示当前时间、用户名、数据库版本\n    SELECT now(), user(), version();\n-- 创建库\n    CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项\n    数据库选项：\n        CHARACTER SET charset_name\n        COLLATE collation_name\n-- 查看已有库\n    SHOW DATABASES[ LIKE 'PATTERN']\n-- 查看当前库信息\n    SHOW CREATE DATABASE 数据库名\n-- 修改库的选项信息\n    ALTER DATABASE 库名 选项信息\n-- 删除库\n    DROP DATABASE[ IF EXISTS] 数据库名\n        同时删除该数据库相关的目录及其目录内容\n```\n\n### 表的操作 \n\n```mysql\n-- 创建表\n    CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项]\n        每个字段必须有数据类型\n        最后一个字段后不能有逗号\n        TEMPORARY 临时表，会话结束时表自动消失\n        对于字段的定义：\n            字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string']\n-- 表选项\n    -- 字符集\n        CHARSET = charset_name\n        如果表没有设定，则使用数据库字符集\n    -- 存储引擎\n        ENGINE = engine_name\n        表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同\n        常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive\n        不同的引擎在保存表的结构和数据时采用不同的方式\n        MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引\n        InnoDB表文件含义：.frm表定义，表空间数据和日志文件\n        SHOW ENGINES -- 显示存储引擎的状态信息\n        SHOW ENGINE 引擎名 {LOGS|STATUS} -- 显示存储引擎的日志或状态信息\n    -- 自增起始数\n    \tAUTO_INCREMENT = 行数\n    -- 数据文件目录\n        DATA DIRECTORY = '目录'\n    -- 索引文件目录\n        INDEX DIRECTORY = '目录'\n    -- 表注释\n        COMMENT = 'string'\n    -- 分区选项\n        PARTITION BY ... (详细见手册)\n-- 查看所有表\n    SHOW TABLES[ LIKE 'pattern']\n    SHOW TABLES FROM  库名\n-- 查看表结构\n    SHOW CREATE TABLE 表名 （信息更详细）\n    DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE 'PATTERN']\n    SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern']\n-- 修改表\n    -- 修改表本身的选项\n        ALTER TABLE 表名 表的选项\n        eg: ALTER TABLE 表名 ENGINE=MYISAM;\n    -- 对表进行重命名\n        RENAME TABLE 原表名 TO 新表名\n        RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库）\n        -- RENAME可以交换两个表名\n    -- 修改表的字段机构（13.1.2. ALTER TABLE语法）\n        ALTER TABLE 表名 操作名\n        -- 操作名\n            ADD[ COLUMN] 字段定义       -- 增加字段\n                AFTER 字段名          -- 表示增加在该字段名后面\n                FIRST               -- 表示增加在第一个\n            ADD PRIMARY KEY(字段名)   -- 创建主键\n            ADD UNIQUE [索引名] (字段名)-- 创建唯一索引\n            ADD INDEX [索引名] (字段名) -- 创建普通索引\n            DROP[ COLUMN] 字段名      -- 删除字段\n            MODIFY[ COLUMN] 字段名 字段属性     -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上)\n            CHANGE[ COLUMN] 原字段名 新字段名 字段属性      -- 支持对字段名修改\n            DROP PRIMARY KEY    -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性)\n            DROP INDEX 索引名 -- 删除索引\n            DROP FOREIGN KEY 外键    -- 删除外键\n-- 删除表\n    DROP TABLE[ IF EXISTS] 表名 ...\n-- 清空表数据\n    TRUNCATE [TABLE] 表名\n-- 复制表结构\n    CREATE TABLE 表名 LIKE 要复制的表名\n-- 复制表结构和数据\n    CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名\n-- 检查表是否有错误\n    CHECK TABLE tbl_name [, tbl_name] ... [option] ...\n-- 优化表\n    OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...\n-- 修复表\n    REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM]\n-- 分析表\n    ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...\n```\n\n### 数据操作\n\n```mysql\n/* 数据操作 */ ------------------\n-- 增\n    INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...]\n        -- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。\n        -- 可同时插入多条数据记录！\n        REPLACE 与 INSERT 完全一样，可互换。\n    INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...]\n-- 查\n    SELECT 字段列表 FROM 表名[ 其他子句]\n        -- 可来自多个表的多个字段\n        -- 其他子句可以不使用\n        -- 字段列表可以用*代替，表示所有字段\n-- 删\n    DELETE FROM 表名[ 删除条件子句]\n        没有条件子句，则会删除全部\n-- 改\n    UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件]\n```\n\n### 字符集编码\n\n```mysql\n/* 字符集编码 */ ------------------\n-- MySQL、数据库、表、字段均可设置编码\n-- 数据编码与客户端编码不需一致\nSHOW VARIABLES LIKE 'character_set_%'   -- 查看所有字符集编码项\n    character_set_client        客户端向服务器发送数据时使用的编码\n    character_set_results       服务器端将结果返回给客户端所使用的编码\n    character_set_connection    连接层编码\nSET 变量名 = 变量值\n    SET character_set_client = gbk;\n    SET character_set_results = gbk;\n    SET character_set_connection = gbk;\nSET NAMES GBK;  -- 相当于完成以上三个设置\n-- 校对集\n    校对集用以排序\n    SHOW CHARACTER SET [LIKE 'pattern']/SHOW CHARSET [LIKE 'pattern']   查看所有字符集\n    SHOW COLLATION [LIKE 'pattern']     查看所有校对集\n    CHARSET 字符集编码     设置字符集编码\n    COLLATE 校对集编码     设置校对集编码\n```\n\n### 数据类型(列类型)\n\n```mysql\n/* 数据类型（列类型） */ ------------------\n1. 数值类型\n-- a. 整型 ----------\n    类型         字节     范围（有符号位）\n    tinyint     1字节    -128 ~ 127      无符号位：0 ~ 255\n    smallint    2字节    -32768 ~ 32767\n    mediumint   3字节    -8388608 ~ 8388607\n    int         4字节\n    bigint      8字节\n    int(M)  M表示总位数\n    - 默认存在符号位，unsigned 属性修改\n    - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改\n        例：int(5)   插入一个数'123'，补填后为'00123'\n    - 在满足要求的情况下，越小越好。\n    - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。\n-- b. 浮点型 ----------\n    类型             字节     范围\n    float(单精度)     4字节\n    double(双精度)    8字节\n    浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。\n        不同于整型，前后均会补填0.\n    定义浮点型时，需指定总位数和小数位数。\n        float(M, D)     double(M, D)\n        M表示总位数，D表示小数位数。\n        M和D的大小会决定浮点数的范围。不同于整型的固定范围。\n        M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。\n        支持科学计数法表示。\n        浮点数表示近似值。\n-- c. 定点数 ----------\n    decimal -- 可变长度\n    decimal(M, D)   M也表示总位数，D表示小数位数。\n    保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。\n    将浮点数转换为字符串来保存，每9位数字保存为4个字节。\n2. 字符串类型\n-- a. char, varchar ----------\n    char    定长字符串，速度快，但浪费空间\n    varchar 变长字符串，速度慢，但节省空间\n    M表示能存储的最大长度，此长度是字符数，非字节数。\n    不同的编码，所占用的空间不同。\n    char,最多255个字符，与编码无关。\n    varchar,最多65535字符，与编码有关。\n    一条有效记录最大不能超过65535个字节。\n        utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符\n    varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。\n    varchar 的最大有效长度由最大行大小和使用的字符集确定。\n    最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是65535-1-2=65532字节。\n    例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3\n-- b. blob, text ----------\n    blob 二进制字符串（字节字符串）\n        tinyblob, blob, mediumblob, longblob\n    text 非二进制字符串（字符字符串）\n        tinytext, text, mediumtext, longtext\n    text 在定义时，不需要定义长度，也不会计算总长度。\n    text 类型在定义时，不可给default值\n-- c. binary, varbinary ----------\n    类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。\n    char, varchar, text 对应 binary, varbinary, blob.\n3. 日期时间类型\n    一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。\n    datetime    8字节    日期及时间     1000-01-01 00:00:00 到 9999-12-31 23:59:59\n    date        3字节    日期         1000-01-01 到 9999-12-31\n    timestamp   4字节    时间戳        19700101000000 到 2038-01-19 03:14:07\n    time        3字节    时间         -838:59:59 到 838:59:59\n    year        1字节    年份         1901 - 2155\ndatetime    YYYY-MM-DD hh:mm:ss\ntimestamp   YY-MM-DD hh:mm:ss\n            YYYYMMDDhhmmss\n            YYMMDDhhmmss\n            YYYYMMDDhhmmss\n            YYMMDDhhmmss\ndate        YYYY-MM-DD\n            YY-MM-DD\n            YYYYMMDD\n            YYMMDD\n            YYYYMMDD\n            YYMMDD\ntime        hh:mm:ss\n            hhmmss\n            hhmmss\nyear        YYYY\n            YY\n            YYYY\n            YY\n4. 枚举和集合\n-- 枚举(enum) ----------\nenum(val1, val2, val3...)\n    在已知的值中进行单选。最大数量为65535.\n    枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。\n    表现为字符串类型，存储却是整型。\n    NULL值的索引是NULL。\n    空字符串错误值的索引值是0。\n-- 集合（set） ----------\nset(val1, val2, val3...)\n    create table tab ( gender set('男', '女', '无') );\n    insert into tab values ('男, 女');\n    最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。\n    当创建表时，SET成员值的尾部空格将自动被删除。\n```\n\n### 列属性(列约束)\n\n```mysql\n/* 列属性（列约束） */ ------------------\n1. PRIMARY 主键\n    - 能唯一标识记录的字段，可以作为主键。\n    - 一个表只能有一个主键。\n    - 主键具有唯一性。\n    - 声明字段时，用 primary key 标识。\n        也可以在字段列表之后声明\n            例：create table tab ( id int, stu varchar(10), primary key (id));\n    - 主键字段的值不能为null。\n    - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。\n        例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));\n2. UNIQUE 唯一索引（唯一约束）\n    使得某字段的值也不能重复。\n3. NULL 约束\n    null不是数据类型，是列的一个属性。\n    表示当前列是否可以为null，表示什么都没有。\n    null, 允许为空。默认。\n    not null, 不允许为空。\n    insert into tab values (null, 'val');\n        -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null\n4. DEFAULT 默认值属性\n    当前字段的默认值。\n    insert into tab values (default, 'val');    -- 此时表示强制使用默认值。\n    create table tab ( add_time timestamp default current_timestamp );\n        -- 表示将当前时间的时间戳设为默认值。\n        current_date, current_time\n5. AUTO_INCREMENT 自动增长约束\n    自动增长必须为索引（主键或unique）\n    只能存在一个字段为自动增长。\n    默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;\n6. COMMENT 注释\n    例：create table tab ( id int ) comment '注释内容';\n7. FOREIGN KEY 外键约束\n    用于限制主表与从表数据完整性。\n    alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id);\n        -- 将表t1的t1_id外键关联到表t2的id字段。\n        -- 每个外键都有一个名字，可以通过 constraint 指定\n    存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。\n    作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。\n    MySQL中，可以对InnoDB引擎使用外键约束：\n    语法：\n    foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作]\n    此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。\n    可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。\n    如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择：\n    1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。\n    2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。\n    3. restrict，拒绝父表删除和更新。\n    注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。\n\n```\n\n### 建表规范\n\n```mysql\n/* 建表规范 */ ------------------\n    -- Normal Format, NF\n        - 每个表保存一个实体信息\n        - 每个具有一个ID字段作为主键\n        - ID主键 + 原子表\n    -- 1NF, 第一范式\n        字段不能再分，就满足第一范式。\n    -- 2NF, 第二范式\n        满足第一范式的前提下，不能出现部分依赖。\n        消除复合主键就可以避免部分依赖。增加单列关键字。\n    -- 3NF, 第三范式\n        满足第二范式的前提下，不能出现传递依赖。\n        某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。\n        将一个实体信息的数据放在一个表内实现。\n```\n\n### SELECT \n\n```mysql\n/* SELECT */ ------------------\nSELECT [ALL|DISTINCT] select_expr FROM -> WHERE -> GROUP BY [合计函数] -> HAVING -> ORDER BY -> LIMIT\na. select_expr\n    -- 可以用 * 表示所有字段。\n        select * from tb;\n    -- 可以使用表达式（计算公式、函数调用、字段也是个表达式）\n        select stu, 29+25, now() from tb;\n    -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。\n        - 使用 as 关键字，也可省略 as.\n        select stu+10 as add10 from tb;\nb. FROM 子句\n    用于标识查询来源。\n    -- 可以为表起别名。使用as关键字。\n        SELECT * FROM tb1 AS tt, tb2 AS bb;\n    -- from子句后，可以同时出现多个表。\n        -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。\n        SELECT * FROM tb1, tb2;\n    -- 向优化符提示如何选择索引\n        USE INDEX、IGNORE INDEX、FORCE INDEX\n        SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3;\n        SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;\nc. WHERE 子句\n    -- 从from获得的数据源中进行筛选。\n    -- 整型1表示真，0表示假。\n    -- 表达式由运算符和运算数组成。\n        -- 运算数：变量（字段）、值、函数返回值\n        -- 运算符：\n            =, <=>, <>, !=, <=, <, >=, >, !, &&, ||,\n            in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor\n            is/is not 加上ture/false/unknown，检验某个值的真假\n            <=>与<>功能相同，<=>可用于null比较\nd. GROUP BY 子句, 分组子句\n    GROUP BY 字段/别名 [排序方式]\n    分组后会进行排序。升序：ASC，降序：DESC\n    以下[合计函数]需配合 GROUP BY 使用：\n    count 返回不同的非NULL值数目  count(*)、count(字段)\n    sum 求和\n    max 求最大值\n    min 求最小值\n    avg 求平均值\n    group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。\ne. HAVING 子句，条件子句\n    与 where 功能、用法相同，执行时机不同。\n    where 在开始时执行检测数据，对原数据进行过滤。\n    having 对筛选出的结果再次进行过滤。\n    having 字段必须是查询出来的，where 字段必须是数据表存在的。\n    where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。\n    where 不可以使用合计函数。一般需用合计函数才会用 having\n    SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。\nf. ORDER BY 子句，排序子句\n    order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]...\n    升序：ASC，降序：DESC\n    支持多个字段的排序。\ng. LIMIT 子句，限制结果数量子句\n    仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。\n    limit 起始位置, 获取条数\n    省略第一个参数，表示从索引0开始。limit 获取条数\nh. DISTINCT, ALL 选项\n    distinct 去除重复记录\n    默认为 all, 全部记录\n```\n\n###  UNION\n\n```mysql\n/* UNION */ ------------------\n    将多个select查询的结果组合成一个结果集合。\n    SELECT ... UNION [ALL|DISTINCT] SELECT ...\n    默认 DISTINCT 方式，即所有返回的行都是唯一的\n    建议，对每个SELECT查询加上小括号包裹。\n    ORDER BY 排序时，需加上 LIMIT 进行结合。\n    需要各select查询的字段数量一样。\n    每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。\n```\n\n### 子查询\n\n```mysql\n/* 子查询 */ ------------------\n    - 子查询需用括号包裹。\n-- from型\n    from后要求是一个表，必须给子查询结果取个别名。\n    - 简化每个查询内的条件。\n    - from型需将结果生成一个临时表格，可用以原表的锁定的释放。\n    - 子查询返回一个表，表型子查询。\n    select * from (select * from tb where id>0) as subfrom where id>1;\n-- where型\n    - 子查询返回一个值，标量子查询。\n    - 不需要给子查询取别名。\n    - where子查询内的表，不能直接用以更新。\n    select * from tb where money = (select max(money) from tb);\n    -- 列子查询\n        如果子查询结果返回的是一列。\n        使用 in 或 not in 完成查询\n        exists 和 not exists 条件\n            如果子查询返回数据，则返回1或0。常用于判断条件。\n            select column1 from t1 where exists (select * from t2);\n    -- 行子查询\n        查询条件是一个行。\n        select * from t1 where (id, gender) in (select id, gender from t2);\n        行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...)\n        行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。\n    -- 特殊运算符\n    != all()    相当于 not in\n    = some()    相当于 in。any 是 some 的别名\n    != some()   不等同于 not in，不等于其中某一个。\n    all, some 可以配合其他运算符一起使用。\n```\n\n### 连接查询(join)\n\n```mysql\n/* 连接查询(join) */ ------------------\n    将多个表的字段进行连接，可以指定连接条件。\n-- 内连接(inner join)\n    - 默认就是内连接，可省略inner。\n    - 只有数据存在时才能发送连接。即连接结果不能出现空行。\n    on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真）\n    也可用where表示连接条件。\n    还有 using, 但需字段名相同。 using(字段名)\n    -- 交叉连接 cross join\n        即，没有条件的内连接。\n        select * from tb1 cross join tb2;\n-- 外连接(outer join)\n    - 如果数据不存在，也会出现在连接结果中。\n    -- 左外连接 left join\n        如果数据不存在，左表记录会出现，而右表为null填充\n    -- 右外连接 right join\n        如果数据不存在，右表记录会出现，而左表为null填充\n-- 自然连接(natural join)\n    自动判断连接条件完成连接。\n    相当于省略了using，会自动查找相同字段名。\n    natural join\n    natural left join\n    natural right join\nselect info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id;\n```\n\n### TRUNCATE \n\n```mysql\n/* TRUNCATE */ ------------------\nTRUNCATE [TABLE] tbl_name\n清空数据\n删除重建表\n区别：\n1，truncate 是删除表再创建，delete 是逐条删除\n2，truncate 重置auto_increment的值。而delete不会\n3，truncate 不知道删除了几条，而delete知道。\n4，当被用于带分区的表时，truncate 会保留分区\n```\n\n### 备份与还原\n\n```mysql\n/* 备份与还原 */ ------------------\n备份，将数据的结构与表内数据保存起来。\n利用 mysqldump 指令完成。\n-- 导出\nmysqldump [options] db_name [tables]\nmysqldump [options] ---database DB1 [DB2 DB3...]\nmysqldump [options] --all--database\n1. 导出一张表\n　　mysqldump -u用户名 -p密码 库名 表名 > 文件名(D:/a.sql)\n2. 导出多张表\n　　mysqldump -u用户名 -p密码 库名 表1 表2 表3 > 文件名(D:/a.sql)\n3. 导出所有表\n　　mysqldump -u用户名 -p密码 库名 > 文件名(D:/a.sql)\n4. 导出一个库\n　　mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 > 文件名(D:/a.sql)\n可以-w携带WHERE条件\n-- 导入\n1. 在登录mysql的情况下：\n　　source  备份文件\n2. 在不登录的情况下\n　　mysql -u用户名 -p密码 库名 < 备份文件\n```\n\n### 视图\n\n```mysql\n什么是视图：\n    视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。\n    视图具有表结构文件，但不存在数据文件。\n    对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。\n    视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。\n-- 创建视图\nCREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement\n    - 视图名必须唯一，同时不能与表重名。\n    - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。\n    - 可以指定视图执行的算法，通过ALGORITHM指定。\n    - column_list如果存在，则数目必须等于SELECT语句检索的列数\n-- 查看结构\n    SHOW CREATE VIEW view_name\n-- 删除视图\n    - 删除视图后，数据依然存在。\n    - 可同时删除多个视图。\n    DROP VIEW [IF EXISTS] view_name ...\n-- 修改视图结构\n    - 一般不修改视图，因为不是所有的更新视图都会映射到表上。\n    ALTER VIEW view_name [(column_list)] AS select_statement\n-- 视图作用\n    1. 简化业务逻辑\n    2. 对客户端隐藏真实的表结构\n-- 视图算法(ALGORITHM)\n    MERGE       合并\n        将视图的查询语句，与外部查询需要先合并再执行！\n    TEMPTABLE   临时表\n        将视图执行完毕后，形成临时表，再做外层查询！\n    UNDEFINED   未定义(默认)，指的是MySQL自主去选择相应的算法。\n```\n\n### 事务(transaction) \n\n```mysql\n事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。\n    - 支持连续SQL的集体成功或集体撤销。\n    - 事务是数据库在数据完整性方面的一个功能。\n    - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。\n    - InnoDB被称为事务安全型引擎。\n-- 事务开启\n    START TRANSACTION; 或者 BEGIN;\n    开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。\n-- 事务提交\n    COMMIT;\n-- 事务回滚\n    ROLLBACK;\n    如果部分操作发生问题，映射到事务开启前。\n-- 事务的特性\n    1. 原子性（Atomicity）\n        事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n    2. 一致性（Consistency）\n        事务前后数据的完整性必须保持一致。\n        - 事务开始和结束时，外部数据一致\n        - 在整个事务过程中，操作是连续的\n    3. 隔离性（Isolation）\n        多个用户并发访问数据库时，一个用户的事务不能被其它用户的事务所干扰，多个并发事务之间的数据要相互隔离。\n    4. 持久性（Durability）\n        一个事务一旦被提交，它对数据库中的数据改变就是永久性的。\n-- 事务的实现\n    1. 要求是事务支持的表类型\n    2. 执行一组相关的操作前开启事务\n    3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。\n-- 事务的原理\n    利用InnoDB的自动提交(autocommit)特性完成。\n    普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。\n    而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。\n-- 注意\n    1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。\n    2. 事务不能被嵌套\n-- 保存点\n    SAVEPOINT 保存点名称 -- 设置一个事务保存点\n    ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点\n    RELEASE SAVEPOINT 保存点名称 -- 删除保存点\n-- InnoDB自动提交特性设置\n    SET autocommit = 0|1;   0表示关闭自动提交，1表示开启自动提交。\n    - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。\n    - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是，\n        SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接)\n        而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务)\n\n```\n\n### 锁表\n\n```mysql\n/* 锁表 */\n表锁定只用于防止其它客户端进行不正当地读取和写入\nMyISAM 支持表锁，InnoDB 支持行锁\n-- 锁定\n    LOCK TABLES tbl_name [AS alias]\n-- 解锁\n    UNLOCK TABLES\n```\n\n### 触发器\n\n```mysql\n/* 触发器 */ ------------------\n    触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象\n    监听：记录的增加、修改、删除。\n-- 创建触发器\nCREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt\n    参数：\n    trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。\n    trigger_event指明了激活触发程序的语句的类型\n        INSERT：将新行插入表时激活触发程序\n        UPDATE：更改某一行时激活触发程序\n        DELETE：从表中删除某一行时激活触发程序\n    tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。\n    trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构\n-- 删除\nDROP TRIGGER [schema_name.]trigger_name\n可以使用old和new代替旧的和新的数据\n    更新操作，更新前是old，更新后是new.\n    删除操作，只有old.\n    增加操作，只有new.\n-- 注意\n    1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。\n-- 字符连接函数\nconcat(str1,str2,...])\nconcat_ws(separator,str1,str2,...)\n-- 分支语句\nif 条件 then\n    执行语句\nelseif 条件 then\n    执行语句\nelse\n    执行语句\nend if;\n-- 修改最外层语句结束符\ndelimiter 自定义结束符号\n    SQL语句\n自定义结束符号\ndelimiter ;     -- 修改回原来的分号\n-- 语句块包裹\nbegin\n    语句块\nend\n-- 特殊的执行\n1. 只要添加记录，就会触发程序。\n2. Insert into on duplicate key update 语法会触发：\n    如果没有重复记录，会触发 before insert, after insert;\n    如果有重复记录并更新，会触发 before insert, before update, after update;\n    如果有重复记录但是没有发生更新，则触发 before insert, before update\n3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert\n```\n\n### SQL编程\n\n```mysql\n/* SQL编程 */ ------------------\n--// 局部变量 ----------\n-- 变量声明\n    declare var_name[,...] type [default value]\n    这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。\n-- 赋值\n    使用 set 和 select into 语句为变量赋值。\n    - 注意：在函数内是可以使用全局变量（用户自定义的变量）\n--// 全局变量 ----------\n-- 定义、赋值\nset 语句可以定义并为变量赋值。\nset @var = value;\n也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。\n还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。\nselect @var:=20;\nselect @v1:=id, @v2=name from t1 limit 1;\nselect * from tbl_name where @var:=30;\nselect into 可以将表中查询获得的数据赋给变量。\n    -| select max(height) into @max_height from tb;\n-- 自定义变量名\n为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。\n@var=10;\n    - 变量被定义后，在整个会话周期都有效（登录到退出）\n--// 控制结构 ----------\n-- if语句\nif search_condition then\n    statement_list   \n[elseif search_condition then\n    statement_list]\n...\n[else\n    statement_list]\nend if;\n-- case语句\nCASE value WHEN [compare-value] THEN result\n[WHEN [compare-value] THEN result ...]\n[ELSE result]\nEND\n-- while循环\n[begin_label:] while search_condition do\n    statement_list\nend while [end_label];\n- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。\n    -- 退出循环\n        退出整个循环 leave\n        退出当前循环 iterate\n        通过退出的标签决定退出哪个循环\n--// 内置函数 ----------\n-- 数值函数\nabs(x)          -- 绝对值 abs(-10.9) = 10\nformat(x, d)    -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46\nceil(x)         -- 向上取整 ceil(10.1) = 11\nfloor(x)        -- 向下取整 floor (10.1) = 10\nround(x)        -- 四舍五入去整\nmod(m, n)       -- m%n m mod n 求余 10%3=1\npi()            -- 获得圆周率\npow(m, n)       -- m^n\nsqrt(x)         -- 算术平方根\nrand()          -- 随机数\ntruncate(x, d)  -- 截取d位小数\n-- 时间日期函数\nnow(), current_timestamp();     -- 当前日期时间\ncurrent_date();                 -- 当前日期\ncurrent_time();                 -- 当前时间\ndate('yyyy-mm-dd hh:ii:ss');    -- 获取日期部分\ntime('yyyy-mm-dd hh:ii:ss');    -- 获取时间部分\ndate_format('yyyy-mm-dd hh:ii:ss', '%d %y %a %d %m %b %j'); -- 格式化时间\nunix_timestamp();               -- 获得unix时间戳\nfrom_unixtime();                -- 从时间戳获得时间\n-- 字符串函数\nlength(string)          -- string长度，字节\nchar_length(string)     -- string的字符个数\nsubstring(str, position [,length])      -- 从str的position开始,取length个字符\nreplace(str ,search_str ,replace_str)   -- 在str中用replace_str替换search_str\ninstr(string ,substring)    -- 返回substring首次在string中出现的位置\nconcat(string [,...])   -- 连接字串\ncharset(str)            -- 返回字串字符集\nlcase(string)           -- 转换成小写\nleft(string, length)    -- 从string2中的左边起取length个字符\nload_file(file_name)    -- 从文件读取内容\nlocate(substring, string [,start_position]) -- 同instr,但可指定开始位置\nlpad(string, length, pad)   -- 重复用pad加在string开头,直到字串长度为length\nltrim(string)           -- 去除前端空格\nrepeat(string, count)   -- 重复count次\nrpad(string, length, pad)   --在str后用pad补充,直到长度为length\nrtrim(string)           -- 去除后端空格\nstrcmp(string1 ,string2)    -- 逐字符比较两字串大小\n-- 流程函数\ncase when [condition] then result [when [condition] then result ...] [else result] end   多分支\nif(expr1,expr2,expr3)  双分支。\n-- 聚合函数\ncount()\nsum();\nmax();\nmin();\navg();\ngroup_concat()\n-- 其他常用函数\nmd5();\ndefault();\n--// 存储函数，自定义函数 ----------\n-- 新建\n    CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型\n        函数体\n    - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。\n    - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。\n    - 参数部分，由\"参数名\"和\"参数类型\"组成。多个参数用逗号隔开。\n    - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。\n    - 多条语句应该使用 begin...end 语句块包含。\n    - 一定要有 return 返回值语句。\n-- 删除\n    DROP FUNCTION [IF EXISTS] function_name;\n-- 查看\n    SHOW FUNCTION STATUS LIKE 'partten'\n    SHOW CREATE FUNCTION function_name;\n-- 修改\n    ALTER FUNCTION function_name 函数选项\n--// 存储过程，自定义功能 ----------\n-- 定义\n存储存储过程 是一段代码（过程），存储在数据库中的sql组成。\n一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。\n而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。\n-- 创建\nCREATE PROCEDURE sp_name (参数列表)\n    过程体\n参数列表：不同于函数的参数列表，需要指明参数类型\nIN，表示输入型\nOUT，表示输出型\nINOUT，表示混合型\n注意，没有返回值。\n```\n\n### 存储过程\n\n```mysql\n/* 存储过程 */ ------------------\n存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。\n调用：CALL 过程名\n-- 注意\n- 没有返回值。\n- 只能单独调用，不可夹杂在其他语句中\n-- 参数\nIN|OUT|INOUT 参数名 数据类型\nIN      输入：在调用过程中，将数据输入到过程体内部的参数\nOUT     输出：在调用过程中，将过程体处理完的结果返回到客户端\nINOUT   输入输出：既可输入，也可输出\n-- 语法\nCREATE PROCEDURE 过程名 (参数列表)\nBEGIN\n    过程体\nEND\n```\n\n### 用户和权限管理\n\n```mysql\n/* 用户和权限管理 */ ------------------\n-- root密码重置\n1. 停止MySQL服务\n2.  [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &\n    [Windows] mysqld --skip-grant-tables\n3. use mysql;\n4. UPDATE `user` SET PASSWORD=PASSWORD(\"密码\") WHERE `user` = \"root\";\n5. FLUSH PRIVILEGES;\n用户信息表：mysql.user\n-- 刷新权限\nFLUSH PRIVILEGES;\n-- 增加用户\nCREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串)\n    - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。\n    - 只能创建用户，不能赋予权限。\n    - 用户名，注意引号：如 'user_name'@'192.168.1.1'\n    - 密码也需引号，纯数字密码也要加引号\n    - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD\n-- 重命名用户\nRENAME USER old_user TO new_user\n-- 设置密码\nSET PASSWORD = PASSWORD('密码')  -- 为当前用户设置密码\nSET PASSWORD FOR 用户名 = PASSWORD('密码') -- 为指定用户设置密码\n-- 删除用户\nDROP USER 用户名\n-- 分配权限/添加用户\nGRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] 'password']\n    - all privileges 表示所有权限\n    - *.* 表示所有库的所有表\n    - 库名.表名 表示某库下面的某表\n    GRANT ALL PRIVILEGES ON `pms`.* TO 'pms'@'%' IDENTIFIED BY 'pms0817';\n-- 查看权限\nSHOW GRANTS FOR 用户名\n    -- 查看当前用户权限\n    SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();\n-- 撤消权限\nREVOKE 权限列表 ON 表名 FROM 用户名\nREVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名   -- 撤销所有权限\n-- 权限层级\n-- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。\n全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user\n    GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。\n数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host\n    GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。\n表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv\n    GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。\n列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv\n    当使用REVOKE时，您必须指定与被授权列相同的列。\n-- 权限列表\nALL [PRIVILEGES]    -- 设置除GRANT OPTION之外的所有简单权限\nALTER   -- 允许使用ALTER TABLE\nALTER ROUTINE   -- 更改或取消已存储的子程序\nCREATE  -- 允许使用CREATE TABLE\nCREATE ROUTINE  -- 创建已存储的子程序\nCREATE TEMPORARY TABLES     -- 允许使用CREATE TEMPORARY TABLE\nCREATE USER     -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。\nCREATE VIEW     -- 允许使用CREATE VIEW\nDELETE  -- 允许使用DELETE\nDROP    -- 允许使用DROP TABLE\nEXECUTE     -- 允许用户运行已存储的子程序\nFILE    -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILE\nINDEX   -- 允许使用CREATE INDEX和DROP INDEX\nINSERT  -- 允许使用INSERT\nLOCK TABLES     -- 允许对您拥有SELECT权限的表使用LOCK TABLES\nPROCESS     -- 允许使用SHOW FULL PROCESSLIST\nREFERENCES  -- 未被实施\nRELOAD  -- 允许使用FLUSH\nREPLICATION CLIENT  -- 允许用户询问从属服务器或主服务器的地址\nREPLICATION SLAVE   -- 用于复制型从属服务器（从主服务器中读取二进制日志事件）\nSELECT  -- 允许使用SELECT\nSHOW DATABASES  -- 显示所有数据库\nSHOW VIEW   -- 允许使用SHOW CREATE VIEW\nSHUTDOWN    -- 允许使用mysqladmin shutdown\nSUPER   -- 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。\nUPDATE  -- 允许使用UPDATE\nUSAGE   -- “无权限”的同义词\nGRANT OPTION    -- 允许授予权限\n```\n\n### 表维护\n\n```mysql\n/* 表维护 */\n-- 分析和存储表的关键字分布\nANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 ...\n-- 检查一个或多个表是否有错误\nCHECK TABLE tbl_name [, tbl_name] ... [option] ...\noption = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}\n-- 整理数据文件的碎片\nOPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...\n```\n\n### 杂项\n\n```mysql\n/* 杂项 */ ------------------\n1. 可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！\n2. 每个库目录存在一个保存当前数据库的选项文件db.opt。\n3. 注释：\n    单行注释 # 注释内容\n    多行注释 /* 注释内容 */\n    单行注释 -- 注释内容     (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）)\n4. 模式通配符：\n    _   任意单个字符\n    %   任意多个字符，甚至包括零字符\n    单引号需要进行转义 \\'\n5. CMD命令行内的语句结束符可以为 \";\", \"\\G\", \"\\g\"，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。\n6. SQL对大小写不敏感\n7. 清除已有语句：\\c\n```\n\n"},e778:function(n,r,e){var s={"./0.MySQL常见语句汇总.md":"7c80","./2万字的MySQL八股文背诵版.md":"b603","./InnoDB对MVCC的实现.md":"ca0c","./MySQL Index.md":"d3ba","./MySQL 的全局锁、表级锁、行级锁.md":"97d6","./MySQL三大日志.md":"b2b7","./MySQL总结.md":"62a6","./MySQL数据库索引.md":"093b","./MySQL高性能优化规范建议.md":"bc06","./mysql一条语句是怎么执行.md":"3a39","./mysql删除.md":"2b74","./mysql锁.md":"2767","./mysql随手记-常见知识点总结.md":"6701","./redis事务和mysql事务的区别.md":"7a2e","./《面试八股文》之 MySql 35卷.md":"53f6","./一千行MySQL学习笔记.md":"e371","./一条sql语句在mysql中如何执行的.md":"a669","./事务隔离级别(图文详解).md":"1451","./关于数据库存储时间的一点思考.md":"382d","./回滚和持久化.md":"3fa4","./字符集.md":"cbc6","./数据库基础知识.md":"55aa","./数据库连接池.md":"cf89","./阿里巴巴开发手册数据库部分的一些最佳实践.md":"5604"};function t(n){var r=i(n);return e(r)}function i(n){if(!e.o(s,n)){var r=new Error("Cannot find module '"+n+"'");throw r.code="MODULE_NOT_FOUND",r}return s[n]}t.keys=function(){return Object.keys(s)},t.resolve=i,n.exports=t,t.id="e778"},ef82:function(n,r,e){"use strict";e.r(r),r["default"]="# 第二章：Redis高级\r\n\r\n## 学习目标\r\n\r\n目标1：能够说出redis中的数据删除策与略淘汰策略\r\n\r\n目标2：能够说出主从复制的概念，工作流程以及场景问题及解决方案\r\n\r\n目标3：能够说出哨兵的作用以及工作原理，以及如何启用哨兵\r\n\r\n目标4：能够说出集群的架构设计，完成集群的搭建\r\n\r\n目标5：能够说出缓存预热，雪崩，击穿，穿透的概念，能说出redis的相关监控指标\r\n\r\n## 1.数据删除与淘汰策略\r\n\r\n### 1.1 过期数据\r\n\r\n#### **1.1.1 Redis中的数据特征**\r\n\r\nRedis是一种内存级数据库，所有数据均存放在内存中，内存中的数据可以通过TTL指令获取其状态\r\n\r\nTTL返回的值有三种情况：正数，-1，-2\r\n\r\n- **正数**：代表该数据在内存中还能存活的时间\r\n- **-1**：永久有效的数据\r\n- **2** ：已经过期的数据 或被删除的数据 或 未定义的数据\r\n\r\n**删除策略就是针对已过期数据的处理策略**，已过期的数据是真的就立即删除了吗？其实也不是，我们会有多种删除策略，是分情况的，在不同的场景下使用不同的删除方式会有不同效果，这也正是我们要将的数据的删除策略的问题\r\n\r\n#### 1.1.2 时效性数据的存储结构\r\n\r\n在Redis中，如何给数据设置它的失效周期呢？数据的时效在redis中如何存储呢？看下图：\r\n\r\n![](Redis高级.assets/1.png)\r\n\r\n过期数据是一块独立的存储空间，Hash结构，field是内存地址，value是过期时间，保存了所有key的过期描述，在最终进行过期处理的时候，对该空间的数据进行检测， 当时间到期之后通过field找到内存该地址处的数据，然后进行相关操作。\r\n\r\n### 1.2 数据删除策略\r\n\r\n#### 1.2.1 数据删除策略的目标\r\n\r\n在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或 内存泄露\r\n\r\n针对过期数据要进行删除的时候都有哪些删除策略呢？\r\n\r\n- 1.定时删除\r\n- 2.惰性删除\r\n- 3.定期删除\r\n\r\n#### 1.2.2 定时删除\r\n\r\n创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作\r\n\r\n- **优点**：节约内存，到时就删除，快速释放掉不必要的内存占用\r\n- **缺点**：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量\r\n- **总结**：用处理器性能换取存储空间（拿时间换空间）\r\n\r\n![](Redis高级.assets/2.png)\r\n\r\n#### 1.2.3 惰性删除\r\n\r\n数据到达过期时间，不做处理。等下次访问该数据时，我们需要判断\r\n\r\n1. 如果未过期，返回数据\r\n2. 发现已过期，删除，返回不存在\r\n\r\n- **优点**：节约CPU性能，发现必须删除的时候才删除\r\n- **缺点**：内存压力很大，出现长期占用内存的数据\r\n- **总结**：用存储空间换取处理器性能（拿时间换空间）\r\n\r\n![](Redis高级.assets/3.png)\r\n\r\n#### 1.2.4 定期删除\r\n\r\n定时删除和惰性删除这两种方案都是走的极端，那有没有折中方案？\r\n\r\n我们来讲redis的定期删除方案：\r\n\r\n- Redis启动服务器初始化时，读取配置server.hz的值，默认为10\r\n\r\n- 每秒钟执行server.hz次**serverCron()**--------\x3e**databasesCron()**---------\x3e**activeExpireCycle()**\r\n\r\n- **activeExpireCycle()**对每个expires[*]逐一进行检测，每次执行耗时：250ms/server.hz\r\n\r\n- 对某个expires[*]检测时，随机挑选W个key检测\r\n\r\n```markdown\r\n  如果key超时，删除key\r\n\r\n  如果一轮中删除的key的数量>W*25%，循环该过程\r\n\r\n  如果一轮中删除的key的数量≤W*25%，检查下一个expires[*]，0-15循环\r\n\r\n  W取值=ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP属性值\r\n```\r\n\r\n- 参数current_db用于记录**activeExpireCycle()** 进入哪个expires[*] 执行\r\n\r\n- 如果activeExpireCycle()执行时间到期，下次从current_db继续向下执行\r\n\r\n\r\n![](Redis高级.assets/4.png)\r\n\r\n总的来说：定期删除就是周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度\r\n\r\n- **特点1**：CPU性能占用设置有峰值，检测频度可自定义设置\r\n- **特点2**：内存压力不是很大，长期占用内存的冷数据会被持续清理\r\n- **总结**：周期性抽查存储空间（随机抽查，重点抽查）\r\n\r\n#### 1.2.5 删除策略对比\r\n\r\n1：定时删除：\r\n\r\n```markdown\r\n节约内存，无占用,\r\n不分时段占用CPU资源，频度高,\r\n拿时间换空间\r\n```\r\n\r\n2：惰性删除：\r\n\r\n```markdown\r\n内存占用严重\r\n延时执行，CPU利用率高\r\n拿空间换时间\r\n```\r\n\r\n3：定期删除：\r\n\r\n```markdown\r\n内存定期随机清理\r\n每秒花费固定的CPU资源维护内存\r\n随机抽查，重点抽查\r\n```\r\n\r\n### 1.3 数据淘汰策略（逐出算法）\r\n\r\n#### 1.3.1 淘汰策略概述\r\n\r\n什么叫数据淘汰策略？什么样的应用场景需要用到数据淘汰策略？\r\n\r\n当新数据进入redis时，如果内存不足怎么办？在执行每一个命令前，会调用**freeMemoryIfNeeded()**检测内存是否充足。如果内存不满足新 加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法。\r\n\r\n注意：逐出数据的过程不是100%能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕，  如不能达到内存清理的要求，将出现错误信息如下\r\n\r\n```shell\r\n(error) OOM command not allowed when used memory >'maxmemory'\r\n```\r\n\r\n#### 1.3.2 策略配置\r\n\r\n影响数据淘汰的相关配置如下：\r\n\r\n1：最大可使用内存，即占用物理内存的比例，默认值为0，表示不限制。生产环境中根据需求设定，通常设置在50%以上\r\n\r\n```properties\r\nmaxmemory ?mb\r\n```\r\n\r\n2：每次选取待删除数据的个数，采用随机获取数据的方式作为待检测删除数据\r\n\r\n```properties\r\nmaxmemory-samples count\r\n```\r\n\r\n3：对数据进行删除的选择策略\r\n\r\n```properties\r\nmaxmemory-policy policy\r\n```\r\n\r\n那数据删除的策略policy到底有几种呢？一共是**3类8种**\r\n\r\n**第一类**：检测易失数据（可能会过期的数据集server.db[i].expires ）\r\n\r\n```properties\r\nvolatile-lru：挑选最近最少使用的数据淘汰volatile-lfu：挑选最近使用次数最少的数据淘汰volatile-ttl：挑选将要过期的数据淘汰volatile-random：任意选择数据淘汰\r\n```\r\n\r\n![](Redis高级.assets/lru.png)\r\n\r\n**第二类**：检测全库数据（所有数据集server.db[i].dict ）\r\n\r\n```properties\r\nallkeys-lru：挑选最近最少使用的数据淘汰allkeLyRs-lfu：：挑选最近使用次数最少的数据淘汰allkeys-random：任意选择数据淘汰，相当于随机\r\n```\r\n\r\n**第三类**：放弃数据驱逐\r\n\r\n```properties\r\nno-enviction（驱逐）：禁止驱逐数据(redis4.0中默认策略)，会引发OOM(Out Of Memory)\r\n```\r\n\r\n注意：这些策略是配置到哪个属性上？怎么配置？如下所示\r\n\r\n```properties\r\nmaxmemory-policy volatile-lru\r\n```\r\n\r\n**数据淘汰策略配置依据**\r\n\r\n 使用INFO命令输出监控信息，查询缓存 hit 和 miss 的次数，根据业务需求调优Redis配置\r\n\r\n## 2.主从复制\r\n\r\n### 2.1 主从复制简介\r\n\r\n#### 2.1.1 高可用\r\n\r\n首先我们要理解互联网应用因为其独有的特性我们演化出的**三高**架构\r\n\r\n- 高并发\r\n\r\n  > 应用要提供某一业务要能支持很多客户端同时访问的能力，我们称为并发，高并发意思就很明确了\r\n\r\n- 高性能\r\n\r\n  >性能带给我们最直观的感受就是：速度快，时间短\r\n\r\n- 高可用\r\n\r\n**可用性**：一年中应用服务正常运行的时间占全年时间的百分比，如下图：表示了应用服务在全年宕机的时间\r\n\r\n![](Redis高级.assets/5.png)\r\n\r\n我们把这些时间加在一起就是全年应用服务不可用的时间，然后我们可以得到应用服务全年可用的时间\r\n\r\n>4小时27分15秒+11分36秒+2分16秒=4小时41分7秒=16867秒\r\n>\r\n>1年=365*24*60*60=31536000秒\r\n>\r\n>可用性=（31536000-16867）/31536000*100%=99.9465151%\r\n\r\n业界可用性目标**5个9，即99.999%**，即服务器年宕机时长低于315秒，约5.25分钟\r\n\r\n\r\n\r\n#### 2.1.2 主从复制概念\r\n\r\n知道了三高的概念之后，我们想：你的“Redis”是否高可用？那我们要来分析单机redis的风险与问题\r\n\r\n问题1.机器故障\r\n\r\n- 现象：硬盘故障、系统崩溃\r\n- 本质：数据丢失，很可能对业务造成灾难性打击\r\n- 结论：基本上会放弃使用redis.\r\n\r\n问题2.容量瓶颈\r\n\r\n- 现象：内存不足，从16G升级到64G，从64G升级到128G，无限升级内存\r\n- 本质：穷，硬件条件跟不上\r\n- 结论：放弃使用redis\r\n\r\n结论：\r\n\r\n为了避免单点Redis服务器故障，准备多台服务器，互相连通。将数据复制多个副本保存在不同的服务器上，连接在一起，并保证数据是同步的。即使有其中一台服务器宕机，其他服务器依然可以继续提供服务，实现Redis的高可用，同时实现数据冗余备份。\r\n\r\n多台服务器连接方案：\r\n\r\n![](Redis高级.assets/6.png)\r\n\r\n- 提供数据方：**master**\r\n\r\n主服务器，主节点，主库主客户端\r\n\r\n- 接收数据方：**slave**\r\n\r\n从服务器，从节点，从库\r\n\r\n从客户端\r\n\r\n- 需要解决的问题：\r\n\r\n数据同步（master的数据复制到slave中）\r\n\r\n\r\n\r\n这里我们可以来解释主从复制的概念：\r\n\r\n**概念：主从复制即将master中的数据即时、有效的复制到slave中**\r\n\r\n**特征**：一个master可以拥有多个slave，一个slave只对应一个master\r\n\r\n**职责**：master和slave各自的职责不一样\r\n\r\nmaster:\r\n\r\n```markdown\r\n写数据执行写操作时，将出现变化的数据自动同步到slave读数据（可忽略）\r\n```\r\n\r\nslave:\r\n\r\n```markdown\r\n读数据写数据（禁止）\r\n```\r\n\r\n#### 2.1.3 主从复制的作用\r\n\r\n- 读写分离：master写、slave读，提高服务器的读写负载能力\r\n- 负载均衡：基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数 量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量\r\n- 故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复\r\n- 数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式\r\n- 高可用基石：基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案\r\n\r\n### 2.2 主从复制工作流程\r\n\r\n主从复制过程大体可以分为3个阶段\r\n\r\n- 建立连接阶段（即准备阶段）\r\n- 数据同步阶段\r\n- 命令传播阶段（反复同步）\r\n\r\n![](Redis高级.assets/7.png)\r\n\r\n而命令的传播其实有4种，分别如下：\r\n\r\n![](Redis高级.assets/8.png)\r\n\r\n\r\n\r\n#### 2.2.1 主从复制的工作流程（三个阶段）\r\n\r\n##### 2.2.1.1 阶段一：建立连接\r\n\r\n建立slave到master的连接，使master能够识别slave，并保存slave端口号\r\n\r\n流程如下：\r\n\r\n1. 步骤1：设置master的地址和端口，保存master信息\r\n2. 步骤2：建立socket连接\r\n3. 步骤3：发送ping命令（定时器任务）\r\n4. 步骤4：身份验证\r\n5. 步骤5：发送slave端口信息\r\n\r\n至此，主从连接成功！\r\n\r\n当前状态：\r\n\r\nslave：保存master的地址与端口\r\n\r\nmaster：保存slave的端口\r\n\r\n总体：之间创建了连接的socket\r\n\r\n![](Redis高级.assets/9.png)\r\n\r\n\r\n\r\n**master和slave互联**\r\n\r\n接下来就要通过某种方式将master和slave连接到一起\r\n\r\n方式一：客户端发送命令\r\n\r\n```properties\r\nslaveof masterip masterport\r\n```\r\n\r\n方式二：启动服务器参数\r\n\r\n```properties\r\nredis-server --slaveof masterip masterport\r\n```\r\n\r\n方式三：服务器配置（**主流方式**）\r\n\r\n```properties\r\nslaveof masterip masterport\r\n```\r\n\r\nslave系统信息\r\n\r\n```properties\r\nmaster_link_down_since_secondsmasterhost & masterport\r\n```\r\n\r\nmaster系统信息\r\n\r\n```properties\r\nuslave_listening_port(多个)\r\n```\r\n\r\n**主从断开连接**\r\n\r\n断开slave与master的连接，slave断开连接后，不会删除已有数据，只是不再接受master发送的数据\r\n\r\n```properties\r\nslaveof no one\r\n```\r\n\r\n**授权访问**\r\n\r\nmaster客户端发送命令设置密码\r\n\r\n```properties\r\nrequirepass password\r\n```\r\n\r\nmaster配置文件设置密码\r\n\r\n```properties\r\nconfig set requirepass passwordconfig get requirepass\r\n```\r\n\r\nslave客户端发送命令设置密码\r\n\r\n```properties\r\nauth password\r\n```\r\n\r\nslave配置文件设置密码\r\n\r\n```properties\r\nmasterauth password\r\n```\r\n\r\nslave启动服务器设置密码\r\n\r\n```properties\r\nredis-server –a password\r\n```\r\n\r\n\r\n\r\n##### 2.2.1.2 阶段二：数据同步\r\n\r\n- 在slave初次连接master后，复制master中的所有数据到slave\r\n- 将slave的数据库状态更新成master当前的数据库状态\r\n\r\n同步过程如下：\r\n\r\n1. 步骤1：请求同步数据\r\n2. 步骤2：创建RDB同步数据\r\n3. 步骤3：恢复RDB同步数据\r\n4. 步骤4：请求部分同步数据\r\n5. 步骤5：恢复部分同步数据\r\n\r\n至此，数据同步工作完成！\r\n\r\n当前状态：\r\n\r\nslave：具有master端全部数据，包含RDB过程接收的数据\r\n\r\nmaster：保存slave当前数据同步的位置\r\n\r\n总体：之间完成了数据克隆\r\n\r\n![](Redis高级.assets/10.png)\r\n\r\n**数据同步阶段master说明**\r\n\r\n1：如果master数据量巨大，数据同步阶段应避开流量高峰期，避免造成master阻塞，影响业务正常执行\r\n\r\n2：复制缓冲区大小设定不合理，会导致数据溢出。如进行全量复制周期太长，进行部分复制时发现数据已经存在丢失的情况，必须进行第二次全量复制，致使slave陷入死循环状态。\r\n\r\n```properties\r\nrepl-backlog-size ?mb\r\n```\r\n\r\n3. master单机内存占用主机内存的比例不应过大，建议使用50%-70%的内存，留下30%-50%的内存用于执 行bgsave命令和创建复制缓冲区\r\n\r\n![](Redis高级.assets/11.png)\r\n\r\n**数据同步阶段slave说明**\r\n\r\n1. 为避免slave进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务\r\n\r\n```properties\r\n   slave-serve-stale-data yes|no\r\n```\r\n\r\n2. 数据同步阶段，master发送给slave信息可以理解master是slave的一个客户端，主动向slave发送命令\r\n\r\n3. 多个slave同时对master请求数据同步，master发送的RDB文件增多，会对带宽造成巨大冲击，如果master带宽不足，因此数据同步需要根据业务需求，适量错峰\r\n\r\n4. slave过多时，建议调整拓扑结构，由一主多从结构变为树状结构，中间的节点既是master，也是 slave。注意使用树状结构时，由于层级深度，导致深度越高的slave与最顶层master间数据同步延迟 较大，数据一致性变差，应谨慎选择\r\n\r\n##### 2.2.1.3 阶段三：命令传播\r\n\r\n- 当master数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的状态，同步的动作称为命令传播\r\n- master将接收到的数据变更命令发送给slave，slave接收命令后执行命令\r\n\r\n**命令传播阶段的部分复制**\r\n\r\n命令传播阶段出现了断网现象：\r\n\r\n网络闪断闪连：忽略\r\n\r\n短时间网络中断：部分复制\r\n\r\n长时间网络中断：全量复制\r\n\r\n\r\n\r\n这里我们主要来看部分复制，部分复制的三个核心要素\r\n\r\n1. 服务器的运行 id（run id）\r\n2. 主服务器的复制积压缓冲区\r\n3. 主从服务器的复制偏移量\r\n\r\n- 服务器运行ID（runid）\r\n\r\n```markdown\r\n概念：服务器运行ID是每一台服务器每次运行的身份识别码，一台服务器多次运行可以生成多个运行id组成：运行id由40位字符组成，是一个随机的十六进制字符例如：fdc9ff13b9bbaab28db42b3d50f852bb5e3fcdce作用：运行id被用于在服务器间进行传输，识别身份如果想两次操作均对同一台服务器进行，必须每次操作携带对应的运行id，用于对方识别实现方式：运行id在每台服务器启动时自动生成的，master在首次连接slave时，会将自己的运行ID发送给slave，slave保存此ID，通过info Server命令，可以查看节点的runid\r\n```\r\n\r\n- 复制缓冲区\r\n\r\n```markdown\r\n概念：复制缓冲区，又名复制积压缓冲区，是一个先进先出（FIFO）的队列，用于存储服务器执行过的命令，每次传播命令，master都会将传播的命令记录下来，并存储在复制缓冲区\t复制缓冲区默认数据存储空间大小是1M\t当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列作用：用于保存master收到的所有指令（仅影响数据变更的指令，例如set，select）数据来源：当master接收到主客户端的指令时，除了将指令执行，会将该指令存储到缓冲区中\r\n```\r\n\r\n![](Redis高级.assets/12.png)\r\n\r\n复制缓冲区内部工作原理：\r\n\r\n组成\r\n\r\n- 偏移量\r\n\r\n  >概念：一个数字，描述复制缓冲区中的指令字节位置\r\n  >\r\n  >分类：\r\n  >\r\n  >- master复制偏移量：记录发送给所有slave的指令字节对应的位置（多个）\r\n  >- slave复制偏移量：记录slave接收master发送过来的指令字节对应的位置（一个）\r\n  >\r\n  >作用：同步信息，比对master与slave的差异，当slave断线后，恢复数据使用\r\n  >\r\n  >数据来源：\r\n  >\r\n  >- master端：发送一次记录一次\r\n  >- slave端：接收一次记录一次\r\n\r\n- 字节值\r\n\r\n工作原理\r\n\r\n- 通过offset区分不同的slave当前数据传播的差异\r\n- master记录已发送的信息对应的offset\r\n- slave记录已接收的信息对应的offset\r\n\r\n![](Redis高级.assets/13.png)\r\n\r\n\r\n\r\n#### 2.2.2 流程更新(全量复制/部分复制)\r\n\r\n我们再次的总结一下主从复制的三个阶段的工作流程：\r\n\r\n![](Redis高级.assets/14.png)\r\n\r\n#### 2.2.3 心跳机制\r\n\r\n什么是心跳机制？\r\n\r\n进入命令传播阶段候，master与slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线\r\n\r\nmaster心跳：\r\n\r\n- 内部指令：PING\r\n- 周期：由repl-ping-slave-period决定，默认10秒\r\n- 作用：判断slave是否在线\r\n- 查询：INFO replication  获取slave最后一次连接时间间隔，lag项维持在0或1视为正常\r\n\r\nslave心跳任务\r\n\r\n- 内部指令：REPLCONF ACK {offset}\r\n- 周期：1秒\r\n- 作用1：汇报slave自己的复制偏移量，获取最新的数据变更指令\r\n- 作用2：判断master是否在线\r\n\r\n心跳阶段注意事项：\r\n\r\n- 当slave多数掉线，或延迟过高时，master为保障数据稳定性，将拒绝所有信息同步\r\n\r\n```properties\r\nmin-slaves-to-write 2min-slaves-max-lag 8\r\n```\r\n\r\nslave数量少于2个，或者所有slave的延迟都大于等于8秒时，强制关闭master写功能，停止数据同步\r\n\r\n- slave数量由slave发送REPLCONF ACK命令做确认\r\n\r\n\r\n- slave延迟由slave发送REPLCONF ACK命令做确认\r\n\r\n\r\n\r\n至此：我们可以总结出完整的主从复制流程：\r\n\r\n![](Redis高级.assets/15.png)\r\n\r\n### 2.3 主从复制常见问题\r\n\r\n#### 2.3.1 频繁的全量复制\r\n\r\n- 伴随着系统的运行，master的数据量会越来越大，一旦master重启，runid将发生变化，会导致全部slave的全量复制操作\r\n\r\n\r\n内部优化调整方案：\r\n\r\n1：master内部创建master_replid变量，使用runid相同的策略生成，长度41位，并发送给所有slave\r\n\r\n2：在master关闭时执行命令shutdown save，进行RDB持久化,将runid与offset保存到RDB文件中\r\n\r\n```markdown\r\nrepl-id  repl-offset通过redis-check-rdb命令可以查看该信息\r\n```\r\n\r\n3：master重启后加载RDB文件，恢复数据，重启后，将RDB文件中保存的repl-id与repl-offset加载到内存中\r\n\r\n```markdown\r\nmaster_repl_id=repl  master_repl_offset =repl-offset通过info命令可以查看该信息\r\n```\r\n\r\n作用：本机保存上次runid，重启后恢复该值，使所有slave认为还是之前的master\r\n\r\n\r\n\r\n- 第二种出现频繁全量复制的问题现象：网络环境不佳，出现网络中断，slave不提供服务\r\n\r\n\r\n问题原因：复制缓冲区过小，断网后slave的offset越界，触发全量复制\r\n\r\n最终结果：slave反复进行全量复制\r\n\r\n解决方案：修改复制缓冲区大小\r\n\r\n```properties\r\nrepl-backlog-size ?mb\r\n```\r\n\r\n建议设置如下：\r\n\r\n1.测算从master到slave的重连平均时长second\r\n\r\n2.获取master平均每秒产生写命令数据总量write_size_per_second\r\n\r\n3.最优复制缓冲区空间 = 2 * second * write_size_per_second\r\n\r\n\r\n\r\n#### 2.3.2 频繁的网络中断\r\n\r\n- 问题现象：master的CPU占用过高 或 slave频繁断开连接\r\n\r\n\r\n问题原因\r\n\r\n```markdown\r\nslave每1秒发送REPLCONFACK命令到master当slave接到了慢查询时（keys * ，hgetall等），会大量占用CPU性能master每1秒调用复制定时函数replicationCron()，比对slave发现长时间没有进行响应\r\n```\r\n\r\n最终结果：master各种资源（输出缓冲区、带宽、连接等）被严重占用\r\n\r\n解决方案：通过设置合理的超时时间，确认是否释放slave\r\n\r\n```properties\r\nrepl-timeout seconds\r\n```\r\n\r\n该参数定义了超时时间的阈值（默认60秒），超过该值，释放slave\r\n\r\n\r\n\r\n- 问题现象：slave与master连接断开\r\n\r\n\r\n问题原因\r\n\r\n```markdown\r\nmaster发送ping指令频度较低master设定超时时间较短ping指令在网络中存在丢包\r\n```\r\n\r\n解决方案：提高ping指令发送的频度\r\n\r\n```properties\r\nrepl-ping-slave-period seconds\r\n```\r\n\r\n超时时间repl-time的时间至少是ping指令频度的5到10倍，否则slave很容易判定超时\r\n\r\n#### 2.3.3 数据不一致\r\n\r\n问题现象：多个slave获取相同数据不同步\r\n\r\n问题原因：网络信息不同步，数据发送有延迟\r\n\r\n解决方案\r\n\r\n```markdown\r\n优化主从间的网络环境，通常放置在同一个机房部署，如使用阿里云等云服务器时要注意此现象监控主从节点延迟（通过offset）判断，如果slave延迟过大，暂时屏蔽程序对该slave的数据访问\r\n```\r\n\r\n```properties\r\nslave-serve-stale-data\tyes|no\r\n```\r\n\r\n开启后仅响应info、slaveof等少数命令（慎用，除非对数据一致性要求很高）\r\n\r\n## 3.哨兵模式\r\n\r\n### 3.1 哨兵简介\r\n\r\n#### 3.1.1 哨兵概念\r\n\r\n首先我们来看一个业务场景：如果redis的master宕机了，此时应该怎么办？\r\n\r\n![](Redis高级.assets/16.png)\r\n\r\n那此时我们可能需要从一堆的slave中重新选举出一个新的master，那这个操作过程是什么样的呢？这里面会有什么问题出现呢？\r\n\r\n![](Redis高级.assets/17.png)\r\n\r\n要实现这些功能，我们就需要redis的哨兵，那哨兵是什么呢？\r\n\r\n**哨兵**\r\n\r\n哨兵(sentinel) 是一个分布式系统，用于对主从结构中的每台服务器进行**监控**，当出现故障时通过**投票**机制**选择**新的master并将所有slave连接到新的master。\r\n\r\n![](Redis高级.assets/18.png)\r\n\r\n#### 3.1.2 哨兵作用\r\n\r\n哨兵的作用：\r\n\r\n- 监控：监控master和slave\r\n\r\n  不断的检查master和slave是否正常运行\r\n\r\n  master存活检测、master与slave运行情况检测\r\n\r\n\r\n- 通知（提醒）：当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知\r\n\r\n\r\n- 自动故障转移：断开master与slave连接，选取一个slave作为master，将其他slave连接新的master，并告知客户端新的服务器地址\r\n\r\n注意：哨兵也是一台redis服务器，只是不提供数据相关服务，通常哨兵的数量配置为单数\r\n\r\n### 3.2 启用哨兵\r\n\r\n配置哨兵\r\n\r\n- 配置一拖二的主从结构（利用之前的方式启动即可）\r\n\r\n- 配置三个哨兵（配置相同，端口不同），参看sentinel.conf\r\n\r\n1：设置哨兵监听的主服务器信息， sentinel_number表示参与投票的哨兵数量\r\n\r\n```properties\r\nsentinel monitor master_name  master_host\tmaster_port\t sentinel_number\r\n```\r\n\r\n2：设置判定服务器宕机时长，该设置控制是否进行主从切换\r\n\r\n```properties\r\nsentinel down-after-milliseconds master_name\tmillion_seconds\r\n```\r\n\r\n3：设置故障切换的最大超时时\r\n\r\n```properties\r\nsentinel failover-timeout master_name\tmillion_seconds\r\n```\r\n\r\n4：设置主从切换后，同时进行数据同步的slave数量，数值越大，要求网络资源越高，数值越小，同步时间越长\r\n\r\n```properties\r\nsentinel parallel-syncs master_name sync_slave_number\r\n```\r\n\r\n\r\n- 启动哨兵\r\n\r\n```properties\r\nredis-sentinel filename\r\n```\r\n\r\n### 3.3 哨兵工作原理\r\n\r\n哨兵在进行主从切换过程中经历三个阶段\r\n\r\n- 监控\r\n- 通知\r\n- 故障转移\r\n\r\n#### 3.3.1 监控\r\n\r\n用于同步各个节点的状态信息\r\n\r\n![](Redis高级.assets/19.png)\r\n\r\n- 获取各个sentinel的状态（是否在线）\r\n\r\n\r\n- 获取master的状态\r\n\r\n```markdown\r\nmaster属性\tprunid\tprole：master各个slave的详细信息\t\r\n```\r\n\r\n- 获取所有slave的状态（根据master中的slave信息）\r\n\r\n```markdown\r\nslave属性\tprunid\tprole：slave\tpmaster_host、master_port\tpoffset\r\n```\r\n\r\n其内部的工作原理具体如下：\r\n\r\n![](Redis高级.assets/20.png)\r\n\r\n\r\n\r\n#### 3.3.2 通知\r\n\r\nsentinel在通知阶段要不断的去获取master/slave的信息，然后在各个sentinel之间进行共享，具体的流程如下：\r\n\r\n![](Redis高级.assets/21.png)\r\n\r\n#### 3.3.3 故障转移\r\n\r\n当master宕机后sentinel是如何知晓并判断出master是真的宕机了呢？我们来看具体的操作流程\r\n\r\n![](Redis高级.assets/22.png)\r\n\r\n当sentinel认定master下线之后，此时需要决定更换master，那这件事由哪个sentinel来做呢？这时候sentinel之间要进行选举，如下图所示：\r\n\r\n![](Redis高级.assets/23.png)\r\n\r\n在选举的时候每一个人手里都有一票，而每一个人的又都想当这个处理事故的人，那怎么办？大家就开始抢，于是每个人都会发出一个指令，在内网里边告诉大家我要当选举人，比如说现在的sentinel1和sentinel4发出这个选举指令了，那么sentinel2既能接到sentinel1的也能接到sentinel4的，接到了他们的申请以后呢，sentinel2他就会把他的一票投给其中一方，投给谁呢？谁先过来我投给谁，假设sentinel1先过来，所以这个票就给到了sentinel1。那么给过去以后呢，现在sentinel1就拿到了一票，按照这样的一种形式，最终会有一个选举结果。对应的选举最终得票多的，那自然就成为了处理事故的人。需要注意在这个过程中有可能会存在失败的现象，就是一轮选举完没有选取，那就会接着进行第二轮第三轮直到完成选举。\r\n\r\n接下来就是由选举胜出的sentinel去从slave中选一个新的master出来的工作，这个流程是什么样的呢？\r\n\r\n首先它有一个在服务器列表中挑选备选master的原则\r\n\r\n- 不在线的OUT\r\n\r\n\r\n- 响应慢的OUT\r\n\r\n\r\n- 与原master断开时间久的OUT\r\n\r\n\r\n- 优先原则\r\n\r\n  ​\t优先级\r\n  ​\t\toffset\r\n  ​\t\trunid\r\n\r\n选出新的master之后，发送指令（ sentinel ）给其他的slave：\r\n\r\n- 向新的master发送slaveof no one\r\n\r\n\r\n- 向其他slave发送slaveof 新masterIP端口\r\n\r\n\r\n\r\n**总结**：故障转移阶段\r\n\r\n1. 发现问题，主观下线与客观下线\r\n2. 竞选负责人\r\n3. 优选新master\r\n4. 新master上任，其他slave切换master，原master作为slave故障恢复后连接\r\n\r\n## 4.集群cluster\r\n\r\n现状问题：业务发展过程中遇到的峰值瓶颈\r\n\r\n- redis提供的服务OPS可以达到10万/秒，当前业务OPS已经达到10万/秒\r\n- 内存单机容量达到256G，当前业务需求内存容量1T\r\n- 使用集群的方式可以快速解决上述问题\r\n\r\n### 4.1 集群简介\r\n\r\n集群就是使用网络将若干台计算机联通起来，并提供统一的管理方式，使其对外呈现单机的服务效果\r\n\r\n![](Redis高级.assets/24.png)\r\n\r\n**集群作用：**\r\n\r\n- 分散单台服务器的访问压力，实现负载均衡\r\n- 分散单台服务器的存储压力，实现可扩展性\r\n- 降低单台服务器宕机带来的业务灾难\r\n\r\n![](Redis高级.assets/25.png)\r\n\r\n\r\n\r\n### 4.2 Cluster集群结构设计\r\n\r\n**数据存储设计：**\r\n\r\n1. 通过算法设计，计算出key应该保存的位置\r\n\r\n2. 将所有的存储空间计划切割成16384份，每台主机保存一部分\r\n\r\n   注意：每份代表的是一个存储空间，不是一个key的保存空间\r\n\r\n3. 将key按照计算出的结果放到对应的存储空间\r\n\r\n![](Redis高级.assets/26.png)\r\n\r\n那redis的集群是如何增强可扩展性的呢？譬如我们要增加一个集群节点\r\n\r\n![](Redis高级.assets/27.png)\r\n\r\n当我们查找数据时，集群是如何操作的呢？\r\n\r\n- 各个数据库相互通信，保存各个库中槽的编号数据\r\n- 一次命中，直接返回\r\n- 一次未命中，告知具体位置\r\n\r\n![](Redis高级.assets/28.png)\r\n\r\n### 4.3 Cluster集群结构搭建\r\n\r\n首先要明确的几个要点：\r\n\r\n- 配置服务器（3主3从）\r\n- 建立通信（Meet）\r\n- 分槽（Slot）\r\n- 搭建主从（master-slave）\r\n\r\n**Cluster配置**\r\n\r\n- 是否启用cluster，加入cluster节点\r\n\r\n```properties\r\ncluster-enabled yes|no\r\n```\r\n\r\n- cluster配置文件名，该文件属于自动生成，仅用于快速查找文件并查询文件内容\r\n\r\n```properties\r\ncluster-config-file filename\r\n```\r\n\r\n- 节点服务响应超时时间，用于判定该节点是否下线或切换为从节点\r\n\r\n```properties\r\ncluster-node-timeout milliseconds\r\n```\r\n\r\n- master连接的slave最小数量\r\n\r\n```properties\r\ncluster-migration-barrier min_slave_number\r\n```\r\n\r\n**Cluster节点操作命令**\r\n\r\n-  查看集群节点信息\r\n\r\n```properties\r\ncluster nodes\r\n```\r\n\r\n- 更改slave指向新的master\r\n\r\n```properties\r\ncluster replicate master-id\r\n```\r\n\r\n- 发现一个新节点，新增master\r\n\r\n```properties\r\ncluster meet ip:port\r\n```\r\n\r\n- 忽略一个没有solt的节点\r\n\r\n```properties\r\ncluster forget server_id\r\n```\r\n\r\n- 手动故障转移\r\n\r\n```properties\r\ncluster failover\r\n```\r\n\r\n**集群操作命令：**\r\n\r\n- 创建集群\r\n\r\n```properties\r\nredis-cli –-cluster create masterhost1:masterport1 masterhost2:masterport2  masterhost3:masterport3 [masterhostn:masterportn …] slavehost1:slaveport1  slavehost2:slaveport2 slavehost3:slaveport3 -–cluster-replicas n\r\n```\r\n\r\n注意：master与slave的数量要匹配，一个master对应n个slave，由最后的参数n决定\r\n\r\nmaster与slave的匹配顺序为第一个master与前n个slave分为一组，形成主从结构\r\n\r\n\r\n\r\n- 添加master到当前集群中，连接时可以指定任意现有节点地址与端口\r\n\r\n```properties\r\nredis-cli --cluster add-node new-master-host:new-master-port now-host:now-port\r\n```\r\n\r\n- 添加slave\r\n\r\n```properties\r\nredis-cli --cluster add-node new-slave-host:new-slave-port master-host:master-port --cluster-slave --cluster-master-id masterid\r\n```\r\n\r\n- 删除节点，如果删除的节点是master，必须保障其中没有槽slot\r\n\r\n```properties\r\nredis-cli --cluster del-node del-slave-host:del-slave-port del-slave-id\r\n```\r\n\r\n- 重新分槽，分槽是从具有槽的master中划分一部分给其他master，过程中不创建新的槽\r\n\r\n```properties\r\nredis-cli --cluster reshard new-master-host:new-master:port --cluster-from src-  master-id1, src-master-id2, src-master-idn --cluster-to target-master-id --  cluster-slots slots\r\n```\r\n\r\n注意：将需要参与分槽的所有masterid不分先后顺序添加到参数中，使用，分隔\r\n\r\n指定目标得到的槽的数量，所有的槽将平均从每个来源的master处获取\r\n\r\n- 重新分配槽，从具有槽的master中分配指定数量的槽到另一个master中，常用于清空指定master中的槽\r\n\r\n```properties\r\nredis-cli --cluster reshard src-master-host:src-master-port --cluster-from src-  master-id --cluster-to target-master-id --cluster-slots slots --cluster-yes\r\n```\r\n\r\n## 5.企业级解决方案\r\n\r\n### 5.1 缓存预热\r\n\r\n**场景**：“宕机”\r\n\r\n服务器启动后迅速宕机\r\n\r\n**问题排查**：\r\n\r\n1.请求数量较高，大量的请求过来之后都需要去从缓存中获取数据，但是缓存中又没有，此时从数据库中查找数据然后将数据再存入缓存，造成了短期内对redis的高强度操作从而导致问题\r\n\r\n2.主从之间数据吞吐量较大，数据同步操作频度较高\r\n\r\n**解决方案：**\r\n\r\n- 前置准备工作：\r\n\r\n1.日常例行统计数据访问记录，统计访问频度较高的热点数据\r\n\r\n2.利用LRU数据删除策略，构建数据留存队列例如：storm与kafka配合\r\n\r\n- 准备工作：\r\n\r\n1.将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据\r\n\r\n2.利用分布式多服务器同时进行数据读取，提速数据加载过程\r\n\r\n3.热点数据主从同时预热\r\n\r\n- 实施：\r\n\r\n4.使用脚本程序固定触发数据预热过程\r\n\r\n5.如果条件允许，使用了CDN（内容分发网络），效果会更好\r\n\r\n\r\n\r\n**总的来说**：缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！\r\n\r\n### 5.2 缓存雪崩\r\n\r\n**场景**：数据库服务器崩溃，一连串的场景会随之儿来\r\n\r\n1.系统平稳运行过程中，忽然数据库连接量激增\r\n\r\n2.应用服务器无法及时处理请求\r\n\r\n3.大量408，500错误页面出现\r\n\r\n4.客户反复刷新页面获取数据\r\n\r\n5.数据库崩溃\r\n\r\n6.应用服务器崩溃\r\n\r\n7.重启应用服务器无效\r\n\r\n8.Redis服务器崩溃\r\n\r\n9.Redis集群崩溃\r\n\r\n10.重启数据库后再次被瞬间流量放倒\r\n\r\n\r\n\r\n**问题排查**：\r\n\r\n1.在一个较短的时间内，缓存中较多的key集中过期\r\n\r\n2.此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据\r\n\r\n3.数据库同时接收到大量的请求无法及时处理\r\n\r\n4.Redis大量请求被积压，开始出现超时现象\r\n\r\n5.数据库流量激增，数据库崩溃\r\n\r\n6.重启后仍然面对缓存中无数据可用\r\n\r\n7.Redis服务器资源被严重占用，Redis服务器崩溃\r\n\r\n8.Redis集群呈现崩塌，集群瓦解\r\n\r\n9.应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃\r\n\r\n10.应用服务器，redis，数据库全部重启，效果不理想\r\n\r\n\r\n\r\n总而言之就两点：短时间范围内，大量key集中过期\r\n\r\n\r\n\r\n**解决方案**\r\n\r\n- 思路：\r\n\r\n1.更多的页面静态化处理\r\n\r\n2.构建多级缓存架构\r\n\r\n​\tNginx缓存+redis缓存+ehcache缓存\r\n\r\n3.检测Mysql严重耗时业务进行优化\r\n\r\n​\t对数据库的瓶颈排查：例如超时查询、耗时较高事务等\r\n\r\n4.灾难预警机制\r\n\r\n​\t监控redis服务器性能指标\r\n\r\n​\t\tCPU占用、CPU使用率\r\n\r\n​\t\t内存容量\r\n\r\n​\t\t查询平均响应时间\r\n\r\n​\t\t线程数\r\n\r\n5.限流、降级\r\n\r\n短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问\r\n\r\n- 落地实践：\r\n\r\n1.LRU与LFU切换\r\n\r\n2.数据有效期策略调整\r\n\r\n​\t根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟\r\n\r\n​\t过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量\r\n\r\n3.超热数据使用永久key\r\n\r\n4.定期维护（自动+人工）\r\n\r\n​\t对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时\r\n\r\n5.加锁：慎用！\r\n\r\n\r\n\r\n**总的来说**：缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力。如能够有效避免过期时间集中，可以有效解决雪崩现象的 出现（约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。\r\n\r\n### 5.3 缓存击穿\r\n\r\n**场景**：还是数据库服务器崩溃，但是跟之前的场景有点不太一样\r\n\r\n1.系统平稳运行过程中\r\n\r\n2.数据库连接量瞬间激增\r\n\r\n3.Redis服务器无大量key过期\r\n\r\n4.Redis内存平稳，无波动\r\n\r\n5.Redis服务器CPU正常\r\n\r\n6.数据库崩溃\r\n\r\n**问题排查：**\r\n\r\n1.Redis中某个key过期，该key访问量巨大\r\n\r\n2.多个数据请求从服务器直接压到Redis后，均未命中\r\n\r\n3.Redis在短时间内发起了大量对数据库中同一数据的访问\r\n\r\n\r\n\r\n总而言之就两点：单个key高热数据，key过期\r\n\r\n\r\n\r\n**解决方案**：\r\n\r\n1.预先设定\r\n\r\n​\t以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长 注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势\r\n\r\n2.现场调整\r\n\r\n​\t监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key\r\n\r\n3.后台刷新数据\r\n\r\n​\t启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失\r\n\r\n4.二级缓存\r\n\r\n​\t设置不同的失效时间，保障不会被同时淘汰就行\r\n\r\n5.加锁\r\n\r\n​\t分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！\r\n\r\n\r\n\r\n**总的来说**：缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中redis后，发起了大量对同一数据的数据库访问，导致对数 据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过 期监控难度较高，配合雪崩处理策略即可。\r\n\r\n### 5.4 缓存穿透\r\n\r\n**场景**：数据库服务器又崩溃了，跟之前的一样吗？\r\n\r\n1.系统平稳运行过程中\r\n\r\n2.应用服务器流量随时间增量较大\r\n\r\n3.Redis服务器命中率随时间逐步降低\r\n\r\n4.Redis内存平稳，内存无压力\r\n\r\n5.Redis服务器CPU占用激增\r\n\r\n6.数据库服务器压力激增\r\n\r\n7.数据库崩溃\r\n\r\n\r\n\r\n**问题排查：**\r\n\r\n1.Redis中大面积出现未命中\r\n\r\n2.出现非正常URL访问\r\n\r\n\r\n\r\n**问题分析**：\r\n\r\n- 获取的数据在数据库中也不存在，数据库查询未得到对应数据\r\n- Redis获取到null数据未进行持久化，直接返回\r\n- 下次此类数据到达重复上述过程\r\n- 出现黑客攻击服务器\r\n\r\n**解决方案**：\r\n\r\n1.缓存null\r\n\r\n​\t对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟\r\n\r\n2.白名单策略\r\n\r\n​\t提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时放行，加载异常数据时直接拦截（效率偏低）\r\n\r\n​\t使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略）\r\n\r\n2.实施监控\r\n\r\n​\t实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比\r\n\r\n​\t\t非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象\r\n\r\n​\t\t活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象\r\n\r\n​\t根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）\r\n\r\n4.key加密\r\n\r\n​\t问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验\r\n\r\n​\t例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问\r\n\r\n\r\n\r\n**总的来说**：缓存击穿是指访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。\r\n\r\n无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。\r\n\r\n### 5.5 性能指标监控\r\n\r\nredis中的监控指标如下：\r\n\r\n- 性能指标：Performance\r\n\r\n>响应请求的平均时间:\r\n>\r\n>```properties\r\n>latency\r\n>```\r\n>\r\n>平均每秒处理请求总数\r\n>\r\n>```properties\r\n>instantaneous_ops_per_sec\r\n>```\r\n>\r\n>缓存查询命中率（通过查询总次数与查询得到非nil数据总次数计算而来）\r\n>\r\n>```properties\r\n>hit_rate(calculated)\r\n>```\r\n\r\n- 内存指标：Memory\r\n\r\n>当前内存使用量\r\n>\r\n>```properties\r\n>used_memory\r\n>```\r\n>\r\n>内存碎片率（关系到是否进行碎片整理）\r\n>\r\n>```properties\r\n>mem_fragmentation_ratio\r\n>```\r\n>\r\n>为避免内存溢出删除的key的总数量\r\n>\r\n>```properties\r\n>evicted_keys\r\n>```\r\n>\r\n>基于阻塞操作（BLPOP等）影响的客户端数量\r\n>\r\n>```properties\r\n>blocked_clients\r\n>```\r\n\r\n- 基本活动指标：Basic_activity\r\n\r\n>当前客户端连接总数\r\n>\r\n>```properties\r\n>connected_clients\r\n>```\r\n>\r\n>当前连接slave总数\r\n>\r\n>```properties\r\n>connected_slaves\r\n>```\r\n>\r\n>最后一次主从信息交换距现在的秒\r\n>\r\n>```properties\r\n>master_last_io_seconds_ago\r\n>```\r\n>\r\n>key的总数\r\n>\r\n>```properties\r\n>keyspace\r\n>```\r\n\r\n- 持久性指标：Persistence\r\n\r\n>当前服务器最后一次RDB持久化的时间\r\n>\r\n>```properties\r\n>rdb_last_save_time\r\n>```\r\n>\r\n>当前服务器最后一次RDB持久化后数据变化总量\r\n>\r\n>```properties\r\n>rdb_changes_since_last_save\r\n>```\r\n\r\n\r\n\r\n- 错误指标：Error\r\n\r\n>被拒绝连接的客户端总数（基于达到最大连接值的因素）\r\n>\r\n>```properties\r\n>rejected_connections\r\n>```\r\n>\r\n>key未命中的总次数\r\n>\r\n>```properties\r\n>keyspace_misses\r\n>```\r\n>\r\n>主从断开的秒数\r\n>\r\n>```properties\r\n>master_link_down_since_seconds\r\n>```\r\n\r\n\r\n\r\n\r\n\r\n要对redis的相关指标进行监控，我们可以采用一些用具：\r\n\r\n- CloudInsight Redis\r\n- Prometheus\r\n- Redis-stat\r\n- Redis-faina\r\n- RedisLive\r\n- zabbix\r\n\r\n也有一些命令工具：\r\n\r\n- benchmark\r\n\r\n>测试当前服务器的并发性能\r\n>\r\n>```properties\r\n>redis-benchmark [-h ] [-p ] [-c ] [-n <requests]> [-k ]\r\n>```\r\n>\r\n>范例1：50个连接，10000次请求对应的性能\r\n>\r\n>```properties\r\n>redis-benchmark\r\n>```\r\n>\r\n>范例2：100个连接，5000次请求对应的性能\r\n>\r\n>```properties\r\n>redis-benchmark -c 100 -n 5000\r\n>```\r\n>\r\n>![](Redis高级.assets/29.png)\r\n\r\n- redis-cli\r\n\r\n  ​\tmonitor：启动服务器调试信息\r\n\r\n>```properties\r\n>monitor\r\n>```\r\n\r\n  \tslowlog：慢日志\r\n\r\n>获取慢查询日志\r\n>\r\n>```properties\r\n>slowlog [operator]\r\n>```\r\n>\r\n>​\tget ：获取慢查询日志信息\r\n>\r\n>​\tlen ：获取慢查询日志条目数\r\n>\r\n>​\treset ：重置慢查询日志\r\n>\r\n>相关配置\r\n>\r\n>```properties\r\n>slowlog-log-slower-than 1000 #设置慢查询的时间下线，单位：微妙slowlog-max-len 100\t#设置慢查询命令对应的日志显示长度，单位：命令数\r\n>```\r\n\r\n"}}]);